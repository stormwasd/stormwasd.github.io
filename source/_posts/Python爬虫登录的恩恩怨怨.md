---
title: Python爬虫登录的恩恩怨怨
date: 2022-1-14 10:58:30
---

曾几何时，登录是一件很简单的事情，一个账户及其密码，POST给服务器，服务器验证通过即可。那是一个美好的朴素年代，服务器不设防，用户不贪婪。然而，时过境迁，人心变了。越来越多的人想要收集数据，爬虫也就越来越多；而网站就有了网络请求压力，也有了死守数据私心。天下熙熙，皆为利来；天下攘攘，皆为利往。现在的互联网，就成了一个利字当头、魔高一尺道高一丈的战场

如今，各种网站都设置了复杂的登录这堵高高的墙来阻止爬虫大量甚至全部获取网站的数据。比如，12306的验证码是点选图片，微博是变形的字母验证码，知乎是点选倒立的汉字，哔哩哔哩通过拖动滑块拼图来验证。这些*变态的验证*过程都是加入人的交互来防止爬虫自动登录，从而阻止爬虫自动化的大批量抓取

小猿们都已经知道，HTTP协议是无状态的，用户登录的状态靠cookies在浏览器和服务器之间来回传送来记录。完成登录后，cookies在一定时间范围内是保持不变的，直接获得这个cookies给爬虫用，就可以让爬虫有了登录的状态，进而进行后面的抓取，当然，这个抓取只能持续到cookies过期之前

在这里我们来看看爬虫登录的三种层次，完成登录这个过程，最好是程序自动化实现，那么你写好程序就可以一边玩去了，然而好多时候，事情不是那么让人省心，登录还需要人工参与一下下；总结下来，实现登陆有以下三种层次:

1. 简单的PODT账户密码就可以实现自动化登录
2. 通过程序可以模拟出登录流程实现自动化登录
3. 登录需要人工智能介入，人工智能实现自动化登录

第一个层次，使用requests模块加一两行代码就可以实现，关键是现如今很少有这样的良心网站了

第二个层次，是很有挑战性的，也是爬虫界人士力求达到的层次

第三个层次，就需要接入人工智能，利用人工智能识别验证码

由此看来，登录状态的cookies的获取，主要还是靠模拟登录流程或者人工智能识别验证码为主