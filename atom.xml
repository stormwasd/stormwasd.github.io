<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-05-09T09:30:31.609Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>解决MobaXterm不时地自我断开的问题</title>
    <link href="http://example.com/2022/05/09/%E8%A7%A3%E5%86%B3MobaXterm%E4%B8%8D%E6%97%B6%E5%9C%B0%E8%87%AA%E6%88%91%E6%96%AD%E5%BC%80%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2022/05/09/%E8%A7%A3%E5%86%B3MobaXterm%E4%B8%8D%E6%97%B6%E5%9C%B0%E8%87%AA%E6%88%91%E6%96%AD%E5%BC%80%E7%9A%84%E9%97%AE%E9%A2%98/</id>
    <published>2022-05-09T09:30:30.000Z</published>
    <updated>2022-05-09T09:30:31.609Z</updated>
    
    <content type="html"><![CDATA[<p>参考自:</p><p><a class="link"   href="https://blog.csdn.net/weixin_41106187/article/details/109443373" >https://blog.csdn.net/weixin_41106187/article/details/109443373<i class="fas fa-external-link-alt"></i></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;参考自:&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;link&quot;   href=&quot;https://blog.csdn.net/weixin_41106187/article/details/109443373&quot; &gt;https://blog.csdn.net/weixin_411061</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>hexo博客搭建记录</title>
    <link href="http://example.com/2022/05/09/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"/>
    <id>http://example.com/2022/05/09/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/</id>
    <published>2022-05-09T07:17:03.000Z</published>
    <updated>2022-05-09T07:19:19.315Z</updated>
    
    <content type="html"><![CDATA[<p>以下记录下我用hexo搭建博客的一些细节：</p><h3 id="第一部分"><a href="#第一部分" class="headerlink" title="第一部分"></a>第一部分</h3><p>首先要准备nodejs和git</p><p>nodejs下载官网：<a class="link"   href="https://nodejs.org/zh-cn/" >https://nodejs.org/zh-cn/<i class="fas fa-external-link-alt"></i></a></p><p>由于稷生的电脑是win7的所以不能安装高版本的node，高版本的node都要求是在win8以上，然后我们可以首先点击下载然后点击以往的版本：</p><p><a href="https://imgtu.com/i/T1rhrT"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/22/T1rhrT.png"                      alt="T1rhrT.png"                ></a></p><p>然后就是无脑下一步安装即可</p><p>安装完后打开命令行，安装的时候会默认把node加入环境变量，用以下命令验证node是否安装成功以及node的包管理工具是否安装成功：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure><p>然后就是安装git，这里也给出git的下载网站：<a class="link"   href="https://git-scm.com/" >https://git-scm.com/<i class="fas fa-external-link-alt"></i></a></p><p>这个安装后会生成gitbash，不过我们用gitbash而不用win自带的出cmd也是可以的，看个人喜好</p><p>同样是无脑下一步即可</p><p>然后我们接下来安装hexo</p><p>我们可以先建一个文件夹Blog,然后cd到这个文件夹下，或者在这个文件夹下直接右键git bash打开</p><p>键入命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure><p>依旧使用hexo -v查看一下hexo的版本</p><p>然后我们来初始化一下hexo,这个myblog是自己取名字的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init myblog</span><br></pre></td></tr></table></figure><p>然后进入这个文件夹，再往里面放一些东西</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd myblog</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure><p>新建完成之后，刚刚的myblog文件夹目录下有：</p><p>node_modules:依赖包</p><p>scaffolds:存放生成的页面</p><p>surce:用来存放你的文章</p><p>themes:主题</p><p>_config.yml:博客的配置文件</p><p>然后输入以下两条命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure><p>这样就打开了hexo的服务，在浏览器输入localhost:4000就可以看到生成的博客了</p><p>大概长这样：</p><p><a href="https://imgtu.com/i/T16tPJ"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/22/T16tPJ.png"                      alt="T16tPJ.png"                ></a></p><p>可以使用ctrl+c把服务关闭</p><p>然后在github上创建一个特定的仓库，创建一个和你用户名相同的仓库，后面加上github.io，只有这样，将来要部署到github page的时候才会被识别，也就是xxxxx.github.io,其中xxx就是你注册github的用户名，如下图所示：</p><p><a href="https://imgtu.com/i/T16RxI"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/22/T16RxI.png"                      alt="T16RxI.png"                ></a><br>然后就是生成ssh添加到github，这一部分可以见其他笔记</p><p>下面就是将hexo部署到github</p><p>这一步，我们将可以将hexo和github关联起来，也就是将hexo生成的文章部署到git湖北上，进入到刚刚的myblog文件中，打开配置文件_config.yml,滑到最后，修改为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  repo: https://github.com/YourgithubName/YourgithubName.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure><p>这边建议使用ssh的克隆方式，毕竟刚刚设置或ssh，不能白设置啊</p><p>这个时候我们就要部署了，在此之前还要安装一个部署的工具deploy-git,用以下命令安装：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><p>然后依次键入以下三个命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br></pre></td></tr></table></figure><p>其中hexo clean清除了你之前生成的东西，也可以不加</p><p>hexo generate顾名思义，生成静态文章，也可以使用hexo g缩写</p><p>hexo deploy部署文章，可以用hexo d缩写</p><p>得到下图就说明部署成功了，应该过个十几秒就可以在<code>http://youname.github.io</code>这个网站看到你的博客了:</p><p><a href="https://imgtu.com/i/T1gC0f"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/22/T1gC0f.png"                      alt="T1gC0f.png"                ></a></p><p>你现在的个人网站的网址是yourname.github.io,如果觉得这个网址逼格不太够，这就需要你设置个人域名了，在阿里云上购买一个域名，我买的是kest.club，每个后缀的价格不太一样，比如最广泛的.com就比较贵，看钱包咯。</p><p>你需要先进去进行实名认证，然后在域名控制台中，看到你购买的域名，点进去，添加解析或者解析设置：</p><p><a href="https://imgtu.com/i/T3OkB8"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/23/T3OkB8.png"                      alt="T3OkB8.png"                ></a></p><p>然后就进入以下页面，这边我是设置好的，来看看我怎么设置的：</p><p><a href="https://imgtu.com/i/T3O3HU"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/23/T3O3HU.png"                      alt="T3O3HU.png"                ></a></p><p>上图中的192.30.252.153和192.30.252.154是github的服务器地址，注意，这时的解析路线选择默认，像我这么设置即可。</p><p>然后进入github中刚刚创建的仓库，点击settings，下滑，来到GitHub Pages，点击Check it out here：</p><p><a href="https://imgtu.com/i/T3ObCj"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/23/T3ObCj.png"                      alt="T3ObCj.png"                ></a></p><p>跳转后输入购买的域名即可：</p><p><a href="https://imgtu.com/i/T3XSVU"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/23/T3XSVU.png"                      alt="T3XSVU.png"                ></a></p><p>这个时候应该过个几十秒就能用购买的域名访问你创建的博客站点了：<br><a href="https://imgtu.com/i/T3XF2R"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/23/T3XF2R.png"                      alt="T3XF2R.png"                ></a></p><h3 id="第二部分"><a href="#第二部分" class="headerlink" title="第二部分"></a>第二部分</h3><p>hexo的基本配置，更换主题，实现多终端工作，以及在config page部署实现国内外分流</p><ol><li><p>hexo的基本配置</p><p>在文件根目录下的_config.yml，就是整个hexo框架的配置文件了，可以在里面修改大部分的配置，详细可参考官方的配置描述：<a class="link"   href="https://hexo.io/zh-cn/docs/configuration" >https://hexo.io/zh-cn/docs/configuration<i class="fas fa-external-link-alt"></i></a></p><p>对网站的配置：</p><p><a href="https://imgtu.com/i/T3Xosx"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/23/T3Xosx.png"                      alt="T3Xosx.png"                ></a></p><p>这里附上hexo一些比较常用的命令：<a class="link"   href="https://hexo.io/zh-cn/docs/commands.html" >https://hexo.io/zh-cn/docs/commands.html<i class="fas fa-external-link-alt"></i></a></p><p>对网址的修改：</p><p><a href="https://imgtu.com/i/T3xuIU"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/23/T3xuIU.png"                      alt="T3xuIU.png"                ></a></p><p>在往下翻，中间这些都默认就好了，然后我们来看下theme和deploy：<br><a href="https://imgtu.com/i/T3zSyR"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/23/T3zSyR.png"                      alt="T3zSyR.png"                ></a></p><p>theme就是选择什么主题，也就是在theme这个文件夹下，在官网上有很多个主题，默认给你安装的是landscape这个主题，当你需要更换主题时，在官网上下载，把主题的文件放在theme文件夹下，再修改这个参数即可。</p><p>接下来deploy就是网站的部署的，reop就是仓库(repository)的缩写，branch选择仓库的哪个分支，在这个进行github page部署的时候已经修改过了，不再赘述，而这个在后面进行双平台部署的时候会再次用到。</p><p>对Front-matter的修改：</p><p>Front-matter是文件最上方以—分隔的区域，用于指定个别文件的变量，举例来说：</p><p>layout(布局):<br>当你每一次使用代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new paper</span><br></pre></td></tr></table></figure><p>它其实默认使用的是post这个布局，也就是在source文件夹下的_posts里面。</p><p>hexo有三种默认布局:post,page和draft，他们分别对应不同的路径，而自定义的其他布局和post相同，豆浆存储到source/_posts文件夹:</p><p><a href="https://imgtu.com/i/T89KmR"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/23/T89KmR.png"                      alt="T89KmR.png"                ></a></p><p>而new这个命令其实是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new [layout] &lt;title&gt;</span><br></pre></td></tr></table></figure><p>只不过这个layout默认是post罢了</p><p>page：</p><p>如果你想另起一页，可以用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new page board</span><br></pre></td></tr></table></figure><p>系统会自动给你在source文件夹创建一个board文件夹，以及board文件夹中的index.md，这样你访问的board对应的链接就是<a class="link"   href="http://xxx.xxx/board/" >http://xxx.xxx/board/<i class="fas fa-external-link-alt"></i></a></p><p>draft:</p><p>draft就是草稿的意思，也就是你如果想写文章，又不想被看到，那么可以</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new draft newpage</span><br></pre></td></tr></table></figure><p>这样会在source/_draft中新建一个newpage.md文件，如果你的草稿文件写的过程中，想要预览一下，那么可以使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo server --draft</span><br></pre></td></tr></table></figure><p>在本地端口中开启服务预览</p><p>如果你的草稿文件写完了，想要发表到post中，可以使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo publish draft newpage</span><br></pre></td></tr></table></figure><p>就会自动把newpage.md发送到_posts中</p><ol start="2"><li><p>更换主题</p><p>如果你觉得默认的landscape主题不好看，那么可以在官网的主题中，选择你喜欢的一个主题进行修改就可以啦，点击：<a class="link"   href="https://hexo.io/themes/" >https://hexo.io/themes/<i class="fas fa-external-link-alt"></i></a></p><p>我这里选择的是keep风格的主题，感觉比较简约</p><p>这里给出keep的git地址：<a class="link"   href="https://github.com/XPoet/hexo-theme-keep%EF%BC%8C%E9%87%8C%E9%9D%A2%E4%B9%9F%E6%9C%89%E8%AF%A6%E7%BB%86%E7%9A%84%E9%85%8D%E7%BD%AE%E6%AD%A5%E9%AA%A4" >https://github.com/XPoet/hexo-theme-keep，里面也有详细的配置步骤<i class="fas fa-external-link-alt"></i></a></p></li><li><p>git分支进行多终端工作</p><p>在这个电脑上我们写了博客，但是如果我们换了一台电脑继续写如何实现呢，这里我们就要搞清hexo的一个工作机制，由于hexo d上传部署到github的其实是hexo编译后的文件，是用来生成网页的，不包含源文件：</p><p><a href="https://imgtu.com/i/TYQVtf"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/24/TYQVtf.png"                      alt="TYQVtf.png"                ></a></p><p>也就是上传的是本地目录里自动生成的.deploy_git</p><p>其他文件，都没有上传到github</p><p>所以我们可以利用git的分支管理，将源文件上传到github的另一个分支即可</p><p>下面我们来看看如何上传分支：</p><p>首先，先在github上新建一个分支，如图：</p><p><a href="https://imgtu.com/i/TYlmUx"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/24/TYlmUx.png"                      alt="TYlmUx.png"                ></a></p><p>创建好hexo分支后，就把除了.deploy_git的其他文件都上传到hexo分支</p><p>或者说我们直接新建一个仓库，然后把除了.deploy_git的其他文件都上传到这个仓库</p><p>我感觉最好还是直接新建一个仓库，因为如果两个分支，上传代码或者拉取代码的时候就要切换分支比较麻烦，一个仓库就放网页所需要的资源文件，另一个仓库就用于我们切换终端，切换工作场景，而不用管分支的问题(可能hexo默认就部署在master分支上，这样就能解释得通了)</p><p>我在下午试了一下，果然，我的github仓库默认的分支是hexo，但用hexo g生成静态文件然后用hexo d这个部署命令后显示还是上传到主分支(master):<br><a href="https://imgtu.com/i/TYvxI0"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s4.ax1x.com/2021/12/24/TYvxI0.png"                      alt="TYvxI0.png"                ></a></p><p>但是有些文件是不需要上传的，我们可以写一个.gitignore</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.DS_Store</span><br><span class="line">Thumbs.db</span><br><span class="line">db.json</span><br><span class="line">*.log</span><br><span class="line">node_modules/</span><br><span class="line">public/</span><br><span class="line">.deploy*/</span><br></pre></td></tr></table></figure><p>打开git bush 然后键入touch .gitignore即可，若想了解更多，访问：<a class="link"   href="https://jingyan.baidu.com/article/c85b7a64bb7979003aac955a.html" >https://jingyan.baidu.com/article/c85b7a64bb7979003aac955a.html<i class="fas fa-external-link-alt"></i></a></p><p>创建好gitignore后，在任意一个空白文件夹右键gitbush，然后git clone 刚刚创建的仓库(最好是新建一个仓库)：</p><p>这里写一个栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone git@github.com:ZJUFangzh/ZJUFangzh.github.io.git</span><br></pre></td></tr></table></figure><p>然后把我们网站文件中除了.deploy_git的所有文件都放在刚刚的空白文件中，这里需要注意的是，如果这些文件中有.git文件，需要把它删除，因为git不能嵌套上传，最好给文件设置显示隐藏文件，检查一下有没有，否则上传的时候会出错，特别是主题文件中检查一下，出错了就会导致主题文件上传失败，这样的配置在别的电脑就无法使用了</p><p>然后就是把刚刚复制到新文件夹的文件上传到仓库：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit –m <span class="string">&quot;add branch&quot;</span></span><br><span class="line">git push </span><br></pre></td></tr></table></figure><p>这样就上传完了，可以去你的github看看hexo分支有没有上传上去，其中node_modules，public，db,json已经被忽略掉了，没有关系，不需要上传的，后面我们如果在其他电脑上工作会用命令重新生成</p><p>更换电脑工作：</p><ol><li><p>安装git</p><p>前面介绍过，下载安装一直下一步即可</p></li><li><p>设置git全局邮箱和用户名</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --<span class="keyword">global</span> user.name <span class="string">&quot;yourgithubname&quot;</span></span><br><span class="line">git config --<span class="keyword">global</span> user.email <span class="string">&quot;yourgithubemail&quot;</span></span><br></pre></td></tr></table></figure></li><li><p>然后就是生成sshkey然后再填到github上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;youremail&quot;</span></span><br><span class="line"><span class="comment">#生成后填到github和coding上（有coding平台的话）</span></span><br><span class="line"><span class="comment">#验证是否成功</span></span><br><span class="line">ssh -T git@github.com</span><br><span class="line">ssh -T git@git.coding.net <span class="comment">#(有coding平台的话)</span></span><br></pre></td></tr></table></figure></li><li><p>安装nodejs</p><p>前面介绍过，下载安装一直下一步即可，不过要注意版本，高版本的需要win8以上环境</p></li><li><p>安装hexo</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure><p>之后不用初始化，我们直接在任意文件夹下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone git@………………</span><br></pre></td></tr></table></figure><p>然后进入到进入到克隆的文件夹：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nup install</span><br><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><p>生成，部署：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>然后就可以开始写博客了(这个命令会默认以post为layout, 也可以指定)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new newpage</span><br></pre></td></tr></table></figure><p>不要忘了，每次写完最好都把源文件上传一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">&quot;add branch&quot;</span></span><br><span class="line">git push</span><br></pre></td></tr></table></figure><p>如果是已经在编辑过的电脑上，已经有clone文件夹了，那么每次只要和远端同步一下就行了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull</span><br></pre></td></tr></table></figure><p>git pull 命令用于从远程获取代码并合并到本地的版本：<br><a class="link"   href="https://www.runoob.com/git/git-pull.html" >https://www.runoob.com/git/git-pull.html<i class="fas fa-external-link-alt"></i></a></p><p>至此完结</p><p>本文参考自：<a class="link"   href="https://blog.csdn.net/sinat_37781304/article/details/82729029/" >https://blog.csdn.net/sinat_37781304/article/details/82729029/<i class="fas fa-external-link-alt"></i></a></p><p>这里也推荐一些自带评论组件的themes：<a class="link"   href="https://valine.js.org/hexo.html#hexo-theme-zhaoo" >https://valine.js.org/hexo.html#hexo-theme-zhaoo<i class="fas fa-external-link-alt"></i></a></p></li></ol></li></ol></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;以下记录下我用hexo搭建博客的一些细节：&lt;/p&gt;
&lt;h3 id=&quot;第一部分&quot;&gt;&lt;a href=&quot;#第一部分&quot; class=&quot;headerlink&quot; title=&quot;第一部分&quot;&gt;&lt;/a&gt;第一部分&lt;/h3&gt;&lt;p&gt;首先要准备nodejs和git&lt;/p&gt;
&lt;p&gt;nodejs下载官网</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>完美使用MobaxTerm，不再担心SSH总是断开</title>
    <link href="http://example.com/2022/05/09/%E5%AE%8C%E7%BE%8E%E4%BD%BF%E7%94%A8MobaxTerm%EF%BC%8C%E4%B8%8D%E5%86%8D%E6%8B%85%E5%BF%83SSH%E6%80%BB%E6%98%AF%E6%96%AD%E5%BC%80/"/>
    <id>http://example.com/2022/05/09/%E5%AE%8C%E7%BE%8E%E4%BD%BF%E7%94%A8MobaxTerm%EF%BC%8C%E4%B8%8D%E5%86%8D%E6%8B%85%E5%BF%83SSH%E6%80%BB%E6%98%AF%E6%96%AD%E5%BC%80/</id>
    <published>2022-05-09T06:58:30.000Z</published>
    <updated>2022-05-09T07:10:04.616Z</updated>
    
    <content type="html"><![CDATA[<p>这两天在使用MobaxTerm的时候，发现ssh总是会自动断开，后面发现它每隔六分钟就会自动断开:</p><p>就拿http协议的连接来说，一旦建立连接就会从3600秒开始倒数:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/05/09/qGWEB4zCpLDsPSH.png"                      alt="image.png"                ></p><p>这还了得，这就得总是重新连接，然后直到我找到了这篇文章:</p><p>还是大佬的算法牛</p><p><a class="link"   href="https://blog.csdn.net/weixin_39540280/article/details/122163223" >https://blog.csdn.net/weixin_39540280/article/details/122163223<i class="fas fa-external-link-alt"></i></a></p><p>然后输入用户名和软件的版本即可，现在我的版本是最新的22.0:</p><p>运行完之后就会生成一个Custom.mxtpro文件，把它放在MobaxTerm的安装目录下即可:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/05/09/Q93XACIGW268lNz.png"                      alt="image.png"                ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/05/09/43GICbjBHSxiwD5.png"                      alt="image.png"                ></p><p>然后就不会可以去掉3600秒的倒计时勾选了:</p><p>3600这个数字始终不变</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/05/09/SaAvVluNOCqhfY4.png"                      alt="image.png"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这两天在使用MobaxTerm的时候，发现ssh总是会自动断开，后面发现它每隔六分钟就会自动断开:&lt;/p&gt;
&lt;p&gt;就拿http协议的连接来说，一旦建立连接就会从3600秒开始倒数:&lt;/p&gt;
&lt;p&gt;&lt;img  
                     lazyload
  </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Centos8安装MySQL8.0和Redis</title>
    <link href="http://example.com/2022/05/09/Centos8%E5%AE%89%E8%A3%85MySQL8.0%E5%92%8CRedis/"/>
    <id>http://example.com/2022/05/09/Centos8%E5%AE%89%E8%A3%85MySQL8.0%E5%92%8CRedis/</id>
    <published>2022-05-09T06:34:30.000Z</published>
    <updated>2022-05-09T06:38:16.592Z</updated>
    
    <content type="html"><![CDATA[<p>安装MySQL8.0:</p><p><a class="link"   href="https://blog.csdn.net/weixin_46353366/article/details/120188992" >https://blog.csdn.net/weixin_46353366/article/details/120188992<i class="fas fa-external-link-alt"></i></a></p><p>安装Redis5:</p><p><a class="link"   href="https://www.jianshu.com/p/18add77c8038" >https://www.jianshu.com/p/18add77c8038<i class="fas fa-external-link-alt"></i></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;安装MySQL8.0:&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;link&quot;   href=&quot;https://blog.csdn.net/weixin_46353366/article/details/120188992&quot; &gt;https://blog.csdn.net/weixin</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Centos云服务器编译安装Python3.7.6小记</title>
    <link href="http://example.com/2022/05/09/Centos%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85Python3.7.6%E5%B0%8F%E8%AE%B0/"/>
    <id>http://example.com/2022/05/09/Centos%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85Python3.7.6%E5%B0%8F%E8%AE%B0/</id>
    <published>2022-05-08T16:00:45.000Z</published>
    <updated>2022-05-08T16:29:52.577Z</updated>
    
    <content type="html"><![CDATA[<p>这两天在折腾一个Django项目，然后需要Linux的版本是Centos，我想着跟着视频大佬一步步来，就索性也花了几顿饭钱搞了个百度云的Centos的云服务器，然后进去发现这啥也没，Python3也没，然后就只有自力更生了:</p><p>安装Python3.7.6参考自以下文章:</p><p><a class="link"   href="https://blog.csdn.net/ispeasant/article/details/107791316?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165202122216781818787429%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=165202122216781818787429&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-107791316-null-null.142" >https://blog.csdn.net/ispeasant/article/details/107791316?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165202122216781818787429%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=165202122216781818787429&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-107791316-null-null.142<i class="fas fa-external-link-alt"></i></a></p><p>然后在使用<code>yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel libffi-devel gcc make</code>这个命令时候出现了报错，因为我的是Centos8，原来的镜像已经不在centos的官网进行托管了，迁移到了其他网站，然后通过相关资料，用以下文章解决了:</p><p><a class="link"   href="https://blog.csdn.net/weixin_43252521/article/details/124409151" >https://blog.csdn.net/weixin_43252521/article/details/124409151<i class="fas fa-external-link-alt"></i></a></p><p>但这里，Centos8.2安装Python3.7.6完结！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这两天在折腾一个Django项目，然后需要Linux的版本是Centos，我想着跟着视频大佬一步步来，就索性也花了几顿饭钱搞了个百度云的Centos的云服务器，然后进去发现这啥也没，Python3也没，然后就只有自力更生了:&lt;/p&gt;
&lt;p&gt;安装Python3.7.6参考自以</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>VMware创建Centos虚拟机小记</title>
    <link href="http://example.com/2022/05/07/VMware%E5%88%9B%E5%BB%BACentos%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%B0%8F%E8%AE%B0/"/>
    <id>http://example.com/2022/05/07/VMware%E5%88%9B%E5%BB%BACentos%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%B0%8F%E8%AE%B0/</id>
    <published>2022-05-07T09:15:10.000Z</published>
    <updated>2022-05-08T09:28:23.003Z</updated>
    
    <content type="html"><![CDATA[<p>参考文章如下:</p><p><a class="link"   href="https://www.runoob.com/w3cnote/vmware-install-centos7.html" >https://www.runoob.com/w3cnote/vmware-install-centos7.html<i class="fas fa-external-link-alt"></i></a></p><p>上面这篇文章比较全面，但是在配置网络这一部分出了点问题，然后我直接按步骤网下走了</p><p>进入系统之后按下面的文章再配置的网络:</p><p><a class="link"   href="https://blog.csdn.net/jujudeyueyue/article/details/121358663" >https://blog.csdn.net/jujudeyueyue/article/details/121358663<i class="fas fa-external-link-alt"></i></a></p><p>这里附上centos7镜像:</p><p><a class="link"   href="https://www.aliyundrive.com/drive/folder/62778bb537bafc639f3b4e3ea3a58144d1139fe8" >https://www.aliyundrive.com/drive/folder/62778bb537bafc639f3b4e3ea3a58144d1139fe8<i class="fas fa-external-link-alt"></i></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;参考文章如下:&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;link&quot;   href=&quot;https://www.runoob.com/w3cnote/vmware-install-centos7.html&quot; &gt;https://www.runoob.com/w3cnote/vmware</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>快速入门Scrapy</title>
    <link href="http://example.com/2022/04/30/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8scrapy/"/>
    <id>http://example.com/2022/04/30/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8scrapy/</id>
    <published>2022-04-30T06:28:30.000Z</published>
    <updated>2022-04-30T06:28:32.869Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Scrapy架构流程介绍"><a href="#1-Scrapy架构流程介绍" class="headerlink" title="1. Scrapy架构流程介绍"></a>1. Scrapy架构流程介绍</h2><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/aa3757afba708f8e.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/fe25a16f652610d7.png"                                     ></p><p>spiders就是我们自己写的爬虫文件，我们写的爬虫文件只有两个功能，一个是提取数据，另一个就是发送请求(构建请求), 提取数据会提取到两种，一个是item数据，也就是需要保存的数据，就交给item pipeline去存储，如果是url的话，我们把它构建成一个请求，交给调度器，调度器再交给下载器去下载</p><p>下载中间件(Downloader Middlewares)是位于引擎和下载器之间的一个组件，这个组件是可以自己定制的，比如说我们在这边定制一个随机的代理处理，给每个请求拿过来之后加个代理，或者给每个请求拿过来之后加个user-agent，又或者说每个请求过来之后我们使用selenium加phantomjs去下载；这就是下载中间件的一个作用</p><p>爬虫中间件(Spider  Middlewares)是用来爬虫文件和引擎之间的一个交互的，可以处理引擎和爬虫之间的通信，这个用的比较少，大部分都会在spiders中写完</p><h4 id="1-1-Scrapy的运行流程"><a href="#1-1-Scrapy的运行流程" class="headerlink" title="1.1 Scrapy的运行流程"></a>1.1 Scrapy的运行流程</h4><p>我们来梳理一下，首先从我们定义的(自己写的)spiders，spiders会定义一个一开始要爬取的url地址，这里假设我们要爬新浪(新浪里面分了很多种类，但这些种类的内容都由新浪的主url发散出来)，然后spiders构建好请求后就把请求交给引擎，引擎交给调度器，调度器把请求入队列之后然后就把请求出队列(这个时候只有一个请求)，然后请求就到了下载器去下载，下载器下到分类的url地址之后返回响应文件返回到spiders，spiders从响应文件中再提取具体的url地址再构建成请求交给引擎，引擎再交给调度器，调度器把所有的请求入队列，为什么要入队列呢，因为要在队列里面做去重处理，做请求出队的处理,然后就又是交给下载器去下载，一层一层往下深挖，直到我们要的数据浮出水面，然后这个时候item pipeline就派上用场了，就对数据进行持久化处理</p><p>我们再来看一个小故事，也是Scrapy的一个运行流程：<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/a3ef1f51495e93f8.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/6ddc3a76000e407d.png"                                     ></p><p>引擎就是用来控制整个框架的信号的，信号就是每个部分完成什么东西后的一个返回标志，然后引擎就会根据信号做下一步的处理，比如该叫谁往下处理</p><p>流程总结：<br>首先我们写好一个爬虫(spiders)然后构建请求</p><p>请求交给引擎，引擎交给调度器</p><p>调度器入队列，入完队列就交给下载器</p><p>下载器返回的响应文件会交给爬虫文件(spiders)</p><p>爬虫文件处理数据</p><p>如果是url地址就接着交给调度器入队列然后再交给下载器去下载</p><p>如果是item数据就交给管道去存储</p><p>以此循环</p><p>什么时候请求会停止呢，就是当调度器中不存在任何请求的时候才会停止</p><h4 id="1-2-制作Scrapy的四大步骤"><a href="#1-2-制作Scrapy的四大步骤" class="headerlink" title="1.2 制作Scrapy的四大步骤"></a>1.2 制作Scrapy的四大步骤</h4><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/a3477b76b0743352.png"                                     ></p><h2 id="2-Scrapy框架配置安装和命令介绍"><a href="#2-Scrapy框架配置安装和命令介绍" class="headerlink" title="2. Scrapy框架配置安装和命令介绍"></a>2. Scrapy框架配置安装和命令介绍</h2><h3 id="2-1-制作Scrapy爬虫的四大步骤"><a href="#2-1-制作Scrapy爬虫的四大步骤" class="headerlink" title="2.1 制作Scrapy爬虫的四大步骤"></a>2.1 制作Scrapy爬虫的四大步骤</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/a3477b76b0743352.png"                                     ></p><h3 id="2-2-Scrapy的安装介绍"><a href="#2-2-Scrapy的安装介绍" class="headerlink" title="2.2 Scrapy的安装介绍"></a>2.2 Scrapy的安装介绍</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/c2e4cf49de46270f.png"                                     ></p><h4 id="2-2-1-windows安装方式"><a href="#2-2-1-windows安装方式" class="headerlink" title="2.2.1 windows安装方式"></a>2.2.1 windows安装方式</h4><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/c7cd5c9943b28113.png"                                     ></p><h4 id="2-2-3-ubuntu需要9-10或以上版本安装方式"><a href="#2-2-3-ubuntu需要9-10或以上版本安装方式" class="headerlink" title="2.2.3 ubuntu需要9.10或以上版本安装方式"></a>2.2.3 ubuntu需要9.10或以上版本安装方式</h4><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/5e9cb6edcdaed1ee.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/e3049ac99a3c2c15.png"                                     ></p><p>安装好之后键入scrapy如果出现以下字符则安装成功：<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/b7157f871e586ffe.png"                                     ></p><p>bench：用来测试</p><p>fdtch：用来查看响应的</p><p>genspider：用来创建爬虫的</p><p>runspider：用来启动一个爬虫的</p><p>settings：用来设置配置文件的</p><p>shell：shell环境，用来处理响应环境</p><p>startproject：创建一个项目</p><p>version：查看scrapy版本号</p><p>view：使用浏览器视图</p><h2 id="3-入门案例-1"><a href="#3-入门案例-1" class="headerlink" title="3. 入门案例(1)"></a>3. 入门案例(1)</h2><h3 id="学习目标："><a href="#学习目标：" class="headerlink" title="学习目标："></a>学习目标：</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/cc0b64e6127819d0.png"                                     ></p><h3 id="3-1-新建项目-scrapy-startproject"><a href="#3-1-新建项目-scrapy-startproject" class="headerlink" title="3.1 新建项目(scrapy startproject)"></a>3.1 新建项目(scrapy startproject)</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/b79f11d345496e34.png"                                     ></p><p>比如我们这边创建个项目叫ITcast</p><p>然后我们进入ITcast这个文件夹然后发现里面还有一个ITcast和scrapy.cfg,scrapy.cfg是scrapy的配置文件</p><p>我们在进入ITcast发现有以下文件：<br><strong>init</strong>.py, items.py, middlewares.py, settings.py, spiders文件夹</p><p><strong>init</strong>.py是控制包的</p><p>我们打开items.py看看：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/3d62eb007b568a27.png"                                     ></p><p>import scrapy表示导入框架的一个组件</p><p>下面的类继承了scrapy.Item,然后它提供了一个使用方式是这样的：name = scrapy.Field()，这个就是用来创建一个item字段的，这个字段的格式和字典很相似(它本身不是一个字典,但可以和字典做一个转换)，比如我们先定义一个item = {}，然后item[“name” ] = “bigcat”,我们在spiders中就可以这样写</p><p>我们需要提取的字段就可以放到item里面去</p><p>我们打开middlewares.py(中间件)来看看</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/8d921eb14b79c030.png"                                     ></p><p>可以看到里面有一堆</p><p>加代理或者加user-agent都可以在中间件里面写</p><p>早期版本的scrapy是没有middlewares.py的，如果不是太复杂项目可以不用它</p><p>我们打开pipelines.py来看看：<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/f8236258c0b67305.png"                                     ></p><p>管道文件就是用来处理我们的item数据的，从上图中我们可以看到类名也是创建项目时生成的，这边有个process_item的一个方法，他会帮我们处理传进来的每个item，我们可以创建一个文件将item写进去，如果downloader传递给spiders的是item就交给pipilines.py里面来处理item</p><p>我们打开settings.py看看：<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/803171307035a62d.png"                                     ></p><p>项目在执行的时候就会参考配置文件来执行也就是看这里的settings.py</p><p>首先看到的第一个BOT_NAME就是我们爬虫的一个项目名称</p><p>SPIDER_MODULES表示爬虫文件在什么位置</p><p>NEWSPIDER_MODULE表示新建一个爬虫文件放在什么位置</p><p>我们发现在settings.py中有一个user-agent，我们可以直接在里面写，之后发出去的每个请求都会携带这个user-agent</p><p>ROBOTSTXT_OBEY表示爬虫是否遵循网站的robots协议，这个一般都是Flase或者注释掉</p><p>CONCURRENT_REQUESTS表示请求的一个并发量，默认是32，也就是说我们一次可以发出32个请求来处理这些响应,只要机器性能和网络足够好可以改大一点</p><p>DOWNLOAD_DELAY表示下载延迟，默认是3秒，我们可以注释它选择为不等待</p><p>CONCURRENT_REQUESTS_PER_DOMAIN和CONCURRENT_REQUESTS_PER_IP表示当前请求的域和ip</p><p>COOKIES_ENABLED表示是否启用cookie,在爬取页面的时候会生成cookie，如果这边选择注释，也就是启用cookie，有的网站会根据cookie来监测我们的爬虫行为</p><p>TELNETCONSOLE_ENABLED表示是否启用telnet，相当于是一个爬虫监控</p><p>DEFAULT_REQUEST_HEADERS是一个默认的一个请求报头</p><p>SPIDER_MIDDLEWARES爬虫中间件，介于爬虫和引擎之间的一个中间件注释就表示不启动</p><p>DOWNLOADER_MIDDLEWARES下载中间件，介于下载器和引擎之间的一个中间件注释表示不启动，这边都是字典，表示可以再加其他中间件，字典的值是介于0到1000的，值越小，优先级越高，如果有多个中间件就会根据这个数值来排序，数值就是优先级，先启用优先级大的</p><p>ITEM_PIPELINES管道文件也可以写多个，比如一个管道文件用来写入json的，一个用来写入xml的，后面的数字也是表示优先级</p><p>我们打开spiders文件来看看</p><p>发现里面就一个__init__.py</p><p>但是我们不能删除这个文件，不然导包就导不进，爬虫就执行不了</p><p>spiders文件夹就是我们写爬虫文件的，我们可以使用scrapy genspider xxx “允许的一个域的范围”来创建一个爬虫文件</p><p>比如创建一个爬虫叫itcast：scrapy genspider itcast “<a class="link"   href="http://www.itcast.cn&quot;/" >http://www.itcast.cn&quot;<i class="fas fa-external-link-alt"></i></a>, 后面跟一个域的作用是如果在爬取过程中遇到其他网站的就不会爬了，会局限在这个域去爬取</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/c13696f97880a75a.png"                                     ></p><p>basic模板是比较常用的</p><p>在生成这个爬虫文件时也会生成一个init.pyc(高版本是没有的),我们打开刚刚创建的爬虫看看：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/b69737487f6d0e43.png"                                     ></p><p>打开之后我们看到这是一个基于scrapy.Spider这个类的一个基本的模板(后面还会有个scrapy.Crawlspider)，然后给了一个爬虫名称，后面我们在命令行中如果要执行这个爬虫就要用到爬虫名称，是可以改的，然后给了一个爬虫允许的域的范围，start_urls表示第一个请求获取的url地址，上面的域和这里的start_urls都是列表都可以是多个，下面定义了一个parse方法也就是一个解析方法，针对上面的每个url放进调度器进队列出队列然后进入下载器后所下载下来的资源都要经过这个parse方法的过滤</p><p>现在我们来测试一下，不写管道文件啥的，就单独打印传智播客的官网html信息测试下：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/b498ab98c0e884ac.png"                                     ></p><p>这个时候我们发现好像多了几项：<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/00882ca6985ace81.png"                                     ></p><p>首先我们来check一下(测试爬虫是否正常)：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/500531551c9c5c5e.png"                                     ></p><p>然后我们用scrapy crawl itcast来运行下爬虫：<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/451a947f444f30c8.png"                                     ></p><h2 id="4-入门案例-2"><a href="#4-入门案例-2" class="headerlink" title="4. 入门案例(2)"></a>4. 入门案例(2)</h2><p>一，新建项目(scrapy startproject)</p><p>在开始爬取之前，必须创建一个新的scrapy项目，进入自定义的项目目录中，运行下列命令：<br>scrapy startproject myspider</p><p>其中，myscrapy为项目名称，可以看到将会创建一个myspider文件夹，目录结构大致如下：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/1d515f9654dde099.png"                                     ></p><p>简单介绍下各个文件的主要作用：<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/a72d0ec7f88b6083.png"                                     ></p><p>二，明确目标(myspider/items.py)</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/daeaf27a132ad566.png"                                     ></p><p>三，制作爬虫(spiders/itcastSpider.py)</p><ol><li><p>爬数据</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/da31a6ce52d21044.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/8bec8fedb52a1106.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/7a115c715664b556.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/16d205cf1464333d.png"                                     ></p></li><li><p>取数据</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/e495953b4c2beeae.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/84f462e47d98de71.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/60411b2de0a464f2.png"                                     ></p></li><li><p>保存数据</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/33c050135764291e.png"                                     ></p></li><li><p>返回item，将上面的parse函数改为生成器</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/1eba42ba2969f3cb.png"                                     ></p><p>yield是把数据返回给管道了，管道处理完之后会回到这里再继续执行没有完成的for循环语句</p></li><li><p>由于上面改写了方法，我们就需要处理管道了</p><p>我们itcast.py中的item就是返回到了pipelines.py中process_item()中</p><p>return item就是告诉引擎，这个item处理完了，一定要返回，不然影响后面的就处理不了</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/acf3f5b50a3934b5.png"                                     ></p><p>我们管道可以写多个，可以写个处理数据库的或者其他的，那么我们怎么去定制管道呢，可以在settings.py去启用管道，在67行的管道item_pipelines里去配置</p><p>每个item都会经过我们定义的管道，根据优先级来决定顺序：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/8293803b4688d34c.png"                                     ></p></li><li><p>总结</p><p>首先第一个启动的是爬虫文件(这里是itcast.py)爬虫文件会发送url里面的请求获取响应，响应再通过xpath，或者是re，或者是json去提取数据，提取数据之后呢我们就把提取到的数据存到item.py里面的字段去，然后通过yield去返回给管道，管道就对item进行进一步的处理(比如存文件),然后接着处理一次次yield返回过来的值</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/96db5300305ce01b.png"                                     ></p></li></ol><h2 id="5-Scrapy-shell"><a href="#5-Scrapy-shell" class="headerlink" title="5. Scrapy shell"></a>5. Scrapy shell</h2><h3 id="5-1-什么是Scrapy-shell："><a href="#5-1-什么是Scrapy-shell：" class="headerlink" title="5.1 什么是Scrapy shell："></a>5.1 什么是Scrapy shell：</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/a8b0331368ac7435.png"                                     ></p><h3 id="5-2-启动Scrapy-shell"><a href="#5-2-启动Scrapy-shell" class="headerlink" title="5.2 启动Scrapy shell"></a>5.2 启动Scrapy shell</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/3a3d8f21ea195bba.png"                                     ></p><p>Scrapy shell返回的就相当于写的爬虫文件里的parse函数中的response：<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/ea5ba70034a79c3e.png"                                     ></p><p>Scrapy shell的响应文件就是response</p><p>可以接着做一些测试，比如respose.xpath(“//h3”).extract()</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/6bc2d55f67aadb79.png"                                     ></p><h3 id="5-3-Selectors选择器"><a href="#5-3-Selectors选择器" class="headerlink" title="5.3 Selectors选择器"></a>5.3 Selectors选择器</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/c205f37c5cfc96fb.png"                                     ></p><h3 id="5-4-Spider主要属性和方法"><a href="#5-4-Spider主要属性和方法" class="headerlink" title="5.4 Spider主要属性和方法"></a>5.4 Spider主要属性和方法</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/fbf286726380f700.png"                                     ></p><h2 id="6-分页爬取腾讯招聘案例"><a href="#6-分页爬取腾讯招聘案例" class="headerlink" title="6. 分页爬取腾讯招聘案例"></a>6. 分页爬取腾讯招聘案例</h2><p>爬虫文件,tencent.py:<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/1268af3716f363cf.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/0ed7777c760a5ecf.png"                                     ></p><p>最后yield执行了一个回调函数，也可以自己再写个回调函数，这里没必要</p><p>写字段,items.py:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/933971c43da457a0.png"                                     ></p><p>写管道pipelines.py:<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/ca7578cc9a6b9018.png"                                     ></p><p>启动管道：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://www.tupians.top/imgs/2021/11/09f492ebc6f90fc5.png"                                     ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-Scrapy架构流程介绍&quot;&gt;&lt;a href=&quot;#1-Scrapy架构流程介绍&quot; class=&quot;headerlink&quot; title=&quot;1. Scrapy架构流程介绍&quot;&gt;&lt;/a&gt;1. Scrapy架构流程介绍&lt;/h2&gt;&lt;p&gt;&lt;img  
             </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>13天搞定爬虫听课笔记</title>
    <link href="http://example.com/2022/04/30/13%E5%A4%A9%E6%90%9E%E5%AE%9A%E7%88%AC%E8%99%AB%E5%90%AC%E8%AF%BE%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2022/04/30/13%E5%A4%A9%E6%90%9E%E5%AE%9A%E7%88%AC%E8%99%AB%E5%90%AC%E8%AF%BE%E7%AC%94%E8%AE%B0/</id>
    <published>2022-04-30T06:22:30.000Z</published>
    <updated>2022-04-30T06:22:40.049Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-爬虫介绍"><a href="#1-爬虫介绍" class="headerlink" title="1. 爬虫介绍"></a>1. 爬虫介绍</h1><h3 id="1-1-什么是爬虫？"><a href="#1-1-什么是爬虫？" class="headerlink" title="1.1 什么是爬虫？"></a>1.1 什么是爬虫？</h3><p><strong>网络爬虫</strong>也叫<strong>网络蜘蛛</strong>，如果把互联网比喻成一个蜘蛛网，那么蜘蛛就是在网上爬来爬去的蜘蛛，爬虫程序通过请求url地址，根据响应的内容进行解析采集数据，<br>比如：如果响应内容是html，分析dom结构，进行dom解析、或者正则匹配，如果响应内容是xml/json数据，就可以转数据对象，然后对数据进行解析。</p><h3 id="1-2-爬虫有什么作用？"><a href="#1-2-爬虫有什么作用？" class="headerlink" title="1.2 爬虫有什么作用？"></a>1.2 爬虫有什么作用？</h3><p>通过有效的爬虫手段批量采集数据，可以降低人工成本，提高有效数据量，给予运营/销售的数据支撑，加快产品发展。</p><h3 id="1-3-业界的情况"><a href="#1-3-业界的情况" class="headerlink" title="1.3 业界的情况"></a>1.3 业界的情况</h3><p>目前互联网产品竞争激烈，业界大部分都会使用爬虫技术对竞品产品的数据进行挖掘、采集、大数据分析，这是必备手段，并且很多公司都设立了<code>爬虫工程师</code>的岗位</p><h3 id="1-4-合法性"><a href="#1-4-合法性" class="headerlink" title="1.4 合法性"></a>1.4 合法性</h3><p>爬虫是利用程序进行批量爬取网页上的公开信息，也就是前端显示的数据信息。因为信息是完全公开的，所以是合法的。其实就像浏览器一样，浏览器解析响应内容并渲染为页面，而爬虫解析响应内容采集想要的数据进行存储。</p><h3 id="1-5-反爬虫"><a href="#1-5-反爬虫" class="headerlink" title="1.5 反爬虫"></a>1.5 反爬虫</h3><p>爬虫很难完全的制止，道高一尺魔高一丈，这是一场没有硝烟的战争，码农VS码农<br>反爬虫一些手段：</p><ul><li>合法检测：请求校验(useragent，referer，接口加签名，等)</li><li>小黑屋：IP/用户限制请求频率，或者直接拦截</li><li>投毒：反爬虫高境界可以不用拦截，拦截是一时的，投毒返回虚假数据，可以误导竞品决策</li><li>… …</li></ul><h3 id="1-6-选这一门语言"><a href="#1-6-选这一门语言" class="headerlink" title="1.6 选这一门语言"></a>1.6 选这一门语言</h3><p>爬虫可以用各种语言写, C++, Java都可以, 为什么要Python?</p><p>首先用C++搞网络开发的例子不多(可能是我见得太少)<br>然后由于Oracle收购了Sun, Java目前虽然在Android开发上很重要, 但是如果Google官司进展不顺利, 那么很有可能用Go语言替代掉Java来做Android开发. 在这计算机速度高速增长的年代里, 选语言都要看他爹的业绩, 真是稍不注意就落后于时代. 随着计算机速度的高速发展, 某种语言开发的软件运行的时间复杂度的常数系数已经不像以前那么重要, 我们可以越来越偏爱为程序员打造的而不是为计算机打造的语言. 比如Ruby这种传说中的纯种而又飘逸的的OOP语言, 或者Python这种稍严谨而流行库又非常多的语言, 都大大弱化了针对计算机运行速度而打造的特性, 强化了为程序员容易思考而打造的特性. 所以我选择Python</p><h3 id="1-7-选择Python版本"><a href="#1-7-选择Python版本" class="headerlink" title="1.7 选择Python版本"></a>1.7 选择Python版本</h3><p>有2和3两个版本, 3比较新, 听说改动大. 根据我在知乎上搜集的观点来看, 我还是倾向于使用”在趋势中将会越来越火”的版本, 而非”目前已经很稳定而且很成熟”的版本. 这是个人喜好, 而且预测不一定准确. 但是如果Python3无法像Python2那么火, 那么整个Python语言就不可避免的随着时间的推移越来越落后, 因此我想其实选哪个的最坏风险都一样, 但是最好回报却是Python3的大. 其实两者区别也可以说大也可以说不大, 最终都不是什么大问题. 我选择的是Python 3</p><h3 id="1-8-爬虫基本套路"><a href="#1-8-爬虫基本套路" class="headerlink" title="1.8 爬虫基本套路"></a>1.8 爬虫基本套路</h3><ul><li>基本流程<ul><li>目标数据</li><li>来源地址</li><li>结构分析</li><li>实现构思</li><li>操刀编码</li></ul></li><li>基本手段<ul><li>破解请求限制<ul><li>请求头设置，如：useragant为有效客户端</li><li>控制请求频率(根据实际情景)</li><li>IP代理</li><li>签名/加密参数从html/cookie/js分析</li></ul></li><li>破解登录授权<ul><li>请求带上用户cookie信息</li></ul></li><li>破解验证码<ul><li>简单的验证码可以使用识图读验证码第三方库</li></ul></li></ul></li><li>解析数据<ul><li>HTML Dom解析<ul><li>正则匹配，通过的正则表达式来匹配想要爬取的数据，如：有些数据不是在html 标签里，而是在html的script 标签的js变量中</li><li>使用第三方库解析html dom，比较喜欢类jquery的库</li></ul></li><li>数据字符串<ul><li>正则匹配(根据情景使用) </li><li>转 JSON/XML 对象进行解析</li></ul></li></ul></li></ul><h3 id="1-9-Python爬虫"><a href="#1-9-Python爬虫" class="headerlink" title="1.9  Python爬虫"></a>1.9  Python爬虫</h3><ul><li>python写爬虫的优势<ul><li>python语法易学，容易上手</li><li>社区活跃，实现方案多可参考</li><li>各种功能包丰富</li><li>少量代码即可完成强大功能</li></ul></li><li>涉及模块包<ul><li>请求<ul><li><code>urllib</code></li><li><code>requests</code></li></ul></li><li>多线程<ul><li><code>threading</code></li></ul></li><li>正则<ul><li><code>re</code></li></ul></li><li>json解析<ul><li><code>json</code></li></ul></li><li>html dom解析<ul><li><code>beautiful soup</code></li></ul></li><li>lxml<ul><li>xpath</li></ul></li><li>操作浏览器<ul><li>selenium</li></ul></li></ul></li></ul><h1 id="2-常用的工具"><a href="#2-常用的工具" class="headerlink" title="2. 常用的工具"></a>2. 常用的工具</h1><ol><li>python</li><li>pycharm</li><li>浏览器<ol><li> chrome</li><li> 火狐</li></ol></li><li>fiddler</li></ol><h3 id="2-1-fiddler的使用"><a href="#2-1-fiddler的使用" class="headerlink" title="2.1 fiddler的使用"></a>2.1 fiddler的使用</h3><ol><li><p>操作的界面</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://i.loli.net/2021/07/31/MmgOfVh1Wz5LyHK.png"                      alt="image-20210731221436389"                ></p></li><li><p>界面含义</p><p>请求 (Request) 部分详解：</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>Headers</td><td>显示客户端发送到服务器的 HTTP 请求的,header 显示为一个分级视图，包含了 Web 客户端信息、Cookie、传输状态等</td></tr><tr><td>Textview</td><td>显示 POST 请求的 body 部分为文本</td></tr><tr><td>WebForms</td><td>显示请求的 GET 参数 和 POST body 内容</td></tr><tr><td>HexView</td><td>用十六进制数据显示请求</td></tr><tr><td>Auth</td><td>显示响应 header 中的 Proxy-Authorization(代理身份验证) 和 Authorization(授权) 信息</td></tr><tr><td>Raw</td><td>将整个请求显示为纯文本</td></tr><tr><td>JSON</td><td>显示JSON格式文件</td></tr><tr><td>XML</td><td>如果请求的 body 是 XML格式，就是用分级的 XML 树来显示它</td></tr></tbody></table><p>响应 (Response) 部分详解：</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>Transformer</td><td>显示响应的编码信息</td></tr><tr><td>Headers</td><td>用分级视图显示响应的 header</td></tr><tr><td>TextView</td><td>使用文本显示相应的 body</td></tr><tr><td>ImageVies</td><td>如果请求是图片资源，显示响应的图片</td></tr><tr><td>HexView</td><td>用十六进制数据显示响应</td></tr><tr><td>WebView</td><td>响应在 Web 浏览器中的预览效果</td></tr><tr><td>Auth</td><td>显示响应 header 中的 Proxy-Authorization(代理身份验证) 和 Authorization(授权) 信息</td></tr><tr><td>Caching</td><td>显示此请求的缓存信息</td></tr><tr><td>Privacy</td><td>显示此请求的私密 (P3P) 信息</td></tr><tr><td>Raw</td><td>将整个响应显示为纯文本</td></tr><tr><td>JSON</td><td>显示JSON格式文件</td></tr><tr><td>XML</td><td>如果响应的 body 是 XML 格式，就是用分级的 XML 树来显示它</td></tr></tbody></table></li><li><p>设置</p><ul><li><p>如何打开</p><p>启动Fiddler，打开菜单栏中的 Tools &gt;Options，打开“Fiddler Options”对话框</p></li><li><p>设置</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://i.loli.net/2021/07/31/f2EsarPySVXDB6v.png"                      alt="image-20210731223601668"                ></p><ul><li>Capture HTTPS CONNECTs 捕捉HTTPS连接</li><li>Decrypt HTTPS traffic 解密HTTPS通信</li><li>Ignore server certificate errors 忽略服务器证书错误</li><li>all processes 所有进程</li><li>browsers onlye 仅浏览器</li><li>nono- browsers only 仅非浏览器</li><li>remote clients only 仅远程链接</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://i.loli.net/2021/07/31/L3YvZDrTbEyx6qU.png"                      alt="image-20210731223737528"                ></p><p>Trust Root Certificate(受信任的根证书) 配置Windows信任这个根证书解决安全警告</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://i.loli.net/2021/07/31/QUWXT3vkCyNFBAi.png"                      alt="image-20210731223928199"                ></p><ul><li>Allow remote computers to connect 允许远程连接</li><li>Act as system proxy on startup 作为系统启动代理</li><li>resuse client connections 重用客户端链接</li></ul></li></ul></li></ol><h1 id="3-urllib使用体验"><a href="#3-urllib使用体验" class="headerlink" title="3. urllib使用体验"></a>3. urllib使用体验</h1><h3 id="3-1-小试牛刀"><a href="#3-1-小试牛刀" class="headerlink" title="3.1 小试牛刀"></a>3.1 小试牛刀</h3><p>怎样扒网页呢？</p><p>其实就是根据URL来获取它的网页信息，虽然我们在浏览器中看到的是一幅幅优美的画面，但是其实是由浏览器解释才呈现出来的，实质它是一段HTML代码，加 JS、CSS，如果把网页比作一个人，那么HTML便是他的骨架，JS便是他的肌肉，CSS便是它的衣服。所以最重要的部分是存在于HTML中的，下面我们就写个例子来扒一个网页下来</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"> </span><br><span class="line">response = urlopen(<span class="string">&quot;http://www.baidu.com&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response.read().decode())</span><br></pre></td></tr></table></figure><p>真正的程序就两行，执行如下命令查看运行结果，感受一下</p><p>看，这个网页的源码已经被我们扒下来了，是不是很酸爽？</p><h3 id="3-2-fake-useragent测试"><a href="#3-2-fake-useragent测试" class="headerlink" title="3.2 fake_useragent测试"></a>3.2 fake_useragent测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line">ua = UserAgent()</span><br><span class="line"><span class="built_in">print</span>(ua.chrome)</span><br><span class="line"><span class="built_in">print</span>(ua.firefox)</span><br><span class="line"><span class="built_in">print</span>(ua.ie)</span><br><span class="line"><span class="built_in">print</span>(ua.random)</span><br></pre></td></tr></table></figure><h3 id="3-3-常见到的方法"><a href="#3-3-常见到的方法" class="headerlink" title="3.3 常见到的方法"></a>3.3 常见到的方法</h3><ul><li><p>requset.urlopen(url,data,timeout)</p><ul><li><p>第一个参数url即为URL，第二个参数data是访问URL时要传送的数据，第三个timeout是设置超时时间。</p></li><li><p>第二三个参数是可以不传送的，data默认为空None，timeout默认为 socket._GLOBAL_DEFAULT_TIMEOUT</p></li><li><p>第一个参数URL是必须要传送的，在这个例子里面我们传送了百度的URL，执行urlopen方法之后，返回一个response对象，返回信息便保存在这里面。</p></li></ul></li></ul><ul><li><p>response.read()</p><ul><li>read()方法就是读取文件里的全部内容，返回bytes类型</li></ul></li><li><p>response.getcode()</p><ul><li>返回 HTTP的响应码，成功返回200，4服务器页面出错，5服务器问题</li></ul></li><li><p>response.geturl()</p><ul><li>返回 返回实际数据的实际URL，防止重定向问题</li></ul></li><li><p>response.info()</p><ul><li>返回 服务器响应的HTTP报头</li></ul></li></ul><h3 id="3-4-Request对象"><a href="#3-4-Request对象" class="headerlink" title="3.4 Request对象"></a>3.4 Request对象</h3><p>其实上面的urlopen参数可以传入一个request请求,它其实就是一个Request类的实例，构造时需要传入Url,Data等等的内容。比如上面的两行代码，我们可以这么改写</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request</span><br><span class="line"></span><br><span class="line">request = Request(<span class="string">&quot;http://www.baidu.com&quot;</span>)</span><br><span class="line">response = urlopen(requst)</span><br><span class="line"><span class="built_in">print</span> response.read().decode()</span><br></pre></td></tr></table></figure><p>运行结果是完全一样的，只不过中间多了一个request对象，推荐大家这么写，因为在构建请求时还需要加入好多内容，通过构建一个request，服务器响应请求得到应答，这样显得逻辑上清晰明确</p><h3 id="3-5-Get请求"><a href="#3-5-Get请求" class="headerlink" title="3.5 Get请求"></a>3.5 Get请求</h3><p>大部分被传输到浏览器的html，images，js，css, … 都是通过GET方法发出请求的。它是获取数据的主要方法</p><p>例如：<a class="link"   href="http://www.baidu.com/" >www.baidu.com<i class="fas fa-external-link-alt"></i></a> 搜索</p><p>Get请求的参数都是在Url中体现的,如果有中文，需要转码，这时我们可使用</p><ul><li>urllib.parse.urlencode()</li><li>urllib.parse. quote()</li></ul><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request, urlopen</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://www.baidu.com/s?wd=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(quote(<span class="string">&quot;尚学堂&quot;</span>))</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">request = Request(url, headers=headers)</span><br><span class="line">response = urlopen(request)</span><br><span class="line"><span class="built_in">print</span>(response.read().decode())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request, urlopen</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line">args = &#123;</span><br><span class="line">    <span class="string">&quot;wd&quot;</span>: <span class="string">&quot;尚学堂&quot;</span>,</span><br><span class="line">    <span class="string">&quot;ie&quot;</span>: <span class="string">&quot;utf-8&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">url = <span class="string">&quot;https://www.baidu.com/s?&#123;&#125;&quot;</span>.<span class="built_in">format</span>(urlencode(args))</span><br><span class="line"><span class="built_in">print</span>(url)</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: UserAgent().random</span><br><span class="line">&#125;</span><br><span class="line">request = Request(url, headers=headers)</span><br><span class="line">response = urlopen(request)</span><br><span class="line">info = response.read()</span><br><span class="line"><span class="built_in">print</span>(info.decode())</span><br></pre></td></tr></table></figure><h3 id="3-6-贴吧案例"><a href="#3-6-贴吧案例" class="headerlink" title="3.6  贴吧案例"></a>3.6  贴吧案例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request, urlopen</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_html</span>(<span class="params">url</span>):</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome</span><br><span class="line">    &#125;</span><br><span class="line">    request = Request(url, headers=headers)</span><br><span class="line">    response = urlopen(request)</span><br><span class="line">    <span class="built_in">print</span>(response.read().decode())</span><br><span class="line">    <span class="keyword">return</span> response.read()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_html</span>(<span class="params">filename, html_bytes</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(html_bytes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    content = <span class="built_in">input</span>(<span class="string">&quot;请输入要下载的内容：&quot;</span>)</span><br><span class="line">    num = <span class="built_in">input</span>(<span class="string">&quot;请输入要下载多少页：&quot;</span>)</span><br><span class="line">    base_url = <span class="string">&quot;http://tieba.baidu.com/f?ie=utf-8&amp;&#123;&#125;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> pn <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">int</span>(num)):</span><br><span class="line">        args = &#123;</span><br><span class="line">            <span class="string">&quot;pn&quot;</span>: pn * <span class="number">50</span>,</span><br><span class="line">            <span class="string">&quot;kw&quot;</span>: content</span><br><span class="line">        &#125;</span><br><span class="line">        filename = <span class="string">&quot;第&quot;</span> + <span class="built_in">str</span>(pn + <span class="number">1</span>) + <span class="string">&quot;页.html&quot;</span></span><br><span class="line">        args = urlencode(args)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在下载&quot;</span> + filename)</span><br><span class="line">        html_bytes = get_html(base_url.<span class="built_in">format</span>(args))</span><br><span class="line">        save_html(filename, html_bytes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h3 id="3-7-Post请求"><a href="#3-7-Post请求" class="headerlink" title="3.7 Post请求"></a>3.7 Post请求</h3><p>我们说了Request请求对象的里有data参数，它就是用在POST里的，我们要传送的数据就是这个参数data，data是一个字典，里面要匹配键值对</p><p>发送请求/响应header头的含义：</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>Accept</td><td>告诉服务器，客户端支持的数据类型</td></tr><tr><td>Accept-Charset</td><td>告诉服务器，客户端采用的编码</td></tr><tr><td>Accept-Encoding</td><td>告诉服务器，客户机支持的数据压缩格式</td></tr><tr><td>Accept-Language</td><td>告诉服务器，客户机的语言环境</td></tr><tr><td>Host</td><td>客户机通过这个头告诉服务器，想访问的主机名</td></tr><tr><td>If-Modified-Since</td><td>客户机通过这个头告诉服务器，资源的缓存时间</td></tr><tr><td>Referer</td><td>客户机通过这个头告诉服务器，它是从哪个资源来访问服务器的。（一般用于防盗链）</td></tr><tr><td>User-Agent</td><td>客户机通过这个头告诉服务器，客户机的软件环境</td></tr><tr><td>Cookie</td><td>客户机通过这个头告诉服务器，可以向服务器带数据</td></tr><tr><td>Refresh</td><td>服务器通过这个头，告诉浏览器隔多长时间刷新一次</td></tr><tr><td>Content-Type</td><td>服务器通过这个头，回送数据的类型</td></tr><tr><td>Content-Language</td><td>服务器通过这个头，告诉服务器的语言环境</td></tr><tr><td>Server</td><td>服务器通过这个头，告诉浏览器服务器的类型</td></tr><tr><td>Content-Encoding</td><td>服务器通过这个头，告诉浏览器数据采用的压缩格式</td></tr><tr><td>Content-Length</td><td>服务器通过这个头，告诉浏览器回送数据的长度</td></tr></tbody></table><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request, urlopen</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.sxt.cn/index/login/login.html&quot;</span></span><br><span class="line">form_data = &#123;</span><br><span class="line">    <span class="string">&quot;user&quot;</span>: <span class="string">&quot;17703181473&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;12346&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome</span><br><span class="line">&#125;</span><br><span class="line">f_data = urlencode(form_data)</span><br><span class="line">request = Request(url, data=f_data.encode(), headers=headers)</span><br><span class="line">response = urlopen(request)</span><br><span class="line"><span class="built_in">print</span>(response.read().decode())</span><br></pre></td></tr></table></figure><p>这里我们要注意我们要把data字典先用url_encode转化成字符编码然后再用encode转换成bytes类型，Request函数中的data参数只支持bytes类型的参数，其中的<a class="link"   href="http://www.sxt.cn/index/login/login.html%E6%98%AF%E5%B0%9A%E5%AD%A6%E5%A0%82%E7%9A%84%E7%99%BB%E9%99%86%E7%95%8C%E9%9D%A2" >http://www.sxt.cn/index/login/login.html是尚学堂的登陆界面<i class="fas fa-external-link-alt"></i></a></p><h3 id="3-8-Ajax请求获取数据"><a href="#3-8-Ajax请求获取数据" class="headerlink" title="3.8 Ajax请求获取数据"></a>3.8 Ajax请求获取数据</h3><h4 id="3-8-1-Ajax简介"><a href="#3-8-1-Ajax简介" class="headerlink" title="3.8.1 Ajax简介"></a>3.8.1 Ajax简介</h4><p>Ajax 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术</p><h4 id="3-8-2-什么是Ajax"><a href="#3-8-2-什么是Ajax" class="headerlink" title="3.8.2 什么是Ajax"></a>3.8.2 什么是Ajax</h4><p>Ajax = 异步 JavaScript 和 XML</p><p>Ajax 是一种用于创建快速动态网页的技术</p><p>通过在后台与服务器进行少量数据交换，AJAX 可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。传统的网页（不使用 AJAX）如果需要更新内容，必需重载整个网页面。有很多使用 AJAX 的应用程序案例：新浪微博、Google 地图、开心网等等</p><p>有些网页内容使用Ajax加载，而Ajax一般返回的是json,直接对Ajax地址进行post或get，就返回json数据了</p><h4 id="3-8-4-Ajax网站举例"><a href="#3-8-4-Ajax网站举例" class="headerlink" title="3.8.4 Ajax网站举例"></a>3.8.4 Ajax网站举例</h4><p>豆瓣电影排行：<a class="link"   href="https://movie.douban.com/typerank?type_name=%E5%89%A7%E6%83%85&amp;type=11&amp;interval_id=100:90&amp;action=" >https://movie.douban.com/typerank?type_name=%E5%89%A7%E6%83%85&amp;type=11&amp;interval_id=100:90&amp;action=<i class="fas fa-external-link-alt"></i></a></p><p>打开以上网站，然后打开开发者工具中的network会发现往下划，网页是不会刷新的然后动态新增了很多东西，点击XHR就能看到相应的Ajax请求，Headers能看到一些url以及请求头，然后点击Response这是他的响应信息，这是json格式的，我们可以把它复制出来在<a class="link"   href="https://www.json.cn/%E8%BF%99%E4%B8%AA%E7%BD%91%E7%AB%99%E4%B8%8A%E6%96%B9%E4%BE%BF%E6%9F%A5%E7%9C%8B" >https://www.json.cn/这个网站上方便查看<i class="fas fa-external-link-alt"></i></a></p><p>我们根据动态新增出来的东西headers中的requesturl，发现是有规律的</p><h4 id="3-8-5-Ajax式网站资源爬取示例"><a href="#3-8-5-Ajax式网站资源爬取示例" class="headerlink" title="3.8.5 Ajax式网站资源爬取示例"></a>3.8.5 Ajax式网站资源爬取示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request, urlopen</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line">base_url = <span class="string">&quot;https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=&#123;&#125;&amp;limit=20&quot;</span></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome</span><br><span class="line">    &#125;</span><br><span class="line">    url = base_url.<span class="built_in">format</span>(i * <span class="number">20</span>)</span><br><span class="line">    request = Request(url, headers=headers)</span><br><span class="line">    response = urlopen(request)</span><br><span class="line">    info = response.read().decode()</span><br><span class="line">    <span class="built_in">print</span>(info)</span><br><span class="line">    <span class="keyword">if</span> info == <span class="string">&quot;&quot;</span> <span class="keyword">or</span> info <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    i += <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="3-9-请求SSL证书验证"><a href="#3-9-请求SSL证书验证" class="headerlink" title="3.9 请求SSL证书验证"></a>3.9 请求SSL证书验证</h3><p>现在随处可见 https 开头的网站，urllib可以为 HTTPS 请求验证SSL证书，就像web浏览器一样，如果网站的SSL证书是经过CA认证的，则能够正常访问，如：<a class="link"   href="https://www.baidu.com/" >https://www.baidu.com/<i class="fas fa-external-link-alt"></i></a></p><p>如果SSL证书验证不通过，或者操作系统不信任服务器的安全证书，比如浏览器在访问12306网站如：<a class="link"   href="https://www.12306.cn/mormhweb/%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E4%BC%9A%E8%AD%A6%E5%91%8A%E7%94%A8%E6%88%B7%E8%AF%81%E4%B9%A6%E4%B8%8D%E5%8F%97%E4%BF%A1%E4%BB%BB%E3%80%82%EF%BC%88%E6%8D%AE%E8%AF%B4" >https://www.12306.cn/mormhweb/的时候，会警告用户证书不受信任。（据说<i class="fas fa-external-link-alt"></i></a> 12306 网站证书是自己做的，没有通过CA认证）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 忽略SSL安全认证</span></span><br><span class="line">context = ssl._create_unverified_context()</span><br><span class="line"><span class="comment"># 添加到context参数里</span></span><br><span class="line">response = urllib.request.urlopen(request, context = context)</span><br></pre></td></tr></table></figure><h4 id="3-9-1-12306网站首页爬取示例"><a href="#3-9-1-12306网站首页爬取示例" class="headerlink" title="3.9.1 12306网站首页爬取示例"></a>3.9.1 12306网站首页爬取示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request, urlopen</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://www.12306.cn/mormhweb/&#x27;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome</span><br><span class="line">&#125;</span><br><span class="line">request = Request(url, headers=headers)</span><br><span class="line"><span class="comment"># 忽略验证证书</span></span><br><span class="line">context = ssl._create_unverified_context()</span><br><span class="line">response = urlopen(request, context=context)</span><br><span class="line">info = response.read().decode()</span><br><span class="line"><span class="built_in">print</span>(info)</span><br></pre></td></tr></table></figure><h1 id="4-urllib高级使用-含反爬手段"><a href="#4-urllib高级使用-含反爬手段" class="headerlink" title="4. urllib高级使用(含反爬手段)"></a>4. urllib高级使用(含反爬手段)</h1><h3 id="4-1-设置请求头中加入referer以对付防盗链"><a href="#4-1-设置请求头中加入referer以对付防盗链" class="headerlink" title="4.1 设置请求头中加入referer以对付防盗链"></a>4.1 设置请求头中加入referer以对付防盗链</h3><p>对付防盗链，服务器会识别headers中的referer是不是它自己，如果不是，有的服务器不会响应，所以我们还可以在headers中加入referer</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123; </span><br><span class="line">         <span class="string">&#x27;User-Agent&#x27;</span> : <span class="string">&#x27;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;Referer&#x27;</span>:<span class="string">&#x27;http://www.zhihu.com/articles&#x27;</span> </span><br><span class="line">          &#125; </span><br></pre></td></tr></table></figure><h3 id="4-2-导入ua-list随机选择User-Agent"><a href="#4-2-导入ua-list随机选择User-Agent" class="headerlink" title="4.2 导入ua_list随机选择User_Agent"></a>4.2 导入ua_list随机选择User_Agent</h3><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line">ua_list = [</span><br><span class="line">    <span class="string">&quot;Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Windows; U; Windows NT 5.2) Gecko/2008070208 Firefox/3.0.1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Windows; U; Windows NT 5.2) AppleWebKit/525.13 (KHTML, like Gecko) Version/3.1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Windows; U; Windows NT 5.2) AppleWebKit/525.13 (KHTML, like Gecko) Chrome/0.2.149.27&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1) ;  QIHU 360EE)&quot;</span></span><br><span class="line">]</span><br><span class="line">user_agent = random.choice(ua_list)</span><br><span class="line">request = urllib.request.Request(<span class="string">&quot;http://www.baidu.com&quot;</span>)</span><br><span class="line">request.add_header(<span class="string">&quot;User-Agent&quot;</span>,user_agent)</span><br><span class="line"><span class="comment">#区分大小写</span></span><br><span class="line"><span class="built_in">print</span>(request.get_header(<span class="string">&quot;User-agent&quot;</span>))</span><br></pre></td></tr></table></figure><p>前面我们也介绍了fake_useragent，这个也可以使用</p><h3 id="4-3-opener的使用"><a href="#4-3-opener的使用" class="headerlink" title="4.3 opener的使用"></a>4.3 opener的使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> build_opener</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> HTTPHandler</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.baidu.com&quot;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome</span><br><span class="line">&#125;</span><br><span class="line">request = Request(url, headers=headers)</span><br><span class="line">handler = HTTPHandler()</span><br><span class="line">opener = build_opener(handler)</span><br><span class="line">response = opener.<span class="built_in">open</span>(request)</span><br><span class="line"><span class="built_in">print</span>(response.read().decode())</span><br></pre></td></tr></table></figure><h3 id="4-4-设置代理Pxoxy"><a href="#4-4-设置代理Pxoxy" class="headerlink" title="4.4 设置代理Pxoxy"></a>4.4 设置代理Pxoxy</h3><p>假如一个网站它会检测某一段时间某个IP 的访问次数，如果访问次数过多，它会禁止你的访问。所以你可以设置一些代理服务器来帮助你做工作，每隔一段时间换一个代理，网站君都不知道是谁在捣鬼了，这酸爽！</p><h5 id="分类："><a href="#分类：" class="headerlink" title="分类："></a>分类：</h5><p>透明代理：目标网站知道你使用了代理并且知道你的源IP地址，这种代理显然不符合我们这里使用代理的初衷</p><p>匿名代理：匿名程度比较低，也就是网站知道你使用了代理，但是并不知道你的源IP地址</p><p>高匿代理：这是最保险的方式，目标网站既不知道你使用的代理更不知道你的源IP </p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> ProxyHandler</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> build_opener</span><br><span class="line"></span><br><span class="line">proxy = ProxyHandler(&#123;<span class="string">&quot;http&quot;</span>: <span class="string">&quot;119.109.197.195:80&quot;</span>&#125;)</span><br><span class="line">opener = build_opener(proxy)</span><br><span class="line">url = <span class="string">&quot;http://www.baidu.com&quot;</span></span><br><span class="line">response = opener.<span class="built_in">open</span>(url)</span><br><span class="line"><span class="built_in">print</span>(response.read().decode(<span class="string">&quot;utf-8&quot;</span>))</span><br></pre></td></tr></table></figure><h3 id="4-5-为方便调试使用DebugLog-提一下"><a href="#4-5-为方便调试使用DebugLog-提一下" class="headerlink" title="4.5 为方便调试使用DebugLog(提一下)"></a>4.5 为方便调试使用DebugLog(提一下)</h3><p>可以通过下面的方法把 Debug Log 打开，这样收发包的内容就会在屏幕上打印出来，方便调试，这个也不太常用，仅提一下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> HTTPHandler</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> build_opener</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request</span><br><span class="line"></span><br><span class="line">handler = HTTPHandler(debuglevel=<span class="number">1</span>)</span><br><span class="line">opener = build_opener(handler)</span><br><span class="line">url = <span class="string">&quot;http://www.sohu.com&quot;</span></span><br><span class="line">request = Request(url)</span><br><span class="line">response = opener.<span class="built_in">open</span>(request)</span><br></pre></td></tr></table></figure><h3 id="4-6-Cookie的使用"><a href="#4-6-Cookie的使用" class="headerlink" title="4.6 Cookie的使用"></a>4.6 Cookie的使用</h3><h4 id="4-6-1-为什么要使用Cookie"><a href="#4-6-1-为什么要使用Cookie" class="headerlink" title="4.6.1 为什么要使用Cookie"></a>4.6.1 为什么要使用Cookie</h4><p>Cookie，指某些网站为了辨别用户身份、进行session跟踪而储存在用户本地终端上的数据（通常经过加密）</p><p>比如说有些网站需要登录后才能访问某个页面，在登录之前，你想抓取某个页面内容是不允许的。那么我们可以利用Urllib库保存我们登录的Cookie，然后再抓取其他页面就达到目的了</p><h4 id="4-6-2-如何看到登录后网站的Cookie"><a href="#4-6-2-如何看到登录后网站的Cookie" class="headerlink" title="4.6.2 如何看到登录后网站的Cookie"></a>4.6.2 如何看到登录后网站的Cookie</h4><p>我们以尚学堂为例，在登录后按f12然后点击network中的headers然后点击XHR就会看到登录后本地所保存的cookies：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://i.loli.net/2021/08/01/G1QcFZ2TB8m5IdP.png"                      alt="image-20210801163426055"                ></p><h4 id="4-6-3-案例1-Cookie嵌入到headers中来使用"><a href="#4-6-3-案例1-Cookie嵌入到headers中来使用" class="headerlink" title="4.6.3 案例1:Cookie嵌入到headers中来使用"></a>4.6.3 案例1:Cookie嵌入到headers中来使用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request, urlopen</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.sxt.cn/index/user.html&quot;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome,</span><br><span class="line">    <span class="string">&quot;Cookie&quot;</span>: <span class="string">&quot;UM_distinctid=163d8c88a6740c-01c2fe892f8d8c-737356c-100200-163d8c88a682a2; 53gid2=10466932807008; 53revisit=1528350416275; 53gid1=10466932807008; acw_tc=AQAAAIktZUa8ZQEAoCEsceTKxzX+LOad; CNZZDATA1261969808=52059414-1528348034-%7C1532407588; PHPSESSID=uh265s5725vojpqdsbagj0n726; visitor_type=old; 53gid0=10466932807008; 53kf_72085067_from_host=www.sxt.cn; 53kf_72085067_keyword=http%3A%2F%2Fwww.sxt.cn%2Findex%2Flogin%2Flogin.html; 53kf_72085067_land_page=http%253A%252F%252Fwww.sxt.cn%252F; kf_72085067_land_page_ok=1&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">request = Request(url, headers=headers)</span><br><span class="line">response = urlopen(request)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(response.read().decode())</span><br></pre></td></tr></table></figure><h4 id="4-6-4-案例2-使用HTTPCookieProcessor保存Cookie构造opener"><a href="#4-6-4-案例2-使用HTTPCookieProcessor保存Cookie构造opener" class="headerlink" title="4.6.4 案例2:使用HTTPCookieProcessor保存Cookie构造opener"></a>4.6.4 案例2:使用HTTPCookieProcessor保存Cookie构造opener</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request, urlopen</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> HTTPCookieProcessor,build_opener</span><br><span class="line"><span class="comment"># 登录</span></span><br><span class="line">login_url = <span class="string">&quot;http://www.sxt.cn/index/login/login&quot;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome,</span><br><span class="line">&#125;</span><br><span class="line">form_data = &#123;</span><br><span class="line">    <span class="string">&quot;user&quot;</span>: <span class="string">&quot;17703181473&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;123456&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">f_data = urlencode(form_data).encode()</span><br><span class="line">request = Request(login_url, headers=headers, data=f_data)</span><br><span class="line"><span class="comment">#response = urlopen(request) 错误的</span></span><br><span class="line">handler = HTTPCookieProcessor()</span><br><span class="line">opener = build_opener(handler)</span><br><span class="line">response = opener.<span class="built_in">open</span>(request)</span><br><span class="line"><span class="comment"># print(response.read().decode())</span></span><br><span class="line"><span class="comment"># 访问页面</span></span><br><span class="line">info_url = <span class="string">&quot;http://www.sxt.cn/index/user.html&quot;</span></span><br><span class="line">request = Request(info_url, headers=headers)</span><br><span class="line"><span class="comment">#response = urlopen(request)</span></span><br><span class="line">response = opener.<span class="built_in">open</span>(request)</span><br><span class="line"><span class="built_in">print</span>(response.read().decode())</span><br></pre></td></tr></table></figure><h4 id="4-6-5-Cookielib"><a href="#4-6-5-Cookielib" class="headerlink" title="4.6.5 Cookielib"></a>4.6.5 Cookielib</h4><p>cookielib模块的主要作用是提供可存储cookie的对象，以便于与urllib模块配合使用来访问Internet资源。Cookielib模块非常强大，我们可以利用本模块的CookieJar类的对象来捕获cookie并在后续连接请求时重新发送，比如可以实现模拟登录功能。该模块主要的对象有CookieJar、FileCookieJar、MozillaCookieJar、LWPCookieJar, FileCookieJar是CookieJar的子类，CookieJar是FileCookieJar的子类；</p><h5 id="4-6-5-1-MozillaCookieJar的使用"><a href="#4-6-5-1-MozillaCookieJar的使用" class="headerlink" title="4.6.5.1 MozillaCookieJar的使用"></a>4.6.5.1 MozillaCookieJar的使用</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request, build_opener, HTTPCookieProcessor</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">from</span> http.cookiejar <span class="keyword">import</span> MozillaCookieJar</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 登录</span></span><br><span class="line"><span class="comment"># 保存cookie到文件中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_cookie</span>():</span></span><br><span class="line">    login_url = <span class="string">&quot;http://www.sxt.cn/index/login/login&quot;</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome</span><br><span class="line">    &#125;</span><br><span class="line">    form_data = &#123;</span><br><span class="line">        <span class="string">&quot;user&quot;</span>: <span class="string">&quot;17703181473&quot;</span>,</span><br><span class="line">        <span class="string">&quot;password&quot;</span>: <span class="string">&quot;123456&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    f_data = urlencode(form_data).encode()</span><br><span class="line">    request = Request(login_url, headers=headers, data=f_data)</span><br><span class="line">    cookie_jar = MozillaCookieJar()</span><br><span class="line">    handler = HTTPCookieProcessor(cookie_jar)</span><br><span class="line">    opener = build_opener(handler)</span><br><span class="line">    response = opener.<span class="built_in">open</span>(request)</span><br><span class="line">    cookie_jar.save(<span class="string">&quot;cookie.txt&quot;</span>, ignore_expires=<span class="literal">True</span>, ignore_discard=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">use_cookie</span>():</span></span><br><span class="line">    info_url = <span class="string">&quot;http://www.sxt.cn/index/user.html&quot;</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome</span><br><span class="line">    &#125;</span><br><span class="line">    request = Request(info_url, headers=headers)</span><br><span class="line">    cookie_jar = MozillaCookieJar()</span><br><span class="line">    cookie_jar.load(<span class="string">&quot;cookie.txt&quot;</span>, ignore_discard=<span class="literal">True</span>, ignore_expires=<span class="literal">True</span>)</span><br><span class="line">    handler = HTTPCookieProcessor(cookie_jar)</span><br><span class="line">    opener = build_opener(handler)</span><br><span class="line">    response = opener.<span class="built_in">open</span>(request)</span><br><span class="line">    <span class="built_in">print</span>(response.read().decode())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取cookie从文件中</span></span><br><span class="line"><span class="comment"># 访问页面</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># get_cookie()</span></span><br><span class="line">    use_cookie()</span><br></pre></td></tr></table></figure><h3 id="4-7-URLError的使用"><a href="#4-7-URLError的使用" class="headerlink" title="4.7 URLError的使用"></a>4.7 URLError的使用</h3><p>首先解释下URLError可能产生的原因：</p><ul><li>网络无连接，即本机无法上网</li><li>连接不到特定的服务器</li><li>服务器不存在</li></ul><p>在代码中，我们需要用try-except语句来包围并捕获相应的异常,代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request, urlopen</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> URLError</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.sx123t.cn/index/login/login123&quot;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    req = Request(url, headers=headers)</span><br><span class="line">    resp = urlopen(req)</span><br><span class="line">    <span class="built_in">print</span>(resp.read().decode())</span><br><span class="line"><span class="keyword">except</span> URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">if</span> e.args == ():</span><br><span class="line">        <span class="built_in">print</span>(e.code)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(e.args[<span class="number">0</span>].errno)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;访问完成&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="5-request使用体验"><a href="#5-request使用体验" class="headerlink" title="5. request使用体验"></a>5. request使用体验</h1><h3 id="5-1-介绍"><a href="#5-1-介绍" class="headerlink" title="5.1 介绍"></a>5.1 介绍</h3><p>对了解一些爬虫的基本理念，掌握爬虫爬取的流程有所帮助。入门之后，我们就需要学习一些更加高级的内容和工具来方便我们的爬取。那么这一节来简单介绍一下 requests 库的基本用法</p><h3 id="5-2-安装"><a href="#5-2-安装" class="headerlink" title="5.2 安装"></a>5.2 安装</h3><p>利用 pip 安装：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure><p>如果 pip install xxx 报错：Could not fetch URL，用以下命令代替,这个命令同时指定了豆瓣源：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install xxx -i http://pypi.douban.com/simple --trusted-host pypi.douban.com</span><br></pre></td></tr></table></figure><h3 id="5-3-基本请求与运用"><a href="#5-3-基本请求与运用" class="headerlink" title="5.3 基本请求与运用"></a>5.3 基本请求与运用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">req = requests.get(<span class="string">&quot;http://www.baidu.com&quot;</span>)</span><br><span class="line">req = requests.post(<span class="string">&quot;http://www.baidu.com&quot;</span>)</span><br><span class="line">req = requests.put(<span class="string">&quot;http://www.baidu.com&quot;</span>)</span><br><span class="line">req = requests.delete(<span class="string">&quot;http://www.baidu.com&quot;</span>)</span><br><span class="line">req = requests.head(<span class="string">&quot;http://www.baidu.com&quot;</span>)</span><br><span class="line">req = requests.options(<span class="string">&quot;http://www.baidu.com&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="5-3-1-get请求"><a href="#5-3-1-get请求" class="headerlink" title="5.3.1 get请求"></a>5.3.1 get请求</h4><p>参数是字典，我们也可以传递json类型的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.baidu.com/s&quot;</span></span><br><span class="line">params = &#123;<span class="string">&#x27;wd&#x27;</span>: <span class="string">&#x27;尚学堂&#x27;</span>&#125;</span><br><span class="line">response = requests.get(url, params=params)</span><br><span class="line"><span class="built_in">print</span>(response.url)</span><br><span class="line">response.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line">html = response.text</span><br><span class="line"><span class="comment"># print(html)</span></span><br></pre></td></tr></table></figure><h4 id="5-3-2-post请求"><a href="#5-3-2-post请求" class="headerlink" title="5.3.2 post请求"></a>5.3.2 post请求</h4><p>参数是字典，我们也可以传递json类型的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">&quot;http://www.sxt.cn/index/login/login.html&quot;</span></span><br><span class="line">formdata = &#123;</span><br><span class="line">    <span class="string">&quot;user&quot;</span>: <span class="string">&quot;17703181473&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;123456&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">response = requests.post(url, data=formdata)</span><br><span class="line">response.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line">html = response.text</span><br><span class="line"><span class="comment"># print(html)</span></span><br></pre></td></tr></table></figure><h4 id="5-3-3-代理访问"><a href="#5-3-3-代理访问" class="headerlink" title="5.3.3 代理访问"></a>5.3.3 代理访问</h4><p>采集时为避免被封IP，经常会使用代理。requests也有相应的proxies属性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://httpbin.org/get&quot;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome</span><br><span class="line">&#125;</span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&quot;http&quot;</span>: <span class="string">&quot;http://398707160:j8inhg2g@120.27.224.41:16818&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">response = requests.get(url, headers=headers, proxies=proxies)</span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure><h4 id="5-3-4-SSL验证"><a href="#5-3-4-SSL验证" class="headerlink" title="5.3.4 SSL验证"></a>5.3.4 SSL验证</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 禁用安全请求警告</span></span><br><span class="line">requests.packages.urllib3.disable_warnings()</span><br><span class="line"><span class="comment"># 过滤掉弹出来的错误</span></span><br><span class="line">resp = requests.get(url, verify=<span class="literal">False</span>, headers=headers)</span><br></pre></td></tr></table></figure><p>访问12306：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://www.12306.cn/mormhweb/&quot;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 关闭警告</span></span><br><span class="line">requests.packages.urllib3.disable_warnings()</span><br><span class="line">response = requests.get(url, verify=<span class="literal">False</span>, headers=headers)</span><br><span class="line"><span class="comment"># 如果结果有乱码就要改一下字符集</span></span><br><span class="line">response.encoding = <span class="string">&quot;utf-8&quot;</span></span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure><h4 id="5-3-5-session自动保存cookies"><a href="#5-3-5-session自动保存cookies" class="headerlink" title="5.3.5 session自动保存cookies"></a>5.3.5 session自动保存cookies</h4><p>seesion的意思是保持一个会话，比如 登陆后继续操作(记录身份信息) 而requests是单次请求的请求，身份信息不会被记录</p><p>案例：访问尚学堂</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">session = requests.Session()</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: UserAgent().chrome</span><br><span class="line">&#125;</span><br><span class="line">login_url = <span class="string">&quot;http://www.sxt.cn/index/login/login&quot;</span></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&quot;user&quot;</span>: <span class="string">&quot;17703181473&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;123456&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">response = session.post(login_url, headers=headers, data=params)</span><br><span class="line">info_url = <span class="string">&quot;http://www.sxt.cn/index/user.html&quot;</span></span><br><span class="line">resp = session.get(info_url, headers=headers)</span><br><span class="line"><span class="built_in">print</span>(resp.text)</span><br></pre></td></tr></table></figure><h4 id="5-3-6-获取不同响应格式的写法"><a href="#5-3-6-获取不同响应格式的写法" class="headerlink" title="5.3.6 获取不同响应格式的写法"></a>5.3.6 获取不同响应格式的写法</h4><table><thead><tr><th>代码</th><th>含义</th></tr></thead><tbody><tr><td>resp.json()</td><td>获取响应内容（以json字符串）</td></tr><tr><td>resp.text</td><td>获取响应内容 (以字符串)</td></tr><tr><td>resp.content</td><td>获取响应内容（以字节的方式）</td></tr><tr><td>resp.headers</td><td>获取响应头内容</td></tr><tr><td>resp.url</td><td>获取访问地址</td></tr><tr><td>resp.encoding</td><td>获取网页编码</td></tr><tr><td>resp.request.headers</td><td>请求头内容</td></tr><tr><td>resp.cookie</td><td>获取cookie</td></tr></tbody></table><h1 id="6-正则表达式"><a href="#6-正则表达式" class="headerlink" title="6. 正则表达式"></a>6. 正则表达式</h1><p>在前面我们已经搞定了怎样获取页面的内容，不过还差一步，这么多杂乱的代码夹杂文字我们怎样把它提取出来整理呢？下面就开始介绍一个十分强大的工具，正则表达式！</p><p>正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。</p><p>正则表达式是用来匹配字符串非常强大的工具，在其他编程语言中同样有正则表达式的概念，Python同样不例外，利用了正则表达式，我们想要从返回的页面内容提取出我们想要的内容就易如反掌了</p><h3 id="6-1-规则"><a href="#6-1-规则" class="headerlink" title="6.1 规则"></a>6.1 规则</h3><table><thead><tr><th align="left">模式</th><th>描述</th></tr></thead><tbody><tr><td align="left">^</td><td>匹配字符串的开头</td></tr><tr><td align="left">$</td><td>匹配字符串的末尾</td></tr><tr><td align="left">.</td><td>匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符</td></tr><tr><td align="left">[…]</td><td>用来表示一组字符,单独列出：[amk] 匹配 ‘a’，’m’或’k’</td></tr><tr><td align="left">[^…]</td><td>不在[]中的字符：[^abc] 匹配除了a,b,c之外的字符</td></tr><tr><td align="left">*</td><td>匹配0个或多个的表达式</td></tr><tr><td align="left">+</td><td>匹配1个或多个的表达式</td></tr><tr><td align="left">?</td><td>匹配0个或1个由前面的正则表达式定义的片段，非贪婪方式</td></tr><tr><td align="left">{n}</td><td></td></tr><tr><td align="left">{n,}</td><td>精确匹配n个前面表达式</td></tr><tr><td align="left">{ n, m}</td><td>匹配 n 到 m 次由前面的正则表达式定义的片段，贪婪方式</td></tr><tr><td align="left">a | b</td><td>匹配a或b</td></tr><tr><td align="left">\w</td><td>匹配字母数字及下划线</td></tr><tr><td align="left">\W</td><td>匹配非字母数字及下划线</td></tr><tr><td align="left">\s</td><td>匹配任意空白字符，等价于 [\t\n\r\f]</td></tr><tr><td align="left">\S</td><td>匹配任意非空字符</td></tr><tr><td align="left">\d</td><td>匹配任意数字，等价于 [0-9]</td></tr><tr><td align="left">\D</td><td>匹配任意非数字</td></tr><tr><td align="left">\A</td><td>匹配字符串开始</td></tr><tr><td align="left">\Z</td><td>匹配字符串结束，如果是存在换行，只匹配到换行前的结束字符串</td></tr><tr><td align="left">\z</td><td>匹配字符串结束</td></tr><tr><td align="left">\G</td><td>匹配最后匹配完成的位置</td></tr><tr><td align="left">\b</td><td>匹配一个单词边界，也就是指单词和空格间的位置。例如， ‘er\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’</td></tr><tr><td align="left">\B</td><td>匹配非单词边界。’er\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’</td></tr><tr><td align="left">\n, \t, 等.</td><td>匹配一个换行符。匹配一个制表符</td></tr><tr><td align="left">\1…\9</td><td>匹配第n个分组的内容</td></tr><tr><td align="left">\10</td><td>匹配第n个分组的内容，如果它经匹配。否则指的是八进制字符码的表达式</td></tr><tr><td align="left">[\u4e00-\u9fa5]</td><td>中文</td></tr></tbody></table><h3 id="6-2-正则表达式相关注解"><a href="#6-2-正则表达式相关注解" class="headerlink" title="6.2 正则表达式相关注解"></a>6.2 正则表达式相关注解</h3><h4 id="2-1-数量词的贪婪模式与非贪婪模式"><a href="#2-1-数量词的贪婪模式与非贪婪模式" class="headerlink" title="2.1 数量词的贪婪模式与非贪婪模式"></a>2.1 数量词的贪婪模式与非贪婪模式</h4><p>正则表达式通常用于在文本中查找匹配的字符串<br>Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；非贪婪的则相反，总是尝试匹配尽可能少的字符</p><p>例如：正则表达式”ab*<em>”如果用于查找”abbbc”，将找到”abbb”。而如果使用非贪婪的数量词”ab</em>?”，将找到”a”</p><h4 id="2-2-常用方法"><a href="#2-2-常用方法" class="headerlink" title="2.2 常用方法"></a>2.2 常用方法</h4><ul><li>re.match<ul><li> re.match 尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none</li><li>函数语法：<br> re.match(pattern, string, flags=0)</li></ul></li><li>re.search<ul><li>re.search 扫描整个字符串并返回第一个成功的匹配。</li><li>函数语法：<br>re.search(pattern, string, flags=0)</li></ul></li><li>re.sub<ul><li>re.sub 替换字符串<br>re.sub(pattern,replace,string)</li></ul></li><li>re.findall<ul><li>re.findall 查找全部<br>re.findall(pattern,string,flags=0)</li></ul></li></ul><h3 id="6-3-正则表达式修饰符-可选标志"><a href="#6-3-正则表达式修饰符-可选标志" class="headerlink" title="6.3 正则表达式修饰符-可选标志"></a>6.3 正则表达式修饰符-可选标志</h3><p>正则表达式可以包含一些可选标志修饰符来控制匹配的模式。修饰符被指定为一个可选的标志。多个标志可以通过按位 OR(|) 它们来指定。如 re.I | re.M 被设置成 I 和 M 标志</p><table><thead><tr><th>修饰符</th><th>描述</th></tr></thead><tbody><tr><td>re.I</td><td>使匹配对大小写不敏感</td></tr><tr><td>re.L</td><td>做本地化识别（locale-aware）匹配</td></tr><tr><td>re.M</td><td></td></tr><tr><td>re.S</td><td>使 . 匹配包括换行在内的所有字符</td></tr><tr><td>re.U</td><td>根据Unicode字符集解析字符。这个标志影响 \w, \W, \b, \B</td></tr><tr><td>re.X</td><td>该标志通过给予你更灵活的格式以便你将正则表达式写得更易于理解</td></tr></tbody></table><h3 id="6-4-re使用相关代码"><a href="#6-4-re使用相关代码" class="headerlink" title="6.4 re使用相关代码"></a>6.4 re使用相关代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">str1 = <span class="string">&quot;I Study Python3.6 Everyday&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-------------match()-----------------&quot;</span>)</span><br><span class="line"><span class="comment"># 匹配I字符</span></span><br><span class="line">m1 = re.match(<span class="string">r&#x27;I&#x27;</span>, str1)</span><br><span class="line">m2 = re.match(<span class="string">r&#x27;\w&#x27;</span>, str1)</span><br><span class="line">m3 = re.match(<span class="string">r&#x27;.&#x27;</span>, str1)</span><br><span class="line">m4 = re.match(<span class="string">r&#x27;\D&#x27;</span>, str1)</span><br><span class="line">m5 = re.match(<span class="string">r&#x27;i&#x27;</span>, str1, re.I)</span><br><span class="line">m6 = re.match(<span class="string">r&#x27;\S&#x27;</span>, str1)</span><br><span class="line"><span class="comment"># m7 = re.match(r&#x27;Study&#x27;, str1)  # 匹配不到，因为match是从左开始匹配</span></span><br><span class="line"><span class="built_in">print</span>(m6.group())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-------------search()-----------------&quot;</span>)</span><br><span class="line"><span class="comment"># 匹配Study</span></span><br><span class="line">s1 = re.search(<span class="string">r&#x27;Study&#x27;</span>, str1)</span><br><span class="line">s2 = re.search(<span class="string">r&#x27;S\w+&#x27;</span>, str1)</span><br><span class="line"><span class="comment"># 匹配Python3.6</span></span><br><span class="line">s3 = re.search(<span class="string">r&#x27;P\w+.\d&#x27;</span>, str1)</span><br><span class="line"><span class="built_in">print</span>(s3.group())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-------------findall()-----------------&quot;</span>)</span><br><span class="line"><span class="comment"># 查找所有y</span></span><br><span class="line">f1 = re.findall(<span class="string">r&#x27;y&#x27;</span>, str1)</span><br><span class="line"><span class="built_in">print</span>(f1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-------------test()-----------------&quot;</span>)</span><br><span class="line">str2 = <span class="string">&#x27;&lt;div&gt;&lt;a href=&quot;http://www.bjsxt.com&quot;&gt;bjsxt尚学堂&lt;/a&gt;&lt;/div&gt;&#x27;</span></span><br><span class="line"><span class="comment"># 提取a标签的内容</span></span><br><span class="line">t1 = re.findall(<span class="string">r&#x27;[\u4e00-\u9fa5]\w+&#x27;</span>, str2)</span><br><span class="line">t2 = re.findall(<span class="string">r&#x27;&lt;a href=&quot;http://www.bjsxt.com&quot;&gt;(.+)&lt;/a&gt;&#x27;</span>, str2)</span><br><span class="line"><span class="comment"># 提取herf</span></span><br><span class="line">t3 = re.findall(<span class="string">r&#x27;&lt;a href=&quot;(.+)&quot;&gt;&#x27;</span>, str2)</span><br><span class="line"><span class="built_in">print</span>(t3)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-------------sub()-----------------&quot;</span>)</span><br><span class="line"><span class="comment"># 将str2的div换成span</span></span><br><span class="line">su1 = re.sub(<span class="string">r&#x27;&lt;div&gt;(.+)&lt;/div&gt;&#x27;</span>, <span class="string">r&#x27;&lt;span&gt;\1&lt;/span&gt;&#x27;</span>, str2)</span><br><span class="line"><span class="built_in">print</span>(su1)</span><br></pre></td></tr></table></figure><h1 id="7-正则表达式实战之糗事百科"><a href="#7-正则表达式实战之糗事百科" class="headerlink" title="7. 正则表达式实战之糗事百科"></a>7. 正则表达式实战之糗事百科</h1><p>直接上代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://www.qiushibaike.com/text/page/1/&quot;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: UserAgent().random</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 构造请求</span></span><br><span class="line">response = requests.get(url, headers=headers)</span><br><span class="line">info = response.text</span><br><span class="line"><span class="comment"># print(info)</span></span><br><span class="line">infos = re.findall(<span class="string">r&#x27;&lt;div class=&quot;content&quot;&gt;\s*&lt;span&gt;\s*(.+)\s*&lt;/span&gt;&#x27;</span>, info)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;duanzi.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> info <span class="keyword">in</span> infos:</span><br><span class="line">        f.write(info + <span class="string">&quot;\n\n\n&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="8-Beautiful-Soup"><a href="#8-Beautiful-Soup" class="headerlink" title="8. Beautiful Soup"></a>8. Beautiful Soup</h1><h3 id="8-1-utiful-Soup的简介"><a href="#8-1-utiful-Soup的简介" class="headerlink" title="8.1 utiful Soup的简介"></a>8.1 utiful Soup的简介</h3><blockquote><p>Beautiful Soup提供一些简单的、python式的函数用来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序。</p></blockquote><blockquote><p>Beautiful Soup自动将输入文档转换为Unicode编码，输出文档转换为utf-8编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时，Beautiful Soup就不能自动识别编码方式了。然后，你仅仅需要说明一下原始编码方式就可以了。</p></blockquote><blockquote><p>Beautiful Soup已成为和lxml、html6lib一样出色的python解释器，为用户灵活地提供不同的解析策略或强劲</p></blockquote><p>官网：<a class="link"   href="http://beautifulsoup.readthedocs.io/zh_CN/latest/" >http://beautifulsoup.readthedocs.io/zh_CN/latest/<i class="fas fa-external-link-alt"></i></a></p><h3 id="8-2-Beautiful-Soup-安装"><a href="#8-2-Beautiful-Soup-安装" class="headerlink" title="8.2 Beautiful Soup 安装"></a>8.2 Beautiful Soup 安装</h3><p>Beautiful Soup 3 目前已经停止开发，推荐在现在的项目中使用Beautiful Soup 4，不过它已经被移植到BS4了,也就是说导入时我们需要 import bs4</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure><p>Beautiful Soup支持Python标准库中的HTML解析器,还支持一些第三方的解析器，如果我们不安装它，则 Python 会使用 Python默认的解析器，lxml 解析器更加强大，速度更快，推荐安装</p><table><thead><tr><th>解析器</th><th>使用方法</th><th>优势</th><th>劣势</th></tr></thead><tbody><tr><td>Python标准库</td><td>BeautifulSoup(markup, “html.parser”)</td><td>1. Python的内置标准库  2. 执行速度适中 3.文档容错能力强</td><td>Python 2.7.3 or 3.2.2)前 的版本中文档容错能力差</td></tr><tr><td>lxml HTML 解析器</td><td>BeautifulSoup(markup, “lxml”)</td><td>1. 速度快 2.文档容错能力强</td><td>需要安装C语言库</td></tr><tr><td>lxml XML 解析器</td><td>BeautifulSoup(markup, [“lxml”, “xml”])  BeautifulSoup(markup, “xml”)</td><td>1. 速度快 2.唯一支持XML的解析器 3.需要安装C语言库</td><td></td></tr><tr><td>html5lib</td><td>BeautifulSoup(markup, “html5lib”)</td><td>1. 最好的容错性 2.以浏览器的方式解析文档 3.生成HTML5格式的文档 4.速度慢</td><td>不依赖外部扩展</td></tr></tbody></table><h3 id="8-3-创建-Beautiful-Soup-对象"><a href="#8-3-创建-Beautiful-Soup-对象" class="headerlink" title="8.3 创建 Beautiful Soup 对象"></a>8.3 创建 Beautiful Soup 对象</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(html,<span class="string">&quot;lxml&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="8-4-四大对象种类"><a href="#8-4-四大对象种类" class="headerlink" title="8.4 四大对象种类"></a>8.4 四大对象种类</h3><p>Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以归纳为4种:</p><ul><li>Tag</li><li>NavigableString</li><li>BeautifulSoup</li><li>Comment</li></ul><h4 id="8-4-1-Tag-是什么？通俗点讲就是-HTML-中的一个个标签"><a href="#8-4-1-Tag-是什么？通俗点讲就是-HTML-中的一个个标签" class="headerlink" title="8.4.1 Tag 是什么？通俗点讲就是 HTML 中的一个个标签"></a>8.4.1 Tag 是什么？通俗点讲就是 HTML 中的一个个标签</h4><p>例如：<code>&lt;div&gt;</code> <code>&lt;title&gt;</code></p><p>使用方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#以下代码为例子</span></span><br><span class="line">&lt;title&gt;尚学堂&lt;/title&gt;</span><br><span class="line">&lt;div <span class="class"><span class="keyword">class</span>=&#x27;<span class="title">info</span>&#x27; <span class="title">float</span>=&#x27;<span class="title">left</span>&#x27;&gt;<span class="title">Welcome</span> <span class="title">to</span> <span class="title">SXT</span>&lt;/<span class="title">div</span>&gt;</span></span><br><span class="line"><span class="class">&lt;<span class="title">div</span> <span class="title">class</span>=&#x27;<span class="title">info</span>&#x27; <span class="title">float</span>=&#x27;<span class="title">right</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">span</span>&gt;<span class="title">Good</span> <span class="title">Good</span> <span class="title">Study</span>&lt;/<span class="title">span</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">a</span> <span class="title">href</span>=&#x27;<span class="title">www</span>.<span class="title">bjsxt</span>.<span class="title">cn</span>&#x27;&gt;&lt;/<span class="title">a</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">strong</span>&gt;&lt;!--没用--&gt;&lt;/strong&gt;</span></span><br><span class="line"><span class="class">&lt;/div&gt;</span></span><br></pre></td></tr></table></figure><h5 id="8-4-1-1-获取标签"><a href="#8-4-1-1-获取标签" class="headerlink" title="8.4.1.1 获取标签"></a>8.4.1.1 获取标签</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#以lxml方式解析</span></span><br><span class="line">soup = BeautifulSoup(info, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.title)</span><br><span class="line"><span class="comment"># &lt;title&gt;尚学堂&lt;/title&gt;</span></span><br></pre></td></tr></table></figure><p><strong>注意</strong></p><blockquote><p>相同的标签只能获取第一个符合要求的标签</p></blockquote><h5 id="8-4-1-2-获取属性"><a href="#8-4-1-2-获取属性" class="headerlink" title="8.4.1.2 获取属性"></a>8.4.1.2 获取属性</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取所有属性</span></span><br><span class="line"><span class="built_in">print</span>(soup.title.attrs)</span><br><span class="line"><span class="comment">#class=&#x27;info&#x27; float=&#x27;left&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取单个属性的值</span></span><br><span class="line"><span class="built_in">print</span>(soup.div.get(<span class="string">&#x27;class&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(soup.div[<span class="string">&#x27;class&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(soup.a[<span class="string">&#x27;href&#x27;</span>])</span><br><span class="line"><span class="comment">#info</span></span><br></pre></td></tr></table></figure><h4 id="8-4-2-NavigableString-获取内容"><a href="#8-4-2-NavigableString-获取内容" class="headerlink" title="8.4.2 NavigableString 获取内容"></a>8.4.2 NavigableString 获取内容</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(soup.title.string)</span><br><span class="line"><span class="built_in">print</span>(soup.title.text)</span><br><span class="line"><span class="comment">#尚学堂</span></span><br></pre></td></tr></table></figure><h4 id="8-4-3-BeautifulSoup"><a href="#8-4-3-BeautifulSoup" class="headerlink" title="8.4.3 BeautifulSoup"></a>8.4.3 BeautifulSoup</h4><blockquote><p>BeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法.</p></blockquote><blockquote><p>因为 BeautifulSoup 对象并不是真正的HTML或XML的tag,所以它没有name和attribute属性.但有时查看它的 .name 属性是很方便的,所以 BeautifulSoup 对象包含了一个值为 “[document]” 的特殊属性 .name</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(soup.name)</span><br><span class="line"><span class="built_in">print</span>(soup.head.name)</span><br><span class="line"><span class="comment"># [document]</span></span><br><span class="line"><span class="comment"># head</span></span><br></pre></td></tr></table></figure><h4 id="8-4-4-Comment"><a href="#8-4-4-Comment" class="headerlink" title="8.4.4 Comment"></a>8.4.4 Comment</h4><p>Comment 对象是一个特殊类型的 NavigableString 对象，其实输出的内容仍然不包括注释符号，但是如果不好好处理它，可能会对我们的文本处理造成意想不到的麻烦</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">type</span>(soup.strong.string)==Comment:</span><br><span class="line">    <span class="built_in">print</span>(soup.strong.prettify())</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(soup.strong.string)</span><br></pre></td></tr></table></figure><h3 id="8-5-搜索文档树"><a href="#8-5-搜索文档树" class="headerlink" title="8.5 搜索文档树"></a>8.5 搜索文档树</h3><p>Beautiful Soup定义了很多搜索方法,这里着重介绍2个: find() 和 find_all() .其它方法的参数和用法类似</p><h4 id="8-5-1-过滤器"><a href="#8-5-1-过滤器" class="headerlink" title="8.5.1 过滤器"></a>8.5.1 过滤器</h4><p>介绍 find_all() 方法前,先介绍一下过滤器的类型 ,这些过滤器贯穿整个搜索的API.过滤器可以被用在tag的name中,节点的属性中,字符串中或他们的混合中</p><h5 id="8-5-1-1-字符串"><a href="#8-5-1-1-字符串" class="headerlink" title="8.5.1.1 字符串"></a>8.5.1.1 字符串</h5><p>最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的<div>标签</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#返回所有的div标签</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(<span class="string">&#x27;div&#x27;</span>))</span><br></pre></td></tr></table></figure><p>如果传入字节码参数,Beautiful Soup会当作UTF-8编码,可以传入一段Unicode 编码来避免Beautiful Soup解析编码出错</p><h5 id="8-1-1-2-正则表达式"><a href="#8-1-1-2-正则表达式" class="headerlink" title="8.1.1.2 正则表达式"></a>8.1.1.2 正则表达式</h5><p>如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#返回所有的div标签</span></span><br><span class="line"><span class="built_in">print</span> (soup.find_all(re.<span class="built_in">compile</span>(<span class="string">&quot;^div&quot;</span>)))</span><br></pre></td></tr></table></figure><h5 id="5-1-1-3-列表"><a href="#5-1-1-3-列表" class="headerlink" title="5.1.1.3 列表"></a>5.1.1.3 列表</h5><p>如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#返回所有匹配到的span a标签</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all([<span class="string">&#x27;span&#x27;</span>,<span class="string">&#x27;a&#x27;</span>]))</span><br></pre></td></tr></table></figure><h5 id="5-1-1-4-keyword"><a href="#5-1-1-4-keyword" class="headerlink" title="5.1.1.4 keyword"></a>5.1.1.4 keyword</h5><p>如果一个指定名字的参数不是搜索内置的参数名,搜索时会把该参数当作指定名字tag的属性来搜索,如果包含一个名字为 id 的参数,Beautiful Soup会搜索每个tag的”id”属性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#返回id为welcom的标签</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(<span class="built_in">id</span>=<span class="string">&#x27;welcom&#x27;</span>))</span><br></pre></td></tr></table></figure><h5 id="5-1-1-5-True"><a href="#5-1-1-5-True" class="headerlink" title="5.1.1.5 True"></a>5.1.1.5 True</h5><p>True 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点</p><h5 id="5-1-1-6-按CSS搜索"><a href="#5-1-1-6-按CSS搜索" class="headerlink" title="5.1.1.6 按CSS搜索"></a>5.1.1.6 按CSS搜索</h5><p>按照CSS类名搜索tag的功能非常实用,但标识CSS类名的关键字 class 在Python中是保留字,使用 class 做参数会导致语法错误.从Beautiful Soup的4.1.1版本开始,可以通过 class_ 参数搜索有指定CSS类名的tag</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回class等于info的div</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&#x27;info&#x27;</span>))</span><br></pre></td></tr></table></figure><h5 id="5-1-1-7-按属性的搜索"><a href="#5-1-1-7-按属性的搜索" class="headerlink" title="5.1.1.7 按属性的搜索"></a>5.1.1.7 按属性的搜索</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup.find_all(<span class="string">&quot;div&quot;</span>, attrs=&#123;<span class="string">&quot;class&quot;</span>: <span class="string">&quot;info&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-爬虫介绍&quot;&gt;&lt;a href=&quot;#1-爬虫介绍&quot; class=&quot;headerlink&quot; title=&quot;1. 爬虫介绍&quot;&gt;&lt;/a&gt;1. 爬虫介绍&lt;/h1&gt;&lt;h3 id=&quot;1-1-什么是爬虫？&quot;&gt;&lt;a href=&quot;#1-1-什么是爬虫？&quot; class=&quot;header</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Python爬虫笔记</title>
    <link href="http://example.com/2022/04/30/Python%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2022/04/30/Python%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/</id>
    <published>2022-04-30T06:14:33.000Z</published>
    <updated>2022-04-30T06:17:36.081Z</updated>
    
    <content type="html"><![CDATA[<h1 id="爬虫的概念和价值"><a href="#爬虫的概念和价值" class="headerlink" title="爬虫的概念和价值"></a>爬虫的概念和价值</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-08_21-58-32.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-08_21-58-44.png"                      alt="Snipaste_2020-09-08_21-58-44"                ></p><h1 id="爬虫合法性探究"><a href="#爬虫合法性探究" class="headerlink" title="爬虫合法性探究"></a>爬虫合法性探究</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-08_22-04-46.png"                                     ></p><h1 id="爬虫和反爬虫以及爬虫的君子协定"><a href="#爬虫和反爬虫以及爬虫的君子协定" class="headerlink" title="爬虫和反爬虫以及爬虫的君子协定"></a>爬虫和反爬虫以及爬虫的君子协定</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-08_22-14-36.png"                                     ></p><h1 id="HTTP和HTTPS协议"><a href="#HTTP和HTTPS协议" class="headerlink" title="HTTP和HTTPS协议"></a>HTTP和HTTPS协议</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-08_22-38-18.png"                                     ></p><p>以下分别是三种加密方式的图解</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-08_22-40-26.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-08_22-40-40.png"                      alt="Snipaste_2020-09-08_22-40-40"                ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-08_22-41-06.png"                      alt="Snipaste_2020-09-08_22-41-06"                ></p><h1 id="request第一血"><a href="#request第一血" class="headerlink" title="request第一血"></a>request第一血</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-09_11-17-40.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-09_11-18-18.png"                                     ></p><h1 id="request巩固深入案例介绍"><a href="#request巩固深入案例介绍" class="headerlink" title="request巩固深入案例介绍"></a>request巩固深入案例介绍</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-09_11-21-16.png"                                     ></p><h1 id="request巩固深入案例介绍之简易网页采集器"><a href="#request巩固深入案例介绍之简易网页采集器" class="headerlink" title="request巩固深入案例介绍之简易网页采集器"></a>request巩固深入案例介绍之简易网页采集器</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-09_11-36-05.png"                                     ></p><h1 id="request巩固深入案例介绍之破解百度翻译"><a href="#request巩固深入案例介绍之破解百度翻译" class="headerlink" title="request巩固深入案例介绍之破解百度翻译"></a>request巩固深入案例介绍之破解百度翻译</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-09_15-58-29.png"                                     ></p><h1 id="什么是Ajax"><a href="#什么是Ajax" class="headerlink" title="什么是Ajax"></a>什么是Ajax</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-09_16-02-58.png"                                     ></p><h1 id="request巩固深入案例介绍之破解豆瓣电影"><a href="#request巩固深入案例介绍之破解豆瓣电影" class="headerlink" title="request巩固深入案例介绍之破解豆瓣电影"></a>request巩固深入案例介绍之破解豆瓣电影</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-09_22-02-21.png"                                     ></p><h1 id="正则概述"><a href="#正则概述" class="headerlink" title="正则概述"></a>正则概述</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_15-04-38.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_15-06-02.png"                                     ></p><h1 id="正则案例"><a href="#正则案例" class="headerlink" title="正则案例"></a>正则案例</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_15-17-54.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_15-18-24.png"                      alt="Snipaste_2020-09-10_15-18-24"                ></p><h1 id="bs4概述"><a href="#bs4概述" class="headerlink" title="bs4概述"></a>bs4概述</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_19-16-26.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_19-18-00.png"                      alt="Snipaste_2020-09-10_19-18-00"                ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_19-18-00.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_19-31-46.png"                      alt="Snipaste_2020-09-10_19-31-46"                ></p><h1 id="bs4案例"><a href="#bs4案例" class="headerlink" title="bs4案例"></a>bs4案例</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_20-04-04.png"                                     ></p><h1 id="xpath概述"><a href="#xpath概述" class="headerlink" title="xpath概述"></a>xpath概述</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_21-25-16.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_22-16-58.png"                      alt="Snipaste_2020-09-10_22-16-58"                ></p><h1 id="xpath解析基础"><a href="#xpath解析基础" class="headerlink" title="xpath解析基础"></a>xpath解析基础</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_22-59-57.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_23-01-28.png"                      alt="Snipaste_2020-09-10_23-01-28"                ></p><h1 id="xpath实战58二手房"><a href="#xpath实战58二手房" class="headerlink" title="xpath实战58二手房"></a>xpath实战58二手房</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_22-59-57.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-10_23-01-28.png"                      alt="Snipaste_2020-09-10_23-01-28"                ></p><h1 id="xpath解析案例图片下载"><a href="#xpath解析案例图片下载" class="headerlink" title="xpath解析案例图片下载"></a>xpath解析案例图片下载</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-11_09-11-57.png"                                     ></p><h1 id="xpath解析案例城市名称爬取"><a href="#xpath解析案例城市名称爬取" class="headerlink" title="xpath解析案例城市名称爬取"></a>xpath解析案例城市名称爬取</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-11_12-38-22.png"                      alt="s"                ></p><p>两个xpath表达式还可以用按位或（|）连接，表示同时处理两个xpath</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-11_12-46-53.png"                                     ></p><h1 id="代理在爬虫中的应用"><a href="#代理在爬虫中的应用" class="headerlink" title="代理在爬虫中的应用"></a>代理在爬虫中的应用</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-12_22-18-58.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-12_22-19-49.png"                      alt="Snipaste_2020-09-12_22-19-49"                ></p><h1 id="异步爬虫之线程池和多线程概述"><a href="#异步爬虫之线程池和多线程概述" class="headerlink" title="异步爬虫之线程池和多线程概述"></a>异步爬虫之线程池和多线程概述</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-12_22-40-59.png"                                     ></p><h1 id="线程池的基本使用（对比单线程和多线程）"><a href="#线程池的基本使用（对比单线程和多线程）" class="headerlink" title="线程池的基本使用（对比单线程和多线程）"></a>线程池的基本使用（对比单线程和多线程）</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-12_22-39-27.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-12_22-40-09.png"                      alt="Snipaste_2020-09-12_22-40-09"                ></p><h1 id="线程池的使用之梨视频爬取"><a href="#线程池的使用之梨视频爬取" class="headerlink" title="线程池的使用之梨视频爬取"></a>线程池的使用之梨视频爬取</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> multiprocessing.dummy <span class="keyword">import</span> Pool</span><br><span class="line"></span><br><span class="line">header = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &#x27;</span></span><br><span class="line">                  <span class="string">&#x27;Chrome/85.0.4183.83 Safari/537.36 &#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对下述url发起请求解析出视频的详情页的url以及视频的名称</span></span><br><span class="line">url = <span class="string">&#x27;https://www.pearvideo.com/category_5&#x27;</span></span><br><span class="line">response = requests.get(url=url, headers=header).text</span><br><span class="line">tree = etree.HTML(response)</span><br><span class="line">li_list = tree.xpath(<span class="string">&#x27;//ul[@id=&quot;listvideoListUl&quot;]/li&#x27;</span>)</span><br><span class="line">urls = []  <span class="comment"># 存放所有视频的链接和名字</span></span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">    detail_url = <span class="string">&#x27;https://www.pearvideo.com/&#x27;</span> + li.xpath(<span class="string">&#x27;./div/a/@href&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    name = li.xpath(<span class="string">&#x27;./div/a/div[2]/text()&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;.mp4&#x27;</span></span><br><span class="line">    <span class="comment"># print(detail_url,name)</span></span><br><span class="line">    <span class="comment"># 对详情页的url发起请求</span></span><br><span class="line">    detail_page_text = requests.get(url=detail_url, headers=header).text</span><br><span class="line">    <span class="comment"># 从详情页中解析出视频的地址 var contId=&quot;1696454&quot;,liveStatusUrl=&quot;liveStatus.jsp&quot;,liveSta=&quot;&quot;,playSta=&quot;1&quot;,autoPlay=!1,</span></span><br><span class="line">    <span class="comment"># isLiving=!1,isVrVideo=!1,hdflvUrl=&quot;&quot;,sdflvUrl=&quot;&quot;,hdUrl=&quot;&quot;,sdUrl=&quot;&quot;,ldUrl=&quot;&quot;,</span></span><br><span class="line">    <span class="comment"># srcUrl=&quot;https://video.pearvideo.com/mp4/third/20200910/cont-1696454-10729145-131731-hd.mp4&quot;,vdoUrl=srcUrl,</span></span><br><span class="line">    <span class="comment"># skinRes=&quot;//www.pearvideo.com/domain/skin&quot;,videoCDN=&quot;//video.pearvideo.com&quot;; var player;</span></span><br><span class="line">    ex = <span class="string">&#x27;srcUrl=&quot;(.*?)&quot;,vdoUrl=srcUrl&#x27;</span></span><br><span class="line">    video_url = re.findall(ex, detail_page_text)[<span class="number">0</span>]</span><br><span class="line">    dic = &#123;</span><br><span class="line">        <span class="string">&#x27;name&#x27;</span>: name,</span><br><span class="line">        <span class="string">&#x27;url&#x27;</span>: video_url</span><br><span class="line">    &#125;</span><br><span class="line">    urls.append(dic)</span><br><span class="line">    <span class="comment"># print(video_url)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_video_data</span>(<span class="params">dic</span>):</span></span><br><span class="line">    url = dic[<span class="string">&#x27;url&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(dic[<span class="string">&#x27;name&#x27;</span>], <span class="string">&#x27;正在下载....&#x27;</span>)</span><br><span class="line">    <span class="comment"># 发请求</span></span><br><span class="line">    data = requests.get(url=url, headers=header).content</span><br><span class="line">    <span class="comment"># 持久化存储</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(dic[<span class="string">&#x27;name&#x27;</span>], <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(data)</span><br><span class="line">        <span class="built_in">print</span>(dic[<span class="string">&#x27;name&#x27;</span>], <span class="string">&#x27;下载成功！&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用线程池对对视频数据进行请求（较为耗时的请求）</span></span><br><span class="line"><span class="comment"># 实例化线程池对象</span></span><br><span class="line">pool = Pool(<span class="number">4</span>)  <span class="comment"># 因为只拿到了4个url</span></span><br><span class="line">pool.<span class="built_in">map</span>(get_video_data, urls)</span><br><span class="line"></span><br><span class="line">pool.close()</span><br><span class="line">pool.join()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="协程相关概念讲解"><a href="#协程相关概念讲解" class="headerlink" title="协程相关概念讲解"></a>协程相关概念讲解</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-13_16-06-38.png"                                     ></p><h1 id="同步，异步，阻塞，-非阻塞"><a href="#同步，异步，阻塞，-非阻塞" class="headerlink" title="同步，异步，阻塞， 非阻塞"></a>同步，异步，阻塞， 非阻塞</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-13_22-49-20.png"                                     ></p><h1 id="多任务异步协程实现遇到的问题"><a href="#多任务异步协程实现遇到的问题" class="headerlink" title="多任务异步协程实现遇到的问题"></a>多任务异步协程实现遇到的问题</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">request</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;正在下载&#x27;</span>, url)</span><br><span class="line">    <span class="comment"># 在异步协程中如果出现了同步模块相关的代码，那么就无法实现异步</span></span><br><span class="line">    <span class="comment"># time.sleep(2)</span></span><br><span class="line">    <span class="comment"># 挡在asynico中遇到阻塞操作必须进行手动挂起</span></span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;下载完毕&#x27;</span>, url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line">urls = [</span><br><span class="line">    <span class="string">&#x27;www.baidu.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;www.sogou.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;www.goubanjia.com&#x27;</span></span><br><span class="line">]</span><br><span class="line"><span class="comment"># 任务列表，存放多个任务对象</span></span><br><span class="line">tasks = []</span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">    c = request(url)</span><br><span class="line">    <span class="comment"># asyncio.ensure_future()返回一个协程对象，以下语句是把协程对象封装到task(任务对象)中</span></span><br><span class="line">    task = asyncio.ensure_future(c)</span><br><span class="line">    tasks.append(task)</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line"><span class="comment"># 把任务列表封装到wait中</span></span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(time.time() - start)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="aiohttp模块的引出"><a href="#aiohttp模块的引出" class="headerlink" title="aiohttp模块的引出"></a>aiohttp模块的引出</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line">ulrs = [</span><br><span class="line">    <span class="string">&#x27;http://127.0.0.1:5000/bobo&#x27;</span>, <span class="string">&#x27;http://127.0.0.1:5000/jay&#x27;</span>, <span class="string">&#x27;http://127.0.0.1:5000/tom&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">get_page</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;正在下载&#x27;</span>, url)</span><br><span class="line">    <span class="comment"># requests.get是基于同步，必须使用居于异步的网络请求模块进行指定url的请求发送</span></span><br><span class="line">    <span class="comment"># aiohttp:基于异步网络请求的模块</span></span><br><span class="line">    response = requests.get(url=url)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;下载完毕：&#x27;</span>, response.text)</span><br><span class="line"></span><br><span class="line">tasks = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> ulrs:</span><br><span class="line">    c = get_page(url)</span><br><span class="line">    task = asyncio.ensure_future(c)</span><br><span class="line">    tasks.append(task)</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"></span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;总耗时：&#x27;</span>, end - start)</span><br></pre></td></tr></table></figure><h1 id="aiohttp实现多任务异步爬虫"><a href="#aiohttp实现多任务异步爬虫" class="headerlink" title="aiohttp实现多任务异步爬虫"></a>aiohttp实现多任务异步爬虫</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line">ulrs = [</span><br><span class="line">    <span class="string">&#x27;http://127.0.0.1:5000/bobo&#x27;</span>, <span class="string">&#x27;http://127.0.0.1:5000/jay&#x27;</span>, <span class="string">&#x27;http://127.0.0.1:5000/tom&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">get_page</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;正在下载&#x27;</span>, url)</span><br><span class="line">    <span class="comment"># requests.get是基于同步，必须使用居于异步的网络请求模块进行指定url的请求发送</span></span><br><span class="line">    <span class="comment"># aiohttp:基于异步网络请求的模块</span></span><br><span class="line">    <span class="comment"># response = requests.get(url=url)</span></span><br><span class="line">    <span class="comment"># 用aiohttp.ClientSession()返回一个session对象</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">        <span class="comment"># 使用session对象进行请求发送,返回一个响应对象</span></span><br><span class="line">        <span class="comment"># get()发送的是get请求,post()发送的是post请求,其参数处理分别是:params/data,也可以进行ua(headers=header)和代理IP反爬封装，其中代理ip参数的写法是：proxy:&#x27;http://ip:port&#x27;</span></span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> <span class="keyword">await</span> session.get(url) <span class="keyword">as</span> response:<span class="comment"># 由于get()比较耗时,需要挂起</span></span><br><span class="line">            <span class="comment"># text()返回字符串形式的响应数据</span></span><br><span class="line">            <span class="comment"># read()返回二进制形式的响应数据</span></span><br><span class="line">            <span class="comment"># json()返回的是json()对象</span></span><br><span class="line">            <span class="comment"># 注意：获取响应数据操作之前一定要使用await进行手动挂起</span></span><br><span class="line">            page_text = <span class="keyword">await</span> response.text()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;下载完毕：&#x27;</span>, page_text)</span><br><span class="line"></span><br><span class="line">tasks = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> ulrs:</span><br><span class="line">    c = get_page(url)</span><br><span class="line">    task = asyncio.ensure_future(c)</span><br><span class="line">    tasks.append(task)</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"></span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;总耗时：&#x27;</span>, end - start)</span><br></pre></td></tr></table></figure><h1 id="selenium简介"><a href="#selenium简介" class="headerlink" title="selenium简介"></a>selenium简介</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-15_21-19-04.png"                                     ></p><h1 id="selenium使用流程及其初试"><a href="#selenium使用流程及其初试" class="headerlink" title="selenium使用流程及其初试"></a>selenium使用流程及其初试</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-15_22-33-07.png"                                     ></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="comment"># 实例化一个浏览器对象,(传入浏览器的驱动程序)</span></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="comment"># 让浏览器发起一个指定url对应请求</span></span><br><span class="line">bro.get(<span class="string">&#x27;www.baidu.com&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># page_source 获取浏览器当前页面的页面源码数据</span></span><br><span class="line">page_text = bro.page_source</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解析企业名称</span></span><br><span class="line">tree = etree.HTML(page_text)</span><br><span class="line">li_list = tree.xpath(<span class="string">&#x27;//ul[@id=&quot;gzlist&quot;]/li&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">    name = li.xpath(<span class="string">&#x27;./dl/@title&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(name)</span><br><span class="line">sleep(<span class="number">6</span>)</span><br><span class="line"><span class="comment"># 关闭浏览器</span></span><br><span class="line">bro.quit()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-16_15-51-44.png"                                     ></p><h1 id="selenium处理iframe"><a href="#selenium处理iframe" class="headerlink" title="selenium处理iframe"></a>selenium处理iframe</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-16_19-35-51.png"                                     ></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="comment"># 导入动作链对应的类</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ActionChains</span><br><span class="line"></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">&#x27;./chromedriver.exe&#x27;</span>)</span><br><span class="line">bro.get(<span class="string">&#x27;https://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果定位的标签是存在于iframe标签中的则必须通过如下操作再进行标签定位</span></span><br><span class="line">bro.switch_to.frame(<span class="string">&#x27;iframeResult&#x27;</span>)<span class="comment"># 切换浏览器标签定位的作用域</span></span><br><span class="line">div = bro.find_element_by_id(<span class="string">&#x27;draggable&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 动作链</span></span><br><span class="line">action = ActionChains(bro)</span><br><span class="line"><span class="comment"># 点击长按指定的标签</span></span><br><span class="line">action.click_and_hold(div)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="comment"># perform()立即执行动作链操作</span></span><br><span class="line">    <span class="comment"># move_by_offset(x,y)x水平方向，y竖直方向</span></span><br><span class="line">    action.move_by_offset(<span class="number">17</span>, <span class="number">0</span>).perform()</span><br><span class="line">    sleep(<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 释放动作链</span></span><br><span class="line">action.release()</span><br><span class="line"></span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure><h1 id="selenium模拟登陆"><a href="#selenium模拟登陆" class="headerlink" title="selenium模拟登陆"></a>selenium模拟登陆</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">&#x27;./chromedriver.exe&#x27;</span>)</span><br><span class="line">bro.get(<span class="string">&#x27;http://qzone.qq.com/&#x27;</span>)</span><br><span class="line">bro.switch_to.frame(<span class="string">&#x27;login_frame&#x27;</span>)</span><br><span class="line">a_tag = bro.find_element_by_id(<span class="string">&#x27;switcher_plogin&#x27;</span>)</span><br><span class="line">a_tag.click()</span><br><span class="line"></span><br><span class="line">usserName_tag = bro.find_element_by_id(<span class="string">&#x27;u&#x27;</span>)</span><br><span class="line">password_tag = bro.find_element_by_id(<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line">sleep(<span class="number">1</span>)</span><br><span class="line">usserName_tag.send_keys(<span class="string">&#x27;2565706797&#x27;</span>)</span><br><span class="line">sleep(<span class="number">1</span>)</span><br><span class="line">password_tag.send_keys(<span class="string">&#x27;212331857&#x27;</span>)</span><br><span class="line">btn = bro.find_element_by_id(<span class="string">&#x27;login_button&#x27;</span>)</span><br><span class="line">btn.click()</span><br><span class="line"></span><br><span class="line">sleep(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure><h1 id="selenium实现无头浏览器和规避检测"><a href="#selenium实现无头浏览器和规避检测" class="headerlink" title="selenium实现无头浏览器和规避检测"></a>selenium实现无头浏览器和规避检测</h1><p>无头浏览器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="comment"># 实现无可视化界面</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现无可视化界面的操作</span></span><br><span class="line">chrome_options = Options()</span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;--disable-gpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">&#x27;./chromedriver.exe&#x27;</span>, chrome_options=chrome_options)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 无可视化界面（无头浏览器）</span></span><br><span class="line">bro.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(bro.page_source)</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure><p>规避检测</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="comment"># 实现无可视化界面</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="comment"># 实现规避检测</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ChromeOptions</span><br><span class="line"><span class="comment"># 实现无可视化界面的操作</span></span><br><span class="line">chrome_options = Options()</span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;--disable-gpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现规避检测</span></span><br><span class="line">option = ChromeOptions()</span><br><span class="line">option.add_experimental_option(<span class="string">&#x27;excludeSwitches&#x27;</span>, [<span class="string">&#x27;enable-automation&#x27;</span>])</span><br><span class="line"><span class="comment"># 如何实现让selenium规避被检测的风险</span></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">&#x27;./chromedriver.exe&#x27;</span>, chrome_options=chrome_options,options=option)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 无可视化界面（无头浏览器）</span></span><br><span class="line">bro.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(bro.page_source)</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure><h1 id="scrapy框架初识"><a href="#scrapy框架初识" class="headerlink" title="scrapy框架初识"></a>scrapy框架初识</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-22_23-59-31.png"                                     ></p><h1 id="scrapy基本使用"><a href="#scrapy基本使用" class="headerlink" title="scrapy基本使用"></a>scrapy基本使用</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-23_07-23-02.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-23_07-24-16.png"                                     ></p><p>输出response发现没有信息，这是因为setting中遵守了robos.txt,需要将他改为False</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-23_07-26-54.png"                                     ></p><p>如果只想显示响应数据可以在终端中执行以下命令：<br>scrapy crawl first –nolog</p><p>但是这种方法不会输出错误</p><p>我们可以在配置文件(setting)中添加一下代码</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-23_07-31-44.png"                                     ></p><h1 id="scrapy数据解析操作"><a href="#scrapy数据解析操作" class="headerlink" title="scrapy数据解析操作"></a>scrapy数据解析操作</h1><ol><li><p>创建项目</p><p>scrapy startproject qiutupro</p></li><li><p>创建爬虫代码编写文件</p><p>scrapy genspider qiutu <a class="link"   href="http://www.xx.com/" >www.xx.com<i class="fas fa-external-link-alt"></i></a></p></li><li><p>修改settings.py </p><p>添加user-agent</p><p>修改robotstxt_obey的值为false</p></li><li><p>编写qiutu.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QiutuSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;qiutu&#x27;</span></span><br><span class="line">    <span class="comment"># allowed_domains = [&#x27;www.xxx.com&#x27;]</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.qiushibaike.com/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        li_list = response.xpath(<span class="string">&#x27;//div[@class=&quot;recommend-article&quot;]//li&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">            <span class="comment"># xpath返回的是列表， 但列表元素一定是seletor类型的对象</span></span><br><span class="line">            <span class="comment"># extract可以将selector对象中data参数存储的字符串提取出来</span></span><br><span class="line">            authot = li.xpath(<span class="string">&#x27;./div/div/a/span/text()&#x27;</span>)[<span class="number">0</span>].extract()</span><br><span class="line">            <span class="comment"># 列表调用了extract之后,则表示将列表中每一个seledtor对象中的data对象对应的字符串提取了出来</span></span><br><span class="line">            content = li.xpath(<span class="string">&#x27;./div/a/text()&#x27;</span>).extract()</span><br><span class="line">            content = <span class="string">&#x27;&#x27;</span>.join(content)</span><br><span class="line">            <span class="built_in">print</span>(authot, content)</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>response.xpath 与etree下面的xpath有所不同，其返回的是列表且其中是selector对象，要用extract()方法进行转换字符串， 如果可以保证列表中只有一个元素也可以用extract_first()进行转换</p><h1 id="基于终端指令的持久化存储"><a href="#基于终端指令的持久化存储" class="headerlink" title="基于终端指令的持久化存储"></a>基于终端指令的持久化存储</h1><p>基于中断指令的持久化存储只能通过parse函数的返回值来存储</p><p>具体实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QiutuSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;qiutu&#x27;</span></span><br><span class="line">    <span class="comment"># allowed_domains = [&#x27;www.xxx.com&#x27;]</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.qiushibaike.com/&#x27;</span>]</span><br><span class="line">    <span class="comment"># all_data = []</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        all_data = []</span><br><span class="line">        li_list = response.xpath(<span class="string">&#x27;//div[@class=&quot;recommend-article&quot;]//li&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">            <span class="comment"># xpath返回的是列表， 但列表元素一定是seletor类型的对象</span></span><br><span class="line">            <span class="comment"># extract可以将selector对象中data参数存储的字符串提取出来</span></span><br><span class="line">            author = li.xpath(<span class="string">&#x27;./div/div/a/span/text()&#x27;</span>)[<span class="number">0</span>].extract()</span><br><span class="line">            <span class="comment"># 列表调用了extract之后,则表示将列表中每一个seledtor对象中的data对象对应的字符串提取了出来</span></span><br><span class="line">            content = li.xpath(<span class="string">&#x27;./div/a/text()&#x27;</span>).extract()</span><br><span class="line">            content = <span class="string">&#x27;&#x27;</span>.join(content)</span><br><span class="line">            dic = &#123;<span class="string">&#x27;author&#x27;</span>: author,</span><br><span class="line">                   <span class="string">&#x27;content&#x27;</span>: content</span><br><span class="line">                   &#125;</span><br><span class="line">            all_data.append(dic)</span><br><span class="line">            <span class="comment"># print(author, content)</span></span><br><span class="line">            <span class="comment"># break</span></span><br><span class="line">        <span class="keyword">return</span> all_data</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-23_18-55-53.png"                                     ></p><h1 id="基于管道的持久化存储"><a href="#基于管道的持久化存储" class="headerlink" title="基于管道的持久化存储"></a>基于管道的持久化存储</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="C:\Users\Administrator\Pictures\Snipaste_2020-09-23_19-05-18.png"                                     ></p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;爬虫的概念和价值&quot;&gt;&lt;a href=&quot;#爬虫的概念和价值&quot; class=&quot;headerlink&quot; title=&quot;爬虫的概念和价值&quot;&gt;&lt;/a&gt;爬虫的概念和价值&lt;/h1&gt;&lt;p&gt;&lt;img  
                     lazyload
         </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>关于Restuful API--未完待续</title>
    <link href="http://example.com/2022/04/25/%E5%85%B3%E4%BA%8ERestuful%20API/"/>
    <id>http://example.com/2022/04/25/%E5%85%B3%E4%BA%8ERestuful%20API/</id>
    <published>2022-04-25T15:52:30.000Z</published>
    <updated>2022-04-25T08:12:42.869Z</updated>
    
    <content type="html"><![CDATA[<h2 id="课程简介"><a href="#课程简介" class="headerlink" title="课程简介"></a>课程简介</h2><h3 id="课程目标"><a href="#课程目标" class="headerlink" title="课程目标"></a>课程目标</h3><ol><li>理解RESTful API的6个限制和若干最佳实践</li><li>掌握Koa2、Postman、MongoDB、JWT等技术</li><li>运用上述技术搭建仿知乎RESTful API</li><li>掌握阿里云现上部署方法</li></ol><h3 id="功能技术分析"><a href="#功能技术分析" class="headerlink" title="功能技术分析"></a>功能技术分析</h3><ol><li>RESTful API理论</li><li>Koa2</li><li>Postman</li><li>MongoDB</li><li>JWT</li><li>阿里云部署</li></ol><h3 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h3><ol><li>Node.js基础</li><li>ES6、ES7基础</li></ol><h3 id="重难点分析"><a href="#重难点分析" class="headerlink" title="重难点分析"></a>重难点分析</h3><ol><li>RESTful API理论</li><li>JWT认证原理</li><li>复杂的数据库关系(一对多、多对多等)</li></ol><h3 id="课程安排"><a href="#课程安排" class="headerlink" title="课程安排"></a>课程安排</h3><ol><li>RESTful API理论</li><li>Koa2、MongoDB、Postman、JWT等技术</li><li>使用这些技术进行仿知乎后台接口的搭建</li><li>阿里云线上部署</li></ol><h3 id="课程建议"><a href="#课程建议" class="headerlink" title="课程建议"></a>课程建议</h3><ol><li>理论部分做到自问自答</li><li>实战部分做到举一反三</li><li>不至于本课程，学习更多技术</li></ol><h2 id="REST简介"><a href="#REST简介" class="headerlink" title="REST简介"></a>REST简介</h2><h3 id="REST是什么"><a href="#REST是什么" class="headerlink" title="REST是什么"></a>REST是什么</h3><p>REST是一个风格，是一个<strong>万维网软件架构风格</strong>，风格这个关键词是非常重要的，因为它告诉了我们REST并不是什么协议，也并不是什么硬性的规范，它仅仅是一种架构风格而已，那么这种风格是用来干什么的呢?</p><p>很显然它既然是万维网软件架构风格，那么它必然是用来架构万维网软件的，换句话来说，它就是<strong>用来创建网络服务</strong>的</p><h3 id="为何叫REST"><a href="#为何叫REST" class="headerlink" title="为何叫REST?"></a>为何叫REST?</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/07/kDMarHnjZ8WXKoJ.png"                      alt="image.png"                ></p><h3 id="依然不明白REST"><a href="#依然不明白REST" class="headerlink" title="依然不明白REST?"></a>依然不明白REST?</h3><p>到这还不明白没有关系，REST的字面意思其实很难表达它的精髓，所以仅仅通过字面解读是无法理解REST的，那么怎么办呢，我们可以通过REST的6个限制详细了解它，<strong>这6个限制是REST的精髓，是它的重中之重，在面试中会经常考到</strong></p><h4 id="来看看6个限制"><a href="#来看看6个限制" class="headerlink" title="来看看6个限制"></a>来看看6个限制</h4><h5 id="客户-服务器-Client-Server"><a href="#客户-服务器-Client-Server" class="headerlink" title="客户-服务器(Client-Server)"></a>客户-服务器(Client-Server)</h5><p>也叫CS架构，这个限制其实现在已经非常常见了，现在几乎没有什么不是CS架构的，所以它也是没有任何争议的，值得一提的是，这个限制的本质其实是一种软件架构思想叫做<strong>关注点分离</strong>，所谓关注点分离就是各扫门前雪，自己管好自己的事，在这里指的是<strong>服务端专注数据存储，提高了简单性，而前端专注用户界面，提高了可移植性</strong></p><p>这里用到了一些专有名词，简单性和可移植性，这来着REST作者的博士论文</p><p><strong>简单性</strong>其实就是<strong>让服务端的代码更简单</strong>，那么为什么更简单了呢，因为在过去，服务端还要渲染页面，还要数据存储，那么现在它就什么都不需要管了，它不用管用户界面这一块，只要写好数据存储的逻辑就行了，所以说就更简单了</p><p><strong>可移植性</strong>就是说一个软件<strong>能够很方便地移植到其它平台</strong>，为什么在这里说它更方便移植了呢，这是因为在过去我们的前端其实都是在操作系统里写的那些软件，那时候前端还需要管一些数据存储一些计算一些很复杂的东西，现在的前端就是在浏览器中，不用管一些复杂的计算过程，只需要调用接口，渲染用户界面即可</p><h5 id="无状态-Stateless"><a href="#无状态-Stateless" class="headerlink" title="无状态(Stateless)"></a>无状态(Stateless)</h5><ol><li><p>所有用户会话信息都保存在客户端</p></li><li><p>每次请求必须包括所有信息，不能依赖上下文信息</p><p>举个栗子吧:</p><p>比如说你在看一本小说，你看到某一页，你要进入小说的下一页，这时候你必须要把具体的页数告诉服务端，不能单纯地和服务端说我要进入下一页，因为服务端根本不知道你当前在第几页，你说下一页它根本就无法理解；所以就是说你这个<strong>请求必须要包括所有的信息，不能依赖你当前的上下文，这就是无状态</strong>，那么无状态有什么好处呢，那就是下面这一条:</p></li><li><p>服务端不用保存会话信息，提升了简单性、可靠性、可见性</p><p>简单性刚才已经说了，也就是服务端少了很多代码，那么什么是可靠性呢，<strong>可靠性指的是一个软件的稳定程度，以及它从一次故障中恢复正常的能力</strong>，那么为什么说提升了可靠性呢，因为如果服务端要管理用户会话信息的话，一旦服务端出现故障，用户会话信息就会完全丢失，想要恢复起来几乎是不可能；如果<strong>服务端不管理用户会话信息，那么从故障中恢复起来就会非常容易</strong>，那么可见性指的是什么呢，可见性指的就是在软件工程中那些模块啊，接口之间的透明程度，为什么说提升了可见性呢，因为<strong>每次请求都必须包括所有信息，所以说接口之间就更加透明，因为我了解你所有信息，很多信息你都是传给我了，而不是存在服务端，这就更加透明了，可见性更高</strong></p></li></ol><h5 id="缓存-Cache"><a href="#缓存-Cache" class="headerlink" title="缓存(Cache)"></a>缓存(Cache)</h5><ol><li><p>所有服务端响应都要被标为可缓存或不可缓存</p><p>那么哪些可缓存哪些不可缓存呢，举个栗子吧，比如前端的JS、CSS、静态文件啥的就可以缓存，请求一次就行了，不用请求第二次，因为它们之间变化的可能性不大；那么对于一些动态的接口也就是一些经常会变的接口，那就是不能缓存的，因为如果缓存了，如果更新了那还是会显示老样子，用户就会说，我明明已经更新了啊，为什么还是老样子；那么缓存有什么作用呢，那就是下面这一条:</p></li><li><p>减少前后端交互，提升了性能</p><p>就比如说，<strong>如果没有缓存，那么你的一些JS文件每次都需要从服务端加载，速度很慢，如果缓存在浏览器里面的话，那么页面瞬间就能被打开</strong>，用户感知到的性能就得到了提升</p></li></ol><h5 id="统一接口-Uniform-Interface"><a href="#统一接口-Uniform-Interface" class="headerlink" title="统一接口(Uniform Interface)"></a>统一接口(Uniform Interface)</h5><p>这个限制是<strong>所有限制中最重要的一个</strong>，别的限制，如果不是在REST里面，你也可以遵循，比如说CS架构，现在生活中几乎都是CS架构了，也不一定是REST风格，别的风格也可以用到缓存啥的；但是只有<strong>统一接口突出了REST的特点</strong>，那么统一接口是什么意思呢，我们要分开来看:</p><p>统一:</p><p>所谓统一就是接口设计尽可能统一通用，也就是说接口的设计要遵循同一个规范，所有的接口都像是学校的学生，穿上了校服一样</p><p>提升了简单性:</p><p>既然所有的接口都很相似，那么学习起来肯定就很轻松了，比如说你学会了用户接口，那么你学话题接口、评论接口都是同样的规范，学起来肯定简单了</p><p>提升了可见性:</p><p>所有接口都遵循同一套规范，所以它们之间就更加相似更加透明了</p><p>那么接口又有什么作用呢?</p><p>前后端可以使用接口来进行通信，前端只需要调用接口就可以了，不需要再实现具体的代码；就比如说在过去，我想实现一个PDF转WORLD的功能，我就必须要把这个代码写在前端，一些windows或者mac的软件上，但现在，我只需要调用接口就可以实现了，我的接口和实现是解耦的，这样一来前后端就可以独立开发和迭代，两者只需要遵循同一套接口规范即可，谁也不用依赖谁，谁也不用等谁；就比如说如果在你的团队里面前端说后端这个接口没写完，我根本就没法开发，你就可以告诉他 ，那要接口是干嘛的，接口就是让前后端可以独立开发迭代的，让你们之间是可以解耦的，如果后端没有把接口实现完，可以先让它先给前端一个假数据啊，只要遵循接口规范就可以了，这是接口的作用</p><h5 id="分层系统-Layered-System"><a href="#分层系统-Layered-System" class="headerlink" title="分层系统(Layered System)"></a>分层系统(Layered System)</h5><p>这个限制的意思是，软件架构是分很多层的，而且<strong>每一层只知道相邻一层，后面隐藏的就不知道了</strong>，比如说客户端不知道是和代理还是真实服务器通信，客户端只知道自己最相邻的一层也就是接口，在这里呢，代理就可以算分层系统中的一层，同学们了解代理是什么嘛，就比如你想翻墙去看国外的一些网站，或者说你在家里想连接公司的内网进行办公，这时候你都需要用到代理，看起来你好像访问的还是谷歌、Facebook、YouTube但是你已经从代理那一层绕了一圈了才到了真实的服务器，这个分层系统远不止代理这么简单，在阿里巴巴这个企业有一个部门叫中间件，这个部门号称是阿里做技术的最想去的一个部门或者说那些做技术的最想去的一个部门，因为他们不用关心业务逻辑，只需要做一些中间件，也就是这些分层系统中的层；那么他们具体都做了哪些层呢，比如说有安全层、负载均衡、缓存层等，所谓安全层就是可以提前终止掉不安全的请求，另外有一个特别著名的层叫做负载均衡，所谓负载均衡就是说，如果你的软件或者你的网站用户量特别大，就像双十一那样，有很多很多请求，那你就要用很多服务器，让它们去共同分担这些流量，负载均衡这一层就是用来管理这些流量分发的，比如说这台服务器吃紧了，顶不住了，要挂了，怎么办呢， 负载均衡这一层就是把流量转到下一台服务器上，这就是负载均衡这一层的作用；缓存层一般就是缓存一些静态文件，这个前面也提到过</p><h5 id="按需代码-Code-On-Demand-可选"><a href="#按需代码-Code-On-Demand-可选" class="headerlink" title="按需代码(Code-On_Demand 可选)"></a>按需代码(Code-On_Demand 可选)</h5><p>这个限制是可选的，它也不是很重要，但因为是6大限制之一，所以说我们为了完整性还是提到了它，所谓按需代码指的就是客户端可以下载运行服务端传来的代码(比如JS)，比如你可以服务端给你传一段JS字符串，然后你在浏览器里面执行一下，执行JS的方法是<code>eval</code>，那么这个按需代码有什么好处呢，它通过减少一些功能，简化了客户端，也就是说有些逻辑，前端不需要自己去写，交给服务端就好了，服务端给你传过来执行一下就行了，所以说简化了客户端</p><h4 id="统一接口的限制"><a href="#统一接口的限制" class="headerlink" title="统一接口的限制"></a>统一接口的限制</h4><p>在前面的内容中，我们讲到了REST的6个限制，其中有一个很重要的限制是统一接口的限制，里面讲到了在REST风格中，接口都要设计的尽可能得统一，那么问题来了，接口都被统一成什么样了，这一节我们就要回答这个问题，也就是统一接口的限制，其实在这里应该是属于子限制，因为之前已经有6个限制了，而这属于限制里面的限制，也就是统一接口限制里面的子限制，用大白话说呢，就是想让大家看下REST风格的接口应该设计成什么样</p><h5 id="资源的标识"><a href="#资源的标识" class="headerlink" title="资源的标识"></a>资源的标识</h5><ol><li><p>资源是任何可以命名的事物，比如用户、评论等</p><p>REST整个都是围绕资源展开的，不像其他的是围绕动词展开的，REST是围绕名词展开的</p></li><li><p>每个资源可以通过URI被唯一地标识</p><ul><li><a class="link"   href="https://api.github.com/users" >https://api.github.com/users<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="https://api.github.com/users/lewis617" >https://api.github.com/users/lewis617<i class="fas fa-external-link-alt"></i></a></li></ul></li></ol><h5 id="通过表述来操作资源"><a href="#通过表述来操作资源" class="headerlink" title="通过表述来操作资源"></a>通过表述来操作资源</h5><ol><li><p>表述就是Representation，比如JSON、XML等</p><p>上面这句话可以反过来理解，也就成了下面这句:</p></li><li><p>客户端不能直接操作(比如MySQL)服务器资源</p></li><li><p>客户端只能通过表述(比如JSON)来操作资源</p><p>我们可以以GitHub为例来看看通过表述来操作资源，这是我找的一个网站: <a class="link"   href="http://docs2.lfe.io/v3/#http-verbs" >http://docs2.lfe.io/v3/#http-verbs<i class="fas fa-external-link-alt"></i></a></p></li></ol><h5 id="自描述消息"><a href="#自描述消息" class="headerlink" title="自描述消息"></a>自描述消息</h5><p>每个消息(请求或响应)必须提供足够的信息让接受者理解</p><p>那么这个消息具体又指什么呢，大概有如下几种:</p><p>媒体类型，也就是content-type(application/json、application/xml)</p><p>HTTP 方法: GET(查)、POST(增)、DELETE(删)</p><p>是否缓存: Cache-Control</p><p>我们同样可以以这个网站来看看: <a class="link"   href="http://docs2.lfe.io/v3/#http-verbs" >http://docs2.lfe.io/v3/#http-verbs<i class="fas fa-external-link-alt"></i></a></p><h5 id="超媒体作为应用状态引擎"><a href="#超媒体作为应用状态引擎" class="headerlink" title="超媒体作为应用状态引擎"></a>超媒体作为应用状态引擎</h5><p>超媒体就是带文字的链接，应用状态指的是一个网页，引擎指的是驱动、跳转，那么合起来就是点击链接跳转到另一个网页，就是这个API点击后会跳转</p><h2 id="RESTful-API简介"><a href="#RESTful-API简介" class="headerlink" title="RESTful API简介"></a>RESTful API简介</h2><h3 id="什么是RESTful-API"><a href="#什么是RESTful-API" class="headerlink" title="什么是RESTful API?"></a>什么是RESTful API?</h3><p>符合REST架构风格的API，API指的是应用编程接口</p><h3 id="RESTful-API具体什么样子"><a href="#RESTful-API具体什么样子" class="headerlink" title="RESTful API具体什么样子"></a>RESTful API具体什么样子</h3><p>主要以以下三方面组成:</p><ol><li>基本的URI，如: <a class="link"   href="https://api.github.com/users" >https://api.github.com/users<i class="fas fa-external-link-alt"></i></a></li><li>标准的HTTP方法，如GET、POST、PUT、PATCH、DELETE</li><li>传输的数据媒体类型，如: JSON，XML</li></ol><h3 id="现实举例"><a href="#现实举例" class="headerlink" title="现实举例"></a>现实举例</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/07/gNxH2pRW6BTJl8y.png"                      alt="image.png"                ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/07/RwaqdKhJo9k2NPl.png"                      alt="image.png"                ></p><p>PATCH是部分更新，PUT是整体更新</p><h2 id="RESTful-API设计最佳实践"><a href="#RESTful-API设计最佳实践" class="headerlink" title="RESTful API设计最佳实践"></a>RESTful API设计最佳实践</h2><h3 id="请求设计规范"><a href="#请求设计规范" class="headerlink" title="请求设计规范"></a>请求设计规范</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/07/SA7gKdOBNLv36pq.png"                      alt="image.png"                ></p><h3 id="响应设计规范"><a href="#响应设计规范" class="headerlink" title="响应设计规范"></a>响应设计规范</h3><p>应该来说会有以下这几个大点:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/07/CVZ52Fgyvt1uk8A.png"                      alt="image.png"                ></p><h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><p>使用HTTPS: 现在几乎所有的网站都开始往HTTPS发展了，因为HTTP是容易被篡改的</p><p>使用鉴权: 也就是需要先登录,保证用户的数据安全</p><p>使用限流: 是为了防止那些想故意攻击你网站的，他们会不停地调用接口，让你的服务器撑不下去，最后挂掉；为了防止这类人，我们可以在接口中加一些限流的措施，比如在分层系统里面专门加一个限流的层</p><p>同样参见这个网站: <a class="link"   href="http://docs2.lfe.io/v3/#http-verbs" >http://docs2.lfe.io/v3/#http-verbs<i class="fas fa-external-link-alt"></i></a></p><h3 id="开发者友好"><a href="#开发者友好" class="headerlink" title="开发者友好"></a>开发者友好</h3><ul><li><p>文档</p><p>共享出一份文档</p></li><li><p>超媒体(这个前面提到过)</p></li></ul><h2 id="Koa简介"><a href="#Koa简介" class="headerlink" title="Koa简介"></a>Koa简介</h2><h3 id="一句话简介"><a href="#一句话简介" class="headerlink" title="一句话简介"></a>一句话简介</h3><p>老外的产品就喜欢搞个一句话简介</p><ul><li><p>基于Node.js的下一代Web框架</p><p>基于Node.js这说明Koa基于Node.js模块，下一代表示正蚕食第一代Web框架Express的市场，因为Koa更好用，Koa是一个Web框架，不是我们所熟知的用JS写的命令行工具或算法</p></li></ul><h3 id="官网简介"><a href="#官网简介" class="headerlink" title="官网简介"></a>官网简介</h3><p>链接直达: <a class="link"   href="https://koa.bootcss.com/" >https://koa.bootcss.com/<i class="fas fa-external-link-alt"></i></a></p><p>总结:</p><ul><li>由Express幕后原班人马打造</li><li>Web应用和API开发领域</li><li>更小、更富有表现、更健壮</li><li>利用async函数，丢弃回调函数</li></ul><p>为什么要使用async函数，之前都是使用回调函数的，因为在JavaScript里面，如果多个异步串在一起就会出现回调地狱，写出来的代码非常丑，可读性非常差，自从有了async语法之后，写这种异步的逻辑看起来就和同步一样，非常的简洁，可读性大大提高</p><ul><li>增强错误处理: try…catch…</li></ul><p>也正是使用了async函数，使得代码就和同步一样，我们就可以用try…catch…进行一个错误处理</p><ul><li>没有捆绑任何中间件</li></ul><p>也就是说，你使用koa本身其实几乎什么都做不了，无法实现路由，甚至都无法实现一个静态服务器，但是不用担心，Koa社区里面有大量的中间件，利用这些中间件我们可以做几乎所有的事情；那么问题来了，没有捆绑任何中间件是不是很不方便啊，我们每次使用中间件还要再次安装啊，我的回答是，没错，但这样也有很多好处，就像买东西一样，我们非常不喜欢商家捆绑销售一些东西，这样的话我们就可以根据自己的实际需求来选择我们需要的商品，而不是被强迫购买一些商品；koa在这里的意图也是这样的，它并不想捆绑一些内置中间件，它希望开发者能够按照他自己的意愿使用他需要的中间件</p><ul><li><p>快速而愉快地编写程序</p><p>这是画的一个大饼哈哈哈哈</p></li></ul><h2 id="安装Koa并搭建首个Koa程序"><a href="#安装Koa并搭建首个Koa程序" class="headerlink" title="安装Koa并搭建首个Koa程序"></a>安装Koa并搭建首个Koa程序</h2><h3 id="初始化项目"><a href="#初始化项目" class="headerlink" title="初始化项目"></a>初始化项目</h3><p>在windows电脑上推荐使用Git-bash这个命令行工具来初始化项目，因为在这里面我们可以使用上Linux相关命令</p><p>我就在我的Python_LHJ中创建一个项目文件夹为zhihu-api，使用如下命令:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir zhihu-api</span><br></pre></td></tr></table></figure><p>如果这个时候你想切换到vscode来写代码，就可以使用命令<code>code zhihu-api</code>来切换到vscode中来</p><p>然后我们需要进入到该项目文件夹并初始化该项目，使用如下命令:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm init</span><br></pre></td></tr></table></figure><p>这个命令主要就是创建了一个<code>package.json</code>，这里面保存了项目的名称、描述、作者、依赖啊什么的，它最重要的功能其实是帮我们管理依赖，我们来看看它的用法:</p><p>你输入这个命令后，它会以对话的形式来问你你想要输入哪些东西，第一个问题是包名，默认是和项目名一样的，这个通常保持默认即可，然后会要求我们输入描述，下面的我们都可保持默认，直接按回车即可:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/07/QrNgVIxyJ4pStwc.png"                      alt="image.png"                ></p><p>我们来看看package.json长啥样:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;name&quot;</span>: <span class="string">&quot;zhihu-api&quot;</span>,</span><br><span class="line">  <span class="string">&quot;version&quot;</span>: <span class="string">&quot;1.0.0&quot;</span>,</span><br><span class="line">  <span class="string">&quot;description&quot;</span>: <span class="string">&quot;仿知乎RESTful API&quot;</span>,</span><br><span class="line">  <span class="string">&quot;main&quot;</span>: <span class="string">&quot;index.js&quot;</span>,</span><br><span class="line">  <span class="string">&quot;scripts&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;test&quot;</span>: <span class="string">&quot;echo \&quot;Error: no test specified\&quot; &amp;&amp; exit 1&quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;author&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">  <span class="string">&quot;license&quot;</span>: <span class="string">&quot;ISC&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是它最重要的作用还是管理依赖，那么怎么管理依赖呢，我们就通过</p><h3 id="安装Koa"><a href="#安装Koa" class="headerlink" title="安装Koa"></a>安装Koa</h3><p>安装Koa来看看它怎么管理依赖，使用以下命令安装:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i koa --save</span><br></pre></td></tr></table></figure><p>或者:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install koa --save</span><br></pre></td></tr></table></figure><p><code>--save</code>参数表示将会保存到<code>package.json</code>中，那么保存到里面有什么好处呢，别人拿到你的项目的话就不用再执行<code>npm i koa</code>了，他只需要简单地在目录下执行<code>npm i</code>就行了，为什么呢，因为刚刚的<code>--save</code>已经把<code>koa</code>的安装信息已经保存到了<code>package.json</code>里面了，所以说你执行<code>npm i</code>的时候就会自动安装这个<code>koa</code>了</p><h3 id="编写Hello-World"><a href="#编写Hello-World" class="headerlink" title="编写Hello World"></a>编写Hello World</h3><p>安装完了<code>koa</code>我们如何使用它呢，使用<code>koa</code>非常简单，我们先新建一个<code>index.js</code>文件，这个文件的名称是可以随便写的，新建完这个<code>index.js</code>后，我们先引用<code>koa</code>，那我们直上代码:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Koa = <span class="built_in">require</span>(<span class="string">&#x27;koa&#x27;</span>)  <span class="comment">// 引入koa模块，const后面的变量名一般以大写字母开头，因为它可以看成是一个类，类就是首字母大写</span></span><br><span class="line"><span class="keyword">const</span> app = <span class="keyword">new</span> Koa()  <span class="comment">// 实例化一个对象，app是应用程序(application)的简写，我们待会儿想搭建的应用程序都在这个app里面</span></span><br><span class="line"></span><br><span class="line">app.use(<span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;  <span class="comment">// use方法里面可以传递一个函数，这个函数就是我们所说的中间件</span></span><br><span class="line">    ctx.body = <span class="string">&#x27;hello world!&#x27;</span>  <span class="comment">// 在中间件里面，我们就可以返回返回值了，在这里这个函数接受一个参数叫ctx，它是Context上下文的缩写，我们只需要给这个参数的.body属性赋值就可以</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>);  <span class="comment">// 指定应用的监听端口</span></span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/07/mn6fKXYADey2ti3.png"                      alt="image.png"                ></p><p>如上图所示，我们在运行后控制台是没有任何提示信息的，这个状态就是已经运行起来了，然后我们每次修改代码之后，都要重启服务才能在浏览器看到更改的效果，时间长了次数多了未免会有点繁琐，然后我们可以安装一个小工具，第一次使用这个工具运行了项目之后，后面如果代码又改动这个小工具就会帮我们自动重启，而不用手动了</p><h3 id="学习自动重启"><a href="#学习自动重启" class="headerlink" title="学习自动重启"></a>学习自动重启</h3><p>安装命令为:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i nodemon --save-dev</span><br></pre></td></tr></table></figure><p>这里要注意这个参数<code>--save-dev</code>，<code>--save</code>表示把这个模块加入<code>package.json</code>，后面如果有人使用该项目直接<code>npm i</code>即可完成此项目所有模块的安装，<code>-dev</code>表示它只在开发阶段使用，如果部署到服务器上，是不需要重启的</p><p>之前我们运行项目是<code>node index.js</code>，那么在安装完<code>nodemon</code>后，把<code>node</code>改为<code>nodemon</code>即可</p><p>但是当我们使用<code>nodemon index.js</code>时可能会报一个错:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;nodemon&#x27;不是内部或外部命令，也不是可运行的程序或批处理文件</span><br></pre></td></tr></table></figure><p>这是为什么呢</p><p>因为我们把<code>nodemon</code>安装到了<code>node_modules</code>里面，所以我们直接访问不到，我们要使用可能要先在<code>package.json</code>里面写脚本，但是如果我们全局安装了，也就是使用了<code>npm i nodemon -g</code>这个命令安装，就可以直接使用了</p><p>我们可以在<code>package.json</code>中的<code>scripts</code>字典中新增一个<code>start</code>命令:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;scripts&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;start&quot;</span>: <span class="string">&quot;nodemon index.js&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后我们使用命令<code>npm start</code>就可以启动项目了，<code>start</code>命令实际上就是指代了<code>nodemon index.js</code>命令</p><h2 id="Koa中间件与洋葱模型"><a href="#Koa中间件与洋葱模型" class="headerlink" title="Koa中间件与洋葱模型"></a>Koa中间件与洋葱模型</h2><p>本节以操作为主</p><h3 id="学习async-await"><a href="#学习async-await" class="headerlink" title="学习async await"></a>学习async await</h3><p>async await语法已经成了JavaScript的标准，所以说不管是在node.js还是在chrome的console面板，都可以直接使用这种语法</p><p>我们看看传统的实现，我们对比着来看看:</p><p>我们写的逻辑如下:</p><p>首先请求下github的用户列表接口，这是个异步，请求完之后，我们再请求下github的特定用户的列表接口，并把两次请求接口的结果都打印出来:</p> <figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 传统实现</span></span><br><span class="line">fetch(<span class="string">&#x27;//api.github.com/users&#x27;</span>).then(<span class="function"><span class="params">res</span> =&gt;</span> res.json()).then(<span class="function"><span class="params">json</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(json)</span><br><span class="line">    fetch(<span class="string">&#x27;//api.github.com/storm999&#x27;</span>).then(<span class="function"><span class="params">res</span> =&gt;</span> res.json()).then(<span class="function"><span class="params">json2</span> =&gt;</span> &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(json2)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>可以看到这里我们使用了一个嵌套，第一个json打印完毕之后就打印第二个了，但是我们会发现代码是比较丑的，这里只是请求了两个接口，如果是上十上百个就要一直嵌套了，上面代码运行结果如下: </p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/07/WtnuLfTNeA8ka9g.png"                      alt="image.png"                ></p><p>那么接下来我们就来看看如何使用async await语法来优化下上面的逻辑，首先，如果你要使用await的话，那么你必须在async的函数里面，直接上代码叭，如下所示:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">async</span>() =&gt; &#123;</span><br><span class="line">    <span class="keyword">const</span> res = <span class="keyword">await</span> fetch(<span class="string">&#x27;//api.github.com/users&#x27;</span>);</span><br><span class="line">    <span class="keyword">const</span> json = <span class="keyword">await</span> res.json();  <span class="comment">// 转成json依然是一个异步操作，所以需要加关键字await</span></span><br><span class="line">    <span class="built_in">console</span>.log(json)  <span class="comment">// 打印用户列表接口</span></span><br><span class="line">    <span class="keyword">const</span> res2 = <span class="keyword">await</span> fetch(<span class="string">&#x27;//api.github.com/users/storm666&#x27;</span>);</span><br><span class="line">    <span class="keyword">const</span> json2 = <span class="keyword">await</span> res2.json();  <span class="comment">// 转成json依然是一个异步操作，所以需要加关键字await</span></span><br><span class="line">    <span class="built_in">console</span>.log(json2 )  <span class="comment">// 打印特定用户接口</span></span><br><span class="line">&#125;)()  <span class="comment">// 这是一个立即执行函数</span></span><br></pre></td></tr></table></figure><p>在async await里面就不用在then里面写回调函数了，相比来说比较方便</p><p>我们可以明显感觉到用来异步之后的逻辑就会同步一样清晰明了，这就是async await的用法，这里只是用了async await一个典型的例子</p><h3 id="学习编写Koa中间件"><a href="#学习编写Koa中间件" class="headerlink" title="学习编写Koa中间件"></a>学习编写Koa中间件</h3><p>在编写Hello World一节里面我们就写了一个中间件，现在我们要学习写多个中间件，我们在写了下一个中间件后，发现这个中间件什么都没有打印；其实在koa里面，如果你想执行下一个中间件，那你必须要申明它，在ctx后面加个参数叫next，next就是下一个，next()也是一个异步的函数(返回了一个promise)，所以这里要使用async await关键字，如下图所示:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/25/JLWabkCVwmeZDYt.png"                      alt="image.png"                ></p><p>很明显可以知道是先打印2然后打印1，为了排除图标请求的干扰，我们可以使用fetch方法来看看结果:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/25/vhtZEx5TmFVz8pI.png"                      alt="image.png"                ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/25/3sCFS2DOQJrwyUu.png"                      alt="image.png"                ></p><p>这就是写多个中间件的执行顺序，这个中间件的执行顺序就像洋葱一样:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/25/WFuo36d4CSpsQNP.png"                      alt="image.png"                ></p><h2 id="路由简介"><a href="#路由简介" class="headerlink" title="路由简介"></a>路由简介</h2><h3 id="路由是什么"><a href="#路由是什么" class="headerlink" title="路由是什么"></a>路由是什么</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/25/eJAhQG5Dnaxu2Is.png"                      alt="image.png"                ></p><h3 id="为什么要用路由"><a href="#为什么要用路由" class="headerlink" title="为什么要用路由"></a>为什么要用路由</h3><p>路由指向了不同资源，以此来进行区分</p><h3 id="路由存在的意义"><a href="#路由存在的意义" class="headerlink" title="路由存在的意义"></a>路由存在的意义</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/25/ISkVKYOTXPCp6zH.png"                      alt="image.png"                ></p><h2 id="自己编写Koa路由中间件"><a href="#自己编写Koa路由中间件" class="headerlink" title="自己编写Koa路由中间件"></a>自己编写Koa路由中间件</h2><p>主要用于实现:</p><p>处理不同的URL，处理不同的HTTP方法，解析URL上的参数</p><p>路由为<code>/users</code>就返回这是用户列表页，路由为<code>/</code>就返回这是主页，两个都不匹配的话就返回404，代码如下:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/25/EmPgZBqk1OKCWYI.png"                      alt="image.png"                ></p><p>上面是一个较为简单的功能，下面我们在深入一点，像前面提到的那样，处理不同的HTTP方法，就是GET和POST方法作为区分，那我们就这么设计吧，getusers就返回用户列表页，如果是postusers就返回创建用户，两个都不匹配的话就是方法不允许，也就是返回405，代码如下:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/25/HQNgmD5osA1Ebwn.png"                      alt="image.png"                ></p><p>最后我们来看看如何解析URL上的参数，比如用户请求了一个users/userid，然后返回这是用户，然后加上id，代码如下:</p><p>这里是用的正则表达式，用的是JavaScript原生的match方法</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/25/njxod5HMhKzX6ul.png"                      alt="image.png"                ></p><h2 id="使用Koa-router实现路由"><a href="#使用Koa-router实现路由" class="headerlink" title="使用Koa-router实现路由"></a>使用Koa-router实现路由</h2><p>本节要点:</p><ul><li>更优雅地实现路由基本功能</li><li>演示一些高级路由功能，如前缀、多中间件</li></ul><p>要使用Koa-router首先我们需要先安装下它，使用如下命令安装:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i koa-router --save</span><br></pre></td></tr></table></figure><p>接下来就是使用了:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Koa = <span class="built_in">require</span>(<span class="string">&#x27;koa&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> Router = <span class="built_in">require</span>(<span class="string">&#x27;koa-router&#x27;</span>);  <span class="comment">// 引入&#x27;koa-router</span></span><br><span class="line"><span class="keyword">const</span> app = <span class="keyword">new</span> Koa();</span><br><span class="line"><span class="keyword">const</span> router = <span class="keyword">new</span> Router();  <span class="comment">// 实例化</span></span><br><span class="line"></span><br><span class="line">router.get(<span class="string">&#x27;/&#x27;</span>, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;  <span class="comment">// 写一个路由</span></span><br><span class="line">    ctx.body = <span class="string">&#x27;这是主页&#x27;</span>;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">router.get(<span class="string">&#x27;/users&#x27;</span>, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;这是用户列表&#x27;</span>;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">router.post(<span class="string">&#x27;/users&#x27;</span>, (ctx)) =&gt; &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;创建用户&#x27;</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">router.get(<span class="string">&#x27;/users/:id&#x27;</span>, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;这是用户&#x27;</span> $&#123;ctx.params.id&#125;;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.use(router.routers());  <span class="comment">// 需要把router注册到app里面</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>);</span><br></pre></td></tr></table></figure><p>上面我们通过代码更优雅地实现了路由的基本功能，现在我们来演示一些高级功能，比如前缀和高级中间件:<br>如果有了前缀的话，我们就不用每个路由都写个users了</p><p>首先我们需要再实例化一个新的router，这里就叫usersRouter吧，然后在里面配置一个参数prefix，也就是前缀，然后用usersRouter把下面的router替换掉，那就可以省略之前每个路由中的users了，如下代码所示:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Koa = <span class="built_in">require</span>(<span class="string">&#x27;koa&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> Router = <span class="built_in">require</span>(<span class="string">&#x27;koa-router&#x27;</span>);  <span class="comment">// 引入&#x27;koa-router</span></span><br><span class="line"><span class="keyword">const</span> app = <span class="keyword">new</span> Koa();</span><br><span class="line"><span class="keyword">const</span> router = <span class="keyword">new</span> Router();  <span class="comment">// 实例化</span></span><br><span class="line"><span class="keyword">const</span> usresRouter = <span class="keyword">new</span> Router(&#123; <span class="attr">prefix</span>: <span class="string">&#x27;users/&#x27;</span> &#125;);</span><br><span class="line"></span><br><span class="line">router.get(<span class="string">&#x27;/&#x27;</span>, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;  <span class="comment">// 写一个路由</span></span><br><span class="line">    ctx.body = <span class="string">&#x27;这是主页&#x27;</span>;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">usersRouter.get(<span class="string">&#x27;/&#x27;</span>, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;这是用户列表&#x27;</span>;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">usersRouter.post(<span class="string">&#x27;/&#x27;</span>, (ctx)) =&gt; &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;创建用户&#x27;</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">usersRouter.get(<span class="string">&#x27;/:id&#x27;</span>, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;这是用户&#x27;</span> $&#123;ctx.params.id&#125;;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.use(router.routers());  <span class="comment">// 需要把router注册到app里面</span></span><br><span class="line">app.use(usresRouter.routers())  <span class="comment">// 同样的注册下usresRouter</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>);</span><br></pre></td></tr></table></figure><p>那么前缀的好处第一个就是能大大简洁我们路由中路径的编写，使得路由能灵活变换，使用前缀能帮我们节约一些代码</p><p>接下来我们要实现一个多中间件的功能，多中间件通常用于用户校验或者是用户安全，下面我们伪造一个用户安全，用来说明多中间件，代码如下:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Koa = <span class="built_in">require</span>(<span class="string">&#x27;koa&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> Router = <span class="built_in">require</span>(<span class="string">&#x27;koa-router&#x27;</span>);  <span class="comment">// 引入&#x27;koa-router</span></span><br><span class="line"><span class="keyword">const</span> app = <span class="keyword">new</span> Koa();</span><br><span class="line"><span class="keyword">const</span> router = <span class="keyword">new</span> Router();  <span class="comment">// 实例化</span></span><br><span class="line"><span class="keyword">const</span> usresRouter = <span class="keyword">new</span> Router(&#123; <span class="attr">prefix</span>: <span class="string">&#x27;users/&#x27;</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义一个中间件</span></span><br><span class="line"><span class="keyword">const</span> auth = <span class="keyword">async</span> (ctx, next) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (ctx.url !== <span class="string">&#x27;/users&#x27;</span>)&#123;</span><br><span class="line">        ctx.throw(<span class="number">401</span>);  <span class="comment">// 显示报错信息</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">router.get(<span class="string">&#x27;/&#x27;</span>, auth, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;  <span class="comment">// 写一个路由</span></span><br><span class="line">    ctx.body = <span class="string">&#x27;这是主页&#x27;</span>;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">usersRouter.get(<span class="string">&#x27;/&#x27;</span>, auth, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;这是用户列表&#x27;</span>;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">usersRouter.post(<span class="string">&#x27;/&#x27;</span>, auth, (ctx)) =&gt; &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;创建用户&#x27;</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">usersRouter.get(<span class="string">&#x27;/:id&#x27;</span>, auth, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;这是用户&#x27;</span> $&#123;ctx.params.id&#125;;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.use(router.routers());  <span class="comment">// 需要把router注册到app里面</span></span><br><span class="line">app.use(usresRouter.routers())  <span class="comment">// 同样的注册下usresRouter</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>);</span><br></pre></td></tr></table></figure><h2 id="HTTP-options方法的作用是什么"><a href="#HTTP-options方法的作用是什么" class="headerlink" title="HTTP options方法的作用是什么?"></a>HTTP options方法的作用是什么?</h2><p>为什么要了解options方法的作用？首先这是一道面试题，很多面试官都喜欢通过这个来考察面试者对HTTP理解的深度以及对跨域理解的深度；其次就是它也可以帮助理解koa-router的allowedMethods的作用</p><p>下面我们言归正传，那么HTTP options方法的作用是什么呢？</p><p>第一它可以检测服务器所支持的请求方法，比如说我们之前实现的users这个接口，它支持get和post方法，并没有写其他方法，那么用户想知道users这个接口都支持哪些方法的话就可以使用options这个方法，比如:<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/25/FVKZiXWr8JjbQpn.png"                      alt="image.png"                ></p><p>第二呢，它可以在CORS里面进行预检请求，CORS是用作跨域的一个技术，但是这个技术可能只支持一个网站的其中的其中一部分的接口的其中一部分方法来跨域，那么如何知道这个方法是否可以跨域呢，在这里也可以使用options方法来提前检测下，如果允许跨域了，再发出真实的请求。</p><p>讲了options方法我们就可以顺水推舟来讲讲allowedMethod是的作用，这个方法的第一个作用就是用来响应options方法的，告诉它所支持的请求方法，当用户使用options方法请求某个接口，那么就会自动返回这个接口所支持的方法。</p><p>就以我们上面实现的users路由为例，本来是不支持options方法的的，我们如果直接使用options请求就会报错，我们可以加上<code>app.use(usersRouter.allowedMethods());</code>，再次请求就能返回此接口所支持的所有方法了，代码如下所示:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Koa = <span class="built_in">require</span>(<span class="string">&#x27;koa&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> Router = <span class="built_in">require</span>(<span class="string">&#x27;koa-router&#x27;</span>);  <span class="comment">// 引入&#x27;koa-router</span></span><br><span class="line"><span class="keyword">const</span> app = <span class="keyword">new</span> Koa();</span><br><span class="line"><span class="keyword">const</span> router = <span class="keyword">new</span> Router();  <span class="comment">// 实例化</span></span><br><span class="line"><span class="keyword">const</span> usresRouter = <span class="keyword">new</span> Router(&#123; <span class="attr">prefix</span>: <span class="string">&#x27;users/&#x27;</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义一个中间件</span></span><br><span class="line"><span class="keyword">const</span> auth = <span class="keyword">async</span> (ctx, next) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (ctx.url !== <span class="string">&#x27;/users&#x27;</span>)&#123;</span><br><span class="line">        ctx.throw(<span class="number">401</span>);  <span class="comment">// 显示报错信息</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">router.get(<span class="string">&#x27;/&#x27;</span>, auth, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;  <span class="comment">// 写一个路由</span></span><br><span class="line">    ctx.body = <span class="string">&#x27;这是主页&#x27;</span>;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">usersRouter.get(<span class="string">&#x27;/&#x27;</span>, auth, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;这是用户列表&#x27;</span>;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">usersRouter.post(<span class="string">&#x27;/&#x27;</span>, auth, (ctx)) =&gt; &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;创建用户&#x27;</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">usersRouter.get(<span class="string">&#x27;/:id&#x27;</span>, auth, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;这是用户&#x27;</span> $&#123;ctx.params.id&#125;;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.use(router.routers());  <span class="comment">// 需要把router注册到app里面</span></span><br><span class="line">app.use(usresRouter.routers())  <span class="comment">// 同样的注册下usresRouter</span></span><br><span class="line">app.use(usersRouter.allowedMethods());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>);</span><br></pre></td></tr></table></figure><p>allowedMethod的第二个作用就是它能相应的返回405和501</p><p>刚刚我们配置了allowedMethod，如果用options方法请求接口的话就会返回这个接口所支持的所有方法是get、post和head，但如果我用put来请求呢，这个时候接口就会自动返回405，405就代表这个请求方法不支持；如果用一些比较偏僻的请求方法去请求这个接口，就会返回501，这是因为Koa只支持一些主流的请求 方法，</p><h2 id="RESTful-API最佳实践–增删改查应该返回什么响应？"><a href="#RESTful-API最佳实践–增删改查应该返回什么响应？" class="headerlink" title="RESTful API最佳实践–增删改查应该返回什么响应？"></a>RESTful API最佳实践–增删改查应该返回什么响应？</h2><p>我们在前面的内容中实现了一些简单的路由，这部分内容我们要用路由实现一个完整的增删改查，并在增删改查的每一个接口中返回最适合它的一个响应；其实对查这个操作来说还是比较容易理解的，查列表那就返回一个数组，查单个信息就返回数组中某一项，这个很简单，那么增删改应该返回什么响应呢？在RESTful API最佳实践中，我们约定，增加和修改应该返回当前增加和修改的数据，通常就是一个对象，如果是删除的话因该返回一个204状态码，这个状态码代表没有内容，但是成功了。以上所说的只是RESTful API最佳实践，如果你非要返回其他内容，也是可以的，如果你不这么写就会显得另类和奇怪。</p><p>这部分内容我们实现一个增删改查，然后返回正确的响应，下面来看看代码:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Koa = <span class="built_in">require</span>(<span class="string">&#x27;koa&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> Router = <span class="built_in">require</span>(<span class="string">&#x27;koa-router&#x27;</span>);  <span class="comment">// 引入&#x27;koa-router</span></span><br><span class="line"><span class="keyword">const</span> app = <span class="keyword">new</span> Koa();</span><br><span class="line"><span class="keyword">const</span> router = <span class="keyword">new</span> Router();  <span class="comment">// 实例化</span></span><br><span class="line"><span class="keyword">const</span> usresRouter = <span class="keyword">new</span> Router(&#123; <span class="attr">prefix</span>: <span class="string">&#x27;users/&#x27;</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义一个中间件</span></span><br><span class="line"><span class="keyword">const</span> auth = <span class="keyword">async</span> (ctx, next) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (ctx.url !== <span class="string">&#x27;/users&#x27;</span>)&#123;</span><br><span class="line">        ctx.throw(<span class="number">401</span>);  <span class="comment">// 显示报错信息</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">router.get(<span class="string">&#x27;/&#x27;</span>, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;  <span class="comment">// 写一个路由</span></span><br><span class="line">    ctx.body = <span class="string">&#x27;这是主页&#x27;</span>;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">usersRouter.get(<span class="string">&#x27;/&#x27;</span>, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;这是用户列表&#x27;</span>;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">usersRouter.post(<span class="string">&#x27;/&#x27;</span>, (ctx)) =&gt; &#123;  <span class="comment">// 返回当前增加和修改的对象</span></span><br><span class="line">    ctx.body = &#123; <span class="attr">name</span>: <span class="string">&#x27;li&#x27;</span> &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">usersRouter.get(<span class="string">&#x27;/:id&#x27;</span>, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;</span><br><span class="line">    ctx.body = [&#123; <span class="attr">name</span>: <span class="string">&#x27;li&#x27;</span>&#125;, &#123; <span class="attr">name</span>: <span class="string">&#x27;hou&#x27;</span> &#125;];</span><br><span class="line">&#125;);</span><br><span class="line">    </span><br><span class="line">usersRouter.put(<span class="string">&#x27;/:id&#x27;</span>, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;</span><br><span class="line">    ctx.body = <span class="string">&#x27;这是用户&#x27;</span> $&#123;ctx.params.id&#125;;</span><br><span class="line">&#125;);</span><br><span class="line">    </span><br><span class="line">usersRouter.delete(<span class="string">&#x27;/:id&#x27;</span>, <span class="function">(<span class="params">ctx</span>) =&gt;</span> &#123;</span><br><span class="line">    ctx.status = <span class="number">204</span>;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.use(router.routers());  <span class="comment">// 需要把router注册到app里面</span></span><br><span class="line">app.use(usresRouter.routers())  <span class="comment">// 同样的注册下usresRouter</span></span><br><span class="line">app.use(usersRouter.allowedMethods());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>);</span><br></pre></td></tr></table></figure><h2 id="控制器简介"><a href="#控制器简介" class="headerlink" title="控制器简介"></a>控制器简介</h2><p>控制器就是拿到路由分配的任务，并执行，其实在前面部分的内容中，注册在路由中的那个中间件就是个控制器，所以在Koa中控制器也是一个中间件，那么我们为什么要用控制器呢，控制器主要分为三个方面:</p><ul><li>可以用来获取HTTP请求参数</li><li>然后它可以处理一些业务逻辑</li><li>它会根据不同情况发送不同的HTTP响应</li></ul><p>HTTP请求参数主要有两方面:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/25/YXRjpk5ZLxDME9O.png"                      alt="image.png"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;课程简介&quot;&gt;&lt;a href=&quot;#课程简介&quot; class=&quot;headerlink&quot; title=&quot;课程简介&quot;&gt;&lt;/a&gt;课程简介&lt;/h2&gt;&lt;h3 id=&quot;课程目标&quot;&gt;&lt;a href=&quot;#课程目标&quot; class=&quot;headerlink&quot; title=&quot;课程目标&quot;&gt;&lt;/a</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>hexo在Git上传时报ssh connect to host github.com port 22 Connection timed out</title>
    <link href="http://example.com/2022/04/25/hexo%E5%9C%A8Git%E4%B8%8A%E4%BC%A0%E6%97%B6%E6%8A%A5ssh%20connect%20to%20host%20github.com%20port%2022%20Connection%20timed%20out/"/>
    <id>http://example.com/2022/04/25/hexo%E5%9C%A8Git%E4%B8%8A%E4%BC%A0%E6%97%B6%E6%8A%A5ssh%20connect%20to%20host%20github.com%20port%2022%20Connection%20timed%20out/</id>
    <published>2022-04-25T06:22:30.000Z</published>
    <updated>2022-04-25T06:25:52.298Z</updated>
    
    <content type="html"><![CDATA[<p>今天在hexo上传时报了如下错误:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/25/eLT6D82btQrOizv.png"                      alt="image.png"                ></p><p>解决方案如下:</p><p>转载自csdn: <a class="link"   href="https://blog.csdn.net/hdm314/article/details/119947761" >https://blog.csdn.net/hdm314/article/details/119947761<i class="fas fa-external-link-alt"></i></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;今天在hexo上传时报了如下错误:&lt;/p&gt;
&lt;p&gt;&lt;img  
                     lazyload
                     src=&quot;/images/loading.svg&quot;
                     data-sr</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Nginx最新易懂教程--哔哩哔哩狂神说</title>
    <link href="http://example.com/2022/04/24/Nginx%E6%9C%80%E6%96%B0%E6%98%93%E6%87%82%E6%95%99%E7%A8%8B--%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E7%8B%82%E7%A5%9E%E8%AF%B4/"/>
    <id>http://example.com/2022/04/24/Nginx%E6%9C%80%E6%96%B0%E6%98%93%E6%87%82%E6%95%99%E7%A8%8B--%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E7%8B%82%E7%A5%9E%E8%AF%B4/</id>
    <published>2022-04-24T06:21:30.000Z</published>
    <updated>2022-04-24T09:02:32.634Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Nginx简介"><a href="#Nginx简介" class="headerlink" title="Nginx简介"></a>Nginx简介</h2><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/24/AzQuhOs5va2tXZW.png"                      alt="image.png"                ></p><p>同时提供Web服务和邮件服务，其特定是占用内存少(大概1M)，并发能力也好，支撑5万个并发连接数的响应，tomcat一般才五六百个，如果网站不是特别大，一个Nginx就够用了。</p><h2 id="正向代理和反向代理"><a href="#正向代理和反向代理" class="headerlink" title="正向代理和反向代理"></a>正向代理和反向代理</h2><p>Nginx第一个最核心的功能就是反向代理，在了解反向代理之前我们先来看看正向代理</p><p><strong>正向代理是代理客户端的</strong>，比方说你在你本机上装的VPN软件，这个VPN软件就是代理你的本机，通过VPN这个代理，才能去请求外网:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/24/3CmGs7ultvp8XTy.png"                      alt="image.png"                ></p><p><strong>反向代理是代理服务器端的</strong>，让你无感知地去浏览服务器资源，我后面无论动态扩容增加多少台服务器你访问的永远是我们的域名；就拿百度来说，百度肯定不止这一台服务器，这就是使用了反向代理，让我们无论访问哪一台服务器比如访问深圳的服务器或者广州的服务器，都能通过<code>www.baidu.com</code>来获取资源。</p><h2 id="负载均衡理解"><a href="#负载均衡理解" class="headerlink" title="负载均衡理解"></a>负载均衡理解</h2><p>比如我们有三个服务器，一个是64G的，一个是16G的，一个是8G的我们希望更多的请求打到64G的服务器上，更少的请求打到8G的服务器上，这个时候就要使用上负载均衡了，Nginx具有一些内置的策略:</p><p>Nginx提供的负载均衡策略有两种: 内置策略和扩展策略。内置策略为轮询、加权轮询和ip hash。扩展策略，就天马行空只有你想不到的，没有它做不到的。</p><p>轮询理解起来就是依次把请求打到每一个服务器然后循环，如下图所示:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/24/cSANKt894iPCban.png"                      alt="image.png"                ></p><p>加权轮询理解起来就是每个服务器都有一个权重，权重大的会接收到更多的请求，权重小的会接收到更少的请求，如下图所示:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/24/G3nRtIjbkiTgJFY.png"                      alt="image.png"                ></p><p>什么叫ip hash呢，我们在写项目的时候经常有个Session的问题，这个Session也就是会话，它会保存到tomcat里面，但如果我们启动了很多个服务器，就有很多个tomcat，这时候tomcat就有n个，那n个tomcat，Session就有n个，这个时候肯定是不可能做到Session共享的；我们现在更多方案可能是使用Redis，Nginx也给我们提供了一种默认的算法，就是可以通过ip进行计算，固定的ip永远只能打到这台服务器上，那就可以保证Session一直在这台服务器上，但这样做性能也不是很好，如果这台服务器挂了，那所有信息就都没了，所以最好还是使用Redis来做Session共享，ip hash实现如下图所示:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/24/ZEj6QMufmThK9F2.png"                      alt="image.png"                ></p><p>我们还可以使用Nginx来做动静分离，什么叫动静分离呢，比如说你项目里面有很多静态资源，比如说你放了一个bootstrap的js或者说放了一堆jQuery的js，像这样一堆静态资源每次都要从你的jar包里面去加载就比较麻烦，那我希望有一个静态资源服务器去返回这些静态资源，Nginx就能做到这个</p><h2 id="Nginx安装-Windows"><a href="#Nginx安装-Windows" class="headerlink" title="Nginx安装-Windows"></a>Nginx安装-Windows</h2><p>Nginx是跨平台的</p><p>直接官网安装即可，你可以发现，它才1.几M</p><p>里面有个conf文件，然后其中有个nginx.conf文件，打开这个文件发现有个listen监听端口，默认是80端口，以后只要访问这个端口，就会被Nginx拦截:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/24/WYMITVwZS32yKkJ.png"                      alt="image.png"                ></p><p>我们可以双击nginx.exe来启动Nginx，但是我不建议大家双击，因为双击会一闪而过然后就没了，我们可以在路径这一栏先清除，然后输入cmd进入控制台，然后键入nginx.exe进行启动，这个时候要注意，如果路径中包含中文是可能报错的；那么怎么判断启动成功了呢，我们可以在浏览器中访问本地的80端口，因为刚刚配置文件中默认配的监听端口就是80，80端口是HTTP的默认端口，我们也可以省略不写，如果能看到Welcome to nginx就代表我们的nginx启动成功了，如下图所示:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/24/x3FBXHLDZPA8e6O.png"                      alt="image.png"                ></p><h2 id="Nginx安装-Linux"><a href="#Nginx安装-Linux" class="headerlink" title="Nginx安装-Linux"></a>Nginx安装-Linux</h2><p>Linux安装就需要下载Linux版本的Nginx的安装包，然后把它上传到Linux的服务器上，首先我们要确保本机上是没有Nginx的，使用命令<code>whereis nginx</code>来查看是否已经存在Nginx(还可以输入局nginx来再次确定):<img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/24/DPzdgoU648QbRat.png"                      alt="image.png"                ></p><p>确保本机上没有Nginx后，我们需要解压刚刚上传的nginx-1.18.0.tar.gz，使用<code>tar -zxvf nginx-1.18.0.tar.gz</code>来解压，解压完之后，我们进入nginx-1.18.0这个目录(在Linux上一般叫做目录)来看看它其实和在Windows上看到的目录是一样的，这里面也有我们的config配置文件，在这里面的话，我们要去安装以前学Linux的话学过make命令，这里面有个configure文件，我们先使用<code>.\configure</code>执行下这个文件，等它执行完之后使用命令<code>make</code>一下就可以了，跟安装咱们的Redis是一样的，然后再使用<code>make install</code>命令，执行完这个命令之后我们可以使用<code>whereis nginx</code>来找一下nginx，看看能不嫩肤找得到，找得到就说明安装成功了。那么如何启动它呢，我们可以进入它的安装目录，然后使用<code>ll</code>名看看有什么文件夹，可以看到有个sbin文件夹:<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/24/QPMxarkOVIuHogj.png"                      alt="image.png"                ></p><p>sbin里面就是一些执行文件，我们可以在里面进行启动，首先进入到这个文件夹，然后可以看到里面有个nginx的程序，直接执行这个nginx文件即可:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/24/BgnsFIQtlx8dvZS.png"                      alt="image.png"                ></p><p>如果执行成功的话，你是看不到任何日志的，在Linux里面没有报错就代表成功了，我们可以像刚刚在Windows中访问80端口一样看看是否能打开<code>Welcome to nginx</code>页面，能打开就说明启动成功了</p><h2 id="Nginx的常用命令"><a href="#Nginx的常用命令" class="headerlink" title="Nginx的常用命令"></a>Nginx的常用命令</h2><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/04/24/vYSKqOaePsH1wb6.png"                      alt="image.png"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Nginx简介&quot;&gt;&lt;a href=&quot;#Nginx简介&quot; class=&quot;headerlink&quot; title=&quot;Nginx简介&quot;&gt;&lt;/a&gt;Nginx简介&lt;/h2&gt;&lt;p&gt;&lt;img  
                     lazyload
             </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>详解如何进入、退出docker容器的方法</title>
    <link href="http://example.com/2022/04/18/%E8%AF%A6%E8%A7%A3%E5%A6%82%E4%BD%95%E8%BF%9B%E5%85%A5%E3%80%81%E9%80%80%E5%87%BAdocker%E5%AE%B9%E5%99%A8%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>http://example.com/2022/04/18/%E8%AF%A6%E8%A7%A3%E5%A6%82%E4%BD%95%E8%BF%9B%E5%85%A5%E3%80%81%E9%80%80%E5%87%BAdocker%E5%AE%B9%E5%99%A8%E7%9A%84%E6%96%B9%E6%B3%95/</id>
    <published>2022-04-18T01:29:30.000Z</published>
    <updated>2022-04-18T01:51:24.889Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>启动docker服务:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service docker start</span><br></pre></td></tr></table></figure><p>或者:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure></li><li><p>关闭docker服务:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service docker stop</span><br></pre></td></tr></table></figure><p>或者:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop docker</span><br></pre></td></tr></table></figure></li><li><p>启动docker的某个image(镜像)的container(容器)，也就是从指定镜像生成一个容器并启动它，容器也被称为镜像的一个实例:</p><p>Docker的镜像称为image，容器称为container；对于Docker来说，image是静态的，类似于操作系统快照，而container则是动态的，是image的运行实例；比如，有一个image名称为ubuntu，那么比如现在我们启动这个image的container<strong>并且进入到这个container的bash命令行中</strong>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -t -i ubuntu /<span class="built_in">bin</span>/bash</span><br></pre></td></tr></table></figure><p>命令理解:</p><ul><li>docker run: 启动由指定image生成的container</li><li>ubuntu: 你指定的image</li><li>-t: 进入container的终端</li><li>-i: 获得一个交互式的连接，通过获取container的输入</li><li>/bin/bash: 在container中启动一个bash shell</li></ul><p>这样就进入container的内部了:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@af8bae53bdd3:/<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>如果要退出当前容器，使用<code>exit</code>或者<code>Ctrl+D</code>，退出后，这个容器也会停止运行，我们要使用以下命令重启这个container:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker start goofy_almeida</span><br></pre></td></tr></table></figure><p>其中<code>goofy_almeida</code>是容器的名称</p><p>那么这里也提下，停止一个<code>container</code>使用以下命令:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker stop goofy_almeida</span><br></pre></td></tr></table></figure><p>其中<code>goofy_almeida</code>是容器的名称</p></li><li><p>进入container(容器)</p><ul><li><p>使用<code>docker attach</code>命令进入:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker attach goofy_almeida</span><br></pre></td></tr></table></figure><p>其中<code>goofy_almeida</code>是容器的名称</p></li><li><p>使用<code>docker exec -it</code>命令进入:</p><p>使用<code>docker attach</code>命令进入<code>container</code>有一个缺点，那就是每次从<code>container</code>中退出到前台时，<code>container</code>也跟着退出了；要想退出<code>container</code>时，让<code>container</code>仍然在后台运行着，那就需要使用<code>docker exec -it</code>命令，每次使用这个命令进入<code>container</code>后，当退出<code>container</code>后，<code>container</code>仍然在后台运行，使用方法如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it goofy_almeida /<span class="built_in">bin</span>/bash</span><br></pre></td></tr></table></figure><ul><li>goofy_almeida: 要进入容器的名称</li><li>/bin/bash: 在container中启动一个bash shell</li></ul><p>这样输入<code>exit</code>或者按键<code>Ctrl+C</code>退出<code>container</code>时，这个<code>container</code>仍然在后台运行，我们可以使用<code>docker ps</code>来查看当前在运行的<code>container</code>，使用<code>docker ps -a</code>查看所有容器，包括在运行的和不在运行的</p></li></ul></li></ol><p>参考自: <a class="link"   href="https://www.jb51.net/article/203279.htm" >https://www.jb51.net/article/203279.htm<i class="fas fa-external-link-alt"></i></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;ol&gt;
&lt;li&gt;&lt;p&gt;启动docker服务:&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;t</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Docker部署Django项目</title>
    <link href="http://example.com/2022/04/18/Docker%E9%83%A8%E7%BD%B2Django%E9%A1%B9%E7%9B%AE/"/>
    <id>http://example.com/2022/04/18/Docker%E9%83%A8%E7%BD%B2Django%E9%A1%B9%E7%9B%AE/</id>
    <published>2022-04-18T01:17:20.000Z</published>
    <updated>2022-04-18T01:18:29.136Z</updated>
    
    <content type="html"><![CDATA[<p>最近在搞毕设，然后想着前端这边还是用docker部署下，转载自CSDN: <a class="link"   href="https://blog.csdn.net/qq_42393859/article/details/106429198?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1.pc_relevant_aa&amp;spm=1001.2101.3001.4242.2&amp;utm_relevant_index=4" >https://blog.csdn.net/qq_42393859/article/details/106429198?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1.pc_relevant_aa&amp;spm=1001.2101.3001.4242.2&amp;utm_relevant_index=4<i class="fas fa-external-link-alt"></i></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近在搞毕设，然后想着前端这边还是用docker部署下，转载自CSDN: &lt;a class=&quot;link&quot;   href=&quot;https://blog.csdn.net/qq_42393859/article/details/106429198?utm_medium=distr</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Docker部署Flask项目</title>
    <link href="http://example.com/2022/04/16/Docker%E9%83%A8%E7%BD%B2Flask%E9%A1%B9%E7%9B%AE/"/>
    <id>http://example.com/2022/04/16/Docker%E9%83%A8%E7%BD%B2Flask%E9%A1%B9%E7%9B%AE/</id>
    <published>2022-04-16T10:43:30.000Z</published>
    <updated>2022-04-16T10:58:09.887Z</updated>
    
    <content type="html"><![CDATA[<p>小项目其实用不着docker部署，不过这里也还是记录下，之前的文章(Flask以配置文件启动)其实就足够了</p><p>首先我们需要创建一个<code>requirements.txt</code>，推荐使用<code>pipreqs</code>，可以参考这个文章，点击<a class="link"   href="http://kest.club/2022/04/16/%E5%AF%B9%E6%AF%94pip%20freeze,%E6%88%91%E9%80%89%E6%8B%A9pipreqs/" >跳转<i class="fas fa-external-link-alt"></i></a>，示例如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">django==<span class="number">1.8</span><span class="number">.7</span></span><br><span class="line">numpy</span><br><span class="line">pandas</span><br></pre></td></tr></table></figure><p>然后我们需要创建一个Dockerfile文件，该文件没有后缀，以便Docker镜像的构建，示例如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">FROM python:<span class="number">3.6</span></span><br><span class="line"></span><br><span class="line">WORKDIR /usr/src/app</span><br><span class="line"></span><br><span class="line">COPY requirements.txt ./</span><br><span class="line">RUN pip install --no-cache-<span class="built_in">dir</span> -r requirements.txt</span><br><span class="line"></span><br><span class="line">COPY . .</span><br><span class="line"></span><br><span class="line">CMD [<span class="string">&quot;gunicorn&quot;</span>, <span class="string">&quot;app:app&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;./gunicorn.conf.py&quot;</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#基于的基础镜像</span></span><br><span class="line">FROM python:<span class="number">3.5</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#代码添加到code文件夹</span></span><br><span class="line">ADD ./package /code</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 设置code文件夹是工作目录</span></span><br><span class="line">WORKDIR /code</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 安装支持</span></span><br><span class="line">RUN pip install -i https://pypi.doubanio.com/simple/ -r requirements.txt</span><br><span class="line"> </span><br><span class="line">CMD [<span class="string">&quot;python&quot;</span>, <span class="string">&quot;/code/docker_test/run.py&quot;</span>]</span><br></pre></td></tr></table></figure><p>然后是把代码上传到云服务器创建镜像(反正我是这么做的):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t flask项目名 .</span><br></pre></td></tr></table></figure><p>查看镜像:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure><p>运行镜像，生成并启动容器:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it -p <span class="number">8000</span>:<span class="number">8000</span> --name xxx xxxx</span><br></pre></td></tr></table></figure><p>-it: 表示交互式终端的容器，非启动后立刻结束的容器</p><p>-p 8000:8000：表示将docker的8000端口，映射到Linux的8000端口</p><p>–name xxx：给容器取个名字，嫌麻烦可以省去</p><p>xxxx: 容器是用哪个镜像启动的(一个容器，必须依赖一个镜像启动)</p><ul><li>参考自: <a class="link"   href="https://blog.csdn.net/qq_42393859/article/details/106429198?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1.pc_relevant_aa&amp;spm=1001.2101.3001.4242.2&amp;utm_relevant_index=4" >https://blog.csdn.net/qq_42393859/article/details/106429198?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1.pc_relevant_aa&amp;spm=1001.2101.3001.4242.2&amp;utm_relevant_index=4<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="https://juejin.cn/post/6844904142159233038" >https://juejin.cn/post/6844904142159233038<i class="fas fa-external-link-alt"></i></a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;小项目其实用不着docker部署，不过这里也还是记录下，之前的文章(Flask以配置文件启动)其实就足够了&lt;/p&gt;
&lt;p&gt;首先我们需要创建一个&lt;code&gt;requirements.txt&lt;/code&gt;，推荐使用&lt;code&gt;pipreqs&lt;/code&gt;，可以参考这个文章，点击</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Flask以配置文件启动</title>
    <link href="http://example.com/2022/04/16/Flask%E4%BB%A5%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%90%AF%E5%8A%A8/"/>
    <id>http://example.com/2022/04/16/Flask%E4%BB%A5%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%90%AF%E5%8A%A8/</id>
    <published>2022-04-16T10:39:30.000Z</published>
    <updated>2022-04-16T10:42:39.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近在写毕业设计，然后要完成一个图片的上传接口，我是用Flask写的，然后需要放到云服务器上去跑，这个时候我们可以在项目中写一个<code>gunicorn.conf.py</code>文件这个文件其实就是<code>gunicorn</code>的配置文件，然后我们还需要安装两个模块<code>gunicorn</code>和<code>gevent</code>，使用以下命令安装:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install gunicorn gevent</span><br></pre></td></tr></table></figure><p>以下是我接口项目的<code>gunicorn.conf.py</code>，在这里也是给出一个案例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">workers = <span class="number">5</span>    <span class="comment"># 定义同时开启的处理请求的进程数量，根据网站流量适当调整</span></span><br><span class="line">worker_class = <span class="string">&quot;gevent&quot;</span>   <span class="comment"># 采用gevent库，支持异步处理请求，提高吞吐量</span></span><br><span class="line">bind = <span class="string">&quot;0.0.0.0:8888&quot;</span>    <span class="comment"># 监听IP放宽(让别的主机也能访问)</span></span><br></pre></td></tr></table></figure><p>到这里，我们就可以在云服务器上跑我们的接口了，使用以下命令:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gunicorn -c gunicorn.conf.py app:app</span><br></pre></td></tr></table></figure><p>第一个<code>app</code>指的是<code>app.py</code>文件的名字，第二个<code>app</code>指的是flask应用的名字，还可以加上参数<code>-d</code>表示后台启动</p><p>附上一个<code>Flask</code>代码案例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># app.py</span></span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_app</span>():</span>  </span><br><span class="line">    app = Flask(__name__)  </span><br><span class="line">    <span class="keyword">return</span> app  </span><br><span class="line">app = create_app()  </span><br><span class="line">  </span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/&#x27;</span></span>)  </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span>():</span>  </span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;hello world!&#x27;</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    app.run()   <span class="comment"># .run()前的就是flask应用的名字</span></span><br></pre></td></tr></table></figure><p>附上<code>gunicorn</code>的参数详解:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">-c CONFIG    : CONFIG,配置文件的路径，通过配置文件启动；生产环境使用；</span><br><span class="line"></span><br><span class="line">-b ADDRESS   : ADDRESS，ip加端口，绑定运行的主机；</span><br><span class="line"></span><br><span class="line">-w INT, --workers INT：用于处理工作进程的数量，为正整数，默认为<span class="number">1</span>；</span><br><span class="line"></span><br><span class="line">-k STRTING, --worker-<span class="class"><span class="keyword">class</span> <span class="title">STRTING</span>：要使用的工作模式，默认为<span class="title">sync</span>异步，可以下载<span class="title">eventlet</span>和<span class="title">gevent</span>并指定</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">threads</span> <span class="title">INT</span>：处理请求的工作线程数，使用指定数量的线程运行每个<span class="title">worker</span>。为正整数，默认为1。</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">worker</span>-<span class="title">connections</span> <span class="title">INT</span>：最大客户端并发数量，默认情况下这个值为1000。</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">backlog</span> <span class="title">int</span>：未决连接的最大数量，即等待服务的客户的数量。默认2048个，一般不修改；</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">-<span class="title">p</span> <span class="title">FILE</span>, --<span class="title">pid</span> <span class="title">FILE</span>：设置<span class="title">pid</span>文件的文件名，如果不设置将不会创建<span class="title">pid</span>文件</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">access</span>-<span class="title">logfile</span> <span class="title">FILE</span>   ：  要写入的访问日志目录</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">access</span>-<span class="title">logformat</span> <span class="title">STRING</span>：要写入的访问日志格式</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">error</span>-<span class="title">logfile</span> <span class="title">FILE</span>, --<span class="title">log</span>-<span class="title">file</span> <span class="title">FILE</span>  ：  要写入错误日志的文件目录。</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">log</span>-<span class="title">level</span> <span class="title">LEVEL</span>   ：   错误日志输出等级。</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">limit</span>-<span class="title">request</span>-<span class="title">line</span> <span class="title">INT</span>   ：  <span class="title">HTTP</span>请求头的行数的最大大小，此参数用于限制<span class="title">HTTP</span>请求行的允许大小，默认情况下，这个值为4094。值是0~8190的数字。</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">limit</span>-<span class="title">request</span>-<span class="title">fields</span> <span class="title">INT</span>   ：  限制<span class="title">HTTP</span>请求中请求头字段的数量。此字段用于限制请求头字段的数量以防止<span class="title">DDOS</span>攻击，默认情况下，这个值为100，这个值不能超过32768</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">limit</span>-<span class="title">request</span>-<span class="title">field</span>-<span class="title">size</span> <span class="title">INT</span>  ：  限制<span class="title">HTTP</span>请求中请求头的大小，默认情况下这个值为8190字节。值是一个整数或者0，当该值为0时，表示将对请求头大小不做限制</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">-<span class="title">t</span> <span class="title">INT</span>, --<span class="title">timeout</span> <span class="title">INT</span>：超过这么多秒后工作将被杀掉，并重新启动。一般设定为30秒；</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">daemon</span>： 是否以守护进程启动，默认<span class="title">false</span>；</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">chdir</span>： 在加载应用程序之前切换目录；</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">graceful</span>-<span class="title">timeout</span> <span class="title">INT</span>：默认情况下，这个值为30，在超时(<span class="params">从接收到重启信号开始</span>)之后仍然活着的工作将被强行杀死；一般使用默认；</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">keep</span>-<span class="title">alive</span> <span class="title">INT</span>：在<span class="title">keep</span>-<span class="title">alive</span>连接上等待请求的秒数，默认情况下值为2。一般设定在1~5秒之间。</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">reload</span>：默认为<span class="title">False</span>。此设置用于开发，每当应用程序发生更改时，都会导致工作重新启动。</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">spew</span>：打印服务器执行过的每一条语句，默认<span class="title">False</span>。此选择为原子性的，即要么全部打印，要么全部不打印；</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">--<span class="title">check</span>-<span class="title">config</span>   ：显示现在的配置，默认值为<span class="title">False</span>，即显示。</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">-<span class="title">e</span> <span class="title">ENV</span>, --<span class="title">env</span> <span class="title">ENV</span>： 设置环境变量；</span></span><br></pre></td></tr></table></figure><p>参考自:</p><ul><li><a class="link"   href="https://blog.csdn.net/weixin_42881588/article/details/108768493" >https://blog.csdn.net/weixin_42881588/article/details/108768493<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="https://juejin.cn/post/6844904142159233038" >https://juejin.cn/post/6844904142159233038<i class="fas fa-external-link-alt"></i></a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近在写毕业设计，然后要完成一个图片的上传接口，我是用Flask写的，然后需要放到云服务器上去跑，这个时候我们可以在项目中写一个&lt;code&gt;gunicorn.conf.py&lt;/code&gt;文件这个文件其实就是&lt;code&gt;gunicorn&lt;/code&gt;的配置文件，然后我们还需要</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Django项目在服务器上跑出现样式不起作用</title>
    <link href="http://example.com/2022/04/16/Django%E9%A1%B9%E7%9B%AE%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E8%B7%91%E5%87%BA%E7%8E%B0%E6%A0%B7%E5%BC%8F%E4%B8%8D%E8%B5%B7%E4%BD%9C%E7%94%A8/"/>
    <id>http://example.com/2022/04/16/Django%E9%A1%B9%E7%9B%AE%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E8%B7%91%E5%87%BA%E7%8E%B0%E6%A0%B7%E5%BC%8F%E4%B8%8D%E8%B5%B7%E4%BD%9C%E7%94%A8/</id>
    <published>2022-04-15T17:10:50.000Z</published>
    <updated>2022-04-16T01:06:14.289Z</updated>
    
    <content type="html"><![CDATA[<p>请参考: <a class="link"   href="https://blog.csdn.net/qq_36874480/article/details/100652364?spm=1001.2101.3001.6650.5&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-5.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-5.pc_relevant_default&amp;utm_relevant_index=9" >https://blog.csdn.net/qq_36874480/article/details/100652364?spm=1001.2101.3001.6650.5&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_default&amp;utm_relevant_index=9<i class="fas fa-external-link-alt"></i></a></p><p>可以加个<code>--insecure </code>参数，但这是处于不安全模式下的</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;请参考: &lt;a class=&quot;link&quot;   href=&quot;https://blog.csdn.net/qq_36874480/article/details/100652364?spm=1001.2101.3001.6650.5&amp;amp;utm_medium=distrib</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Layui使用文档</title>
    <link href="http://example.com/2022/04/16/Layui%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3/"/>
    <id>http://example.com/2022/04/16/Layui%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3/</id>
    <published>2022-04-15T17:04:43.000Z</published>
    <updated>2022-04-16T01:06:16.715Z</updated>
    
    <content type="html"><![CDATA[<p>请跳转: <a class="link"   href="http://layui-doc.pearadmin.com/doc/index.html" >http://layui-doc.pearadmin.com/doc/index.html<i class="fas fa-external-link-alt"></i></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;请跳转: &lt;a class=&quot;link&quot;   href=&quot;http://layui-doc.pearadmin.com/doc/index.html&quot; &gt;http://layui-doc.pearadmin.com/doc/index.html&lt;i class=&quot;fas f</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>前后端分离与不分离</title>
    <link href="http://example.com/2022/04/16/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E4%B8%8E%E4%B8%8D%E5%88%86%E7%A6%BB/"/>
    <id>http://example.com/2022/04/16/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E4%B8%8E%E4%B8%8D%E5%88%86%E7%A6%BB/</id>
    <published>2022-04-15T16:54:45.000Z</published>
    <updated>2022-04-16T01:06:19.026Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a class="link"   href="https://www.cnblogs.com/xiaobenshou/p/10263851.html" >https://www.cnblogs.com/xiaobenshou/p/10263851.html<i class="fas fa-external-link-alt"></i></a></li></ul><p>前后端不分离: 后端直接返回一个完整的html文件给前端，前端只负责将他展示出来</p><p>前后端分离: 后端将生成一个接口(API)，前端访问该接口获取相应的数据(比如数据库数据)，然后再进行页面渲染展示</p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;link&quot;   href=&quot;https://www.cnblogs.com/xiaobenshou/p/10263851.html&quot; &gt;https://www.cnblogs.com/xiaobenshou/p/10263851.html&lt;i</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Python创建虚拟环境之pipenv</title>
    <link href="http://example.com/2022/04/16/Python%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E4%B9%8Bpipenv/"/>
    <id>http://example.com/2022/04/16/Python%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E4%B9%8Bpipenv/</id>
    <published>2022-04-15T16:35:29.000Z</published>
    <updated>2022-04-16T01:06:20.978Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a class="link"   href="https://www.cnblogs.com/xp1315458571/p/13365454.html" >https://www.cnblogs.com/xp1315458571/p/13365454.html<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="https://blog.csdn.net/RNG_uzi_/article/details/121903762" >https://blog.csdn.net/RNG_uzi_/article/details/121903762<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="https://zhuanlan.zhihu.com/p/349919589" >https://zhuanlan.zhihu.com/p/349919589<i class="fas fa-external-link-alt"></i></a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;link&quot;   href=&quot;https://www.cnblogs.com/xp1315458571/p/13365454.html&quot; &gt;https://www.cnblogs.com/xp1315458571/p/13365454.html</summary>
      
    
    
    
    
  </entry>
  
</feed>
