<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Lhj">
    
    <title>
        
            Python3网络爬虫开发实战第二版第2章-基本库的使用 |
        
        Alexander
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/css/font-awesome.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":true}}},"local_search":{"enable":true,"preload":false},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":true},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                Alexander
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                NOTE
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                ABOUT
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">NOTE</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">Python3网络爬虫开发实战第二版第2章-基本库的使用</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/avatar.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Lhj</span>
                        
                            <span class="author-label">Lv6</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2022-02-07 17:18:30</span>
        <span class="mobile">2022-02-07 17:18</span>
    </span>
    
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>13.1k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>62 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <p>Python提供了功能齐全的类库来帮助我们实现需求，最基础的有HTTP库有urllib、requests、httpx等</p>
<h2 id="urllib的使用"><a href="#urllib的使用" class="headerlink" title="urllib的使用"></a>urllib的使用</h2><p>注意: 在Python2中，有urllib和urllib2两个库来实现HTTP请求的发送，而<strong>在Python3中，urllib2库已经不存在了，统一为了urllib</strong></p>
<p><strong>urllib是Python内置的HTTP请求库</strong>，也就是说不需要额外安装，可直接使用；urllib库包括如下4个模块:</p>
<ul>
<li>request: 这是最基本的HTTP请求模块，可以模拟请求的发送，就像在浏览器中输入网址然后按下了回车一样，只需要给库方法传入URL以及额外的参数，就可以模拟实现发送请求的过程了</li>
<li>error: 异常处理模块，如果出现请求异常，那么我们可以捕获这些异常，然后进行重试或其他操作以保证程序运行不会意外终止</li>
<li>parse: 一个工具模块，提供了许多URL的处理方法，例如拆分、解析、合并等</li>
<li>robotparser: 主要用来识别网站的robots.txt文件，然后判断哪些网站可以爬，哪些网站不可以爬，它其实用的比较少</li>
</ul>
<h3 id="发送请求"><a href="#发送请求" class="headerlink" title="发送请求"></a>发送请求</h3><h4 id="urlopen"><a href="#urlopen" class="headerlink" title="urlopen"></a>urlopen</h4><p><strong>urllib.request模块提供了最基本的构造HTTP请求的方法，利用这个模块可以模拟浏览器的请求发起过程</strong>，同时它还具有处理授权验证，重定向，浏览器Cookie以及其他一些功能</p>
<p>下面以Python官网为例体验下这个模块:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;https://www.python.org&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>运行结果如下图所示:</p>
<p>我们来看看返回的是个什么类型:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;https://www.python.org&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))</span><br></pre></td></tr></table></figure>

<p>输出结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">http</span>.<span class="title">client</span>.<span class="title">HTTPResponse</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure>

<p>这是一个HTTPResponse类型的对象，主要包含read、readinto、getheader、getheaders、fileno等方法，以及msg、version、status、reason、debuglevel、closed等属性</p>
<p>我们来看看实例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;https://www.python.org&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(response.status)</span><br><span class="line"><span class="built_in">print</span>(response.getheaders())</span><br><span class="line"><span class="built_in">print</span>(response.getheader(<span class="string">&#x27;Server&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">200</span></span><br><span class="line">[(<span class="string">&#x27;Connection&#x27;</span>, <span class="string">&#x27;close&#x27;</span>), (<span class="string">&#x27;Content-Length&#x27;</span>, <span class="string">&#x27;49476&#x27;</span>), (<span class="string">&#x27;Server&#x27;</span>, <span class="string">&#x27;nginx&#x27;</span>), (<span class="string">&#x27;Content-Type&#x27;</span>, <span class="string">&#x27;text/html; charset=utf-8&#x27;</span>), (<span class="string">&#x27;X-Frame-Options&#x27;</span>, <span class="string">&#x27;DENY&#x27;</span>), (<span class="string">&#x27;Via&#x27;</span>, <span class="string">&#x27;1.1 vegur, 1.1 varnish, 1.1 varnish&#x27;</span>), (<span class="string">&#x27;Accept-Ranges&#x27;</span>, <span class="string">&#x27;bytes&#x27;</span>), (<span class="string">&#x27;Date&#x27;</span>, <span class="string">&#x27;Sun, 06 Feb 2022 14:10:46 GMT&#x27;</span>), (<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;283&#x27;</span>), (<span class="string">&#x27;X-Served-By&#x27;</span>, <span class="string">&#x27;cache-iad-kcgs7200085-IAD, cache-nrt18330-NRT&#x27;</span>), (<span class="string">&#x27;X-Cache&#x27;</span>, <span class="string">&#x27;HIT, HIT&#x27;</span>), (<span class="string">&#x27;X-Cache-Hits&#x27;</span>, <span class="string">&#x27;3, 353&#x27;</span>), (<span class="string">&#x27;X-Timer&#x27;</span>, <span class="string">&#x27;S1644156646.362936,VS0,VE0&#x27;</span>), (<span class="string">&#x27;Vary&#x27;</span>, <span class="string">&#x27;Cookie&#x27;</span>), (<span class="string">&#x27;Strict-Transport-Security&#x27;</span>, <span class="string">&#x27;max-age=63072000; includeSubDomains&#x27;</span>)]</span><br><span class="line">nginx</span><br></pre></td></tr></table></figure>

<p>下面是urlopen方法的API:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urllib.request.urlopen(url, data=<span class="literal">None</span>, [timeout,]*, cafile=<span class="literal">None</span>, capath=<span class="literal">None</span>, cadefault=<span class="literal">False</span>, context=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<p>接下来详细说明下urlopen方法中几个参数的用法:</p>
<ul>
<li><p>data参数</p>
<p><strong>data参数为可选，使用该参数需要使用bytes方法将参数转化为字节流编码格式的内容即bytes类型，如果传递了这个参数，那么它的请求方式就不再是GET了，而是POST了</strong></p>
<p>以下是实例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">data = <span class="built_in">bytes</span>(urllib.parse.urlencode(&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>&#125;), encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;https://www.httpbin.org/post&#x27;</span>, data=data)</span><br><span class="line"><span class="built_in">print</span>(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>上面代码中转码时使用了bytes方法，该方法的第一个参数得是str类型，因此用<strong>urllib.parse模块里的urlencode方法将字典参数转化为字符串</strong>，第二个参数指定编码格式</p>
<p>此处我们请求的站点是<a class="link"   target="_blank" rel="noopener" href="http://www.httpbin.org,它可以提供http请求测试,上面实例的运行结果如下/" >www.httpbin.org，它可以提供HTTP请求测试，上面实例的运行结果如下<i class="fas fa-external-link-alt"></i></a>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;args&quot;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&quot;data&quot;</span>: <span class="string">&quot;&quot;</span>, </span><br><span class="line">  <span class="string">&quot;files&quot;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&quot;form&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;germey&quot;</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">&quot;headers&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;Accept-Encoding&quot;</span>: <span class="string">&quot;identity&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Content-Length&quot;</span>: <span class="string">&quot;11&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/x-www-form-urlencoded&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Host&quot;</span>: <span class="string">&quot;www.httpbin.org&quot;</span>, </span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Python-urllib/3.7&quot;</span>, </span><br><span class="line">    <span class="string">&quot;X-Amzn-Trace-Id&quot;</span>: <span class="string">&quot;Root=1-61ffda7a-05a2c9b60ba676290898d9d9&quot;</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">&quot;json&quot;</span>: null, </span><br><span class="line">  <span class="string">&quot;origin&quot;</span>: <span class="string">&quot;182.101.213.95&quot;</span>, </span><br><span class="line">  <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.httpbin.org/post&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>timeout参数</p>
<p>直接上实例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>, timeout=<span class="number">0.1</span>)</span><br><span class="line"><span class="built_in">print</span>(response.read())</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  File <span class="string">&quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\urllib\request.py&quot;</span>, line <span class="number">1360</span>, <span class="keyword">in</span> https_open</span><br><span class="line">    context=self._context, check_hostname=self._check_hostname)</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\urllib\request.py&quot;</span>, line <span class="number">1319</span>, <span class="keyword">in</span> do_open</span><br><span class="line">    <span class="keyword">raise</span> URLError(err)</span><br><span class="line">urllib.error.URLError: &lt;urlopen error timed out&gt;</span><br></pre></td></tr></table></figure>

<p>利用try except语句也可实现:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = urllib.request.urlopen(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>, timeout=<span class="number">0.1</span>)</span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(e.reason, socket.timeout):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;time out&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time out</span><br></pre></td></tr></table></figure></li>
<li><p>其他参数</p>
<p>除了以上两个参数，<strong>urlopen还有context参数，该参数必须是ssl.SSLContext类型，用来指定SSL的设置</strong>，此外，cafile和capath这连个参数分别用来指定CA证书和其路径，这两个在请求HTTPS链接时会有用，cadefault参数现在已经弃用了，其默认值为Flase，到这里我们就讲完了urlopen方法的用法</p>
</li>
</ul>
<h4 id="Request"><a href="#Request" class="headerlink" title="Request"></a>Request</h4><p>urlopen可以发起最基本的请求，但它那几个简单的参数并不足以构建一个完整的请求，如果需要往请求中加入Headers等信息，就需要使用更强大的Request来构建请求了</p>
<p>来看看最基本的实例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(<span class="string">&#x27;http://www.baidu.com&#x27;</span>)</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"><span class="built_in">print</span>(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>我们来看下可以通过怎样的参数来构造Request类，构造方法如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urllib.request.Request(url, data=<span class="literal">None</span>, headers=&#123;&#125;, origin_req_host=<span class="literal">None</span>, unverifiable=<span class="literal">False</span>, method=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>url为请求的URL，这是必传参数，其他都是可选参数</li>
<li>data如果要传数据，必须传bytes类型的，如果数据是字典，可以先用urllib.parse模块里的urlencode方法进行编码</li>
<li>第三个参数是一个字典，这是请求头，可以用headers参数直接构造，也可以调用请求实例的add_heade方法添加</li>
<li>origin_req_host指的是请求方的host名称或者IP地址</li>
<li>unverifiable表示请求是否是无法验证的，默认取值是False，意思是用户没有足够的权限来接收这个请求的结果</li>
<li>method是一个字符串，指示请求使用的方法</li>
</ul>
<p>由于urllib使用不是太频繁，详情见书本</p>
<h2 id="requests的使用"><a href="#requests的使用" class="headerlink" title="requests的使用"></a>requests的使用</h2><p>我们感觉使用urllib不太方便，接下来我们来看看requests库的强大之处叭</p>
<h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>首先我们需要安装requests:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install requests</span><br></pre></td></tr></table></figure>

<h3 id="实例引入"><a href="#实例引入" class="headerlink" title="实例引入"></a>实例引入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://www.baidu.com/&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r))</span><br><span class="line"><span class="built_in">print</span>(r.status_code)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.text))</span><br><span class="line"><span class="built_in">print</span>(r.text[<span class="number">100</span>])</span><br><span class="line"><span class="built_in">print</span>(r.cookies)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">requests</span>.<span class="title">models</span>.<span class="title">Response</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">200</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> &#x27;<span class="title">str</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">&lt;!<span class="title">DOCTYPE</span> <span class="title">html</span>&gt;</span></span><br><span class="line"><span class="class">&lt;!--<span class="title">STATUS</span> <span class="title">OK</span>--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-<span class="built_in">type</span> content=text/html;charse</span></span><br><span class="line"><span class="class">&lt;RequestsCookieJar[&lt;Cookie BDORZ=27315 <span class="keyword">for</span> .baidu.com/&gt;]&gt;</span></span><br></pre></td></tr></table></figure>

<p>使用get方法成功实现一个GET请求算不了什么，requests库更方便之处在于其他请求类型依然可以用一句话完成:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = resquests.get(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>)</span><br><span class="line">r = resquests.post(<span class="string">&#x27;https://www.httpbin.org/post&#x27;</span>)</span><br><span class="line">r = resquests.put(<span class="string">&#x27;https://www.httpbin.org/put&#x27;</span>)</span><br><span class="line">r = resquests.delete(<span class="string">&#x27;https://www.httpbin.org/delete&#x27;</span>)</span><br><span class="line">r = resquests.patch(<span class="string">&#x27;https://www.httpbin.org/patch&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="GET请求"><a href="#GET请求" class="headerlink" title="GET请求"></a>GET请求</h3><h4 id="基本实例"><a href="#基本实例" class="headerlink" title="基本实例"></a>基本实例</h4><p>我们来构建一个简单的get请求，是否要直接把参数放在URL中呢，这样看起来有点不方便，我们可以使用params参数:</p>
<p>比如我们要构造如下请求链接:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.httpbin.org/get?name=germey&amp;age=<span class="number">25</span></span><br></pre></td></tr></table></figure>

<p>我们其实可以直接就<code>r = requests.get(&#39;https://www.httpbin.org/get?name=germey&amp;age=25&#39;)</code>，但是这样未免看起来有点不太人性化，所以我们修改下使用params参数:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span></span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>, params=data)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.text))</span><br><span class="line"><span class="built_in">print</span>(r.json())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.josn()))</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;args&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;age&quot;</span>: <span class="string">&quot;25&quot;</span>, </span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;germey&quot;</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">&quot;headers&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;Accept&quot;</span>: <span class="string">&quot;*/*&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Accept-Encoding&quot;</span>: <span class="string">&quot;gzip, deflate, br&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Host&quot;</span>: <span class="string">&quot;www.httpbin.org&quot;</span>, </span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;python-requests/2.27.1&quot;</span>, </span><br><span class="line">    <span class="string">&quot;X-Amzn-Trace-Id&quot;</span>: <span class="string">&quot;Root=1-622028bb-33c00fdf64178c4910985f42&quot;</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">&quot;origin&quot;</span>: <span class="string">&quot;113.65.130.252&quot;</span>, </span><br><span class="line">  <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.httpbin.org/get?name=germey&amp;age=25&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>另外，网页的返回结果虽然是str类型的，但是它很特殊，是JSON格式的字符串，<strong>如果想直接解析返回结果，得到一个JSON格式的数据，可以直接调用json方法</strong>，示例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span></span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>, params=data)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.text))</span><br><span class="line"><span class="built_in">print</span>(r.json())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.json()))</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">str</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">&#123;&#x27;<span class="title">args</span>&#x27;:</span> &#123;<span class="string">&#x27;age&#x27;</span>: <span class="string">&#x27;25&#x27;</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>&#125;, <span class="string">&#x27;headers&#x27;</span>: &#123;<span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;*/*&#x27;</span>, <span class="string">&#x27;Accept-Encoding&#x27;</span>: <span class="string">&#x27;gzip, deflate, br&#x27;</span>, <span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27;www.httpbin.org&#x27;</span>, <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;python-requests/2.27.1&#x27;</span>, <span class="string">&#x27;X-Amzn-Trace-Id&#x27;</span>: <span class="string">&#x27;Root=1-622029d0-4ca397d865eae0927ca97af0&#x27;</span>&#125;, <span class="string">&#x27;origin&#x27;</span>: <span class="string">&#x27;113.65.130.252&#x27;</span>, <span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://www.httpbin.org/get?name=germey&amp;age=25&#x27;</span>&#125;</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">dict</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure>

<p>可以发现，调用json方法可以将返回结果(JSON格式的字符串)转化为字典，但需要注意的是，如果返回结果不是JSON格式，就会出现解析错误，抛出json.decoder.JSONDecodeError异常</p>
<h4 id="抓取网页"><a href="#抓取网页" class="headerlink" title="抓取网页"></a>抓取网页</h4><p>直接上实例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://ssr1.scrape.center/&#x27;</span>)</span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;&lt;h2.*?&gt;(.*?)&lt;/h2&gt;&#x27;</span>,  re.S)</span><br><span class="line">titles = re.findall(pattern, r.text)</span><br><span class="line"><span class="built_in">print</span>(titles)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&#x27;霸王别姬 - Farewell My Concubine&#x27;</span>, <span class="string">&#x27;这个杀手不太冷 - Léon&#x27;</span>, <span class="string">&#x27;肖申克的救赎 - The Shawshank Redemption&#x27;</span>, <span class="string">&#x27;泰坦尼克号 - Titanic&#x27;</span>, <span class="string">&#x27;罗马假日 - Roman Holiday&#x27;</span>, <span class="string">&#x27;唐伯虎点秋香 - Flirting Scholar&#x27;</span>, <span class="string">&#x27;乱世佳人 - Gone with the Wind&#x27;</span>, <span class="string">&#x27;喜剧之王 - The King of Comedy&#x27;</span>, <span class="string">&#x27;楚门的世界 - The Truman Show&#x27;</span>, <span class="string">&#x27;狮子王 - The Lion King&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h4 id="抓取二进制数据"><a href="#抓取二进制数据" class="headerlink" title="抓取二进制数据"></a>抓取二进制数据</h4><p>图片、音频、视频这些文件本质上都是由二进制码组成的，由于有特定的保存格式和对应的解析方式，我们才可以看到这些形形色色的多媒体，所以，我们要想抓取它们，就必须拿到它们的二进制数据</p>
<p>直接上实例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://scrape.center/favicon.ico&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br><span class="line"><span class="built_in">print</span>(r.content)</span><br></pre></td></tr></table></figure>

<p>r.text:</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/bJG6C6"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s4.ax1x.com/2022/03/03/bJG6C6.png"
                      alt="bJG6C6.png"
                ></a></p>
<p>r.content:</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/bJGxVs"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s4.ax1x.com/2022/03/03/bJGxVs.png"
                      alt="bJGxVs.png"
                ></a></p>
<p>可以注意到，<strong>r.text中出现了乱码，t.content的前面带有一个b，代表这是bytes类型的数据；由于图片是二进制数据，所以前者在打印时会转化为str类型，也就是图片直接转化为字符串，那这肯定会出现乱码</strong></p>
<p>上面的运行结果我们并不能看懂，它实际上是图片的二进制数据，不过没关系，我们将刚才提取的数据信息保存下来就好了，代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://scrape.center/favicon.ico&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;favicon.ico&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(r.content)</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/bJYQkn"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s4.ax1x.com/2022/03/03/bJYQkn.png"
                      alt="bJYQkn.png"
                ></a></p>
<h4 id="添加请求头"><a href="#添加请求头" class="headerlink" title="添加请求头"></a>添加请求头</h4><p>使用headers这个参数</p>
<p>直接上代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(<span class="string">&#x27;https://scrape.center/favicon.ico&#x27;</span>, headers=headers)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br><span class="line"><span class="built_in">print</span>(r.content)</span><br></pre></td></tr></table></figure>

<p>当然，可以在headers参数中添加任意其他字段信息</p>
<h3 id="POST请求"><a href="#POST请求" class="headerlink" title="POST请求"></a>POST请求</h3><h4 id="基本实例-1"><a href="#基本实例-1" class="headerlink" title="基本实例"></a>基本实例</h4><p>我们需要用到data参数，要区别于params参数</p>
<p>直接上代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">r = requests.post(<span class="string">&#x27;https://www.httpbin.org/post&#x27;</span>, data=data)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;args&quot;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&quot;data&quot;</span>: <span class="string">&quot;&quot;</span>, </span><br><span class="line">  <span class="string">&quot;files&quot;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&quot;form&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;age&quot;</span>: <span class="string">&quot;25&quot;</span>, </span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;germey&quot;</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">&quot;headers&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;Accept&quot;</span>: <span class="string">&quot;*/*&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Accept-Encoding&quot;</span>: <span class="string">&quot;gzip, deflate, br&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Content-Length&quot;</span>: <span class="string">&quot;18&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/x-www-form-urlencoded&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Host&quot;</span>: <span class="string">&quot;www.httpbin.org&quot;</span>, </span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;python-requests/2.27.1&quot;</span>, </span><br><span class="line">    <span class="string">&quot;X-Amzn-Trace-Id&quot;</span>: <span class="string">&quot;Root=1-62202f58-569c426034f0fb24370d7550&quot;</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">&quot;json&quot;</span>: null, </span><br><span class="line">  <span class="string">&quot;origin&quot;</span>: <span class="string">&quot;113.65.130.252&quot;</span>, </span><br><span class="line">  <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.httpbin.org/post&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以发现，我们成功获得了返回结果，其中form部分就是提交的数据，这说明POST请求成功发送</p>
<h4 id="响应"><a href="#响应" class="headerlink" title="响应"></a>响应</h4><p>请求发送后，自然会得到响应；在上面的实例中，我们使用了text和content分别获取了文本和二进制的响应结果，此外，还有很多属性和方法可以用来获取其他信息，例如状态码、响应头、Cookie等，实例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">r = requests.post(<span class="string">&#x27;https://www.httpbin.org/post&#x27;</span>, data=data)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.status_code), r.status_code)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.headers), r.headers)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.cookies), r.cookies)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.url), r.url)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.history), r.history)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">int</span>&#x27;&gt; 200</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> &#x27;<span class="title">requests</span>.<span class="title">structures</span>.<span class="title">CaseInsensitiveDict</span>&#x27;&gt; &#123;&#x27;<span class="title">Date</span>&#x27;:</span> <span class="string">&#x27;Thu, 03 Mar 2022 03:07:56 GMT&#x27;</span>, <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span>, <span class="string">&#x27;Content-Length&#x27;</span>: <span class="string">&#x27;513&#x27;</span>, <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;keep-alive&#x27;</span>, <span class="string">&#x27;Server&#x27;</span>: <span class="string">&#x27;gunicorn/19.9.0&#x27;</span>, <span class="string">&#x27;Access-Control-Allow-Origin&#x27;</span>: <span class="string">&#x27;*&#x27;</span>, <span class="string">&#x27;Access-Control-Allow-Credentials&#x27;</span>: <span class="string">&#x27;true&#x27;</span>&#125;</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">requests</span>.<span class="title">cookies</span>.<span class="title">RequestsCookieJar</span>&#x27;&gt; &lt;<span class="title">RequestsCookieJar</span>[]&gt;</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> &#x27;<span class="title">str</span>&#x27;&gt; <span class="title">https</span>:</span>//www.httpbin.org/post</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">list</span>&#x27;&gt; []</span></span><br></pre></td></tr></table></figure>

<p>可以看到，headers和cookies这两个属性得到的结果分别是<code>CaseInsensitiveDict</code>，<code>RequestsCookieJar</code>对象，由第一章我们知道，状态码是用来表示响应状态的，例如200代表我们得到的响应是没问题的，上面的例子输出的状态码正好也是200，所以我们可以通过判断这个数字知道爬虫爬取成功了</p>
<p>requests库还提供了一个内置的状态码查询对象requests.codes，用法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://ssr1.scrape.center/&#x27;</span>)</span><br><span class="line">exit() <span class="keyword">if</span> <span class="keyword">not</span> r.status_code == requests.codes.ok <span class="keyword">else</span> <span class="built_in">print</span>(<span class="string">&quot;Reauest Successfully&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>这个状态肯定不止<code>ok</code>这一个，我们可以再去拓展下</p>
<h3 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h3><p>前面我们已经了解了requests库的基本用法，如基本的GET、POST请求以及Response对象；下面我们再来了解一些requests库的高级用法，如文件上传、Cookie设置、代理设置等</p>
<h4 id="文件上传"><a href="#文件上传" class="headerlink" title="文件上传"></a>文件上传</h4><p>我们知道使用requests库可以模拟提交一些数据，除此之外，要是有网站需要上传数据，也可以用它来实现，非常简单，实例如下:</p>
<p>这里需要用到files参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">files = &#123;<span class="string">&#x27;file&#x27;</span>: <span class="built_in">open</span>(<span class="string">&#x27;favicon.ico&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>)&#125;</span><br><span class="line">r = requests.post(<span class="string">&quot;https://www.httpbin.org/post&quot;</span>, files=files)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;args&quot;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&quot;data&quot;</span>: <span class="string">&quot;&quot;</span>, </span><br><span class="line">  <span class="string">&quot;files&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;file&quot;</span>: <span class="string">&quot;data:application/octet-stream;base64,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&quot;</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">&quot;form&quot;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&quot;headers&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;Accept&quot;</span>: <span class="string">&quot;*/*&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Accept-Encoding&quot;</span>: <span class="string">&quot;gzip, deflate, br&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Content-Length&quot;</span>: <span class="string">&quot;4433&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;multipart/form-data; boundary=d062ca2ab753328533c38d77704c89ea&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Host&quot;</span>: <span class="string">&quot;www.httpbin.org&quot;</span>, </span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;python-requests/2.27.1&quot;</span>, </span><br><span class="line">    <span class="string">&quot;X-Amzn-Trace-Id&quot;</span>: <span class="string">&quot;Root=1-6220345e-1b614f71335328ac3117c118&quot;</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">&quot;json&quot;</span>: null, </span><br><span class="line">  <span class="string">&quot;origin&quot;</span>: <span class="string">&quot;113.65.130.252&quot;</span>, </span><br><span class="line">  <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.httpbin.org/post&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们可以看到，响应中包含着files字段和form字段，而form字段是空的，这证明文件上传部分会单独用到一个files字端来标识</p>
<h4 id="Cookie设置"><a href="#Cookie设置" class="headerlink" title="Cookie设置"></a>Cookie设置</h4><p>用urllib设置cookie是比较复杂的，但在requests中，获取和设置Cookie只要一步即可完成</p>
<p>我们先用一个实例看一下获取Cookie的过程:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(r.cookies)</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> r.cookies.items():</span><br><span class="line">	<span class="built_in">print</span>(key + <span class="string">&#x27;=&#x27;</span> + value)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;RequestsCookieJar[&lt;Cookie BDORZ=<span class="number">27315</span> <span class="keyword">for</span> .baidu.com/&gt;]&gt;</span><br><span class="line">BDORZ=<span class="number">27315</span></span><br></pre></td></tr></table></figure>

<p>这里我们首先调用cookies属性，成功得到cookies，可以发现它属于RequestsCookieJar类型，然后调用items方法将cookies转化为由元组组成的列表，遍历出每一个cookie条目的名称和值，实现对cookie的遍历解析</p>
<p>当然，我们也可以直接用cookie来维持登录状态，有以下两种方式:</p>
<ul>
<li><p>直接在heaers中加入cookie</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">headers=&#123;<span class="string">&#x27;Cookie&#x27;</span>:<span class="string">&#x27;_zap=01f158f1-ff75-438d-a8b3-cba055f449c1; d_c0=&quot;AICj1MstoA2PTkXzALxQcWePBFMeB7iJcjY=|1526867722&quot;; q_c1=113a730a7a4c40d0bffd84d42a551489|1527563854000|1524791871000; Hm_lvt_ba7c84ce230944c13900faeba642b2b4=1527241782,1527563857,1527586103,1527743355; _xsrf=c92a1b0b-8efa-4ddf-b2b3-07cf5610b11c; l_n_c=1; l_cap_id=&quot;ZTc0MjgxYjYxMWNkNDUxMGFmMGQ5Y2ZlYmE2NDgxYmI=|1529994964|cae58c665907a32ef8d27ad74a51eca98fe4f97a&quot;; r_cap_id=&quot;MTJjYmJmYjIzYTBhNGQ4MWIyZmQzZDZmNWJhNGY5Mjc=|1529994964|3d6f86e368a9f9ac5cb945f334656c07d408c613&quot;; cap_id=&quot;ZWRiNzhhNjg3YjFhNDhiMWEyMGE4NGIyYWQ0M2E4YTQ=|1529994964|a48525f631fa3ace981207f6a748b9936f38ce73&quot;; n_c=1; __utma=51854390.1837640810.1529994966.1529994966.1529994966.1; __utmc=51854390; __utmz=51854390.1529994966.1.1.utmcsr=zhihu.com|utmccn=(referral)|utmcmd=referral|utmcct=/; __utmv=51854390.000--|3=entry_date=20180427=1; tgw_l7_route=860ecf76daf7b83f5a2f2dc22dccf049; capsion_ticket=&quot;2|1:0|10:1529998680|14:capsion_ticket|44:MzI5NDI3NmY0ZDg2NDhlOGIwNTRhYzM1ODhlNTJiYTY=|177bd3ed5d98ccee8ca6b291d12240aaedaf6f1325fcb08457c912e4fbfeef46&quot;; z_c0=&quot;2|1:0|10:1529998692|4:z_c0|92:Mi4xLVV3eUFBQUFBQUFBZ0tQVXl5MmdEU1lBQUFCZ0FsVk5aRHNmWEFCcmdPU2JNODdhYWgyM00tZ1oxT3l5dnRiMmp3|ccb1e3c59663aec502eddd76f154e65479fef3005490def7b35d8e2956a07b8a&quot;&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;host&#x27;</span>:<span class="string">&#x27;www.zhihu.com&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">r=requests.get(<span class="string">&#x27;https://www.zhihu.com&#x27;</span>,headers=headers)</span><br></pre></td></tr></table></figure></li>
<li><p>通过cookies参数来设置cookie的信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cookies=<span class="string">&#x27;_zap=01f158f1-ff75-438d-a8b3-cba055f449c1; d_c0=&quot;AICj1MstoA2PTkXzALxQcWePBFMeB7iJcjY=|1526867722&quot;; q_c1=113a730a7a4c40d0bffd84d42a551489|1527563854000|1524791871000; Hm_lvt_ba7c84ce230944c13900faeba642b2b4=1527241782,1527563857,1527586103,1527743355; _xsrf=c92a1b0b-8efa-4ddf-b2b3-07cf5610b11c; l_n_c=1; l_cap_id=&quot;ZTc0MjgxYjYxMWNkNDUxMGFmMGQ5Y2ZlYmE2NDgxYmI=|1529994964|cae58c665907a32ef8d27ad74a51eca98fe4f97a&quot;; r_cap_id=&quot;MTJjYmJmYjIzYTBhNGQ4MWIyZmQzZDZmNWJhNGY5Mjc=|1529994964|3d6f86e368a9f9ac5cb945f334656c07d408c613&quot;; cap_id=&quot;ZWRiNzhhNjg3YjFhNDhiMWEyMGE4NGIyYWQ0M2E4YTQ=|1529994964|a48525f631fa3ace981207f6a748b9936f38ce73&quot;; n_c=1; __utma=51854390.1837640810.1529994966.1529994966.1529994966.1; __utmc=51854390; __utmz=51854390.1529994966.1.1.utmcsr=zhihu.com|utmccn=(referral)|utmcmd=referral|utmcct=/; __utmv=51854390.000--|3=entry_date=20180427=1; tgw_l7_route=860ecf76daf7b83f5a2f2dc22dccf049; capsion_ticket=&quot;2|1:0|10:1529998680|14:capsion_ticket|44:MzI5NDI3NmY0ZDg2NDhlOGIwNTRhYzM1ODhlNTJiYTY=|177bd3ed5d98ccee8ca6b291d12240aaedaf6f1325fcb08457c912e4fbfeef46&quot;; z_c0=&quot;2|1:0|10:1529998692|4:z_c0|92:Mi4xLVV3eUFBQUFBQUFBZ0tQVXl5MmdEU1lBQUFCZ0FsVk5aRHNmWEFCcmdPU2JNODdhYWgyM00tZ1oxT3l5dnRiMmp3|ccb1e3c59663aec502eddd76f154e65479fef3005490def7b35d8e2956a07b8a&quot;&#x27;</span></span><br><span class="line">headers=&#123;<span class="string">&#x27;host&#x27;</span>:<span class="string">&#x27;www.zhihu.com&#x27;</span>,<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">jar=requests.cookies.RequestsCookieJar()</span><br><span class="line"><span class="keyword">for</span> cookie <span class="keyword">in</span> cookies.split(<span class="string">&#x27;;&#x27;</span>):</span><br><span class="line">    key,value=cookie.split(<span class="string">&#x27;=&#x27;</span>,<span class="number">1</span>)  <span class="comment"># 以&#x27;=&#x27;为分隔符，分隔成两个</span></span><br><span class="line">    jar.<span class="built_in">set</span>(key,value)</span><br><span class="line">r=requests.get(<span class="string">&#x27;https://www.zhihu.com&#x27;</span>,headers=headers,cookies=jar) </span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="Session维持"><a href="#Session维持" class="headerlink" title="Session维持"></a>Session维持</h4><p>利用session对象，我们可以很方便地维护一个session，而且不用担心cookie的问题，它会自动帮我们处理好，我们先做个小实验，如果沿用之前的写法，实例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">requests.get(<span class="string">&#x27;https://www.httpbin.org/cookies/set/number/123456789&#x27;</span>)</span><br><span class="line">r = request.get(<span class="string">&#x27;https://www.httpbin.org/cookies&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;cookies&quot;</span>: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里我们请求了一个测试网址<a class="link"   target="_blank" rel="noopener" href="https://www.httpbin.org/cookies/set/number/123456789%EF%BC%8C%E8%AF%B7%E6%B1%82%E8%BF%99%E4%B8%AA%E7%BD%91%E5%9D%80%E6%97%B6%EF%BC%8C%E6%88%91%E4%BB%AC%E8%AE%BE%E7%BD%AE%E4%BA%86%E4%B8%80%E4%B8%AAcookie%E6%9D%A1%E7%9B%AE%EF%BC%8C%E5%90%8D%E7%A7%B0%E6%98%AFnumber%EF%BC%8C%E5%86%85%E5%AE%B9%E6%98%AF1234567589%EF%BC%8C%E9%9A%8F%E5%90%8E%E5%8F%88%E8%AF%B7%E6%B1%82%E4%BA%86https://www.httpbin.org/cookies%EF%BC%8C%E4%BB%A5%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E7%9A%84cookie%E4%BF%A1%E6%81%AF" >https://www.httpbin.org/cookies/set/number/123456789，请求这个网址时，我们设置了一个cookie条目，名称是number，内容是1234567589，随后又请求了https://www.httpbin.org/cookies，以获取当前的cookie信息<i class="fas fa-external-link-alt"></i></a></p>
<p>如上面的运行结果，这样拿不到cookie</p>
<p>我们再用刚刚提到的session试试看:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">s = requests.session()</span><br><span class="line">s.get(<span class="string">&#x27;https://www.httpbin.org/cookies/set/number/123456789&#x27;</span>)</span><br><span class="line">r = s.get(<span class="string">&#x27;https://www.httpbin.org/cookies&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;cookies&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;number&quot;</span>: <span class="string">&quot;123456789&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>所以，维持在同一个session就像是告诉服务器这两个请求是同一个人，而不用再检查cookie了，利用session可以做到模拟同一个会话而不用担心cookie的问题，它通常在模拟登录成功之后，进行下一步操作时用到</p>
<h4 id="SSL证书验证"><a href="#SSL证书验证" class="headerlink" title="SSL证书验证"></a>SSL证书验证</h4><p>如果证书错误，我们可以使用verify这个参数来控制是否验证证书，不验证我们就可以<code>verify=false</code>， 如果有警告，我们可以通过忽略这个警告的方式来屏蔽这个警告:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.packages <span class="keyword">import</span> urllib3</span><br><span class="line"></span><br><span class="line">urllib.disable_warnings()</span><br><span class="line">response = requests.get(<span class="string">&#x27;https://ssr2.scrape.center/&#x27;</span>, verify=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(response.status_code)</span><br></pre></td></tr></table></figure>

<p>或者通过捕获警告到日志的方式忽略警告:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">logging.captureWarning(Ture)</span><br><span class="line">response = request.get(<span class="string">&#x27;https://ssr2.scrape.center/&#x27;</span>, verify=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(response.status_code)</span><br></pre></td></tr></table></figure>

<p>当然，我们也可以啊指定一个本地证书用作客户端证书，这可以是单个文件(包含秘钥和证书)或一个包含两个文件路径的元组:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">&#x27;https://ssr2.scrape.center/&#x27;</span>, cert=(<span class="string">&#x27;/path/server.crt&#x27;</span>, <span class="string">&#x27;path/server.key&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(response.status_code)</span><br></pre></td></tr></table></figure>

<p>当然，上面的代码是演示示例，我们需要有crt和key文件，并且指定它们的路径；另外注意<strong>本地私有证书的key必须是解密状态，加密状态的key是不支持的</strong></p>
<h4 id="超时设置"><a href="#超时设置" class="headerlink" title="超时设置"></a>超时设置</h4><p>在本机的网络状况不好或者服务器网络响应太慢甚至无响应时，我们可能会等待特别久的时间才能接收到响应，甚至到最后因为接收不到响应而报错；为了防止服务器不能及时响应，应该设置一个超时时间，如果超过这个时间还没收到响应，那就报错；这需要用到<strong>timeout</strong>参数，其值是从发起请求到服务器返回响应的时间，示例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>, timeout=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(r.status_code)</span><br></pre></td></tr></table></figure>

<p>通过这样的方式，我们可以将超时时间设置为1秒，意味着如果1秒内没有响应，就抛出异常，实际上，请求分为两个阶段: 连接(connect)和读取(read)</p>
<p>上面设置的timeout是用作连接和读取的timeout的总和，如果要分别指定用作连接和读取的timeout，则可以传入一个元组:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>, timeout=(<span class="number">5</span>, <span class="number">30</span>))</span><br></pre></td></tr></table></figure>

<p>如果想永久等待，可以直接将timeout参数设置为None，或者不设置直接留空，因为默认取值是None，这样的话，如果服务器还在运行，只是响应慢，那就慢慢等，它永远不会返回超时错误的，其用法如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>, timeout=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<p>或者直接不加参数:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="身份认证"><a href="#身份认证" class="headerlink" title="身份认证"></a>身份认证</h4><p>在网站弹出一个身份认证时，如<a class="link"   target="_blank" rel="noopener" href="https://ssr3.scrape.center/%EF%BC%8C%E6%88%91%E4%BB%AC%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%E5%91%A2%EF%BC%8C%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8urllib%E5%BA%93%E6%9D%A5%E5%AE%9E%E7%8E%B0%E8%BA%AB%E4%BB%BD%E7%9A%84%E6%A0%A1%E9%AA%8C%EF%BC%8C%E4%BD%86%E5%AE%9E%E7%8E%B0%E8%B5%B7%E6%9D%A5%E7%9B%B8%E5%AF%B9%E7%B9%81%E7%90%90%EF%BC%8C%E9%82%A3%E5%A6%82%E6%9E%9C%E4%BD%BF%E7%94%A8requests%E5%91%A2%EF%BC%8C%E5%BD%93%E7%84%B6%E4%B9%9F%E6%9C%89%E5%8A%9E%E6%B3%95%E7%9A%84" >https://ssr3.scrape.center/，我们该怎么办呢，可以使用urllib库来实现身份的校验，但实现起来相对繁琐，那如果使用requests呢，当然也有办法的<i class="fas fa-external-link-alt"></i></a></p>
<p>弹出身份认证的窗口效果如下:</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/bN6LuQ"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s4.ax1x.com/2022/03/04/bN6LuQ.png"
                      alt="bN6LuQ.png"
                ></a></p>
<p>我们可以使用requests库自带的身份认证功能，通过auth参数即可设置，示例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.auth <span class="keyword">import</span> HTTPBasicAuth</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://ssr3.scrape.center/&#x27;</span>, auth=HTTPBasicAuth(<span class="string">&#x27;admin&#x27;</span>, <span class="string">&#x27;admin&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(r.status_code)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">200</span></span><br></pre></td></tr></table></figure>

<p>这个实例网站的用户名和密码都是admin，在这里我们可以直接设置，如果用户名和密码正确，那么请求时就会自动认证成功，返回200状态码；如果认证失败，则返回401状态码</p>
<p>当然，如果参数都传一个HTTPBasicAuth类，就显得有点繁琐了，我们可以使用一个简便的写法，requests提供了一个更简单的写法，可以直接传一个元组，它会默认使用HTTPBasicAuth这个类来验证，所以上面的代码可以直接简写如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.auth <span class="keyword">import</span> HTTPBasicAuth</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://ssr3.scrape.center/&#x27;</span>, auth=(<span class="string">&#x27;admin&#x27;</span>, <span class="string">&#x27;admin&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(r.status_code)</span><br></pre></td></tr></table></figure>

<p>此外，requests库还提供了其它认证方式，如OAuth认证，不过此时需要安装oauth包，安装命令如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install requests_oauthlib</span><br></pre></td></tr></table></figure>

<p>使用OAuth1认证的示例方法如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests_oauthlib <span class="keyword">import</span> OAuth1</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://api.twitter.com/1.1/account/verify_credentials.json&quot;</span></span><br><span class="line">auth = OAuth1(<span class="string">&#x27;YOUR_APP_KEY&#x27;</span>, <span class="string">&#x27;YOUR_APP_SECRET&#x27;</span>, <span class="string">&#x27;USER_OAUTH_TOKEN&#x27;</span>, <span class="string">&#x27;USER_OAUTH_TOKEN_SECRET&#x27;</span>)</span><br><span class="line">requests.get(url, auth=auth)</span><br></pre></td></tr></table></figure>

<h4 id="代理设置"><a href="#代理设置" class="headerlink" title="代理设置"></a>代理设置</h4><p>某些网站在测试的时候请求几次，都能正常获取内容；但是一旦开始大规模爬取，面对大规模而且频繁的请求时，这些网站就可能弹出验证码，或者跳转到登录认证页面，更有甚者可能会直接封禁客户端的ip，导致在一段时间那无法访问</p>
<p>那么，为了应对这种情况，我们可以使用代码，可以向如下这般设置:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://10.0.10.0:1083&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;https://10.0.21.1:2014&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>

<p>当然，我们直接运行这个示例是运行不起来的，因为这代理是无效的，可以直接搜寻可用的代理进替换</p>
<p>若代理需要使用上文所述的身份认证，可以使用类似<code>http://user:password@host:port</code>这样的语法来设置代理，实例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://user:password@10.0.10.0:1083&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;https://user:password@10.0.21.1:2014&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>

<p>除了基本的HTTP代理之外，requests库还支持SOCKS协议的代理，首先，我们需要安装socks这个库:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install <span class="string">&quot;requests[socks]&quot;</span></span><br></pre></td></tr></table></figure>

<p>然后就可以使用SOCKS代理了，实例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;socks5://user:password@host:port&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;socks5://user:password@host:port&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>

<h4 id="Prepared-Request"><a href="#Prepared-Request" class="headerlink" title="Prepared Request"></a>Prepared Request</h4><p>我们当然可以使用requests库的get和post方法发送请求，但又没有想过，这个请求内部是怎么实现的呢？</p>
<p>实际上，<strong>requests在发送请求的时候，是在内部构造了一个Request对象，并给这个对象赋予了各种参数</strong>，包括url、headers、data等，然后直接把这个Requests对象发送出去，请求成功后会再得到一个Request对象，解析这个对象即可</p>
<p>那么Request对象是什么类型呢？实际上它就是Prepared Request</p>
<p>我们深入一下，不用get方法，直接构造一个Prepared Request对象来试试，代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> requests <span class="keyword">import</span> Request, Session</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://httpbin.org/post&#x27;</span></span><br><span class="line">data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>&#125;</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">s = Session()</span><br><span class="line">req = Request(<span class="string">&#x27;POST&#x27;</span>, url, data=data, headers=headers)</span><br><span class="line">prepped = s.prepare_request(req)</span><br><span class="line">r = s.send(prepped)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;args&quot;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&quot;data&quot;</span>: <span class="string">&quot;&quot;</span>, </span><br><span class="line">  <span class="string">&quot;files&quot;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&quot;form&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;germey&quot;</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">&quot;headers&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;Accept&quot;</span>: <span class="string">&quot;*/*&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Accept-Encoding&quot;</span>: <span class="string">&quot;gzip, deflate, br&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Content-Length&quot;</span>: <span class="string">&quot;11&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/x-www-form-urlencoded&quot;</span>, </span><br><span class="line">    <span class="string">&quot;Host&quot;</span>: <span class="string">&quot;httpbin.org&quot;</span>, </span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36&quot;</span>, </span><br><span class="line">    <span class="string">&quot;X-Amzn-Trace-Id&quot;</span>: <span class="string">&quot;Root=1-622186d8-292773bf3ba893ee5a86582c&quot;</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">&quot;json&quot;</span>: null, </span><br><span class="line">  <span class="string">&quot;origin&quot;</span>: <span class="string">&quot;113.65.130.252&quot;</span>, </span><br><span class="line">  <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://httpbin.org/post&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，这达到了POST请求同样的效果，有了Request这个对象，就可以将请求当做独立的对象来看待，这样在一些场景中我们可以直接操作这个Request对象，更灵活地实现了请求的调度和各种操作</p>
<h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><p>正则表达式相对来说是一种比较万能的匹配规则，下面我们来看看:</p>
<h3 id="实例引入-1"><a href="#实例引入-1" class="headerlink" title="实例引入"></a>实例引入</h3><p>这基本语法这里就不赘述了，可以看这个链接: <a class="link"   target="_blank" rel="noopener" href="https://www.runoob.com/regexp/regexp-tutorial.html" >https://www.runoob.com/regexp/regexp-tutorial.html<i class="fas fa-external-link-alt"></i></a></p>
<p>这里附上一张正则表达式常用的一些匹配规则:</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/bNIgiQ"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s4.ax1x.com/2022/03/04/bNIgiQ.png"
                      alt="bNIgiQ.png"
                ></a></p>
<p>然后推荐一个正则表达式测试工具: <a class="link"   target="_blank" rel="noopener" href="http://tool.oschina.net/regex/%EF%BC%8C%E7%82%B9%E5%BC%80%E8%BF%99%E4%B8%AA%E7%BD%91%E7%AB%99%E4%BC%9A%E6%9C%89%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%9A%84%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%EF%BC%8C%E4%BB%80%E4%B9%88%E5%8C%B9%E9%85%8D%E6%B1%89%E5%AD%97%E3%80%81%E7%A9%BA%E7%99%BD%E8%A1%8C%E3%80%81%E9%82%AE%E7%AE%B1%E3%80%81%E6%89%8B%E6%9C%BA%E5%8F%B7%E3%80%81%E9%82%AE%E6%94%BF%E7%BC%96%E7%A0%81%E3%80%81%E8%BA%AB%E4%BB%BD%E8%AF%81%E5%95%A5%E7%9A%84%E9%83%BD%E6%9C%89" >http://tool.oschina.net/regex/，点开这个网站会有一些常用的正则表达式，什么匹配汉字、空白行、邮箱、手机号、邮政编码、身份证啥的都有<i class="fas fa-external-link-alt"></i></a></p>
<h3 id="match"><a href="#match" class="headerlink" title="match"></a>match</h3><p>match方法会<strong>尝试从字符串的起始位置开始匹配正则表达式</strong>，如果匹配，就返回匹配成功的结果，如果不匹配，就返回None，示例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content = <span class="string">&#x27;Hello 123 4567 World_This is a Regex Demo&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(content))</span><br><span class="line">result = re.match(<span class="string">&#x27;^Hello\s\d\d\d\s\d&#123;4&#125;\s\w&#123;10&#125;&#x27;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="built_in">print</span>(result.group())</span><br><span class="line"><span class="built_in">print</span>(result.span())</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">41</span></span><br><span class="line">&lt;re.Match <span class="built_in">object</span>; span=(<span class="number">0</span>, <span class="number">25</span>), match=<span class="string">&#x27;Hello 123 4567 World_This&#x27;</span>&gt;</span><br><span class="line">Hello <span class="number">123</span> <span class="number">4567</span> World_This</span><br><span class="line">(<span class="number">0</span>, <span class="number">25</span>)</span><br></pre></td></tr></table></figure>

<p>这个实例首先声明了一个字符串，其中包括英文字母、空白字符，数字等，接着写了一个正则表达式:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">^Hello\s\d\d\d\s\d&#123;<span class="number">4</span>&#125;\s\w&#123;<span class="number">10</span>&#125;</span><br></pre></td></tr></table></figure>

<p>用它来匹配声明的那个长字符串，开头的<code>^</code>表示匹配字符串的开头，也就是以Hello开头，然后<code>\s</code>表示匹配空白字符，用来匹配目标字符串里Hello后面的空格；·<code>\d</code>表示匹配数字，3个<code>\d</code>用来匹配123,；紧接着的1个<code>\s</code>表示匹配空格；目标字符串的后面还有4567，我们其实依然可以用4个<code>\d</code>来匹配，但是这么写比较繁琐，所以可以用<code>\d</code>，后面跟<code>&#123;4&#125;</code>的形式表示匹配4次数字；后面又是一个空白字符，最后<code>\w&#123;10&#125;</code>表示匹配10个字母下划线，我们注意到，这里其实并没有把目标字符串匹配完，不过这样依然可以进行匹配，只是匹配结果短一点而已</p>
<p><strong>在match方法中，第一个参数是正则表达式，第二个参数是传入了要匹配的字符串</strong></p>
<p>将输出结果打印出来，可以看到结果是<code>re_match</code>对象，，证明匹成功，该对象包含两个方法: group方法可以输出匹配到的内容，span方法可以输出匹配的范围</p>
<h4 id="匹配目标"><a href="#匹配目标" class="headerlink" title="匹配目标"></a>匹配目标</h4><p>用match方法可以实现匹配，如果想从字符串中提取一部分内容，该怎么办呢，就像上一节的例子中提到的，从一段文本中提取出E-mail地址电话号码</p>
<p>我们可以使用括号<code>()</code>将想要提取的子字符串括起来，**<code>()</code>实际上标记了一个子表达式的开始和结束的位置**，被标记的每个子表达式依次对应每个分组，调用group方法传入分组的索引即可获取提取结果，实例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content = <span class="string">&#x27;Hello 1234567 World_This is a Regex Demo&#x27;</span></span><br><span class="line">result = re.match(<span class="string">&#x27;^Hello\s(\d+)\sWorld&#x27;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="built_in">print</span>(result.group())</span><br><span class="line"><span class="built_in">print</span>(result.group(<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(result.span())</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;re.Match <span class="built_in">object</span>; span=(<span class="number">0</span>, <span class="number">19</span>), match=<span class="string">&#x27;Hello 1234567 World&#x27;</span>&gt;</span><br><span class="line">Hello <span class="number">1234567</span> World</span><br><span class="line"><span class="number">1234567</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">19</span>)</span><br></pre></td></tr></table></figure>

<p>可以看到，我们成功得到了1234567，这里用的是group(1)，它与group()有所不同，后者会输出完整的匹配内容，前者会输出第一个热被()包围的匹配结果，假如正则表达式后面还有用()包围的，那么可以依次用group(2)、group(3)等获取</p>
<h4 id="通用匹配"><a href="#通用匹配" class="headerlink" title="通用匹配"></a>通用匹配</h4><p>刚才我们写的正则表达式其实比较复杂，只要出现空白字符就需要写<code>\s</code>匹配，出现数学就需要写<code>\d</code>匹配，这样的工作量就非常大；其实完全没必要这么做，因为还有一个万能匹配可以使用，就是<code>.*</code>，其中<code>.</code>可以匹配任意字符(除了换行符)，<code>*</code>代表匹配前面的字符无限次，所以它们组合在一起就可以匹配任意字符了；有了它，我们就不用挨个字符进行匹配了</p>
<p>接着上面的例子，我们利用<code>.*</code>改写下正则表达式:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content = <span class="string">&#x27;Hello 123 4567 World_This is a Regex Demo&#x27;</span></span><br><span class="line">result = re.match(<span class="string">&#x27;^Hello.*Demo$&#x27;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="built_in">print</span>(result.group())</span><br><span class="line"><span class="built_in">print</span>(result.span())</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;re.Match <span class="built_in">object</span>; span=(<span class="number">0</span>, <span class="number">41</span>), match=<span class="string">&#x27;Hello 123 4567 World_This is a Regex Demo&#x27;</span>&gt;</span><br><span class="line">Hello <span class="number">123</span> <span class="number">4567</span> World_This <span class="keyword">is</span> a Regex Demo</span><br><span class="line">(<span class="number">0</span>, <span class="number">41</span>)</span><br></pre></td></tr></table></figure>

<h4 id="贪婪与非贪婪"><a href="#贪婪与非贪婪" class="headerlink" title="贪婪与非贪婪"></a>贪婪与非贪婪</h4><p>使用通用匹配<code>.*</code>匹配到的内容有时候并不是我们想要的结果，看下面的例子:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content = <span class="string">&#x27;Hello 1234567 World_This is a Regex Demo&#x27;</span></span><br><span class="line">result = re.match(<span class="string">&#x27;^He.*(\d+).*Demo$&#x27;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="built_in">print</span>(result.group(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;re.Match <span class="built_in">object</span>; span=(<span class="number">0</span>, <span class="number">40</span>), match=<span class="string">&#x27;Hello 1234567 World_This is a Regex Demo&#x27;</span>&gt;</span><br><span class="line"><span class="number">7</span></span><br></pre></td></tr></table></figure>

<p>这里我们的目标是或趋数字的，可后面却拿到了最后一个数字7，这就是贪婪匹配的造成的结果</p>
<p>第一个<code>.*</code>会 一直向后匹配，然后只会给<code>\d</code>留一个7</p>
<p>那么我们这个时候就要使用非贪婪匹配了，只需要在第一个<code>.*</code>前面后面加上一个<code>?</code>，我们来看看效果:</p>
<p>代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content = <span class="string">&#x27;Hello 1234567 World_This is a Regex Demo&#x27;</span></span><br><span class="line">result = re.match(<span class="string">&#x27;^He.*?(\d+).*Demo$&#x27;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="built_in">print</span>(result.group(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;re.Match <span class="built_in">object</span>; span=(<span class="number">0</span>, <span class="number">40</span>), match=<span class="string">&#x27;Hello 1234567 World_This is a Regex Demo&#x27;</span>&gt;</span><br><span class="line"><span class="number">1234567</span></span><br></pre></td></tr></table></figure>

<p>这里要注意，如果要匹配的结果在字符串结尾，<code>.*?</code>可能匹配不到任何内容了，因为它会匹配尽可能少的内容，例如:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content = <span class="string">&#x27;http://weibo.com/comment/kEraCN&#x27;</span></span><br><span class="line">result1 = re.match(<span class="string">&#x27;http.*?comment/(.*?)&#x27;</span>, content)</span><br><span class="line">result2 = re.match(<span class="string">&#x27;http.*?comment/(.*)&#x27;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;result1&#x27;</span>, result1.group(<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;result2&#x27;</span>, result2.group(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<h4 id="修饰符"><a href="#修饰符" class="headerlink" title="修饰符"></a>修饰符</h4><p>在正则表达式中，可以用一些可选标志修饰符来控制匹配的模式；修饰符被指定为一个可选的标志，我们用实例来看看:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content = <span class="string">&#x27;&#x27;&#x27;Hello 1234567 World_This</span></span><br><span class="line"><span class="string">is a Regex Demo</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">result = re.match(<span class="string">&#x27;^He.*?(\d+).*?Demo$&#x27;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(result.group(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<p>和上面的例子相仿，我们在字符串中添加了换行符，正则表达式还是一样的，用来匹配其中的数字，看一下运行结果:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;D:/Python_LHJ/test/test.py&quot;</span>, line <span class="number">7</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="built_in">print</span>(result.group(<span class="number">1</span>))</span><br><span class="line">AttributeError: <span class="string">&#x27;NoneType&#x27;</span> <span class="built_in">object</span> has no attribute <span class="string">&#x27;group&#x27;</span></span><br></pre></td></tr></table></figure>

<p>发现运行直接报错，这是因为匹配的内容是除了换行符之外的任意字符，当遇到换行符时，<code>.*?</code>就不能匹配了，所以导致匹配失败，这里只需要加一个修饰符``re.S，即可修正这个错误:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = re.match(<span class="string">&#x27;^He.*?(\d+).*?Demo$&#x27;</span>, content, re.S)</span><br></pre></td></tr></table></figure>

<p>这个修饰符的作用是使匹配内容包括换行符在内的所有字符，此时运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1234567</span></span><br></pre></td></tr></table></figure>

<p>这个re.S在网页匹配中经常用到，因为HTML节点经常会有换行，加上它，就可以匹配节点与节点之间的换行了，另外，还有一些修饰符，在必要的情况下也可以使用，如下图所示:</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/bUJHfA"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s4.ax1x.com/2022/03/04/bUJHfA.png"
                      alt="bUJHfA.png"
                ></a></p>
<p>在网页匹配中，较为常用的有re.S和re.I</p>
<h4 id="转义匹配"><a href="#转义匹配" class="headerlink" title="转义匹配"></a>转义匹配</h4><p>我们知道正则表达式定义了许多匹配模式，如<code>.</code>用于匹配除换行符以外的任意字符，但如果目标字符串里就包含<code>.</code>这个字符，那该怎么办呢，这时就需要用到转义匹配，实例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content = <span class="string">&#x27;(百度) www.baidu.com&#x27;</span></span><br><span class="line">result = re.match(<span class="string">&#x27;\(百度 \) www\.baidu\.com&#x27;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># (百度) www.baidu.com</span></span><br></pre></td></tr></table></figure>

<p>当在目标字符串中遇到用作匹配模式的特殊字符时，在此字符前面加反斜线<code>\</code>转义一下即可</p>
<h3 id="search"><a href="#search" class="headerlink" title="search"></a>search</h3><p>前文提过，match方法是从字符串的开头开始匹配的，意味着一旦开头不匹配，整个匹配就失败了，我么看下面的例子:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content = <span class="string">&#x27;Extra stings Hello 1234567 World_This is a Regex Demo Extra stings&#x27;</span></span><br><span class="line">result = re.match(<span class="string">&#x27;Hello.*?(\d+).*?Demo&#x27;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<p>这里的字符串以Extra开头，正则表达式却以Hello开头，其实整个正则表达式是字符串的一部分，但这样匹配是失败的，因为match必须要从字符串的开头进行匹配，不然就匹配不上</p>
<p>我们把上面的match方法改成search方法，再看下运行结果:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;re.Match <span class="built_in">object</span>; span=(<span class="number">13</span>, <span class="number">53</span>), match=<span class="string">&#x27;Hello 1234567 World_This is a Regex Demo&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>

<p>这样就能匹配了，search方法会在匹配时扫描整个字符串，然后返回一个匹配成功的结果，也就是说，正则表达式可以是字符串的一部分，因此，为了匹配方便，尽量使用search方法</p>
<h3 id="findall"><a href="#findall" class="headerlink" title="findall"></a>findall</h3><p>findall会返回与正则表达式相匹配的所有字符串</p>
<p>示例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">html = <span class="string">&#x27;&#x27;&#x27;&lt;div id=&quot;songs-list&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;h2 class=&quot;title&quot;&gt;经典老歌&lt;/h2&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;introduction&quot;&gt;</span></span><br><span class="line"><span class="string">经典老歌列表</span></span><br><span class="line"><span class="string">&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;ul id=&quot;list&quot; class=&quot;list-group&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;li data-view=&quot;2&quot;&gt;一路上有你&lt;/li&gt;</span></span><br><span class="line"><span class="string">&lt;li data-view=&quot;7&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;a href=&quot;/2.mp3&quot; singer=&quot;任贤齐&quot;&gt;沧海一声笑&lt;/a&gt;</span></span><br><span class="line"><span class="string">&lt;/li&gt;</span></span><br><span class="line"><span class="string">&lt;li data-view=&quot;4&quot; class=&quot;active&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;a href=&quot;/3.mp3&quot; singer=&quot;齐秦&quot;&gt;往事随风&lt;/a&gt;</span></span><br><span class="line"><span class="string">&lt;/li&gt;</span></span><br><span class="line"><span class="string">&lt;li data-view=&quot;6&quot;&gt;&lt;a href=&quot;/4.mp3&quot; singer=&quot;beyond&quot;&gt;光辉岁月&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">&lt;li data-view=&quot;5&quot;&gt;&lt;a href=&quot;/5.mp3&quot; singer=&quot;陈慧琳&quot;&gt;记事本&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">&lt;li data-view=&quot;5&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;a href=&quot;/6.mp3&quot; singer=&quot;邓丽君&quot;&gt;但愿人长久&lt;/a&gt;</span></span><br><span class="line"><span class="string">&lt;/li&gt;</span></span><br><span class="line"><span class="string">&lt;/ul&gt;</span></span><br><span class="line"><span class="string">&lt;/div&gt;&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">results = re.findall(<span class="string">&#x27;&lt;li.*?href=&quot;(.*?)&quot;.*?singer=&quot;(.*?)&quot;&gt;(.*?)&lt;/a&gt;&#x27;</span>, html, re.S)</span><br><span class="line"><span class="built_in">print</span>(results)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(results))</span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    <span class="built_in">print</span>(result)</span><br><span class="line">    <span class="built_in">print</span>(result[<span class="number">0</span>], result[<span class="number">1</span>], result[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="string">&#x27;/2.mp3&#x27;</span>, <span class="string">&#x27;任贤齐&#x27;</span>, <span class="string">&#x27;沧海一声笑&#x27;</span>), (<span class="string">&#x27;/3.mp3&#x27;</span>, <span class="string">&#x27;齐秦&#x27;</span>, <span class="string">&#x27;往事随风&#x27;</span>), (<span class="string">&#x27;/4.mp3&#x27;</span>, <span class="string">&#x27;beyond&#x27;</span>, <span class="string">&#x27;光辉岁月&#x27;</span>), (<span class="string">&#x27;/5.mp3&#x27;</span>, <span class="string">&#x27;陈慧琳&#x27;</span>, <span class="string">&#x27;记事本&#x27;</span>), (<span class="string">&#x27;/6.mp3&#x27;</span>, <span class="string">&#x27;邓丽君&#x27;</span>, <span class="string">&#x27;但愿人长久&#x27;</span>)]</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">list</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">(<span class="params"><span class="string">&#x27;/2.mp3&#x27;</span>, <span class="string">&#x27;任贤齐&#x27;</span>, <span class="string">&#x27;沧海一声笑&#x27;</span></span>)</span></span><br><span class="line"><span class="class">/2.<span class="title">mp3</span> 任贤齐 沧海一声笑</span></span><br><span class="line"><span class="class">(<span class="params"><span class="string">&#x27;/3.mp3&#x27;</span>, <span class="string">&#x27;齐秦&#x27;</span>, <span class="string">&#x27;往事随风&#x27;</span></span>)</span></span><br><span class="line"><span class="class">/3.<span class="title">mp3</span> 齐秦 往事随风</span></span><br><span class="line"><span class="class">(<span class="params"><span class="string">&#x27;/4.mp3&#x27;</span>, <span class="string">&#x27;beyond&#x27;</span>, <span class="string">&#x27;光辉岁月&#x27;</span></span>)</span></span><br><span class="line"><span class="class">/4.<span class="title">mp3</span> <span class="title">beyond</span> 光辉岁月</span></span><br><span class="line"><span class="class">(<span class="params"><span class="string">&#x27;/5.mp3&#x27;</span>, <span class="string">&#x27;陈慧琳&#x27;</span>, <span class="string">&#x27;记事本&#x27;</span></span>)</span></span><br><span class="line"><span class="class">/5.<span class="title">mp3</span> 陈慧琳 记事本</span></span><br><span class="line"><span class="class">(<span class="params"><span class="string">&#x27;/6.mp3&#x27;</span>, <span class="string">&#x27;邓丽君&#x27;</span>, <span class="string">&#x27;但愿人长久&#x27;</span></span>)</span></span><br><span class="line"><span class="class">/6.<span class="title">mp3</span> 邓丽君 但愿人长久</span></span><br></pre></td></tr></table></figure>

<p>如果只想获取匹配到的第一个字符串，可以用search方法，如果需要提取多个内容可以用findall方法</p>
<h3 id="sub"><a href="#sub" class="headerlink" title="sub"></a>sub</h3><p>除了使用正则表达式提取信息，有时候还需要借助它来修改文本；例如，想要把一串文本的所有数字都去掉，如果只用字符串的replace方法，未免太繁琐了，这时可以借助sub方法，实例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content = <span class="string">&#x27;54aK54yr5oiR54ix5L2g&#x27;</span></span><br><span class="line">content = re.sub(<span class="string">&#x27;\d+&#x27;</span>, <span class="string">&#x27;&#x27;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aKyroiRixLg</span><br></pre></td></tr></table></figure>

<h3 id="compile"><a href="#compile" class="headerlink" title="compile"></a>compile</h3><p>compile方法可以将正则字符串编译成正则表达式对象，以便在后面的匹配中复用，示例代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content1 = <span class="string">&#x27;2019-12-15 12:00&#x27;</span></span><br><span class="line">content2 = <span class="string">&#x27;2019-12-17 12:55&#x27;</span></span><br><span class="line">content3 = <span class="string">&#x27;2019-12-22 13:21&#x27;</span></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;\d&#123;2&#125;:\d&#123;2&#125;&#x27;</span>)</span><br><span class="line">result1 = re.sub(pattern, <span class="string">&#x27;&#x27;</span>, content1)</span><br><span class="line">result2 = re.sub(pattern, <span class="string">&#x27;&#x27;</span>, content2)</span><br><span class="line">result3 = re.sub(pattern, <span class="string">&#x27;&#x27;</span>, content3)</span><br><span class="line"><span class="built_in">print</span>(result1, result2, result3)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2019</span>-<span class="number">12</span>-<span class="number">15</span>  <span class="number">2019</span>-<span class="number">12</span>-<span class="number">17</span>  <span class="number">2019</span>-<span class="number">12</span>-<span class="number">22</span></span><br></pre></td></tr></table></figure>

<p>另外，compile还可以传入修饰符，例如re.S等修饰符，这样在search、findall等方法中就不需要额外传了，所以，可以说compile方法是给正则表达式做了一层封装，以便我们更好地复用</p>
<h2 id="httpx的使用"><a href="#httpx的使用" class="headerlink" title="httpx的使用"></a>httpx的使用</h2><p>前面我们介绍了urllib库和requests库的使用，已经可以爬取绝大多数网站的数据，但对于某些网站任然无能为力，因为这些网站强制使用HTTP/2.0协议访问，这时urllib和requests是无法爬取数据的，因为它们只支持HTTP/1.1，不支持HTHTP/2.0，那这种情况我们可以使用一些支持HTTP/2.0的请求库就好了，目前来说，比较有代表性的是hyper和httpx，后者使用起来更加方便，功能也更强大，requests已有的功能它几乎都支持</p>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>我们来看一个案例: <a class="link"   target="_blank" rel="noopener" href="https://spa16.scrape.center/%E5%B0%B1%E6%98%AF%E5%BC%BA%E5%88%B6%E4%BD%BF%E7%94%A8HTTP/2.0%E8%AE%BF%E9%97%AE%E7%9A%84%E4%B8%80%E4%B8%AA%E7%BD%91%E7%AB%99%EF%BC%8C%E7%94%A8%E6%B5%8F%E8%A7%88%E5%99%A8%E6%89%93%E5%BC%80%E6%AD%A4%E7%BD%91%E7%AB%99%EF%BC%8C%E6%9F%A5%E7%9C%8Bnetwork%E9%9D%A2%E6%9D%BF%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0Protocal%E4%B8%80%E5%88%97%E9%83%BD%E6%98%AFh2%EF%BC%8C%E8%AF%81%E6%98%8E%E8%AF%B7%E6%B1%82%E6%89%80%E7%94%A8%E7%9A%84%E5%8D%8F%E8%AE%AE%E6%98%AFHTTP/2.0%EF%BC%8C%E5%A6%82%E4%B8%8B%E5%9B%BE%E6%89%80%E7%A4%BA" >https://spa16.scrape.center/就是强制使用HTTP/2.0访问的一个网站，用浏览器打开此网站，查看network面板，可以看到Protocal一列都是h2，证明请求所用的协议是HTTP/2.0，如下图所示<i class="fas fa-external-link-alt"></i></a>:</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/bU6JxO"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s4.ax1x.com/2022/03/04/bU6JxO.png"
                      alt="bU6JxO.png"
                ></a></p>
<p>这个网站用requests是无法爬取的，不妨来尝试下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://spa6.scrape.center/&#x27;</span></span><br><span class="line">response = requests.get(url)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.exceptions.ConnectionError: (<span class="string">&#x27;Connection aborted.&#x27;</span>, ConnectionResetError(<span class="number">10054</span>, <span class="string">&#x27;远程主机强迫关闭了一个现有的连接。&#x27;</span>, <span class="literal">None</span>, <span class="number">10054</span>, <span class="literal">None</span>))</span><br></pre></td></tr></table></figure>

<p>可以看到，直接远程就关闭了连接</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>使用以下命令:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install httpx</span><br></pre></td></tr></table></figure>

<p>但这样安装完的httpx是不支持HTTP/2..0的，如果想支持，可以这样安装:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install <span class="string">&#x27;httpx[http2]&#x27;</span></span><br></pre></td></tr></table></figure>

<p>这样就既安装了httpx，又安装了httpx对HTTP/2.0的支持模块</p>
<h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3><p>httpx和requests的很多API存在相似之处，我们先看下最基本的GET请求的用法:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"></span><br><span class="line">response = httpx.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(response.status_code)</span><br><span class="line"><span class="built_in">print</span>(response.headers)</span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure>

<p>我们也可以添加headers参数:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">response = httpx.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>, headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure>

<p>回到本节开头的示例网站，我们试着用httpx请求下这个网站，看看效果如何，代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://spa16.scrape.center/&#x27;</span></span><br><span class="line">response = httpx.get(url)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>

<p>会发现还是报错，这是为什么呢</p>
<p>其实，httpx默认是不会开启对HTTP/2.0的，默认使用的是HTTP/1.1，需要手动声明一下才能使用HTTP/2.0，代码改写如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line">client = httpx.Client(http2=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">response = client.get(</span><br><span class="line">    <span class="string">&#x27;https://spa16.scrape.center/&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure>

<p>刚才我们也提到了，httpx和requests有很多相似的API，下面我们来列举下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"></span><br><span class="line">r = httpx.get(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>, params=&#123;<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;germey&#x27;</span>&#125;)</span><br><span class="line">r = httpx.post(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>, data=&#123;<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;germey&#x27;</span>&#125;)</span><br><span class="line">r = httpx.put(<span class="string">&#x27;https://www.httpbin.org/put&#x27;</span>)</span><br><span class="line">r = httpx.delete(<span class="string">&#x27;https://www.httpbin.org/delete&#x27;</span>)</span><br><span class="line">r = httpx.patch(<span class="string">&#x27;https://www.httpbin.org/patch&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>基于得到的Response对象，可以使用如下属性和方法获取想要的内容</p>
<ul>
<li>status_code: 状态码</li>
<li>text: 响应体的文本内容</li>
<li>content: 响应体的二进制内容</li>
<li>headers: 响应头，是Headers对象</li>
<li>json: 方法，可以调用此方法将文本结果转化为JSON对象</li>
</ul>
<h3 id="client对象"><a href="#client对象" class="headerlink" title="client对象"></a>client对象</h3><p>httpx中有一些基本的API和requests中的非常相似，但也有一些API是不相似的，例如<strong>httpx中有一个Client对象，就可以和requests中的Session中的Session对象类比学习</strong></p>
<p>下面我们我们介绍Client对象的使用，官方比较推荐的使用方式是with as语句，示例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> httpx.Client() <span class="keyword">as</span> client:</span><br><span class="line">    response = client.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>

<p>这个用法等价于:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"></span><br><span class="line">client = httpx.Client()</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = client.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    client.close()</span><br></pre></td></tr></table></figure>

<p>另外，在声明Client对象时，可以指定一些参数，例如headers，这样使用该对象发起的所有请求都会默认带上这些参数配置，示例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://httpbin.org/headers&#x27;</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;my-app/0.0.1&#x27;</span>&#125;</span><br><span class="line"><span class="keyword">with</span> httpx.Client(headers=headers) <span class="keyword">as</span> client:</span><br><span class="line">    r = client.get(url)</span><br><span class="line">    <span class="built_in">print</span>(r.json()[<span class="string">&#x27;headers&#x27;</span>][<span class="string">&#x27;User-Agent&#x27;</span>])</span><br></pre></td></tr></table></figure>

<h3 id="支持HTTP-2-0"><a href="#支持HTTP-2-0" class="headerlink" title="支持HTTP/2.0"></a>支持HTTP/2.0</h3><p>接上上面的，要使得Client对象支持HTTP/2.0，需要将http2参数设置为True，如果不设置，那么默认支持HTTP/1.1</p>
<p>写法如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line">client = httpx.Client(http2=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">response = client.get(</span><br><span class="line">    <span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br><span class="line"><span class="built_in">print</span>(response.http_version)</span><br></pre></td></tr></table></figure>

<h3 id="支持异步请求"><a href="#支持异步请求" class="headerlink" title="支持异步请求"></a>支持异步请求</h3><p>httpx还支持异步客户端请求，支持Python的async的请求模式，写法如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">fetch</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> httpx.AsyncClient(http2=<span class="literal">True</span>) <span class="keyword">as</span> client:</span><br><span class="line">        response = <span class="keyword">await</span> client.get(url)</span><br><span class="line">        <span class="built_in">print</span>(response.text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    asyncio.get_event_loop().run_until_complete(fetch(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h2 id="基础爬虫案例实战"><a href="#基础爬虫案例实战" class="headerlink" title="基础爬虫案例实战"></a>基础爬虫案例实战</h2><p>这里直接上代码，直接看代码叭:</p>
<p>这是使用PyQuery + MongoDB + 多进程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                    <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;</span>)</span><br><span class="line"></span><br><span class="line">BASE_URL = <span class="string">&#x27;https://ssr1.scrape.center&#x27;</span></span><br><span class="line">TOTAL_PAGE = <span class="number">10</span></span><br><span class="line">MONGO_CONNECTION_STRING = <span class="string">&#x27;mongodb://localhost:27017&#x27;</span></span><br><span class="line">MONGO_DB_NAME = <span class="string">&#x27;movies&#x27;</span></span><br><span class="line">MONGO_COLLECTION_NAME = <span class="string">&#x27;movies&#x27;</span></span><br><span class="line"></span><br><span class="line">client = pymongo.MongoClient(MONGO_CONNECTION_STRING)</span><br><span class="line">db = client[<span class="string">&#x27;movies&#x27;</span>]</span><br><span class="line">collection = db[<span class="string">&#x27;movies&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_page</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    scrape page by url and return its html</span></span><br><span class="line"><span class="string">    :param url: page url</span></span><br><span class="line"><span class="string">    :return: html of page</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    logging.info(<span class="string">&#x27;scraping %s...&#x27;</span>, url)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">        logging.error(<span class="string">&#x27;get invalid status code %s while scraping %s&#x27;</span>, response.status_code, url)</span><br><span class="line">    <span class="keyword">except</span> requests.RequestException:</span><br><span class="line">        logging.error(<span class="string">&#x27;error occurred while scraping %s&#x27;</span>, url, exc_info=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_index</span>(<span class="params">page</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    scrape index page and return its html</span></span><br><span class="line"><span class="string">    :param page: page of index page</span></span><br><span class="line"><span class="string">    :return: html of index page</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    index_url = <span class="string">f&#x27;<span class="subst">&#123;BASE_URL&#125;</span>/page/<span class="subst">&#123;page&#125;</span>&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> scrape_page(index_url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_index</span>(<span class="params">html</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    parse index page</span></span><br><span class="line"><span class="string">    :param html: html of index page</span></span><br><span class="line"><span class="string">    :return: generator of detail page url</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    doc = pq(html)</span><br><span class="line">    links = doc(<span class="string">&#x27;.el-card .name&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> links.items():</span><br><span class="line">        href = link.attr(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">        detail_url = urljoin(BASE_URL, href)</span><br><span class="line">        logging.info(<span class="string">&#x27;get detail url %s&#x27;</span>, detail_url)</span><br><span class="line">        <span class="keyword">yield</span> detail_url</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_detail</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    scrape detail page and return its html</span></span><br><span class="line"><span class="string">    :param page: page of detail page</span></span><br><span class="line"><span class="string">    :return: html of detail page</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> scrape_page(url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_detail</span>(<span class="params">html</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    parse detail page</span></span><br><span class="line"><span class="string">    :param html: html of detail page</span></span><br><span class="line"><span class="string">    :return: data</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    doc = pq(html)</span><br><span class="line">    cover = doc(<span class="string">&#x27;img.cover&#x27;</span>).attr(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">    name = doc(<span class="string">&#x27;a &gt; h2&#x27;</span>).text()</span><br><span class="line">    categories = [item.text() <span class="keyword">for</span> item <span class="keyword">in</span> doc(<span class="string">&#x27;.categories button span&#x27;</span>).items()]</span><br><span class="line">    published_at = doc(<span class="string">&#x27;.info:contains(上映)&#x27;</span>).text()</span><br><span class="line">    published_at = re.search(<span class="string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;)&#x27;</span>, published_at).group(<span class="number">1</span>) \</span><br><span class="line">        <span class="keyword">if</span> published_at <span class="keyword">and</span> re.search(<span class="string">&#x27;\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;&#x27;</span>, published_at) <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    drama = doc(<span class="string">&#x27;.drama p&#x27;</span>).text()</span><br><span class="line">    score = doc(<span class="string">&#x27;p.score&#x27;</span>).text()</span><br><span class="line">    score = <span class="built_in">float</span>(score) <span class="keyword">if</span> score <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;cover&#x27;</span>: cover,</span><br><span class="line">        <span class="string">&#x27;name&#x27;</span>: name,</span><br><span class="line">        <span class="string">&#x27;categories&#x27;</span>: categories,</span><br><span class="line">        <span class="string">&#x27;published_at&#x27;</span>: published_at,</span><br><span class="line">        <span class="string">&#x27;drama&#x27;</span>: drama,</span><br><span class="line">        <span class="string">&#x27;score&#x27;</span>: score</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_data</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    save to mongodb</span></span><br><span class="line"><span class="string">    :param data:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    collection.update_one(&#123;</span><br><span class="line">        <span class="string">&#x27;name&#x27;</span>: data.get(<span class="string">&#x27;name&#x27;</span>)</span><br><span class="line">    &#125;, &#123;</span><br><span class="line">        <span class="string">&#x27;$set&#x27;</span>: data</span><br><span class="line">    &#125;, upsert=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">page</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    main process</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    index_html = scrape_index(page)</span><br><span class="line">    detail_urls = parse_index(index_html)</span><br><span class="line">    <span class="keyword">for</span> detail_url <span class="keyword">in</span> detail_urls:</span><br><span class="line">        detail_html = scrape_detail(detail_url)</span><br><span class="line">        data = parse_detail(detail_html)</span><br><span class="line">        logging.info(<span class="string">&#x27;get detail data %s&#x27;</span>, data)</span><br><span class="line">        logging.info(<span class="string">&#x27;saving data to mongodb&#x27;</span>)</span><br><span class="line">        save_data(data)</span><br><span class="line">        logging.info(<span class="string">&#x27;data saved successfully&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pool = multiprocessing.Pool()</span><br><span class="line">    pages = <span class="built_in">range</span>(<span class="number">1</span>, TOTAL_PAGE + <span class="number">1</span>)</span><br><span class="line">    pool.<span class="built_in">map</span>(main, pages)</span><br><span class="line">    pool.close()</span><br></pre></td></tr></table></figure>

<p>正则表达式 + 文本 + 多进程版本:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> makedirs</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> exists</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                    <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;</span>)</span><br><span class="line"></span><br><span class="line">BASE_URL = <span class="string">&#x27;https://ssr1.scrape.center&#x27;</span></span><br><span class="line">TOTAL_PAGE = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">RESULTS_DIR = <span class="string">&#x27;results&#x27;</span></span><br><span class="line">exists(RESULTS_DIR) <span class="keyword">or</span> makedirs(RESULTS_DIR)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_page</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    scrape page by url and return its html</span></span><br><span class="line"><span class="string">    :param url: page url</span></span><br><span class="line"><span class="string">    :return: html of page</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    logging.info(<span class="string">&#x27;scraping %s...&#x27;</span>, url)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">        logging.error(<span class="string">&#x27;get invalid status code %s while scraping %s&#x27;</span>,</span><br><span class="line">                      response.status_code, url)</span><br><span class="line">    <span class="keyword">except</span> requests.RequestException:</span><br><span class="line">        logging.error(<span class="string">&#x27;error occurred while scraping %s&#x27;</span>, url, exc_info=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_index</span>(<span class="params">page</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    scrape index page and return its html</span></span><br><span class="line"><span class="string">    :param page: page of index page</span></span><br><span class="line"><span class="string">    :return: html of index page</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    index_url = <span class="string">f&#x27;<span class="subst">&#123;BASE_URL&#125;</span>/page/<span class="subst">&#123;page&#125;</span>&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> scrape_page(index_url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_index</span>(<span class="params">html</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    parse index page and return detail url</span></span><br><span class="line"><span class="string">    :param html: html of index page</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;&lt;a.*?href=&quot;(.*?)&quot;.*?class=&quot;name&quot;&gt;&#x27;</span>)</span><br><span class="line">    items = re.findall(pattern, html)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> items:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        detail_url = urljoin(BASE_URL, item)</span><br><span class="line">        logging.info(<span class="string">&#x27;get detail url %s&#x27;</span>, detail_url)</span><br><span class="line">        <span class="keyword">yield</span> detail_url</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_detail</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    scrape detail page and return its html</span></span><br><span class="line"><span class="string">    :param page: page of detail page</span></span><br><span class="line"><span class="string">    :return: html of detail page</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> scrape_page(url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_detail</span>(<span class="params">html</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    parse detail page</span></span><br><span class="line"><span class="string">    :param html: html of detail page</span></span><br><span class="line"><span class="string">    :return: data</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    cover_pattern = re.<span class="built_in">compile</span>(</span><br><span class="line">        <span class="string">&#x27;class=&quot;item.*?&lt;img.*?src=&quot;(.*?)&quot;.*?class=&quot;cover&quot;&gt;&#x27;</span>, re.S)</span><br><span class="line">    name_pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;&lt;h2.*?&gt;(.*?)&lt;/h2&gt;&#x27;</span>)</span><br><span class="line">    categories_pattern = re.<span class="built_in">compile</span>(</span><br><span class="line">        <span class="string">&#x27;&lt;button.*?category.*?&lt;span&gt;(.*?)&lt;/span&gt;.*?&lt;/button&gt;&#x27;</span>, re.S)</span><br><span class="line">    published_at_pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;)\s?上映&#x27;</span>)</span><br><span class="line">    drama_pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;&lt;div.*?drama.*?&gt;.*?&lt;p.*?&gt;(.*?)&lt;/p&gt;&#x27;</span>, re.S)</span><br><span class="line">    score_pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;&lt;p.*?score.*?&gt;(.*?)&lt;/p&gt;&#x27;</span>, re.S)</span><br><span class="line"></span><br><span class="line">    cover = re.search(cover_pattern, html).group(</span><br><span class="line">        <span class="number">1</span>).strip() <span class="keyword">if</span> re.search(cover_pattern, html) <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    name = re.search(name_pattern, html).group(</span><br><span class="line">        <span class="number">1</span>).strip() <span class="keyword">if</span> re.search(name_pattern, html) <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    categories = re.findall(categories_pattern, html) <span class="keyword">if</span> re.findall(</span><br><span class="line">        categories_pattern, html) <span class="keyword">else</span> []</span><br><span class="line">    published_at = re.search(published_at_pattern, html).group(</span><br><span class="line">        <span class="number">1</span>) <span class="keyword">if</span> re.search(published_at_pattern, html) <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    drama = re.search(drama_pattern, html).group(</span><br><span class="line">        <span class="number">1</span>).strip() <span class="keyword">if</span> re.search(drama_pattern, html) <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    score = <span class="built_in">float</span>(re.search(score_pattern, html).group(<span class="number">1</span>).strip()</span><br><span class="line">                  ) <span class="keyword">if</span> re.search(score_pattern, html) <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;cover&#x27;</span>: cover,</span><br><span class="line">        <span class="string">&#x27;name&#x27;</span>: name,</span><br><span class="line">        <span class="string">&#x27;categories&#x27;</span>: categories,</span><br><span class="line">        <span class="string">&#x27;published_at&#x27;</span>: published_at,</span><br><span class="line">        <span class="string">&#x27;drama&#x27;</span>: drama,</span><br><span class="line">        <span class="string">&#x27;score&#x27;</span>: score</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_data</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    save to json file</span></span><br><span class="line"><span class="string">    :param data:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    name = data.get(<span class="string">&#x27;name&#x27;</span>)</span><br><span class="line">    data_path = <span class="string">f&#x27;<span class="subst">&#123;RESULTS_DIR&#125;</span>/<span class="subst">&#123;name&#125;</span>.json&#x27;</span></span><br><span class="line">    json.dump(data, <span class="built_in">open</span>(data_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>),</span><br><span class="line">              ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">page</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    main process</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    index_html = scrape_index(page)</span><br><span class="line">    detail_urls = parse_index(index_html)</span><br><span class="line">    <span class="keyword">for</span> detail_url <span class="keyword">in</span> detail_urls:</span><br><span class="line">        detail_html = scrape_detail(detail_url)</span><br><span class="line">        data = parse_detail(detail_html)</span><br><span class="line">        logging.info(<span class="string">&#x27;get detail data %s&#x27;</span>, data)</span><br><span class="line">        logging.info(<span class="string">&#x27;saving data to json file&#x27;</span>)</span><br><span class="line">        save_data(data)</span><br><span class="line">        logging.info(<span class="string">&#x27;data saved successfully&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pool = multiprocessing.Pool()</span><br><span class="line">    pages = <span class="built_in">range</span>(<span class="number">1</span>, TOTAL_PAGE + <span class="number">1</span>)</span><br><span class="line">    pool.<span class="built_in">map</span>(main, pages)</span><br><span class="line">    pool.close()</span><br></pre></td></tr></table></figure>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li>Post title：Python3网络爬虫开发实战第二版第2章-基本库的使用</li>
        <li>Post author：Lhj</li>
        <li>Create time：2022-02-07 17:18:30</li>
        <li>
            Post link：https://keep.xpoet.cn/2022/02/07/Python3网络爬虫开发实战第二版第2章-基本库的使用/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2022/02/08/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC3%E7%AB%A0-%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A7%A3%E6%9E%90%E6%8F%90%E5%8F%96/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Python3网络爬虫开发实战第二版第3章-网页数据的解析提取</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2022/01/28/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC1%E7%AB%A0-%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Python3网络爬虫开发实战第二版第1章-爬虫基础</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;Comments</i>
    </div>
    

        
            
    <div class="valine-container">
        <script data-pjax
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script data-pjax>
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'nIcO1O6cSVuRH8EROCWwNFWN-gzGzoHsz',
                    appKey: 'qrglokTeum8DXiYRzM4k4NF4',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: '😜 尽情吐槽吧~',
                    lang: 'en'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Lhj';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('true') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2022&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Lhj</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#urllib%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">1.</span> <span class="nav-text">urllib的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82"><span class="nav-number">1.1.</span> <span class="nav-text">发送请求</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#urlopen"><span class="nav-number">1.1.1.</span> <span class="nav-text">urlopen</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Request"><span class="nav-number">1.1.2.</span> <span class="nav-text">Request</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#requests%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">2.</span> <span class="nav-text">requests的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="nav-number">2.1.</span> <span class="nav-text">准备工作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E4%BE%8B%E5%BC%95%E5%85%A5"><span class="nav-number">2.2.</span> <span class="nav-text">实例引入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GET%E8%AF%B7%E6%B1%82"><span class="nav-number">2.3.</span> <span class="nav-text">GET请求</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E5%AE%9E%E4%BE%8B"><span class="nav-number">2.3.1.</span> <span class="nav-text">基本实例</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8A%93%E5%8F%96%E7%BD%91%E9%A1%B5"><span class="nav-number">2.3.2.</span> <span class="nav-text">抓取网页</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8A%93%E5%8F%96%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0%E6%8D%AE"><span class="nav-number">2.3.3.</span> <span class="nav-text">抓取二进制数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B7%BB%E5%8A%A0%E8%AF%B7%E6%B1%82%E5%A4%B4"><span class="nav-number">2.3.4.</span> <span class="nav-text">添加请求头</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#POST%E8%AF%B7%E6%B1%82"><span class="nav-number">2.4.</span> <span class="nav-text">POST请求</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E5%AE%9E%E4%BE%8B-1"><span class="nav-number">2.4.1.</span> <span class="nav-text">基本实例</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%93%8D%E5%BA%94"><span class="nav-number">2.4.2.</span> <span class="nav-text">响应</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95"><span class="nav-number">2.5.</span> <span class="nav-text">高级用法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0"><span class="nav-number">2.5.1.</span> <span class="nav-text">文件上传</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Cookie%E8%AE%BE%E7%BD%AE"><span class="nav-number">2.5.2.</span> <span class="nav-text">Cookie设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Session%E7%BB%B4%E6%8C%81"><span class="nav-number">2.5.3.</span> <span class="nav-text">Session维持</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SSL%E8%AF%81%E4%B9%A6%E9%AA%8C%E8%AF%81"><span class="nav-number">2.5.4.</span> <span class="nav-text">SSL证书验证</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B6%85%E6%97%B6%E8%AE%BE%E7%BD%AE"><span class="nav-number">2.5.5.</span> <span class="nav-text">超时设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81"><span class="nav-number">2.5.6.</span> <span class="nav-text">身份认证</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE"><span class="nav-number">2.5.7.</span> <span class="nav-text">代理设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Prepared-Request"><span class="nav-number">2.5.8.</span> <span class="nav-text">Prepared Request</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="nav-number">3.</span> <span class="nav-text">正则表达式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E4%BE%8B%E5%BC%95%E5%85%A5-1"><span class="nav-number">3.1.</span> <span class="nav-text">实例引入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#match"><span class="nav-number">3.2.</span> <span class="nav-text">match</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8C%B9%E9%85%8D%E7%9B%AE%E6%A0%87"><span class="nav-number">3.2.1.</span> <span class="nav-text">匹配目标</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%9A%E7%94%A8%E5%8C%B9%E9%85%8D"><span class="nav-number">3.2.2.</span> <span class="nav-text">通用匹配</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B4%AA%E5%A9%AA%E4%B8%8E%E9%9D%9E%E8%B4%AA%E5%A9%AA"><span class="nav-number">3.2.3.</span> <span class="nav-text">贪婪与非贪婪</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%AE%E9%A5%B0%E7%AC%A6"><span class="nav-number">3.2.4.</span> <span class="nav-text">修饰符</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BD%AC%E4%B9%89%E5%8C%B9%E9%85%8D"><span class="nav-number">3.2.5.</span> <span class="nav-text">转义匹配</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#search"><span class="nav-number">3.3.</span> <span class="nav-text">search</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#findall"><span class="nav-number">3.4.</span> <span class="nav-text">findall</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sub"><span class="nav-number">3.5.</span> <span class="nav-text">sub</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#compile"><span class="nav-number">3.6.</span> <span class="nav-text">compile</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#httpx%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">4.</span> <span class="nav-text">httpx的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B"><span class="nav-number">4.1.</span> <span class="nav-text">示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85"><span class="nav-number">4.2.</span> <span class="nav-text">安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="nav-number">4.3.</span> <span class="nav-text">基本使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#client%E5%AF%B9%E8%B1%A1"><span class="nav-number">4.4.</span> <span class="nav-text">client对象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%AF%E6%8C%81HTTP-2-0"><span class="nav-number">4.5.</span> <span class="nav-text">支持HTTP&#x2F;2.0</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%BC%82%E6%AD%A5%E8%AF%B7%E6%B1%82"><span class="nav-number">4.6.</span> <span class="nav-text">支持异步请求</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E7%88%AC%E8%99%AB%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98"><span class="nav-number">5.</span> <span class="nav-text">基础爬虫案例实战</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/dark-light-toggle.js"></script>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/local-search.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/code-copy.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/lazyload.js"></script>


<div class="post-scripts pjax">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/toc.js"></script>
    
</div>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/pjax.min.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
