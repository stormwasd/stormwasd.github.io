<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Lhj">
    
    <title>
        
            Python3网络爬虫开发实战第二版第9章-代理的使用 |
        
        Alexander
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/css/font-awesome.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":true}}},"local_search":{"enable":true,"preload":false},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":true},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                Alexander
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                NOTE
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                ABOUT
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">NOTE</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">Python3网络爬虫开发实战第二版第9章-代理的使用</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/avatar.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Lhj</span>
                        
                            <span class="author-label">Lv5</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2022-02-15 16:52:30</span>
        <span class="mobile">2022-02-15 16:52</span>
    </span>
    
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>6.9k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>29 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <p>在使用爬虫的过程中经常会遇到这样的情况，爬虫最初还可以正常运行，正常爬取数据，一切看起来都是那么美好，然而一杯茶的功夫，就可能出现了错误，比如返回403或者啥的，出现这些现象的原因是网站采取了一些反爬措施，例如服务器会检测某个IP在单位时间内的请求次数，如果这个次数超过了指定的阈值，就直接拒绝服务，并返回一些错误信息，这种情况就称为封IP，既然服务器检测的是单位时间内某个IP在单位时间的请求次数，那么借助某种方式把IP伪装起来，让服务器识别不出是由我们本机发起的请求不就可以了</p>
<h3 id="代理的设置"><a href="#代理的设置" class="headerlink" title="代理的设置"></a>代理的设置</h3><h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><p>代理的基本原理可移步第一章，这样有助于更好地理解和学习以下内容；另外，需要先获取一个可用代理，代理就是IP地址和端口的组合，格式是<code>&lt;ip&gt;:&lt;port&gt;</code>；如果代理需要访问认证，则还需要额外的用户名和密码两个信息</p>
<p>那么如何获取一个可用代理呢，使用搜索引擎搜索代理两字，会返回许多代理服务网站，网站上提供了很多免费或付费代理，例如快代理的免费HTTP代理: https:<a class="link"   target="_blank" rel="noopener" href="http://www.kuaidaili.com/free/%E5%B0%B1%E6%8F%90%E4%BE%9B%E4%BA%86%E5%BE%88%E5%A4%9A%E5%85%8D%E8%B4%B9%E4%BB%A3%E7%90%86%EF%BC%8C%E4%BD%86%E5%9C%A8%E5%A4%A7%E5%A4%9A%E6%95%B0%E6%83%85%E5%86%B5%E4%B8%8B%E8%BF%99%E4%BA%9B%E5%85%8D%E8%B4%B9%E4%BB%A3%E7%90%86%E5%B9%B6%E4%B8%80%E5%AE%9A%E7%A8%B3%E5%AE%9A%EF%BC%8C%E6%89%80%E4%BB%A5%E6%AF%94%E8%BE%83%E9%9D%A0%E8%B0%B1%E7%9A%84%E8%BF%98%E6%98%AF%E8%B4%AD%E4%B9%B0%E4%BB%98%E8%B4%B9%E4%BB%A3%E7%90%86" >www.kuaidaili.com/free/就提供了很多免费代理，但在大多数情况下这些免费代理并一定稳定，所以比较靠谱的还是购买付费代理<i class="fas fa-external-link-alt"></i></a></p>
<p>除了购买付费代理，也可以在本机配置一些代理软件，具体的配制方法可以参考<a class="link"   target="_blank" rel="noopener" href="https://setup.scrape.center/proxy-client" >https://setup.scrape.center/proxy-client<i class="fas fa-external-link-alt"></i></a></p>
<p>以下示例都是基于本机代理软件</p>
<h4 id="urllib的代理设置"><a href="#urllib的代理设置" class="headerlink" title="urllib的代理设置"></a>urllib的代理设置</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> URLError</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> ProxyHandler, build_opener</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;127.0.0.1:7890&#x27;</span></span><br><span class="line">proxy_handler = ProxyHandler(&#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://&#x27;</span> + proxy,</span><br><span class="line">    <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;http://&#x27;</span> + proxy</span><br><span class="line">&#125;)</span><br><span class="line">opener = build_opener(proxy_handler)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = opener.<span class="built_in">open</span>(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"><span class="keyword">except</span> URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e.reason)</span><br></pre></td></tr></table></figure>

<p>这里需要借助ProxyHandler对象设置代理，参数是字典类型的数据，键名是协议类型，键值是代理地址(注意，此处的代理地址前面需要加上协议，即http://或者https://)，当请求链接使用的是HTTP协议时，使用http键名对应的代理地址， 反之就使用https</p>
<p>如果遇到需要认证的代理，可以使用如下方式设置:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> URLError</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> ProxyHandler, build_opener</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;username:password@127.0.0.1:7890&#x27;</span></span><br><span class="line">proxy_handler = ProxyHandler(&#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://&#x27;</span> + proxy,</span><br><span class="line">    <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;http://&#x27;</span> + proxy</span><br><span class="line">&#125;)</span><br><span class="line">opener = build_opener(proxy_handler)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = opener.<span class="built_in">open</span>(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"><span class="keyword">except</span> URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e.reason)</span><br></pre></td></tr></table></figure>

<p>如果代理是SOCKS代理，那么可以使用如下方式设置代理，需要注意要在本机7891端口运行一个SOCKS代理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Description : </span></span><br><span class="line"><span class="string">@File        : urllib_socks</span></span><br><span class="line"><span class="string">@Project     : test</span></span><br><span class="line"><span class="string">@Time        : 2022/2/15 17:25</span></span><br><span class="line"><span class="string">@Author      : LiHouJian</span></span><br><span class="line"><span class="string">@Software    : PyCharm</span></span><br><span class="line"><span class="string">@issue       : </span></span><br><span class="line"><span class="string">@change      : </span></span><br><span class="line"><span class="string">@reason      : </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> socks</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> URLError</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">socks.set_default_proxy(socks.SOCKS5, <span class="string">&#x27;127.0.0.1&#x27;</span>, <span class="number">7891</span>)</span><br><span class="line">socket.socket = socks.socksocket</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">	response = request.urlopen(<span class="string">&#x27;https://www.httpbin.org/get&#x27;</span>)</span><br><span class="line">	<span class="built_in">print</span>(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"><span class="keyword">except</span> URLError <span class="keyword">as</span> e:</span><br><span class="line">	<span class="built_in">print</span>(e.reason)</span><br></pre></td></tr></table></figure>

<h4 id="requests的代理设置"><a href="#requests的代理设置" class="headerlink" title="requests的代理设置"></a>requests的代理设置</h4><p>对于requests来说，代理设置非常简单，只需要传入prosies参数即可，这里以我本机的代理为例，看一下requests的HTTP代理配置，代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;127.0.0.1:7890&#x27;</span></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://&#x27;</span> + proxy,</span><br><span class="line">    <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;http://&#x27;</span> + proxy,</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = requests.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>, proxies=proxies)</span><br><span class="line">    <span class="built_in">print</span>(response.text)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.ConnectionError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Error&#x27;</span>, e.args)</span><br></pre></td></tr></table></figure>

<p>这里同样使用httpbin这个测试站点，这个返回的是一个json格式的数据，如果运行结果中的origin字段如果是代理服务器的IP，则证明代理已经设置成功</p>
<p>如果代理类型是SOCKS，可以使用如下方式设置代理:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;127.0.0.1:7891&#x27;</span></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;socks5://&#x27;</span> + proxy,</span><br><span class="line">    <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;socks5://&#x27;</span> + proxy</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = requests.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>, proxies=proxies)</span><br><span class="line">    <span class="built_in">print</span>(response.text)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.ConnectionError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Error&#x27;</span>, e.args)</span><br></pre></td></tr></table></figure>

<p>要运行以上代码我们要额外安装一个包requests[socks]，相关命令如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install <span class="string">&quot;requests[socks]&quot;</span></span><br></pre></td></tr></table></figure>

<p>另外还有一种设置SOCKS代理的方法，即使用socks模块，需要安装socks库，这种设置方式如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> socks</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line">socks.set_default_proxy(socks.SOCKS5, <span class="string">&#x27;127.0.0.1&#x27;</span>, <span class="number">7891</span>)</span><br><span class="line">socket.socket = socks.socksocket</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = requests.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(response.text)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.ConnectionError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Error&#x27;</span>, e.args)</span><br></pre></td></tr></table></figure>

<h4 id="httpx代理设置"><a href="#httpx代理设置" class="headerlink" title="httpx代理设置"></a>httpx代理设置</h4><p>httpx的用法本身就和requests的非常相似，所以也是通过proxies参数设置代理，不过也有不同，就是proxies参数的键名不能再是http或https，而需要改为http://或者https://</p>
<p>设置HTTP代理的方式如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;127.0.0.1:7890&#x27;</span></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&#x27;http://&#x27;</span>: <span class="string">&#x27;http://&#x27;</span> + proxy,</span><br><span class="line">    <span class="string">&#x27;https://&#x27;</span>: <span class="string">&#x27;http://&#x27;</span> + proxy,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> httpx.Client(proxies=proxies) <span class="keyword">as</span> client:</span><br><span class="line">    response = client.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure>

<p>对于需要认证的代理，也是在代理地址前加上用户名和密码，在使用的时候替换username和password字段:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proxy = <span class="string">&#x27;username:password@127.0.0.1:7890&#x27;</span></span><br></pre></td></tr></table></figure>

<p>对于SOCKS代理，需要安装httpx-socks[asyncio]库，安装方式如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install <span class="string">&#x27;httpx-socks[asyncio]&#x27;</span></span><br></pre></td></tr></table></figure>

<p>与此同时需要设置同步模式或异步模式，同步模式的设置方式如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"><span class="keyword">from</span> httpx_socks <span class="keyword">import</span> SyncProxyTransport</span><br><span class="line"></span><br><span class="line">transport = SyncProxyTransport.from_url(</span><br><span class="line">    <span class="string">&#x27;socks5://127.0.0.1:7891&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> httpx.Client(transport=transport) <span class="keyword">as</span> client:</span><br><span class="line">    response = client.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure>

<p>异步模式的设置方式如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> httpx_socks <span class="keyword">import</span> AsyncProxyTransport</span><br><span class="line"></span><br><span class="line">transport = AsyncProxyTransport.from_url(</span><br><span class="line">    <span class="string">&#x27;socks5://127.0.0.1:7891&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> httpx.AsyncClient(transport=transport) <span class="keyword">as</span> client:</span><br><span class="line">        response = <span class="keyword">await</span> client.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(response.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<h4 id="Selenium的代理设置"><a href="#Selenium的代理设置" class="headerlink" title="Selenium的代理设置"></a>Selenium的代理设置</h4><p>对于无认证的代理设置如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;127.0.0.1:7890&#x27;</span></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_argument(<span class="string">&#x27;--proxy-server=http://&#x27;</span> + proxy)</span><br><span class="line">browser = webdriver.Chrome(options=options)</span><br><span class="line">browser.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(browser.page_source)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>

<p>如果代理需要认证，则设置方式相对繁琐点:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"></span><br><span class="line">ip = <span class="string">&#x27;127.0.0.1&#x27;</span></span><br><span class="line">port = <span class="number">7890</span></span><br><span class="line">username = <span class="string">&#x27;foo&#x27;</span></span><br><span class="line">password = <span class="string">&#x27;bar&#x27;</span></span><br><span class="line"></span><br><span class="line">manifest_json = <span class="string">&quot;&quot;&quot;&#123;&quot;version&quot;:&quot;1.0.0&quot;,&quot;manifest_version&quot;: 2,&quot;name&quot;:&quot;Chrome Proxy&quot;,&quot;permissions&quot;: [&quot;proxy&quot;,&quot;tabs&quot;,&quot;unlimitedStorage&quot;,&quot;storage&quot;,&quot;&lt;all_urls&gt;&quot;,&quot;webRequest&quot;,&quot;webRequestBlocking&quot;],&quot;background&quot;: &#123;&quot;scripts&quot;: [&quot;background.js&quot;]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">background_js = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">var config = &#123;</span></span><br><span class="line"><span class="string">        mode: &quot;fixed_servers&quot;,</span></span><br><span class="line"><span class="string">        rules: &#123;</span></span><br><span class="line"><span class="string">          singleProxy: &#123;</span></span><br><span class="line"><span class="string">            scheme: &quot;http&quot;,</span></span><br><span class="line"><span class="string">            host: &quot;%(ip) s&quot;,</span></span><br><span class="line"><span class="string">            port: %(port) s</span></span><br><span class="line"><span class="string">          &#125;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">chrome.proxy.settings.set(&#123;value: config, scope: &quot;regular&quot;&#125;, function() &#123;&#125;);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">function callbackFn(details) &#123;</span></span><br><span class="line"><span class="string">    return &#123;</span></span><br><span class="line"><span class="string">        authCredentials: &#123;username: &quot;%(username) s&quot;,</span></span><br><span class="line"><span class="string">            password: &quot;%(password) s&quot;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">chrome.webRequest.onAuthRequired.addListener(</span></span><br><span class="line"><span class="string">            callbackFn,</span></span><br><span class="line"><span class="string">            &#123;urls: [&quot;&lt;all_urls&gt;&quot;]&#125;,</span></span><br><span class="line"><span class="string">            [&#x27;blocking&#x27;]</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span> % &#123;<span class="string">&#x27;ip&#x27;</span>: ip, <span class="string">&#x27;port&#x27;</span>: port, <span class="string">&#x27;username&#x27;</span>: username, <span class="string">&#x27;password&#x27;</span>: password&#125;</span><br><span class="line"></span><br><span class="line">plugin_file = <span class="string">&#x27;proxy_auth_plugin.zip&#x27;</span></span><br><span class="line"><span class="keyword">with</span> zipfile.ZipFile(plugin_file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> zp:</span><br><span class="line">    zp.writestr(<span class="string">&quot;manifest.json&quot;</span>, manifest_json)</span><br><span class="line">    zp.writestr(<span class="string">&quot;background.js&quot;</span>, background_js)</span><br><span class="line">options = Options()</span><br><span class="line">options.add_argument(<span class="string">&quot;--start-maximized&quot;</span>)</span><br><span class="line">options.add_extension(plugin_file)</span><br><span class="line">browser = webdriver.Chrome(options=options)</span><br><span class="line">browser.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(browser.page_source)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>

<p>这里在本地创建了一个manifest.json配置文件和background.js脚本来设置认证代理，运行代码后本地会生成一个proxy_auth_plugin.zip文件来保存当前的配置，SOCKS代理的配置方式也比较简单，如下所示:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;127.0.0.1:7891&#x27;</span></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_argument(<span class="string">&#x27;--proxy-server=socks5://&#x27;</span> + proxy)</span><br><span class="line">browser = webdriver.Chrome(options=options)</span><br><span class="line">browser.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(browser.page_source)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>

<h4 id="aiohttp代理设置"><a href="#aiohttp代理设置" class="headerlink" title="aiohttp代理设置"></a>aiohttp代理设置</h4><p>对于aiohttp，可以通过proxy参数直接设置代理，HTTP设置方式如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;http://127.0.0.1:7890&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> session.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>, proxy=proxy) <span class="keyword">as</span> response:</span><br><span class="line">            <span class="built_in">print</span>(<span class="keyword">await</span> response.text())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<p>如果代理需要认证，就把代理地址修改下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proxy = <span class="string">&#x27;http://username:password@127.0.0.1:7890&#x27;</span></span><br></pre></td></tr></table></figure>

<p>对于SOCKS代理，需要安装一个aiohttp-socks库，安装方式如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install aiohttp-socks</span><br></pre></td></tr></table></figure>

<p>可以借助这个库的ProxyConnector方法来设置SOCKS代理:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">from</span> aiohttp_socks <span class="keyword">import</span> ProxyConnector, ProxyType</span><br><span class="line"></span><br><span class="line"><span class="comment"># connector = ProxyConnector.from_url(&#x27;socks5://127.0.0.1:7891&#x27;)</span></span><br><span class="line"></span><br><span class="line">connector = ProxyConnector(</span><br><span class="line">    proxy_type=ProxyType.HTTP,</span><br><span class="line">    host=<span class="string">&#x27;127.0.0.1&#x27;</span>,</span><br><span class="line">    port=<span class="number">7890</span>,</span><br><span class="line">    <span class="comment"># username=&#x27;user&#x27;,</span></span><br><span class="line">    <span class="comment"># password=&#x27;password&#x27;,</span></span><br><span class="line">    <span class="comment"># rdns=True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession(connector=connector) <span class="keyword">as</span> session:</span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> session.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>) <span class="keyword">as</span> response:</span><br><span class="line">            <span class="built_in">print</span>(<span class="keyword">await</span> response.text())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<p>另外，aiohttp-socks库还支持SOCKS4代理、HTTP代理以及需要认证的代理，详情可以参见官方介绍</p>
<h4 id="Pyppeteer的代理设置"><a href="#Pyppeteer的代理设置" class="headerlink" title="Pyppeteer的代理设置"></a>Pyppeteer的代理设置</h4><p>对于Pyppeteer，由于其默认使用的是类似Chrome的Chromium浏览器，因此代理的设置方式和使用Chrome的Selenium一样，都是通过args参数设置HTTP代理的，代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;127.0.0.1:7890&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    browser = <span class="keyword">await</span> launch(&#123;<span class="string">&#x27;args&#x27;</span>: [<span class="string">&#x27;--proxy-server=http://&#x27;</span> + proxy], <span class="string">&#x27;headless&#x27;</span>: <span class="literal">False</span>&#125;)</span><br><span class="line">    page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">    <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="keyword">await</span> page.content())</span><br><span class="line">    <span class="keyword">await</span> browser.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<p>SOCKS代理也一样，只需要将协议修改为socks5即可:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;127.0.0.1:7891&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    browser = <span class="keyword">await</span> launch(&#123;<span class="string">&#x27;args&#x27;</span>: [<span class="string">&#x27;--proxy-server=socks5://&#x27;</span> + proxy], <span class="string">&#x27;headless&#x27;</span>: <span class="literal">False</span>&#125;)</span><br><span class="line">    page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">    <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="keyword">await</span> page.content())</span><br><span class="line">    <span class="keyword">await</span> browser.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<h4 id="Playwright的代理设置"><a href="#Playwright的代理设置" class="headerlink" title="Playwright的代理设置"></a>Playwright的代理设置</h4><p>HTTP代理设置:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> playwright.sync_api <span class="keyword">import</span> sync_playwright</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> sync_playwright() <span class="keyword">as</span> p:</span><br><span class="line">    browser = p.chromium.launch(headless=<span class="literal">False</span>, proxy=&#123;</span><br><span class="line">        <span class="string">&#x27;server&#x27;</span>: <span class="string">&#x27;http://127.0.0.1:7890&#x27;</span>  <span class="comment"># 填入代理地址</span></span><br><span class="line">    &#125;)</span><br><span class="line">    page = browser.new_page()</span><br><span class="line">    page.goto(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(page.content())</span><br><span class="line">    browser.close()</span><br></pre></td></tr></table></figure>

<p>SOCKS代理设置:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> playwright.sync_api <span class="keyword">import</span> sync_playwright</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> sync_playwright() <span class="keyword">as</span> p:</span><br><span class="line">    browser = p.chromium.launch(proxy=&#123;</span><br><span class="line">        <span class="string">&#x27;server&#x27;</span>: <span class="string">&#x27;socks5://127.0.0.1:7891&#x27;</span></span><br><span class="line">    &#125;)</span><br><span class="line">    page = browser.new_page()</span><br><span class="line">    page.goto(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(page.content())</span><br><span class="line">    browser.close()</span><br></pre></td></tr></table></figure>

<p>需要认证的代理:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> playwright.sync_api <span class="keyword">import</span> sync_playwright</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> sync_playwright() <span class="keyword">as</span> p:</span><br><span class="line">    browser = p.chromium.launch(proxy=&#123;</span><br><span class="line">        <span class="string">&#x27;server&#x27;</span>: <span class="string">&#x27;http://127.0.0.1:7890&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;username&#x27;</span>: <span class="string">&#x27;foo&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;password&#x27;</span>: <span class="string">&#x27;bar&#x27;</span></span><br><span class="line">    &#125;)</span><br><span class="line">    page = browser.new_page()</span><br><span class="line">    page.goto(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(page.content())</span><br><span class="line">    browser.close()</span><br></pre></td></tr></table></figure>

<h3 id="代理池的维护"><a href="#代理池的维护" class="headerlink" title="代理池的维护"></a>代理池的维护</h3><p>前面在代理的设置中了解了给各个请求库设置代理的方法，如何实时高效地获取大量可用代理变成了新的问题</p>
<p>首先，互联网上有大量公开免费的代理，当然我们也可以购买付费代理，但无论是免费代理还是付费代理，都不能保证是可用的，因为自己选用的IP，可能别人也在使用，爬取的还是同样的目标网站，从而被封禁，或者代理服务器突然发生故障、网络繁忙；一旦选用的是一个不可用的代理，势必就会影响爬虫的工作效率，所以我们要提前做筛选，删除掉不可用的代理，只保留可用的代理，那么怎么实现呢？这就需要借助一个叫代理池的东西了，下面我们就来看看如何搭建一个高效易用的代理池:</p>
<h4 id="准备工作-1"><a href="#准备工作-1" class="headerlink" title="准备工作"></a>准备工作</h4><p>存储代理池需要借助Redis数据库，因此需要额外安装Redis数据库；整体来讲，需要的环境如下:</p>
<ul>
<li><p>安装并成功运行和连接一个Redis数据库，它运行在本地或者远端服务器都行，只要能正常连接就行，安装的方式可以参考: <a class="link"   target="_blank" rel="noopener" href="https://setup.scrape.center/redis" >https://setup.scrape.center/redis<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p>安装好一些必要的库，包括aiohttp、requests、redis-py、pyquery、Flask、loguru等，安装命令如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install aiohttp requests redis pyquery flask loguru</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="代理池四大基本模块"><a href="#代理池四大基本模块" class="headerlink" title="代理池四大基本模块"></a>代理池四大基本模块</h4><p>代理池分为4个基本模块: 存储模块、获取模块、检测模块和接口模块；各模块的功能如下:</p>
<ul>
<li>存储模块: 负责存储爬取下来的代理，首先要保证代理不重复，标识代理的可用情况，其次要动态实时地处理每个代理，一种比较高效和方便的存储方式就是Redis的Sorted Set，即有序集合</li>
<li>获取模块: 负责定时在各大代理网站爬取代理，代理既可以是免费公开的，也可以是付费的，形式都是IP加端口，此模块尽量从不同来源爬取，并且尽量爬取高匿代理，爬取成功后存储到存储模块中</li>
<li>检测模块: 用负责定时检测存储模块中的代理是否可用，这里需要设置一个检测链接，最好是设置为要爬取的那个网站，这样更具有针对性；对于一个通用型的代理，可以设置为百度等链接；另外，需要标识每一个代理的状态，例如设置分数表示，100分代表可用，分数越少代表越不可用；经检测，如果代理可用，可以将立即设置为满分100，也可以在原分数基础上加1；如果代理不可用，就将分数标识减1，当分数减到一定阈值后，直接从存储模块中删除此代理，这样就可以标识代理的可用情况，在选用的时候也会更加有针对性</li>
<li>接口模式: 用API提供对外服务的接口。其实我们可以直接连接数据库来获取对应的数据，但这样需要知道数据库的连接信息，并且要配置连接；比较安全和方便的方式是提供一个Web API接口，访问这个接口即可拿到可用代理；另外，由于可用代理可能有多个，所以可以设置一个随机返回某个可用代理的接口，这样就能保证每个可用代理都有机会被获取，实现负载均衡</li>
</ul>
<h4 id="代理池的整体架构"><a href="#代理池的整体架构" class="headerlink" title="代理池的整体架构"></a>代理池的整体架构</h4><p>根据上面的描述，代理池的架构可以是是这样的:<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://cdn.jsdelivr.net/gh/stormwasd/image-hosting@master/20220216/Snipaste_2022-02-16_09-40-07.47c4lwlj5sg0.webp"
                      alt="Snipaste_2022-02-16_09-40-07"
                ></p>
<p>以上代理池架构分为四个部分，获取模块、存储模块、检测模块、接口模块</p>
<ul>
<li>存储模块使用 Redis 的有序集合，用以代理的去重和状态标识，同时它也是中心模块和基础模块，将其他模块串联起来</li>
<li>获取模块定时从代理网站获取代理，将获取的代理传递给存储模块，保存到数据库</li>
<li>检测模块定时通过存储模块获取所有代理，并对其进行检测，根据不同的检测结果对代理设置不同的标识</li>
<li>接口模块通过 Web API 提供服务接口，其内部还是连接存储模块，获取可用的代理</li>
</ul>
<h4 id="代理池的实现"><a href="#代理池的实现" class="headerlink" title="代理池的实现"></a>代理池的实现</h4><p>代码量大，源码地址为: <a class="link"   target="_blank" rel="noopener" href="https://github.com/Python3WebSpider/ProxyPool" >https://github.com/Python3WebSpider/ProxyPool<i class="fas fa-external-link-alt"></i></a><br>对代码的解释可详见: <a class="link"   target="_blank" rel="noopener" href="https://cuiqingcai.com/7048.html" >https://cuiqingcai.com/7048.html<i class="fas fa-external-link-alt"></i></a></p>
<h3 id="付费代理的使用"><a href="#付费代理的使用" class="headerlink" title="付费代理的使用"></a>付费代理的使用</h3><h4 id="付费代理的分类以及代理商推荐"><a href="#付费代理的分类以及代理商推荐" class="headerlink" title="付费代理的分类以及代理商推荐"></a>付费代理的分类以及代理商推荐</h4><ul>
<li>一类是代理商提供代理提取接口的付费代理，我们可以通过接口获取这类代理组成的列表，这类代理地址的IP和端口都是可见的，想用哪个就用哪个，灵活操作即可，这类代理一般会按照时间或者量来收费，比较有代表性的的有快代理(<a class="link"   target="_blank" rel="noopener" href="https://www.kuaidaili.com/)%E3%80%81%E8%8A%9D%E9%BA%BB%E4%BB%A3%E7%90%86(https://www.zhimaruanjian.com/)%E5%92%8C%E5%A4%9A%E8%B4%9D%E4%BB%A3%E7%90%86(http://www.dobel.cn)%E7%AD%89" >https://www.kuaidaili.com/)、芝麻代理(https://www.zhimaruanjian.com/)和多贝代理(http://www.dobel.cn)等<i class="fas fa-external-link-alt"></i></a></li>
<li>另一类是代理商搭建了隧道代理的付费代理，我们可以直接把此类代理设置为固定的IP和端口，无需进一步通过请求接口获取随机代理并设置；在这种情况下，我们只需要知道一个固定的代理服务器地址即可，代理商会在背后进一步将我们发出的请求分发给不同的代理服务器并做负载均衡，同时代理商会负责维护背后的整个代理池，因此开发者使用起来更加方便，但这样就无法自由控制设置哪个IP了；比较有代表性的这类代理有阿布云代理(<a class="link"   target="_blank" rel="noopener" href="https://www.abuyun.com/)%E3%80%81%E5%BF%AB%E4%BB%A3%E7%90%86(https://www.kuaidaili.com/)%E5%92%8C%E5%A4%9A%E8%B4%9D%E4%BB%A3%E7%90%86(http://www.dobel.cn)%E7%AD%89" >https://www.abuyun.com/)、快代理(https://www.kuaidaili.com/)和多贝代理(http://www.dobel.cn)等<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h4 id="如何使用"><a href="#如何使用" class="headerlink" title="如何使用"></a>如何使用</h4><p>至于如何使用，在对应服务商购买之后应该会有相应的教程</p>
<p><a class="link"   target="_blank" rel="noopener" href="https://cuiqingcai.com/7051.html" >https://cuiqingcai.com/7051.html<i class="fas fa-external-link-alt"></i></a></p>
<h3 id="ADSL拨号代理的搭建方法"><a href="#ADSL拨号代理的搭建方法" class="headerlink" title="ADSL拨号代理的搭建方法"></a>ADSL拨号代理的搭建方法</h3><p>这个详情见: <a class="link"   target="_blank" rel="noopener" href="https://cuiqingcai.com/3443.html" >https://cuiqingcai.com/3443.html<i class="fas fa-external-link-alt"></i></a></p>
<h3 id="代理反爬案例爬取实战"><a href="#代理反爬案例爬取实战" class="headerlink" title="代理反爬案例爬取实战"></a>代理反爬案例爬取实战</h3><h4 id="实战目标"><a href="#实战目标" class="headerlink" title="实战目标"></a>实战目标</h4><p>以一个IP反爬网站为例进行一次实战演练，该网站限制单个IP</p>
<p>每五分钟最多访问10次，访问次数超过10，该网站便会封锁该IP，并返回403状态码，10分钟后才解除封锁</p>
<h4 id="准备工作-2"><a href="#准备工作-2" class="headerlink" title="准备工作"></a>准备工作</h4><p>首先需要准备并正常运行代理池，还需要安装好一些Python库—requests、redis-py、environs、pyquery和loguru，安装命令如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests redis-py environs pyquery loguru</span><br></pre></td></tr></table></figure>

<h4 id="爬取分析"><a href="#爬取分析" class="headerlink" title="爬取分析"></a>爬取分析</h4><p>目标网站: <a class="link"   target="_blank" rel="noopener" href="https://antispider5.scrape.center/%EF%BC%8C%E8%BF%99%E4%B8%AA%E7%BD%91%E9%A1%B5%E6%89%93%E5%BC%80%E5%90%8E%E7%9C%8B%E4%B8%8A%E5%8E%BB%E5%92%8C%E4%B9%8B%E5%89%8D%E6%B2%A1%E6%9C%89%E5%95%A5%E4%B8%8D%E5%90%8C%EF%BC%8C%E4%BD%86%E8%BF%99%E9%87%8C%E7%BD%91%E7%AB%99%E5%A2%9E%E5%8A%A0%E4%BA%86IP%E5%8F%8D%E7%88%AC%E6%9C%BA%E5%88%B6%EF%BC%8C%E9%99%90%E5%88%B6%E5%8D%95%E4%B8%AAIP%E7%9A%84%E8%AE%BF%E9%97%AE%E6%AC%A1%E6%95%B0%EF%BC%8C%E5%9C%A85%E5%88%86%E9%92%9F%E5%86%85%E8%B6%85%E8%BF%87%E5%8D%81%E6%AC%A1%E8%AE%BF%E9%97%AE%E5%B0%B1%E4%BC%9A%E5%B0%81IP%EF%BC%8C%E4%BD%86%E5%A6%82%E6%9E%9C%E6%AD%A4%E6%97%B6%E5%88%87%E6%8D%A2%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E7%8E%AF%E5%A2%83%EF%BC%8C%E4%BE%8B%E5%A6%82%E4%BD%BF%E7%94%A8%E6%89%8B%E6%9C%BA%E7%83%AD%E7%82%B9%EF%BC%8C%E6%80%BB%E4%B9%8B%E8%AE%A9%E8%AE%BF%E9%97%AE%E7%9B%AE%E6%A0%87%E7%BD%91%E7%AB%99%E6%89%80%E7%94%A8%E7%9A%84IP%E5%9C%B0%E5%9D%80%E5%8F%91%E7%94%9F%E6%94%B9%E5%8F%98%EF%BC%8C%E5%B0%B1%E5%8F%88%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E9%A1%B5%E9%9D%A2%E6%AD%A3%E5%B8%B8%E6%98%BE%E7%A4%BA%E4%BA%86%EF%BC%8C%E4%B9%9F%E6%98%AF%E5%B0%B1%E8%AF%B4%EF%BC%8C%E8%A6%81%E6%83%B3%E5%9C%A8%E7%9F%AD%E6%97%B6%E9%97%B4%E5%86%85%E7%88%AC%E5%8F%96%E8%BF%99%E4%B8%AA%E7%BD%91%E7%AB%99%E7%9A%84%E6%89%80%E6%9C%89%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%BE%97%E6%9B%B4%E6%8D%A2%E5%A4%9A%E4%B8%AAIP%E8%BF%9B%E8%A1%8C%E7%88%AC%E5%8F%96%EF%BC%8C%E8%BF%99%E5%B0%B1%E5%BE%97%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86%E4%BA%86" >https://antispider5.scrape.center/，这个网页打开后看上去和之前没有啥不同，但这里网站增加了IP反爬机制，限制单个IP的访问次数，在5分钟内超过十次访问就会封IP，但如果此时切换一个网络环境，例如使用手机热点，总之让访问目标网站所用的IP地址发生改变，就又可以看到页面正常显示了，也是就说，要想在短时间内爬取这个网站的所有数据，得更换多个IP进行爬取，这就得使用代理了<i class="fas fa-external-link-alt"></i></a></p>
<p>由于我们无法预知某个代理是否能完成一个正常的爬取，因此可能请求成功也可能请求失败，失败原因可能是网站封锁了该代理，或者代理本身失效了；为了保证正常爬取，我们需要添加重试机制，以确保请求失败的时候可以再次爬取，直到成功</p>
<p>那怎么实现失败后的重试呢，我们可以使用队列，当请求失败时，把对应的请求加入队列里，等待下次被调用，队列的实现方式有很多，本节我们选用Redis实现，简单高效</p>
<p>本案例的实现步骤如下:</p>
<ul>
<li> 构造Redis爬取队列，用队列存取请求</li>
<li>实现异常处理，把失败的请求重新加入队列</li>
<li>解析列表页的数据，将爬取详情页和下一页的请求加入队列</li>
<li>提取详情页的信息</li>
</ul>
<h4 id="构造请求对象"><a href="#构造请求对象" class="headerlink" title="构造请求对象"></a>构造请求对象</h4><p>既然要用队列存储请求，就肯定要实现一个请求的数据结构，这个请求需要包含一些必要信息，例如请求链接、请求头、请求方式和超时时间；另外，对于一个请求，需要实现对应的方法来处理它的响应，那么就需要加一个回调函数callback；如果一个请求的失败次数太多，就不会再重新请求了，所以还需要增加失败次数的记录；用这些内容组成一个完整的请求对象并放入队列等待被调度，从队列获取出这个对象后直接执行就行了</p>
<p>我们可以采用继承requests库中的Request对象的方式实现这个数据结构；requests库中已经存在Request对象，它将请求作为一个整体对象去执行，得到响应后再返回；其实requests库里的get、post等方法都是通过Request对象实现的，我们先来看看Request对象的部分源代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Request</span>(<span class="params">RequestHooksMixin</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">            method=<span class="literal">None</span>, url=<span class="literal">None</span>, headers=<span class="literal">None</span>, files=<span class="literal">None</span>, data=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            params=<span class="literal">None</span>, auth=<span class="literal">None</span>, cookies=<span class="literal">None</span>, hooks=<span class="literal">None</span>, json=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Default empty dicts for dict params.</span></span><br><span class="line">        data = [] <span class="keyword">if</span> data <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> data</span><br><span class="line">        files = [] <span class="keyword">if</span> files <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> files</span><br><span class="line">        headers = &#123;&#125; <span class="keyword">if</span> headers <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> headers</span><br><span class="line">        params = &#123;&#125; <span class="keyword">if</span> params <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> params</span><br><span class="line">        hooks = &#123;&#125; <span class="keyword">if</span> hooks <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> hooks</span><br><span class="line"></span><br><span class="line">        self.hooks = default_hooks()</span><br><span class="line">        <span class="keyword">for</span> (k, v) <span class="keyword">in</span> <span class="built_in">list</span>(hooks.items()):</span><br><span class="line">            self.register_hook(event=k, hook=v)</span><br><span class="line"></span><br><span class="line">        self.method = method</span><br><span class="line">        self.url = url</span><br><span class="line">        self.headers = headers</span><br><span class="line">        self.files = files</span><br><span class="line">        self.data = data</span><br><span class="line">        self.json = json</span><br><span class="line">        self.params = params</span><br><span class="line">        self.auth = auth</span><br><span class="line">        self.cookies = cookies</span><br></pre></td></tr></table></figure>

<p>这是 requests 库中 Request 对象的构造方法。这个 Request 已经包含了请求方式、请求链接、请求头这几个属性，但是相比我们需要的还差了几个。我们需要实现一个特定的数据结构，在原先基础上加入上文所提到的额外几个属性。这里我们需要继承 Request 对象重新实现一个请求，将它定义为 MovieRequest，实现如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">TIMEOUT = <span class="number">10</span></span><br><span class="line"><span class="keyword">from</span> requests <span class="keyword">import</span> Request</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MovieRequest</span>(<span class="params">Request</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, url, callback, method=<span class="string">&#x27;GET&#x27;</span>, headers=<span class="literal">None</span>, need_proxy=<span class="literal">False</span>, fail_time=<span class="number">0</span>, timeout=TIMEOUT</span>):</span></span><br><span class="line">        Request.__init__(self, method, url, headers)</span><br><span class="line">        self.callback = callback</span><br><span class="line">        self.fail_time = fail_time</span><br><span class="line">        self.timeout = timeout</span><br></pre></td></tr></table></figure>

<p>这里我们实现了MovieRequest类，代码保存为request.py，在构造方法中先调用了Request类的构造方法，然后加入了几个额外的参数，分别定义为callback、fail_time和timeout，代表回调函数、失败次数和超时时间</p>
<p>之后就可以将MovieRequest作为一个整体来执行，各个MovieRequest对象都是独立的，每个请求都有自己的属性；例如，调用请求的callback属性就可以知道应该用什么方法处理这个请求的响应，调用fail_time就可以知道这个请求失败了多少次，继而判断失败次数是否达到阈值，该不该丢弃这个请求</p>
<h4 id="实现请求队列"><a href="#实现请求队列" class="headerlink" title="实现请求队列"></a>实现请求队列</h4><p>接下来我们就需要构造请求队列，实现请求的存取。存取无非就是两个操作，一个是放，一个是取，所以这里利用 Redis 的 rpush () 和 lpop () 方法即可。 另外还需要注意，存取不能直接存 Request 对象，Redis 里面存的是字符串。所以在存 Request 对象之前我们先把它序列化，取出来的时候再将其反序列化，这个过程可以利用 pickle 模块实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pickle <span class="keyword">import</span> dumps, loads</span><br><span class="line"><span class="keyword">from</span> request <span class="keyword">import</span> MovieRequest</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisQueue</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;初始化 Redis&quot;&quot;&quot;</span></span><br><span class="line">        self.db = StrictRedis(host=REDIS_HOST, port=REDIS_PORT, password=REDIS_PASSWORD)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">self, request</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        向队列添加序列化后的 Request</span></span><br><span class="line"><span class="string">        :param request: 请求对象</span></span><br><span class="line"><span class="string">        :param fail_time: 失败次数</span></span><br><span class="line"><span class="string">        :return: 添加结果</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(request, MovieRequest):</span><br><span class="line">            <span class="keyword">return</span> self.db.rpush(REDIS_KEY, dumps(request))</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        取出下一个 Request 并反序列化</span></span><br><span class="line"><span class="string">        :return: Request or None</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.db.llen(REDIS_KEY):</span><br><span class="line">            <span class="keyword">return</span> loads(self.db.lpop(REDIS_KEY))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">empty</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.db.llen(REDIS_KEY) == <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>这里实现了一个 RedisQueue类，代码文件保存为db.py，它的 <strong>init</strong>() 构造方法里面初始化了一个 StrictRedis 对象。随后实现了 add () 方法，首先判断 Request 的类型，如果是 MovieRequest，那么就把程序就会用 pickle 的 dumps () 方法序列化，然后再调用 rpush () 方法加入队列。pop () 方法则相反，调用 lpop () 方法将请求从队列取出，然后再用 pickle 的 loads () 方法将其转为 MovieRequest 对象。另外，empty () 方法返回队列是否为空，只需要判断队列长度是否为 0 即可。 在调度的时候，我们只需要新建一个 RedisQueue 对象，然后调用 add () 方法，传入 MovieRequest 对象，即可将 MovieRequest 加入队列，调用 pop () 方法，即可取出下一个 MovieRequest对象，非常简单易用</p>
<h4 id="修改代理池"><a href="#修改代理池" class="headerlink" title="修改代理池"></a>修改代理池</h4><p>现在我们要找一些可用代理，这里直接使用崔庆才先生所构建的代理池，我已根据<a class="link"   target="_blank" rel="noopener" href="https://github.com/Python3WebSpider/ProxyPool" >此链接<i class="fas fa-external-link-alt"></i></a>在云服务器上构建好5555端口的接口，接口地址为: <a class="link"   target="_blank" rel="noopener" href="http://175.24.172.64:5555/random%EF%BC%8C%E6%88%91%E4%BB%AC%E5%86%8D%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E7%94%A8%E6%9D%A5%E8%8E%B7%E5%8F%96%E5%8F%AF%E7%94%A8%E4%BB%A3%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95" >http://175.24.172.64:5555/random，我们再定义一个用来获取可用代理的方法<i class="fas fa-external-link-alt"></i></a>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">PROXY_ROOT_RUL = <span class="string">&#x27;http://175.24.172.64:5555/random&#x27;</span></span><br><span class="line"><span class="keyword">from</span> loguru <span class="keyword">import</span> logger</span><br><span class="line"></span><br><span class="line"><span class="meta">@logger.catch</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_proxy</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        get proxy from proxypool</span></span><br><span class="line"><span class="string">        :return: proxy</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        response = requests.get(PROXY_POOL_URL)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            logger.debug(<span class="string">f&#x27;get proxy <span class="subst">&#123;response.text&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="keyword">return</span> response.text</span><br></pre></td></tr></table></figure>

<p>这里有个小技巧，我们使用loguru日志库里的catch方法作为get_proxy方法的装饰器，这样可以在请求代理池失败的时候输出具体的报错信息，同时又不会中断程序运行，也避免了编写try/catch语句的麻烦，使得代码看起来更简洁</p>
<h4 id="第一个请求"><a href="#第一个请求" class="headerlink" title="第一个请求"></a>第一个请求</h4><p>一切工作都做好了，现在我们就可以构造第一个请求请求并放在队列里以供调度了，代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> requests <span class="keyword">import</span> Session</span><br><span class="line"><span class="keyword">from</span> core.db <span class="keyword">import</span> RedisQueue</span><br><span class="line"><span class="keyword">from</span> core.request <span class="keyword">import</span> MovieRequest</span><br><span class="line"></span><br><span class="line">BASE_URL = <span class="string">&#x27;https://antispider5.scrape.center/&#x27;</span></span><br><span class="line">HEADERS = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span>():</span></span><br><span class="line">    session = Session()  <span class="comment"># Session对象</span></span><br><span class="line">    queue = RedisQueue()  <span class="comment"># RedisQueue对象</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        start request</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.session.headers.update(HEADERS)  <span class="comment"># 全局更新了HEADERS</span></span><br><span class="line">        start_url = BASE_URL</span><br><span class="line">        request = MovieRequest(</span><br><span class="line">            url=start_url, callback=self.parse_index)</span><br><span class="line">        <span class="comment"># schedule first request</span></span><br><span class="line">        self.queue.add(request)  <span class="comment"># 请求入队</span></span><br></pre></td></tr></table></figure>

<p>这里先定义了两个全局变量，BASE_URL代表目标网站的URL，HEADERS代表请求头，然后定义了Spider类，代码保存为spider.py</p>
<h4 id="调度请求"><a href="#调度请求" class="headerlink" title="调度请求"></a>调度请求</h4><p>把第一个请求加入队列之后，就可以开始调度执行了；首先从队列中取出这个请求，将它的结果解析出来，生成新的请求加入队列，然后拿出新的请求，将结果解析，再将新生成的请求加入队列，这样循环执行，直到队列中没有请求，代表爬虫结束</p>
<p>我们在Spider类中添加scheduler方法，实现如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">schedule</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        schedule request</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> self.queue.empty():</span><br><span class="line">            request = self.queue.pop()</span><br><span class="line">            callback = request.callback</span><br><span class="line">            logger.debug(<span class="string">f&#x27;executing request <span class="subst">&#123;request.url&#125;</span>&#x27;</span>)</span><br><span class="line">            response = self.request(request)</span><br><span class="line">            logger.debug(<span class="string">f&#x27;response status <span class="subst">&#123;response&#125;</span> of <span class="subst">&#123;request.url&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> response <span class="keyword">or</span> <span class="keyword">not</span> response.status_code <span class="keyword">in</span> VALID_STATUSES:</span><br><span class="line">                self.error(request)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            results = <span class="built_in">list</span>(callback(response))</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> results:</span><br><span class="line">                self.error(request)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(result, MovieRequest):</span><br><span class="line">                    logger.debug(<span class="string">f&#x27;generated new request <span class="subst">&#123;result.url&#125;</span>&#x27;</span>)</span><br><span class="line">                    self.queue.add(result)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(result, <span class="built_in">dict</span>):</span><br><span class="line">                    logger.debug(<span class="string">f&#x27;scraped new data <span class="subst">&#123;result&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>scheduler方法的内部是一个wihle循环，该循环内部的判断条件是队列不为空；当队列不为空时，调用pop方法取出下一个请求，然后调用request方法执行这个请求，request方法的实现如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">request</span>(<span class="params">self, request</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        execute request</span></span><br><span class="line"><span class="string">        :param request: weixin request</span></span><br><span class="line"><span class="string">        :return: response</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            proxy = self.get_proxy()</span><br><span class="line">            logger.debug(<span class="string">f&#x27;get proxy <span class="subst">&#123;proxy&#125;</span>&#x27;</span>)</span><br><span class="line">            proxies = &#123;</span><br><span class="line">                <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://&#x27;</span> + proxy,</span><br><span class="line">                <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;https://&#x27;</span> + proxy</span><br><span class="line">            &#125; <span class="keyword">if</span> proxy <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">            <span class="keyword">return</span> self.session.send(request.prepare(),</span><br><span class="line">                                     timeout=request.timeout,</span><br><span class="line">                                     proxies=proxies)</span><br><span class="line">        <span class="keyword">except</span> RequestException:</span><br><span class="line">            logger.exception(<span class="string">f&#x27;requesting <span class="subst">&#123;request.url&#125;</span> failed&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>以上request方法也可以不用try/catch方法采用logger中的catch装饰器，在这个方法中，首先调用get_proxy()获取代理，然后将代理赋值给proxies字典，接着调用session变量的send方法执行这个请求，这里调用prepare方法将请求转化为了Prepared Request对象(具体可看2.2节)，timeout属性是该请求的超时时间，proxies属性就是刚才声明的代理，最后返回send方法的执行结果</p>
<p>执行request方法之后会得到两种结果，一种是False，即请求失败，连接错误；另一种是Response对象，即请求成功后返回的结果，需要判断其中的状态码，如果状态码合法，就对返回结果进行解析，否则将请求重新放入队列</p>
<p>之后的就自己看代码了: <a class="link"   target="_blank" rel="noopener" href="https://github.com/Python3WebSpider/ScrapeAntispider5" >https://github.com/Python3WebSpider/ScrapeAntispider5<i class="fas fa-external-link-alt"></i></a></p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li>Post title：Python3网络爬虫开发实战第二版第9章-代理的使用</li>
        <li>Post author：Lhj</li>
        <li>Create time：2022-02-15 16:52:30</li>
        <li>
            Post link：https://keep.xpoet.cn/2022/02/15/Python3网络爬虫开发实战第二版第9章-代理的使用/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2022/02/16/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC10%E7%AB%A0-%E6%A8%A1%E6%8B%9F%E7%99%BB%E9%99%86/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Python3网络爬虫开发实战第二版第10章-模拟登陆</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2022/02/14/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC8%E7%AB%A0-%E9%AA%8C%E8%AF%81%E7%A0%81%E7%9A%84%E8%AF%86%E5%88%AB/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Python3网络爬虫开发实战第二版第8章-验证码的识别</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;Comments</i>
    </div>
    

        
            
    <div class="valine-container">
        <script data-pjax
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script data-pjax>
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'nIcO1O6cSVuRH8EROCWwNFWN-gzGzoHsz',
                    appKey: 'qrglokTeum8DXiYRzM4k4NF4',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: '😜 尽情吐槽吧~',
                    lang: 'en'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Lhj';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('true') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2022&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Lhj</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%90%86%E7%9A%84%E8%AE%BE%E7%BD%AE"><span class="nav-number">1.</span> <span class="nav-text">代理的设置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="nav-number">1.1.</span> <span class="nav-text">准备工作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#urllib%E7%9A%84%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE"><span class="nav-number">1.2.</span> <span class="nav-text">urllib的代理设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#requests%E7%9A%84%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE"><span class="nav-number">1.3.</span> <span class="nav-text">requests的代理设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#httpx%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE"><span class="nav-number">1.4.</span> <span class="nav-text">httpx代理设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Selenium%E7%9A%84%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE"><span class="nav-number">1.5.</span> <span class="nav-text">Selenium的代理设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#aiohttp%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE"><span class="nav-number">1.6.</span> <span class="nav-text">aiohttp代理设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pyppeteer%E7%9A%84%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE"><span class="nav-number">1.7.</span> <span class="nav-text">Pyppeteer的代理设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Playwright%E7%9A%84%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE"><span class="nav-number">1.8.</span> <span class="nav-text">Playwright的代理设置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%90%86%E6%B1%A0%E7%9A%84%E7%BB%B4%E6%8A%A4"><span class="nav-number">2.</span> <span class="nav-text">代理池的维护</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C-1"><span class="nav-number">2.1.</span> <span class="nav-text">准备工作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%90%86%E6%B1%A0%E5%9B%9B%E5%A4%A7%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9D%97"><span class="nav-number">2.2.</span> <span class="nav-text">代理池四大基本模块</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%90%86%E6%B1%A0%E7%9A%84%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84"><span class="nav-number">2.3.</span> <span class="nav-text">代理池的整体架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%90%86%E6%B1%A0%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">2.4.</span> <span class="nav-text">代理池的实现</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%98%E8%B4%B9%E4%BB%A3%E7%90%86%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">3.</span> <span class="nav-text">付费代理的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%98%E8%B4%B9%E4%BB%A3%E7%90%86%E7%9A%84%E5%88%86%E7%B1%BB%E4%BB%A5%E5%8F%8A%E4%BB%A3%E7%90%86%E5%95%86%E6%8E%A8%E8%8D%90"><span class="nav-number">3.1.</span> <span class="nav-text">付费代理的分类以及代理商推荐</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8"><span class="nav-number">3.2.</span> <span class="nav-text">如何使用</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ADSL%E6%8B%A8%E5%8F%B7%E4%BB%A3%E7%90%86%E7%9A%84%E6%90%AD%E5%BB%BA%E6%96%B9%E6%B3%95"><span class="nav-number">4.</span> <span class="nav-text">ADSL拨号代理的搭建方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%90%86%E5%8F%8D%E7%88%AC%E6%A1%88%E4%BE%8B%E7%88%AC%E5%8F%96%E5%AE%9E%E6%88%98"><span class="nav-number">5.</span> <span class="nav-text">代理反爬案例爬取实战</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E6%88%98%E7%9B%AE%E6%A0%87"><span class="nav-number">5.1.</span> <span class="nav-text">实战目标</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C-2"><span class="nav-number">5.2.</span> <span class="nav-text">准备工作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%88%AC%E5%8F%96%E5%88%86%E6%9E%90"><span class="nav-number">5.3.</span> <span class="nav-text">爬取分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9E%84%E9%80%A0%E8%AF%B7%E6%B1%82%E5%AF%B9%E8%B1%A1"><span class="nav-number">5.4.</span> <span class="nav-text">构造请求对象</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E8%AF%B7%E6%B1%82%E9%98%9F%E5%88%97"><span class="nav-number">5.5.</span> <span class="nav-text">实现请求队列</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9%E4%BB%A3%E7%90%86%E6%B1%A0"><span class="nav-number">5.6.</span> <span class="nav-text">修改代理池</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E4%B8%AA%E8%AF%B7%E6%B1%82"><span class="nav-number">5.7.</span> <span class="nav-text">第一个请求</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B0%83%E5%BA%A6%E8%AF%B7%E6%B1%82"><span class="nav-number">5.8.</span> <span class="nav-text">调度请求</span></a></li></ol></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/dark-light-toggle.js"></script>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/local-search.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/code-copy.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/lazyload.js"></script>


<div class="post-scripts pjax">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/toc.js"></script>
    
</div>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/pjax.min.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
