[{"title":"Python中常用的国内pip源","url":"/2021/12/29/Python%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84pip%E6%BA%90/","content":"在我们下载包的时候，很可能由于网络原因会很卡，这个时候可能需要科学上网，但是我们又没有买节点，或者没有搭建海外服务器，这个时候我们就可以访问一些国内的pip源，这里面和国外上传的pip源几乎是一样的，也是一段时间就会更新:\n\n阿里云: http://mirrors.aliyun.com/pypi/simple/\n中国科学技术大学: https://pypi.mirrors.ustc.edu.cn/simple/\n豆瓣: http://pypi.douban.com/simple/\n清华大学: https://pypi.tuna.tsinghua.edu.cn/simple/\n华中科技大学: http://pypi.hustunique.com/\n\n注意: 新版ubuntu要求使用https源\n","categories":["Database"]},{"title":"Python中pip和pip3的区别","url":"/2021/12/29/Python%E4%B8%ADpip%E5%92%8Cpip3%E7%9A%84%E5%8C%BA%E5%88%AB/","content":"pip是Python的一款很好用的包管理工具，类似于node中的npm，Python有Python2和Python3的区别，那么pip也有pip和pip3的区别,大概是这样的: \n相同点(虽然主要是区别，但还是有相同点的撒):\n\npip和pip3版本不同，但二者都位于Script\\目录下\n\n不同点：\n\n如果系统中只安装了Python2，那么就只能用pip\n如果系统中只安装了Python3，那么既可以使用pip也可以使用pip3，二者是等价的\n如果系统中同时安装了Python2和Python3，则pip默认给Python2使用，pip3默认给Python3使用\n重要: 在虚拟环境中，若只存在一个Python版本，可以认为在用系统中的pip和pip3命令都是相同作用的\n\n"},{"title":"Python中with...as...语句的深度解刨","url":"/2021/12/28/Python%E4%B8%ADwith...as...%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%B7%B1%E5%BA%A6%E8%A7%A3%E5%88%A8/","content":"任何一门编程语言中，文件的输入输出、数据库的连接断开等，都是很常见的资源管理操作。但资源都是有限的，在写程序时，必须保证这些资源在使用过后得到释放，不然就容易造成资源泄露，轻者使得系统处理缓慢，严重时会使系统崩溃。\n例如，前面在介绍文件操作时，一直强调打开的文件最后一定要关闭，否则会程序的运行造成意想不到的隐患。但是，即便使用 close() 做好了关闭文件的操作，如果在打开文件或文件操作过程中抛出了异常，还是无法及时关闭文件。\n为了更好地避免此类问题，不同的编程语言都引入了不同的机制。在 Python 中，对应的解决方式是使用 with as 语句操作上下文管理器（context manager），它能够帮助我们自动分配并且释放资源，代码示例如下:\nwith open(&quot;test.txt&quot;) as file:    data = file.read()    print(data)# 等价于try:    file = open(&quot;test.txt&quot;)    data = file.read()    print(data)finally:    file.close()\n\nwith…as…语句只会捕获异常而不会处理异常，代码示例如下:\nwith open(&quot;test.txt&quot;) as file:    data = file.read()    print(data)# 若没有test.txt，会出现以下错误,程序会就此停下，说明并不会处理异常FileNotFoundError Traceback (most recent call last)&lt;ipython-input-4-bf5e860f28d5&gt; in &lt;module&gt;      1 try:----&gt; 2     file = open(&quot;test.txt&quot;)      3     data = file.read()      4     print(data)      5 # except Exception as err:FileNotFoundError: [Errno 2] No such file or directory: &#x27;test.txt&#x27;\n\n"},{"title":"Python如何升级pip,以及如何查看pip版本","url":"/2021/12/29/Python%E5%A6%82%E4%BD%95%E5%8D%87%E7%BA%A7pip,%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8Bpip%E7%89%88%E6%9C%AC/","content":"有些时候我们用pip安装包的时候会报红提示说安装失败，也有时候会出现一串黄色的警告说pip版本太低，这个时候我们可能就该考虑升级下pip，升级pip会获得更好的体验然后很多新的包也会收录在新版本的pip下，我们来看下如何升级: \n\n打开命令行键入以下命令:\npip3 install --upgrade pip -i &quot;https://pypi.mirrors.ustc.edu.cn/simple&quot;\n\n对以上命令做下解释:\n\npip3: 如果在系统中既有Python2又有Python3那么且两个都有pip工具,pip3就是为Python3服务\n-i: 指定包的源\n\n\n\n"},{"title":"Python每个版本都自带pip嘛,以及如何安装pip","url":"/2021/12/29/Python%E6%AF%8F%E4%B8%AA%E7%89%88%E6%9C%AC%E9%83%BD%E8%87%AA%E5%B8%A6pip%E5%98%9B,%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85pip/","content":"pip是Python的包管理工具，该工具提供了对Python包的查找、下载、安装、以及卸载的功能，目前如果你在Python.org下载最新版本的安装包，则是已经自带了该工具，Python2.7.9+或者Python3.4+以上版本都自带pip工具(通常跟wheel.exe在同一个目录下)\n下面讲讲如果安装的时候没有自带pip工具那么如何安装pip工具：\n\n访问https://bootstrap.pypa.io/get-pip.py这个网址，然后Ctrl+S将get-pip.py文件保存到你所安装的Python的Script目录下\n然后进入Script目录，并且在该目录下进入下命令行界面\n在命令行界面输入python get-pip.py，pip3工具就会自动安装\n安装成功之后输入python -m pip –version，确保成功安装了pip\n\n"},{"title":"Python如何修改pip源","url":"/2021/12/29/Python%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9pip%E6%BA%90/","content":"如果每次都pip用-i指定源会比较麻烦，我们可以把某个国内源设置为默认，这样下次就会从默认源里面寻找包并且下载，来看看如何设为默认:\n在命令行中键入以下命令:\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n\n以上以清华源的为例\n"},{"title":"Python类中call函数的作用","url":"/2021/12/25/Python%E7%B1%BB%E4%B8%ADcall%E5%87%BD%E6%95%B0%E7%9A%84%E4%BD%9C%E7%94%A8/","content":"本节再介绍 Python类中一个非常特殊的实例方法，即 call()。该方法的功能类似于在类中重载 () 运算符，使得类实例对象可以像调用普通函数那样，以“对象名()”的形式使用，一句话总结: call函数可以把类变成函数来调用\nclass Demo():    def __init__(self, name):        self.name = name    def __call__(self):        print(self.name)Demo(&#x27;孙悟空&#x27;)() # 输出 孙悟空\n\n在Python中，凡是可以将()直接应用到自身并执行，都称为可调用对象，可调用对象包括自定义的函数，Python内置函数以及这里讲的类实例对象，对于可调用对象，实际上“名称()”可以理解为是“名称.call()”的简写。仍以上面程序中定义的 clangs 实例对象为例，其最后一行代码还可以改写为如下形式：\nclangs.__call__(&quot;C语言中文网&quot;,&quot;http://c.biancheng.net&quot;)\n"},{"title":"Python魔法方法总览","url":"/2021/12/28/Python%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95%E6%80%BB%E8%A7%88/","content":"关于魔法方法: 使用魔法方法可以使Python的自由度变得更高，当不需要重写魔法方法也可以在规定的默认情况下生效，在需要重写时也可以让使用者根据自己的需求来重写部分方法来达到自己的预期。而且众所周知Python是支持面向对象的语言，其基本魔法方法就使得Python在面向对象方面做得更好。\n今天在CSDN上看到了有一篇文章整理得还不错，讲述了很多魔法方法以及其作用，详情见:https://blog.csdn.net/qq_38520096/article/details/79237593?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164067535716780261982154%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=164067535716780261982154&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-8-79237593.first_rank_v2_pc_rank_v29&amp;utm_term=python%E7%9A%84%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95&amp;spm=1018.2226.3001.4187\n"},{"title":"对Docker的认识","url":"/2021/12/29/%E5%AF%B9Docker%E7%9A%84%E8%AE%A4%E8%AF%86/","content":"首先，Docker是个容器，使用的是宿主机的资源，因为都是Linux，所以内核资源是可以共用的，无论什么发行版，他们的内核都是Linux kernel，所以Docker才能实现，Docker其实只共用了宿主机的内核，然后我们可以在里面安装镜像，运行一个隔离于系统的独立系统，但是默认是不和宿主机发生交互的，如果要使用到宿主机的文件，就要用volumn将宿主机的文件挂载到容器中，让容器可以访问\n现在windows上也可以安装Docker，其实windows上的Docker只是一个客户端，实际上还是开了一个虚拟机跑Linux，然后Linux里再跑Docker\n"},{"title":"Linux(ubuntu)提示command not fonund的解决","url":"/2021/12/29/Linux(ubuntu)%E6%8F%90%E7%A4%BAcommand%20not%20fonund%E7%9A%84%E8%A7%A3%E5%86%B3/","content":"Linux系统中，-bash: wget: comment not found是找不到命令的意思，也就是无法执行下载命令，这是因为系统太干净了，没有安装下载命令的控制器，我们给系统安装个下载命令即可:\nCentOS系统:\nyum install wget -y\n\nDebian/Ubuntu系统:\napt -get install -y wget\n\n"},{"title":"关于入门Go需要知道的几个特性","url":"/2021/12/29/%E5%85%B3%E4%BA%8E%E5%85%A5%E9%97%A8Go%E7%9A%84%E5%87%A0%E4%B8%AA%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","content":"\ngo的关键字比较少，只有25个，这样可以简化编码过程中的混乱和复杂度\n\ngo没有类和继承的概念，但它通过接口的概念来实现多态\n\ngo支持交叉编译，比如说可以在运行Linux系统的计算机开发能在windows上运行的应用，这是第一门完全支持UTF-8的编程语言，就连他的源码文件格式都是使用UTF-8编码\n\ngo被设计成一门应用与搭载web服务器，存储集群或类似用途的巨型中央服务器的系统编程语言，对于高性能分布式系统领域而言，go有着更高的开发效率，提供了海量并行的支持，这对于游戏服务端的开发最好不过了\n\n尽管go编译器产生的是本地可执行代码，这些代码仍旧运行在go的runtime中，这个runtime类似java和.net所用到的虚拟机，它负责管理包括内存分配，垃圾回收，栈处理、goroutine、channel、切片，map和反射等\n\ngo fmt，这是个工具用来将你的源代码格式化成符合官方统一标准的风格\n\ngo doc，这是个工具从go程序和包文件中提取顶级声明的首行注释以及每个对象的相关注释，并生成相关文档\n\ngo install, 这是go的包的安装工具，类似Ruby中的rubygems\n\ngo test是一个轻量级的单元测试框架\n\ngo fix用于将你的go代码从旧的发行版迁移到最新的发行版\n\ncgo提供了对FFI(外部函数接口)的支持，能够使用go代码安全地调用c语言库，cgo会代替go编译器来产生可以组合在同一个包中的go和c代码\n\n在go代码中使用c语言需要用import&quot;C&quot;来导入，一般还需要import&quot;unsafe&quot;,然后你可以在import&quot;C&quot;之前使用注释(但行或多行注释均可)的形势导入C语言库(甚至有效的C语言代码)，注意他们之间没有空格\n\n左大括号需要放在函数定义这一行\n\nfmt.Println和fmt.Print只差了一个空格\n2021-12-29 18:08:20\n\n\n"},{"title":"在Docker中安装Python3.7","url":"/2021/12/29/%E5%9C%A8Docker%E4%B8%AD%E5%AE%89%E8%A3%85Python3.7/","content":"详情见: \nhttps://www.icode9.com/content-1-120863.html\n"},{"title":"如何在ubuntu16中安装Python","url":"/2021/12/29/%E5%A6%82%E4%BD%95%E5%9C%A8ubuntu16%E4%B8%AD%E5%AE%89%E8%A3%85Python/","content":"详情见:(我这采用的是第二种方法)https://www.runoob.com/docker/ubuntu-docker-install.html\n"},{"title":"查看Docker是否安装成功以及使用Docker安装nginx","url":"/2021/12/29/%E6%9F%A5%E7%9C%8BDocker%E6%98%AF%E5%90%A6%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8Docker%E5%AE%89%E8%A3%85nginx/","content":"\n检查是否安装成功\n使用命令:\ndocker ps\n\n使用docker搜索nginx:\n使用命令:\ndocker search nginx\n使用 docker安装nginx:\n使用命令:\ndocker pull nginx\n\n运行nignx:\n使用命令:\ndocker run nginx\n检查Docker是否安装成功可以使用命令:\ndocker version\n\n有client和service两部分表示docker安装启动都成功了\n\n\n"},{"title":"LeetCode最大回文子串","url":"/2021/12/30/Leetcode%E6%9C%80%E5%A4%A7%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/","content":"动态规划:\n对于一个字串而言，如果它是回文串，并且长度大于2，那么将它首位的两个字母去掉之后，它仍然是个回文串，根据这个思路，我们就可以用动态规划的方法解决本题，我们用s[i, j]表示字符串s的第i个到第j个字母组成的串是否为回文串:\n我们可以得到只有s[i+1, j-1]是回文串，并且s的第i个和第j个字母相同时，s[i, j]才会是回文串\n上文所有讨论都是建立在字串长度大于2的前提上的，我们还需要考虑动态规划中的边界条件，就是字串的长度为1或2。对于长度为1的字串，他显然是个回文串，对于长度为2的字串，只要它的两个字母相同，他就是一个回文串，因此我们就可以得到动态规划的边界条件\nclass Solution:    def longestPalindrome(self, s: str) -&gt; str:        n = len(s)        if n &lt; 2:            return s                max_len = 1        begin = 0        # dp[i][j] 表示 s[i..j] 是否是回文串        dp = [[False] * n for _ in range(n)]        for i in range(n):            dp[i][i] = True                # 递推开始        # 先枚举子串长度        for L in range(2, n + 1):            # 枚举左边界，左边界的上限设置可以宽松一些            for i in range(n):                # 由 L 和 i 可以确定右边界，即 j - i + 1 = L 得                j = L + i - 1                # 如果右边界越界，就可以退出当前循环                if j &gt;= n:                    break                                    if s[i] != s[j]:                    dp[i][j] = False                 else:                    if j - i &lt; 3:                        dp[i][j] = True                    else:                        dp[i][j] = dp[i + 1][j - 1]                                # 只要 dp[i][L] == true 成立，就表示子串 s[i..L] 是回文，此时记录回文长度和起始位置                if dp[i][j] and j - i + 1 &gt; max_len:                    max_len = j - i + 1                    begin = i        return s[begin:begin + max_len]\n\n\n\n"},{"title":"Scrapy添加User-agent的方法","url":"/2021/12/30/Scrapy%E6%B7%BB%E5%8A%A0User-agent%E7%9A%84%E6%96%B9%E6%B3%95/","content":"\n直接在spider中指定，比如在Scrapy项目中有一个项目grasp_baidu:\nimport scrapyclass graspbaidu(scrapy.Spider):    name = &#x27;graspbaidu&#x27;    allowed_domians = [&#x27;www.baidu.com&#x27;]    start_urls = [&quot;http//:www.baidu.com&quot;]    def parse(self, response):        self.logger.debug(response.text)\n\n这里的start_urls会默认由scrapy自带的start_request处理，然后再交给parse函数，我们就可以重写个start_request，然后里面带个UA即可，比如：\ndef start_request(self):    for i in range(1, 2):    url = ff&#x27;https://api2.fx361.com/JunJiProject/JUNJI_012_001/getSearchList?bkpagesize=14&amp;pagesize=30&amp;keyword=%E7%9B%91%E7%90%86%E5%88%9B%E6%96%B0&amp;pageIndex=&#123;i&#125;&amp;fragmentSize=150&#x27;    req = scrapy.Request(url, callback=self.parse, dont_filter=True, headers=self.headers)\n在配置文件settings.py中设置(一劳永逸):\n将settings.py中的USER_AGENT修改一下即可\n\n如果想修改的更加灵活，比如设置随机的Ua，那就需要如下用到一个库:\nfrom fake_useragent import UserAgent\n\n然后需要在middlewares.py文件中添加一个RandomUserAgentMiddleware的类，如下:\nclass RandomUserAgentMiddleware(object):    # 随机更换 user_agent    def __init__(self,srawler):        super(RandomUserAgentMiddleware,self).__init__()        self.ua = UserAgent()    @classmethod    def from_crawler(cls,crawler):        return cls(crawler)     def process_request(self,request,spider):        def get_ua():        request.headers.setdefault(&#x27;User-Agent&#x27;,self.ua.random)        \n\n然后后我们在settings.py中调用这个中间件:\nDOWNLOADER_MIDDLEWARES = &#123;    &#x27;scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware&#x27;: None,    &#x27;scrapydownloadertest.middlewares.RandomUserAgentMiddleware&#x27;: 543,&#125;\n\n"},{"title":"关于协程记录一下","url":"/2021/01/01/%E5%85%B3%E4%BA%8E%E5%8D%8F%E7%A8%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%8B/","content":"\n\n什么是可迭代对象:\n可迭代对象(iterable): Python中的任意对象，只要它定义了可以返回一个迭代器的__iter__方法，或者定义了可以支持下标索引的__gititem__方法这两个魔法方法，那么他就是一个可迭代对象，简单说，可迭代对象就是能提供迭代器的任意对象,常见的可迭代对象有:字符串，列表，字典，元组等。\nfrom collections.abc import Iterable, Iterator, Generatorstr_1 = &#x27;sixkery&#x27;print(&#x27;字符串是否是可迭代对象：&#x27;,isinstance(str_1,Iterable))print(&#x27;字符串是否是迭代器：&#x27;,isinstance(str_1,Iterator))print(&#x27;字符串是否是生成器：&#x27;,isinstance(str_1,Generator))list_1 = [1,2,3,4]print(&#x27;列表是否是可迭代对象：&#x27;,isinstance(list_1,Iterable))print(&#x27;列表是否是迭代器：&#x27;,isinstance(list_1,Iterator))print(&#x27;列表是否是生成器：&#x27;,isinstance(list_1,Generator))dict_1 = &#123;&#x27;name&#x27;:&#x27;小沐&#x27;,&#x27;age&#x27;:23&#125;print(&#x27;字典是否是可迭代对象：&#x27;,isinstance(dict_1,Iterable))print(&#x27;字典是否是迭代器：&#x27;,isinstance(dict_1,Iterator))print(&#x27;字典是否是生成器：&#x27;,isinstance(dict_1,Generator))\n\n以上都是可迭代对象，可以使用方法dir()查看是否有__iter__来判断一个变量是否是可迭代对象，可迭代对象都可以使用for循环\nif &#x27;__iter__&#x27; in dir(list()):\tprint(&#x27;list是可迭代对象&#x27;)\n什么是迭代器\n迭代器，是在可迭代对象的基础上实现的，创建一个迭代器，首先要用一个可迭代对象:\n用iter()方法即可把可迭代对象转化为迭代器：\nstr_1 = &#x27;asdfg&#x27; # 字符串，是可迭代对象alterator = iter(str_1) # 通过方法 iter() 把字符串变成迭代器print(&#x27;是否成功转换成迭代器:&#x27;,isinstance(alterator,Iterator))\n\n迭代器比可迭代对象多了一个函数next(),我们可以用它来获取元素，for循环也是支持的,这是因为在迭代器内部实现了__next__方法：\nnext(alterator)# &#x27;a&#x27;\n\nfor i in alterator:    print(i)# ...\n生成器:\n之所以引入生成器，是为了实现一个在计算下一个值时不需要浪费空间的结构，通常我们使用列表，即使很大一个列表在一开始也得生成，如果能需要使用的时候自动生成下一个那就节省了很大空间\n之前说的迭代器，是在可迭代对象的基础上加了一个next方法，而生成器是在迭代器的基础上，再实现了yield,所以生成器也可以使用for和next()\nyield是啥呢?它相当于我们函数中的return，在每次next(),或者for循环便利的时候，都会在yield的地方将新的值返回回去，并在这里阻塞，等待下一次的调用，正是有了这个机制，才使得生成器在Python中大放异彩，实现节省内存，实现异步编程。\n\n将列表生成式的中括号改成小括号就是一个生成器啦：\na = (x*x for x in range(1,5))next(a)# 1a = (x*x for x in range(1,5))print(&#x27;是否是生成器：&#x27;,isinstance(a,Generator))# 是否是生成器： True\n实现生成器函数(yield)：\ndef my_gen(n):    a = 0    while a &lt; n:        yield a        a += 1if __name__ == &#x27;__main__&#x27;:    gen = my_gen(5)    print(&#x27;是否是生成器：&#x27;,isinstance(gen,Generator))    for i in gen:        print(i)    # 是否是生成器： True01234\n生成器的执行状态，生成器在其生命周期中，会有以下四个状态:\n\nGEN_CREATED: 等待开始执行\nGEN_RUNNING: 解释器正在执行(只有在多线程应用中才能看到这个状态)\nGEN_SUSPENDED: 在yield表达式处暂停\nGEN_CLOSED: 执行结束\n\nfrom inspect import getgeneratorstatedef my_gen(n):    a = 0    while a &lt; n:        yield a        a += 1if __name__ == &#x27;__main__&#x27;:    gen = my_gen(5)    print(getgeneratorstate(gen)) # 等待开始执行        print(next(gen))    print(getgeneratorstate(gen)) # 在 yield 表达式出暂停        print(next(gen))    gen.close() # 手动关闭结束生成器    print(getgeneratorstate(gen)) # 执行结束GEN_CREATED0GEN_SUSPENDED1GEN_CLOSED\n生成器的异常处理\n在生成器工作中，若生成器不满足生成元素的条件，获取没有元素生产了，就会抛出异常(Stopiteration)\na = (x*x for x in range(1,3))next(a)next(a)next(a)\n\n---------------------------------------------------------------------------StopIteration                             Traceback (most recent call last)&lt;ipython-input-50-0f82892640d1&gt; in &lt;module&gt;()      2 next(a)      3 next(a)----&gt; 4 next(a)StopIteration: \n\n所以在定义生成器时，要考虑这个问题，在不满足生产元素条件的时候，抛出异常:\ndef my_gen(n):    a = 0    while a &lt; n:        yield a        a += 1    raise StopIterationif __name__ == &#x27;__main__&#x27;:    gen = my_gen(2)    next(gen)    next(gen)    next(gen)\n\n不过如果用for循环遍历生成器就不会抛出异常\n\n\n\n从生成器过渡到协程: yield\n通过上面的介绍，我们知道了生成器为我们引入了暂停函数执行(yield)的功能，当我们有了暂停函数的功能之后，就想能不能在生成器暂停的时候向生成器发送一点东西(gen.send(None)),这种机制催生了携程的诞生\n协程: 协程是为非抢占式多任务产生子程序组件的，协程允许不同入口点在不同位置暂停或开始执行任务\n从本质上来看，协程并不属于某种语言的概念，而是编程模型上的概念\n协程和线程一样都能交叉串行执行任务，但是线程频繁加锁解锁，线程切换。协程只要在yield暂停处把任务交到别处执行，协程还是很有发展潜力的\ndef fn(n):    a = 0    while a &lt; n:        jump = yield a        if jump is None:            jump = 1        a += jump        if __name__ == &#x27;__main__&#x27;:    itr = fn(5)    print(next(itr))    print(itr.send(2))\n\n02\n\nyield a 是将a返回出去\njump = yield 是接收传递进来的值\n\n\n"},{"title":"Python对象引用,可变性和垃圾回收机制","url":"/2021/12/30/Python%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8,%E5%8F%AF%E5%8F%98%E6%80%A7%E5%92%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/","content":"\n\nPython中的变量到底是什么\nPython的变量实质上是一个指针:\n\n事先没有预定大小，可以是任意类型，比如int,str\n\n可以理解成一个便利贴，可以贴在任何类型上\na = 1a = &#x27;tyu&#x27;\n\n可以理解成一个便利贴，a贴在1上\n注意:\n\n是先生成对象，然后再贴\n不需要声明类型\n\n看一个例子:\na = [1, 2, 3]\nb = a\nb.append(4)\nprint(a)\n输出：[1, 2, 3, 4]\n结论: a和b贴在了同一个地方\n判断一下a和b是不是同一个对象\na = [1,2,3]b = [1,2,3]print(a is b)# 输出：True\n\n再判断一下a和b是不是同一个内存地址:\na = [1,2,3]b = [1,2,3]print(id(a),id(b))# 输出：8533576 8533576\n\n\n==和is的区别\nis是判断两个变量引用对象id是否相等\n==用于判断引用变量的值是否相等\n整数:\na = 123456789b = 123456789print(a is b)print(a == b)# 结果：True True\n\n字符串:\na = &#x27;123456789&#x27;b = &#x27;123456789&#x27;print(a is b)print(a == b)# 结果：True True\n\n列表:\na = [1,2,3]b = [1,2,3]print(a is b)print(a == b)# 结果：False True\n\n字典:\na = &#123;&#x27;name&#x27;:&#x27;sixkery&#x27;&#125;b = &#123;&#x27;name&#x27;:&#x27;sixkery&#x27;&#125;print(a is b)print(a == b)# 结果：False True\n\n集合:\na = (1,2)b = (1,2)print(a is b)print(a == b)# 结果：False True\n\n总结:只要对象的值一样，那么a == b的值一定为True\n如果对象的类型为整数或者字符串且值一样，则a == b和a is b的值都为True(负浮点数不符合)\na = -1.0b = -1.0print(a is b)print(a == b)# 结果：False True\ndel语句和垃圾回收\nPython中垃圾回收算法是: 引用计数\na = 1 # 1 的计数器上加一b = a # 1 的计数器上再加一del a # 计数器减一print(b)print(a)# 结果：1Traceback (most recent call last):   File &quot;e:/python/test.py&quot;, line 8, in &lt;module&gt;    print(a) NameError: name &#x27;a&#x27; is not defined\n\n当计数器加为0的时候，Python就会把1回收，不占用内存\n\n\n"},{"title":"Python之多线程","url":"/2021/12/30/Python%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/","content":"多个任务可以由多进程完成，也可以由一个进程内的多线程完成。\n一个进程由多个线程组成，一个进程至少有一个线程。\n由于线程是操作系统直接支持的单元，因此，高级语言都内置多线程的支持，Python也不例外，并且Python的线程是真正Posix Thread，不是模拟出来的线程。\nPython的标准库提供了两个模块:_thread和threading，_thread是低级模块，threading是高级模块。绝大多数的情况下，我们只用threading就够了。\n启动一个线程就是把函数传入并创建Thread实例,然后调用start(),函数开始执行就可以了:\nimport timeimport threading #线程执行的代码def loop():    print(&#x27;thread %s is running&#x27; % threading.current_thread().name)    n = 0    while n &lt; 5:        n += 1        print(&#x27;thread %s &gt;&gt;&gt; %s&#x27; % (threading.current_thread().name,n))        time.sleep(1)    print(&#x27;thread %s end&#x27; % threading.current_thread().name) print(&#x27;thread %s is running...&#x27; % threading.current_thread().name)t = threading.Thread(target=loop,name=&#x27;LoopTread&#x27;)t.start()t.join()print(&#x27;thread %s end&#x27; % threading.current_thread().name)\n\n运行结果:\nthread MainThread is running...thread LoopTread is runningthread LoopTread &gt;&gt;&gt; 1thread LoopTread &gt;&gt;&gt; 2thread LoopTread &gt;&gt;&gt; 3thread LoopTread &gt;&gt;&gt; 4thread LoopTread &gt;&gt;&gt; 5thread LoopTread endthread MainThread end\n\n由于任何进程都会默认开启一个线程，我们把该线程称为主线程，主线程又可以开启新的线程，Python的threading模块有个current_thread()函数，它永远返回当前线程的实例；主线程实例的名字叫Main Thread，子线程的名字在创建的时候指定，我们用LoopThread命名子线程,名字仅仅在打印的时候用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为Thread-1,Thread-2\nLock\n多进程和多线程最大的不同在于，多进程中，同一个变量，各自有一份拷贝到每个进程，互不影响，而线程中，所有变量都是所有线程共享所有，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险就在与多线程同时修改一个变量，把内容给改乱了，举个栗子:\n#假定这是你的银行存款balance = 0 def change_it(n):    #先存后取    global balance    balance += n    balance -= n def run_thread(n):    for i in range(100000):        change_it(n) t1 = threading.Thread(target=run_thread,args=(5,))t2 = threading.Thread(target=run_thread,args=(8,)) t1.start()t2.start()t1.join()t2.join()print(balance)\n\n我们定义了一个共享变量balance，初始化为0，并且启动两个线程，先存后去，理论上结果应该为0，但是由于线程的调度是由操作系统决定的，当t1，t2交替执行时，只要循环次数足够多，balence的结果就不一定是0了，原因是因为高级语言的一条语句在cpu执行的时候是若干条语句，即使一个简单的计算:\nbalance += n\n\n也要分成两步:\n\n计算balance + n结果存到临时变量中\n将临时变量的值赋给balance\n\n究其原因，是因为修改balance需要多条语句，而执行这几条语句时，线程可能中断，从而导致多个线程把一个对象的内容改乱了。\n两个线程同时一存一取，就可能导致余额不对，你肯定不希望你的银行存款莫名其妙地变成了负数，所以我们要确保balance计算正确，就要给change_it()上一把锁，当某个线程开始执行change_it()时，我们说，该线程因为获得了锁，因此其他线程不能同时执行change_it(),只能等待，直到锁被释放后，获得该锁以后才能改。由于锁只有一个，无论多少线程，同一时间最多只有一个线程持有该锁，所以，不会造成修改的冲突。创建一个锁就是通过threading.Lock()来实现：\nlock = threading.Lock()def run_thread(n):    for i in range(100000):        #先要获取锁        lock.acquire()        try:            #放心改吧            change_it(n)        finally:            #改完记得释放锁哦            lock.release()\n\n当多个线程同时执行lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。\n获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用try…finally…来确保锁一定会被释放。\n\n锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行\n坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。\n其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。\n\n多核CPU\n如果你拥有一个多核CPU，你肯定在想，多核应该可以同时执行多个线程。\n如果写一个死循环的话，会出现什么情况呢？\n打开Mac OS X的Activity Monitor，或者Windows的TaskManager，都可以监控某个进程的CPU使用率，我们可以监控到一个死循环线程会100%占用一个CPU。如果有两个死循环线程，再多核CPU中，可以监控到会占用200%的CPU，就是占用两个CPU核心。如果想把N核CPU的核心全部跑满，就必须启动N个死循环线程，在Python中真的如此嘛?\n试试用Python写个死循环:\nimport threading, multiprocessing def loop():    x = 0    while True:        x = x ^ 1 for i in range(multiprocessing.cpu_count()):    t = threading.Thread(target=loop)    t.start()\n\n启动与CPU核心数量相同的N个线程，在4核CPU上可以监控到CPU占用率仅有102%，也就是仅使用了一核，但是用C、C++或Java来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%，为什么Python不行呢？\n因为Python的线程虽然是真正的 线程，但解释器在执行代码时，有一个GIL锁: Global Interpreter Lock,任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。\nGIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。\n所以，在Python中，可以使用多线程，但不要指望能有效利用多核，如果一定要通过多线程利用多核，那就只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。\n不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自的独立的GIL锁，互不影响。\n"},{"title":"Python图片灰度处理","url":"/2021/12/30/Python%E5%9B%BE%E7%89%87%E7%81%B0%E5%BA%A6%E5%A4%84%E7%90%86/","content":"Python的PIL库为我们提供了一些操作图片的方法，我们可以用这些把图片处理成我们想要的样子，比如把图片变模糊，或者改变大小，还有就是今天我们要讲的把图片变成漫画或者说素描的风格:\nfrom PIL import Imageimport numpy as npa = np.asarray(Image.open(&#x27;1.jpg&#x27;).convert(&#x27;L&#x27;)).astype(&#x27;float&#x27;)depath = 10 # (0-100)grad = np.gradient(a)# 取图像灰度的梯度值grad_x,grad_y = grad # 分别取横纵图像梯度值grad_x = grad_x * depath / 100.grad_y = grad_y * depath / 100.A = np.sqrt(grad_x ** 2 + grad_y ** 2 + 1.)uni_x = grad_x / Auni_y = grad_y / Auni_z = 1. / Avec_el = np.pi / 2.2 # 光源的俯视角度，弧度值vec_az = np.pi / 4 # 光源的方位角度，弧度值dx = np.cos(vec_el) * np.cos(vec_az) # 光源对 x 轴的影响dy = np.cos(vec_el) * np.sin(vec_az) # 光源对 y 轴的影响dz = np.sin(vec_el) # 光源对 z 轴的影响b = 255 * (dx * uni_x + dy * uni_y + dz * uni_z) # 光源归一化b = b.clip(0,255)im = Image.fromarray(b.astype(&#x27;uint8&#x27;)) # 重构图像im.save(&#x27;2.jpg&#x27;)\n\n"},{"title":"Python之多进程","url":"/2021/12/30/Python%E4%B9%8B%E5%A4%9A%E8%BF%9B%E7%A8%8B/","content":"要让Python实现多进程(multiprocessing),我们先来了解下操作系统相关知识, Unix和Linux操作系统提供了一个fork()函数系统调用，它非常特殊，普通的函数，调用一次它执行一次，但是fork()函数调用一次执行两次，因为操作系统自动把当前进程(称为父进程)复制了一份(称为子进程)，然后，分别在子进程和父进程中执行，子进程永远返回0，而父进程返回子进程的ID，而子进程只要调用getpid()就可以拿到父进程的ID。Python中os模块封装了常见的系统调用，其中就包括fork(),可以在Python程序中轻松创建子程序：\nimport os print(&#x27;Process (%s) start ...&#x27; % os.getpid())#Only work on Unix/linux/Mac#不能在Windows平台上运行pid = os.fork()if pid == 0:    print(&#x27;I am child process (%) and my parent is %s.&#x27; % (os.getpid(),os.getppid()))else:    print(&#x27;I (%) just created a child process (%).&#x27; % (os.getpid(),pid))\n\n运行结果:\nProcess (876) start...I (876) just created a child process (877).I am child process (877) and my parent is 876.\n\n由于windows平台下没有fork()函数调用，多以代码没有办法在windows平台下运行，有了fork调用，一个进程在接到任务的时候就可以复制出来一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出新的子进程来处理新的http请求。\nmultiprocessing(多进程)\n如果你想写多进程的服务程序，Unix/LInix平台最好了，当然也可以在Windows平台下来编写，因为Python跨平台，multiprocessing模块就是跨平台版本的多进程模块。multiprocessing模块提供了一个Process类来代表一个进程对象，下面一个例子来演示启动一个进程并等待结束的例子：\nimport osfrom multiprocessing import Process #子进程要执行的代码def run_proc(name):    print(&#x27;Run child process %s (%s)&#x27; % (name,os.getpid())) if __name__ == &#x27;__main__&#x27;:    print(&#x27;parent process %s&#x27; % os.getpid())    p = Process(target=run_proc,args=(&#x27;test&#x27;,))#创建子程序    print(&#x27;Child process will start&#x27;)    p.start()#子程序开始执行    p.join()    print(&#x27;Child process end.&#x27;)\n\n\n创建子程序时，只需要传入衣蛾执行的函数和函数的参数\n\n创建一个Process实例，用start()方式开启，这样创建的进程比fork还简单\n\njoin()方法可以等join子进程执行完后再继续往下运行，通常用于进程之间的同步\n\n如果想要启动大量的子进程，可以用进程池的方式批量创建子进程，如下所示：\nimport os,time,randomfrom multiprocessing import Pool def long_time_task(name):    print(&#x27;Run task %s (%s)...&#x27; % (name,os.getpid()))    start = time.time()    time.sleep(random.random() * 3)    end = time.time()    print(&#x27;Task %s run %0.2f seconds.&#x27; % (name,(end-start))) if __name__ == &#x27;__main__&#x27;:    print(&#x27;Parent process %s.&#x27; % os.getpid())    p = Pool(4)    for i in range(5):        p.apply_async(long_time_task,args=(i,))    print(&#x27;Waiting for all subprocess done...&#x27;)    p.close()    p.join()    print(&#x27;All subprocess done&#x27;)\n\n"},{"title":"Python思维导图","url":"/2021/12/31/Python%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/","content":"\n\n原文链接:https://blog.csdn.net/qq_44647926/article/details/90669352?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164090955916780269896755%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=164090955916780269896755&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-13-90669352.first_rank_v2_pc_rank_v29&amp;utm_term=Python&amp;spm=1018.2226.3001.4187\n"},{"title":"什么是宝塔面板","url":"/2021/12/31/%E4%BB%80%E4%B9%88%E6%98%AF%E5%AE%9D%E5%A1%94%E9%9D%A2%E6%9D%BF/","content":"简单来说: 就是装在服务器上的管理面板！\n宝塔面板是一款简单好用的服务器运维面板，简单说来就是一个可视化的面板管理工具，支持一键LAMP/LNMP/集群/监控/网站/FTP/数据库/JAVA等100多项服务器管理功能。出错少而且安全，由于宝塔面板既有windows版本也有linux版本，尤其是Linux服务器很多用户不会操作，宝塔是为了让那些不会linux的人使用的，使用宝塔，操作linux更简单，更方便，这里要提醒一下虽然宝塔面板可以安装在物理服务器或者云服务器，虚拟主机无法安装的，但是云服务器基本都是可以安装的。\n大型网站程序都安装在服务器上，服务器用的是Linux系统，进行服务器维护需要记住很多的linux命令，这就比较麻烦；\n面板的好处就是通过一个交互界面就能完成服务器的维护工作，比如更新系统，添加网站，修改设置等等，以前需要记住各种命令，下你在通过面板点点按钮就可以了，省时省力.\n"},{"title":"Docker最详细入门教程","url":"/2022/01/05/Docker%E6%9C%80%E8%AF%A6%E7%BB%86%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","content":"请参考: http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html\n"},{"title":"科学上网教程","url":"/2021/12/31/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E6%95%99%E7%A8%8B/","content":"最近在搭hexo博客的时候在一篇theme配置教程中看到了一个开源的图床项目，里面有关于科学上网的介绍，这里我把它搬出来，详情请点击:https://github.com/Alvin9999/new-pac/wiki\n"},{"title":"推荐一款基于GitHub好用的在线图床工具","url":"/2021/12/31/%E6%8E%A8%E8%8D%90%E4%B8%80%E6%AC%BE%E5%9F%BA%E4%BA%8Egitgub%E5%A5%BD%E7%94%A8%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%9B%BE%E5%BA%8A%E5%B7%A5%E5%85%B7/","content":"这是一款基于GItHubAPI开发的图床神器，图片外链使用jsDriver进行CDN加速，免下载，免安装，打开网站简单配置后即可直接使用，免费，稳定，高效\nPicX官网: https://picx.xpoet.cn/#/upload\nPicXGitHub地址: https://github.com/XPoet/picx\n"},{"title":"Bash脚本教程","url":"/2022/01/05/Bash%E8%84%9A%E6%9C%AC%E6%95%99%E7%A8%8B/","content":"请参考: https://www.ruanyifeng.com/blog/2020/04/bash-tutorial.html\n"},{"title":"SSH最详细入门教程","url":"/2022/01/05/SSH%E6%9C%80%E8%AF%A6%E7%BB%86%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","content":"请参考: https://www.ruanyifeng.com/blog/2020/12/ssh-tutorial.html\n"},{"title":"Docker10分钟快速入门","url":"/2022/01/05/Docker10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","content":"\ndocker是用来解决什么样的问题而出现的呢？\n比如你写了个web应用，并且本地调试没有任何问题，这时候你想发给你的朋友试试看，或者部署到远程的云服务器上，那么首先，你需要配置相同的软件，比如数据库，web服务器，必要的插件，库等等:\n\n而且你还不能保证软件一定能正常地运行起来，因为别人用的可能是完全不同的操作系统，即便同样是使用Linux，每一种发行版也会有微小的区别，为了模拟完全相同的本地环境，我们自然会想到使用虚拟机:\n\n但是虚拟机需要模拟硬件，运行整个操作系统，不但体积臃肿，内存占用高，程序的性能也会收到影响，这时候我们的docker就派上了用场，Docker在概念上与虚拟机非常类似，但却轻量很多，它不会去模拟底层的硬件，只会为每一个应用提供完全隔离的运行环境:\n你可以在环境中配置不同的工具软件，并且不同环境之间相互不影响，这个“环境”在Docker中也被称作container/容器，降到这里，我么就不得不提到Docker中的三个重要概念，Dockerfile，Image和Container:\n\n\nDocker中三个重要的概念\n\nImage:\n\n你可以把它理解为一个虚拟机的快照(Snapshot)，里面包含了你要部署的应用程序以及它所关联的所有库，通过镜像，我们可以创建许多个不同的Container容器:\n这里的容器就像是一台台运行起来的虚拟机，里面运行了你的应用程序，每个容器是独立运行的，他们相互之间不影响，最后Dockerfile就像是一个自动化脚本，它主要被用来创建我们之前讲到的镜像(Image)，这个过程就好比是我们在虚拟机中安装操作系统和软件一样，只不过是通过Dockerfile这个自动化脚本完成了\n\nImage\nDocker把应用程序及其依赖，打包在Image文件里面，只有通过这个文件,才能生成Docker容器，Image文件可以看成是容器的模板，Docker根据Image文件生成容器的实例，同一个Image文件，可以生成多个同时运行的容器实例\n# 列出本机的所有 image 文件。$ docker image ls# 删除 image 文件$ docker image rm imageName\nContainer\nContainer就类似于我们所创建的虚拟机，内存没有虚拟机那么大，也更容易创建\n\n\n\n快速上手Docker的最好方法就是亲自安装并去使用它:\n如果你是用的是windows和mac，你可以在官网下载一个Docker Desktop的应用，而且在win10上你可以使用WSL2(也就是windows下的Linux子系统)来运行Docker，如果你不是使用的windows最新的预览版本，WSL2的安装可能稍微复杂一点，不过也是按照官网的给定步骤进行安装，在linux中，我们可以直接使用包管理工具，按照官网给定的指示一步步执行即可，如果使用的是vscode，也特别推荐安装docker的扩展:\n\n他会提供Dockerfile的语法检测，代码高亮，自动补全等等，你也可以通过菜单运行各种Docker命令并且在左侧面板中看到你创建的所有镜像:\n\n接下来我们就尝试使用Docker来部署一个应用，以之前写的一个python程序举例，这是一个非常简单的用Flask搭建的记账工具:\n\n首先我们在应用的根目录下创建一个Dockerfile文件:\n\n第一行我们需要用FROM命令指定一个基础镜像(base image)这样可以帮我们节省许多软件安装和配置的时间:\n\n可以看到在DockerHub上提供了许多高质量的操作系统镜像，比如ubuntu:\n不同的操作系统提供不同的包管理工具，比如ubuntu上的apt，Fedora上的dnf，当然在Docker Hub上还有许多方便某一种语言，某种框架开发的镜像，比如你nginx,Python,node等：\n\n由于我这里做的是python的开发，自然我会使用Python的镜像，这样免去了它的安装步骤，这里的Python是官方镜像的名字:\n\n冒号后面这一串是版本号，同时也是一个标签，我们可以在docker hub中搜索Python然后点击Python转到docker hub的镜像页面，里面可以找到所有支持的标签:\n比如我们这里用的是Python 3.8版本：\n\n运行在debian buster的发行版本上，后面的workdir指定了之后所有Docker命令的工作路径(working directory),注意是这个命令之后的所有Docker命令，比如我们马上要讲到的run，copy等：\n\n当然如果这个路径不存在，Docker会自动帮你创建，这样可以避免使用绝对路径或者手动cd切换路径，增加程序的可读性，之后，我们可以调用copy命令将所有的程序拷贝到Docker镜像中(copy./app表示将当前目录下所有文件(除了.dockerignore排除的路径),都拷贝进入image文件的/app目录)：\n第一个参数代表本地文件，“.”代表程序根目录下的所有文件，第二个参数代表Docker镜像中的路径，这里的.代表当前的工作路径，也就是之前指定的app目录，随后的run允许我们在创建镜像时运行任意的shell命令，因为我们用的是Linux镜像，所以像echo，pwd，cp，rm这些都是合法的，比如我这里用到pip install 来安装Python程序的所有关联:\n通过以上的所有命令，我们就可以完成一个Docker镜像的创建，在Dockerfile的最后，我们会用到CMD来指定当Docker容器运行起来以后要执行的命令：\n\n大家需要注意这里容器和镜像的区别(容器不等于镜像),并且它和之前讲到的run不一样，run是创建镜像时使用的，而cmd是运行容器时使用的，到这里我们的自动化脚本dockerfile就完成了，接下来我们可以使用docker build来创建一个镜像，这里的-t指定了镜像的名字，最后面的.告诉docker应该在当前目录下寻找这个dockerfile，这个不能省略:\n\n第一次调用docker build会比较慢，因为docker会下载必要的镜像文件:\n然后一行行运行我们的指令，不过再次调用就会快很多，\n因为docker会缓存之前的每一个操作，这个在Docker中也被称为分层:\n\n这里我们就不展开谈论了\n有了镜像之后，我们就可以通过docker run来启动一个容器\n这里需要注意的是这个-p参数：\n\n他会将容器上的某一个端口，映射到你的本地主机上，这样你才能从主机上访问容器中的web应用，前面的80是我们本地主机上的端口，后面是容器上的端口，这个不要搞反了，第二个参数-d(–detached)让容器在后台运行，这样容器的输出就不会直接显示在控制台，如果不出意外的话，你已经可以在浏览器中访问这个web应用了，我们通过Docker Desktop这个图形界面可以查看应用在后台的所有输出:\n这个对于调试非常方便，同时我们可以看到当前容器的各种信息：\n\n这里的congainer显示了我们创建的所有容器,我们可以选择停止，重启或者删除他们，还可以通过shell远程调试这个容器：\n\n\n这里是它们所对应的的命令行指令：\n\n需要注意的是，当我们删除一个容器的时候，之前所做的修改，新添加的数据会全部丢失，这就好比是我们删除一个虚拟机，里面的数据会一通销毁一样，如果我们希望保留容器中的数据，我们可以使用Docker提供的volume数据卷:\n你可以把它当做是一个在本地主机和不同容器中共享的文件夹:\n\n比如你在某个容器中修改了某一个volume的数据，他会同时反映在其他的容器上:\n\n我们可以通过docker volume create来创建一个数据卷：\n\n随后在启动容器的时候我们可以通过-v参数指定将这个数据卷挂载(mount)到容器中的哪一个路径上:\n\n这里可以看到我们将my-finance-data挂载到了/etc/finance这个路径下，向这个路径写入的任何数据都会被永久保存在这个数据卷中\n\n多容器共同协作\n之前我们讲到的例子都只涉及单个容器，但在实际使用中，我们的应用程序可能会用到多个容器共同协作，比如我们可以使用一个容器来运行web应用，另一个容器来运行数据库系统:\n\n这样可以做到数据和应用逻辑的有效分离，比如当web程序宕机了，数据库依然在有效运转，这个时候我们只需要修复web容器即可，而Docker compose刚好可以帮我们做到这一点：\n我们可以创建一个docker-compose.yml文件，在这个文件下，我们通过services来定义多个container，比如这里我们定义一个web容器，它里面运行了我们的web应用，然后再定义一个db容器，里面运行了mysql数据库系统,这里我们可以通过这两个环境变量指定数据库的名称和连接密码：\n\n同时在db容器中，我们还可以通过volumes指定一个数据卷用来永久存放数据：\n\n定义完毕之后，我们保存文件，使用docker compose up来运行所有容器，这里的-d(detach)同样代表在后台运行所有的容器，不直接输出在控制台:\n\n与这个命令对应的，我们可以使用docker compose down来停止并删除所有的容器:\n不过新创建的数据卷需要我们手动删除(除非在上面的命令中加上–volumes参数)：\n\n另外刚刚讲到的所有操作都可以做图形界面上完成\n\n简单聊下Docker和kubernetes的区别和联系\n虽然大家都说kubernetes在逐渐取代Dokcer，但其实指的是kubernetes中的容器引擎(container engines)而已：\n实际上kubernetes和Docker并不是同一个层面上的东西，在之前的例子中，我们的应用，数据库容器都运行在同一个计算机中，随着应用规模的增大，一台计算机没有办法满足我们的需求:\n\n当我们想使用一个集群的电脑来提供服务，并做到负载均衡，故障转移等等，这个时候kubernetes就可以大显身手了，一句话将，kubernetes所做的就是将你的各个容器分发到一个集群(cluster)上运行，并进行全自动化的管理，包括应用的部署和升级\n\n最后附上docker中文教程\nhttps://www.coonote.com/docker/docker-tutorial.html\n\n\n"},{"title":"Kubernetes(k8s)10分钟快速入门","url":"/2022/01/06/Kubernetes(k8s)10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","content":"\n首先来看看Kubernetes用来解决一个什么样的问题\n我们知道Docker就像是一个轻量型的虚拟机，它将应用程序的代码，工具库和运行环境全部都封装到了一个容器中:\n因此大大降低了测试和部署的难度，我们要做的不过是在服务器上运行一条指令而已:\n\n但如果你要部署的是像购物系统这类架构复杂，规模庞大的应用，他们需要根据访问量自动分配服务器，网络资源，并且在某个容器宕机之后自动进行灾难恢复，故障转移：\n这个时候Kubernetes就可以大显身手了\n\n我们先从整体上来认识下Kubernetes的工作原理\n我们知道，Kubernetes是一个用于大规模部署分布式应用的平台，他管理着一系列的主机或者服务器：\n他们被称作Node(节点)，每个节点运行了相对独立的pod：\npod是Kubernetes中可以部署的最小执行单元，说白了他就是一个或者多个容器的集合，其中运行了我们应用的某一部分核心组件，比如数据库，web服务器等等，当然这么多的pod，他们需要相互协调才能做到负载均衡或者故障转移，这就需要一台中心计算机来集中管理，这个中心计算机被称作Control Plane(控制面板):\n控制平面通过专有的API与各个节点进行通信，他会实时监测节点的网络状态来平衡服务器的负载，或者临时下发指令来应对突发的状况，比如Kubernetes发现某个容器或者pod挂掉了，他会立即启用在后台预先准别好的，随时待命的备用容器来替换它，这些容器被称作Replica Set(副本集合),正是由于他们的存在，才让我们的应用能够长时间，不间断地可靠运行，而以上讲到的所有节点连同控制面板，一起被称作一个cluster(集群)集群代表了Kubernetes所管理的全部主机节点，要配置一个Kubernetes集群，我们当然可以亲自租用服务器去搭建环境，不过步骤会稍微繁琐一点，另一种做法是使用现成的、预先配置好的云服务提供商:\n\n一种完全免费的方法是使用minikube在本地模拟一个Kubernetes集群，这也是我接下来要用到的方法：\n\n使用Kubernetes\n上面我们提到，使用minikube在本地模拟一个Kubernetes集群，在这里面，我们照样可以使用Kubernetes的全部功能，只不过他不是一个真实的生产环境而已\n我们按照这里的步骤下载并安装对应的版本:\n随后只需要一行指令minikube start启动本地模拟的集群即可:\n\n我们来讲下如何在上面部署一个应用\n首先我们需要创建一个yaml文件，里面定义了我们应用的基本信息，比如它由哪些pod组成，里面运行了哪些容器，以及网络配置等等，它和docker中的dockerfile很类似，你可以把它当做一个自动化脚本，里面描述了应用部署的整个过程，另外在vscode中，强烈建议去安装一个Kubernetes插件，他除了提供基本的语法检测、代码提示，在左侧面板中该显示了我们急缺的各种信息、运行状态：\n整个部署的过程也都可以通过图形界面完成\n这里我们先创建一个deployment.yaml文件，然后输入deployment:\n\n让vscode帮我们生成一个最最基本的配置：\n可以看到这里列出了相当多的属性，我们可以将鼠标悬停在上面找到每个属性的详细用法:\n\n接下来我们去修改其中我们关系的部分即可，首先第一步我们先将所有的myapp改成我们应用的名字，这里的replicas指定了连同备用pod在内的所有pod数量:\n然后最重要的是这里的这个templates，它里面定义了与pod相关的所有信息：\n比如下面的container指定了pod中运行的所有容器\n这里我还是用上个视频同样的项目，一个简单的记账工具(一个非常简单的web应用)作为演示，不过我事先将他的镜像(image)上传到了Docker Hub上：\n这样Kubernetes可以自动拉取到它，于是我们这里直接填写镜像的名称即可：\n另外我们可以通过这里的limits为每一个pod设置合理的cpu和内存配额：\n\n最下面的containerPort指定了容器需要对外暴露的端口：\n比如我们web容器使用的是5000端口\n在默认情况下，我们的pod只能与同一个集群内的其他pod进行通信，虽然每一个pod都拥有一个独立的ip\n\n但这个ip地址对于外网是不可见的，如果要从外网访问我们的应用，我们还需要用到Kubernetes中另一个重要的组件–服务(Services)\n现在我们讲一种最最基础的服务，NodePort，它是一种最原始的将应用端口暴露给外网的方式：\n\n建立在它之上，Kubernetes还提供LoadBalancer或者更加复杂的ingress来实现负载的均衡，不过这里就不展开讨论了，我们先在下方用三个横线隔开(yaml中列表的语法)，然后输入Service来添加一个服务：接下来我们在selectors中指定应当将数据转发到哪一个pod上,这里直接填写之前的应用名称即可：\n\n随后的type指定了服务的类型，也就是NodePort:\n后面的port和targetport我们设置成5000和容器端口保持一致，最后的nodeport指定了暴露给外网的端口，这里我设置成了30080，当然我们也可以省略这一行让Kubernetes自动进行分配：\n到这里我们的配置文件就完成了，接下来到了真正应用部署的环节：\n\n应用部署\n这里我们会用到一个命令行工具kubectl来与kubernetes集群进行交互：\n这是一个所有平台通用的工具，就好比我们之前用到的docker命令一样，他可以操纵任何的集群，包括我们本地模拟的ninikube，通常Docker的桌面版本都自带了cubectl命令，但如果你计算机中没有安装Docker，则需要去这里额外下载:\n安装完毕后，我么可以使用kubectl apply来部署我们的应用，并且传入之前创建的这个yaml文件：\n可以看到这个命令被成功执行，此时kubernetes会在后台开始应用的部署：\n我们可以通过kubectl get pods查看所有pod的运行状态，这里显示了我们之前指定的其中包括pod在内的三个pod,他们目前都是正常运行的状态:\n\n另外使用kubectl get services可以查看所有创建的服务\n\n看到这里，既然应用已经被成功部署，我们自然可以去浏览器中访问它。由于这里我们用到的是minikube模拟的集群，所以需要用到一个专门的指令minikube service 后面跟上我们服务的名字：\n这样minikube会自动在浏览器中打开我们的应用，另外顺便提一下，之前所有的操作也都可以通过vscode中的插件完成，里面可以查看各个节点，pod，服务的运行状态，停止或者删除它们：\n\n更新应用\n这个时候如果我们想要更新应用，比如切换容器镜像的版本，或者重新分配cpu和内存资源，我们只需要去修改之前的deployment.yaml文件：\n然后再次调用kubectl apply即可\n\nkubernetes会在后台无缝地更新我们的应用，确保新版本运行起来以后再去销毁旧的版本，因此用户不会遇到服务停机的问题，类似的，如果我们不再需要这个应用，那么可以通过kubectl delete命令从集群上完全移除它：\n后面我们传入相同的配置文件即可\n讲到这里，我们也不是是介绍了kubernetes中一个非常简单的应用部署，通常生产环境下的应用比这个要复杂得多，如果大家想继续深入的话，还是建议去阅读下官方的文档，里面可以找到各种实用的案例，包括安全配置，网络管理，故障排除甚至是GPU调度等等\n\n\n"},{"title":"Puppeteer10分钟快速上手","url":"/2022/01/06/Puppeteer10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/","content":"爬虫，它就像是一只在互联网删爬行的蜘蛛，会根据我们实现定义好的规制为我们抓取需要的信息，以Python为例，你可以使用urllib或者requests发起一个http请求，并使用beautifulsoup或者lxml来分析返回的html文档，从中提取你需要的信息:\n当然你也可以使用Scrapy这种专门为爬虫设计的框架，帮你完成从数据抓取，解析，存储以及调试的所有流程，Scrapy这类框架的优点自然是功能全，速度快，灵活性高，扩展性强，但是由于现在大多数网站都是动态加载的，前端呈现的内容可能由极其复杂的JavaScript程序控制，遇到加密混淆的程序，可能自己还得去逆向分析很久，今天我为大家介绍另一种，基于puppeteer的爬虫思路， 虽然他的效率不是最高的，但一定能让你在最短的时间内快速实现一个爬虫，并帮你抓取到需要的信息\n\n首先来介绍下puppeteer\npuppeteer是一款强大web自动化工具，相比较selenium，phantomjs这些老牌的框架，puppeteer绝对是后起之秀，如果你写了一个web应用，你需要对页面的功能进行测试，譬如检测某个按钮是否会唤醒对话框界面，puppeter就完全可以胜任这个任务，由于它可以对浏览器进行操控，获取页面数据，自然也可以用它来做爬虫，爬虫不过是它众多应用中的其中一种，其实对于任何自动化的操作，我们都可以用它来完成，谷歌官方的puppeteer是通过JavaScript调用的，但是它在Python，Ruby，Go上都有对应的移植版本，如果你使用Python，你可以下载一个叫做pyppeteer的包，其中所有的API都是一致的，除了少数语法的不同，这里以JavaScript作为演示：\n\nJavaScript演示puppeteer\n首先确保你计算机中安装了Node.js：\n然后创建一个目录来保存我们这个项目(也就是这里的web-scraping-node)：\n\n然后使用npm init 初始化工程:\n最后使用命令npm i puppeteer:\n这过程会持续一段时间，取决于你的网速\n接着我们在文档的入门指南中找到这样一段样例程序，我们直接将代码复制到编辑器中，在它的基础上做修改:\n\n这是修改前的代码:\n这10行代码非常简单:\n这是创建一个浏览器对象:\nconst browser = await puppeteer.launch();\n\n打开一个新页面:\nconst page = await browser.newPage();\n\n然后转到example.com\nawait page.goto(&#x27;https://example.com&#x27;);\n\n保存一张截图后退出:\nawait page.screenshot(&#123;path: &#x27;example.png&#x27;&#125;);\n\n如果你运行代码，在短暂的等待之后，程序会当前目录下保存一张截图文件:\n这里我们稍做修改，首先在创建浏览器对象的时候传入一个新参数headless: false,因为puppeteer默认运行在无头(headless)模式下，也就是说浏览器窗口并不会显示出来，这里我们通过这个参数关闭无头模式，接着我们将网址改为百度，并且删除后面的screenshot()和borwser.close(),保存程序，运行程序，可以看到puppeteer成功打开了百度并显示在新创建的浏览器窗口中，需要注意的是，这里窗口边缘的空白是一个feature，并不是一个bug:\n\n\n用puppeteer写爬虫\n将bilibili上的音乐的热门信息给提取出来\n以下是实施的步骤:我们打开浏览器的控制台，然后我们可以在这里输入任何JavaScript表达式来做测试，比如:\n\n\n如果我们想要在页面中提取相似的元素，我们可以用到selector(选择器)或者xpath，选择器的语法更为简单些，这里我们以选择器为例，比如你想要的匹配页面中的所有链接，可以在控制台中输入$$(‘a’),如果你想要匹配所有li元素下的a标签则可以输入$$(‘li &gt; a’),这里我们想找出能匹配这个视频标题的选择器，其实chrome给我们提供了一个便利，我们可以在标题上点右键，选择下方的检查，选中的元素就会以高亮的形式显示在右边:\n我们点击右键，选择这里的复制选择器：\n\n接下来我们只需要稍作修改，比如删掉这里多余的部分，做一些简化:\n就可以提取出所有的标题元素了：\n然后我们可以遍历返回的每个元素，将标题文字给提取出来:\n\n我们可以先记下这段选择器，待会儿我们就会用到，我们先将浏览器中的网址直接拷贝过来,接下来使用page对象的$$eval函数来获取所有的视频标题：\n这里的第一个参数是选择器，就是我之前测试时用于提取标题的选择器，第二个参数要求你传入一个函数，这个函数会直接在网页的上下文中运行，筛选出你需要的数据并返回给puppeteer，这里我做的是遍历所有的a标签,并将其中的文本给提取出来，我们可以调用log函数将结果打印出来：\n\n运行程序，我们可以看到这样的结果：\n这里为了让程序更健壮，我们可以在获取标题之前，先等待标题元素的出现，这样可以避免页面加载期，无法找到元素而报错的现象:\n后面的代码直接上，我们限定了数据的时间，然后以json的数据格式保存下来：\nconst puppeteer = require(&quot;puppeteer&quot;);const fs = require(&quot;fs&quot;);(async () =&gt; &#123;  let data = [];  const browser = await puppeteer.launch(&#123;    headless: false,    userDataDir: &quot;./data&quot;,  &#125;);  const page = await browser.newPage();  for (let mo = 1; mo &lt; 12; mo++) &#123;    for (let pg = 1; pg &lt;= 10; pg++) &#123;      mo = mo.toString().padStart(2, &quot;0&quot;);      await page.goto(        &quot;https://www.bilibili.com/v/music/cover/?spm_id_from=333.5.b_7375626e6176.3#&quot; +          `/all/click/0/$&#123;pg&#125;/2020-$&#123;mo&#125;-01,2020-$&#123;mo&#125;-29`      );      await page.waitForSelector(&quot;.vd-list-cnt &gt; ul &gt; li &gt; div &gt; div.r &gt; a&quot;);      let titles = await page.$$eval(        &quot;.vd-list-cnt &gt; ul &gt; li &gt; div &gt; div.r &gt; a&quot;,        (links) =&gt; links.map((x) =&gt; x.innerText)      );      console.log(titles);      data = data.concat(titles);    &#125;  &#125;  fs.writeFile(&quot;data.json&quot;, JSON.stringify(data, null, &quot;\\t&quot;), function (err) &#123;    if (err) &#123;      console.log(err);    &#125;  &#125;);&#125;)();\n最后我想提一个大家可能经常会遇到的问题\n我们每次运行脚本的时候，puppteteer磨人都会为我们创建一个崭新的实例，也就是像网页的缓存、cookie都会在脚本退出之后自动销毁：\n像网站的登录信息也不会被保存下来，而通常我们并不希望每次运行脚本都去登录一次，这里我们可以给launch指定另外一个参数，他会将浏览器的数据保存在这个指定的路径下，因此所有的浏览器实例都会共享这些数据：\n登录信息也会被保存下来\n其实用puppteteer来做爬虫确实是一种不错的选择，要知道现在大多数网站都是使用了前端的JavaScript程序来做渲染的，相比于http层的爬虫工具，puppteteer更像是一个模拟网页操作的机器人，他用起来直观很多，也帮我们省去了不少分析前端代码的时间，不过想scrapy还是很强大的，尤其是他的速度和性能\n源码：https://github.com/rossning92/web-scraping\nPuppeteer 中文文档：https://zhaoqize.github.io/puppeteer-api-zh_CN/\n\n\n"},{"title":"mac终端美化教程","url":"/2022/01/07/mac%E7%BB%88%E7%AB%AF%E7%BE%8E%E5%8C%96%E6%95%99%E7%A8%8B/","content":"mac终端美化请参考:https://www.wolai.com/fishc/exwe9Srj8St6THjGE6YVyz\n"},{"title":"Linux系统启动过程","url":"/2022/01/07/Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/","content":"按下系统的电源开关，过一会儿就可以看到Linux的登录界面，你是否想过，从按下电源开关到登录界面的出现，这后面到底发生了什么?\n我们先来看看一个整体的流程图:\n\nLinux系统在启动过程中，首先是固件(PC上大多是CMOS/BIOS)的物理检测，诸如检测系统的显卡，CPU和硬盘等，可从系统按下电源键后看到此检测信息；检测没有问题后，将读取硬盘的MBR(主引导记录)中的自举程序，Linux中常用的自举程序如LILO和GRUB。自举程序GRUB在系统启动期间只有一个作用，就是启动内核，内核在引导期间有两个主要的作用，一个是驱动系统硬件，另一个是启动系统init，init进程将读取其配置文件/etc/initab完成后继续所有的引导。\n整个过程基本可以分为六个步骤:BIOS–&gt;MBR(GRUB)–&gt;Kernel–&gt;Init–&gt;Runlevel:\n\n\n\n\n\n\n"},{"title":"10分钟彻底搞懂“动态规划”算法","url":"/2022/01/06/10%E5%88%86%E9%92%9F%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82%E2%80%9C%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E2%80%9D%E7%AE%97%E6%B3%95/","content":"动态规划是计算机中解决最优化问题的一种方法，它通常给我们的印象是效率高，速度快，但对于初学者来说，可能并不是那么容易理解，今天，我们抛开所有的数学公式，用实例给大家彻底讲懂动态规划算法。\n首先我们来看一个经典的动态规划问题:\n给你一个无序的数组，要求我们找出其中最长的递增的子序列:\n\n比如这里的1，2，4就是其中一个:\n\n1，2，3是另外一个答案:\n\n这里我们再对这个问题做一些简化，我们要求这个算法只返回最长序列的”长度”就好了:\n\n也就是3:\n\n如果是你，你会怎么去求解这个问题呢？\n其实最容易想到的办法是暴力枚举，或者叫暴力搜索；比如从1出发，下一个数字可以取5，2，4或者3，因为他们都是递增的:\n\n假如我们第二个数字选5的话，再下一个数字就取不了了，因为剩下的2，4，3都比5小，不能构成一个递增序列:\n那如果第二个数字选2的话，下一个数字可以是4，也可以是3，此时构成的递增序列长度为3:\n\n以此类推，如果第三个数字取4，下一个数字依然不能选，因为3比4小：\n\n算法就这样一直循环往复地执行下去，直到我们把每个子序列都找了个遍：\n并且在遍历过程中，我们实时记录最长的子序列长度，最后可以知道，最长的子序列长度为3:\n\n最后，我们按照同样的方法计算”从5出发”，”从2出发”，”从4出发”，”从3出发”的序列长度，选出最长的那个，算法结束：\n\n那么我们应该如何去实现这个算法呢？\n我们可以定义一个函数L，这个函数会返回从数组第i个数字开始的最长子序列长度：\n\n然后我们检查i后面的所有数字，我们将索引记为j，只要这个数比当前数大(也就是说可以构成递增序列),我们就递归地调用函数自身，去计算从j开始的最长子序列长度:\n\n然后加1得到目前这个序列的总长度:\n\n接着我们只需要遍历所有的j，然后选出最长的子序列长度返回即可:\n\n当然这个递归函数不能永无止境地调用下去，当i取到最后一个数字的时候，由于它后面已经没有其他数字与它构成子序列了\n\n所以我们直接返回长度1:\n接下来我们只需要对数组中的每一个数i依次调用L函数，然后选出长度最长的那个返回即可：\n我们可以带入之前的数据进行测试:\n\n可以看到这个算法成功返回了3:\n\n这个算法虽然能够帮我们算出答案，不过它最大的问题在于时间复杂度，假设数组的长度为n，那就一共存在2^n个子序列，而每一个子序列我们都需要去遍历一次(判断是否是递增序列)\n\n很显然这是一个指数级别的算法，最慢的算法之一，如果我们用长度为100的数组做测试，可以看到程序运行了整整5秒才算出答案：\n\n我这自己重写了一遍半分钟还没出结果：\n\n那有没有可能对算法进行一些优化呢，如果我们观察这个遍历树，会发现里面存在大量的重复计算：\n比如我们在遍历子序列1，2， 4的时候就已经计算过“从4开始的最大子序列的长度”\n\n后面遍历1,4的时候又重复计算了一次\n\n为了避免重复的计算，我们可以在第一次计算的时候将结果保存下来，之后遍历到相同的节点我们就不用再重复计算了\n\n直接将之前的结果返回\n这里我们可以用一个字典(哈希表)memo记录下“从i开始最长的子序列长度”也就是代码中的max_len，然后我们在函数的开头检查之前是否保存过这个答案，如果是，直接返回结果，否则再去计算答案：\n可以看到经过修改的代码，只用了1毫秒就计算出了结果\n\n相比较之前的5秒是巨大的速度提升，动态规划正是通过避免重复节点的计算，来加速整个计算的过程，由于用到了字典(哈希表)来保存了计算的中间结果，因此我们也称之为“记忆化”搜索，这也是大家经常会说动态规划是“空间”换“时间”,当然也有人叫它“带备忘录”的递归或者叫递归树的“剪枝”，它们都是同一个意思，因为我们不需要对这些树子节点进行重复计算了：\n有了递归的算法，我们还可以尝试将它改写成非递归，或者也叫迭代的形式，这样我们可以更加直观地去分析算法的时间复杂度，并且避免了递归时候的函数调用开销：\n从之前的算法我们知道，要计算出从“1”开始的最长子序列长度，我们需要依次检查它后面的所有数\n\n由于1可以和5，2，4，3构成递增序列，所以我们需要递归地计算从5,2,4,3开始的最长子序列长度，然后选出最长的那个，然后加1得到与第一个数构成的最长子序列长度：\n同样的，要计算从“5”出发的最长子序列，我们也需要先检查它后面的数：\n然后进行同样的计算\n这里很显然，因为后面没有数可以与它构成递增序列，所以结果直接是1：\n\n我们这样以此类推下去，直到最后一个数，由于从3出发的子序列之能是它自己，所以长度直接是1:\n\n从这里的公式中可以发现，我们只要从后往前依次计算，就能把所有的答案给推算出来，大家是不是觉得很像数学归纳法：\n\n最后我们根据列出的式子来实现这个迭代算法：这里我们可以通过两个循环，外面的循环代表从下往上的依次计算：\n里面的循环用于遍历括号中的这些数值:\n\n运算的结果我们可以存放在一个数组中，我们直接叫它L：\n接下来只要后面的数比当前数大(能构成递增序列)，我们就按同样的方法来计算这个L(i):\n最后我们返回L数组中最大的那个即可\n\n这个该写的迭代算法同样可以帮我们计算出最终答案，并且由于这里只用了两个循环，每个循环最多执行n次，因此算法的时间复杂度是o(n^2)和之前的指数级别的算法是天壤之别\n最后我们来总结下动态规划的一般思路：\n\n穷举法/暴力搜索\n记忆化搜索/剪枝\n改写成迭代形式\n\n首先，我们可以先简单粗暴地将所有答案穷举出来\n\n并画出递归树\n\n尝试写一个递归函数来求解，如果发现遍历中存在大量的重复计算\n\n我们可以尝试用哈希表将数据缓存下来\n\n之后遍历到相同的节点就直接查表，避免重复的计算\n最后，我们可以将计算的过程表示出来，然后观察公式求解的顺序\n\n并尝试将递归形式改写成更简洁高效的迭代形式:\n如果大家搞懂了之前的内容，不如我们来试试另一个经典的动态规划问题，给你一个数组，要求我们要找出其中连续子序列的最大和:\n\n比如这里的[2, -1, 2, 6]和最大:\n这个问题又如何求解呢\n"},{"title":"0.1+02等于0.3嘛，无可避免的浮点误差","url":"/2022/01/07/0.1+02%E7%AD%89%E4%BA%8E0.3%E5%98%9B%EF%BC%8C%E6%97%A0%E5%8F%AF%E9%81%BF%E5%85%8D%E7%9A%84%E6%B5%AE%E7%82%B9%E8%AF%AF%E5%B7%AE/","content":"在我们印象中，计算机总是能高效准确地进行运算:直到有一天你满怀欣喜地打开最喜欢的编程环境，输入0.1+0.2，但计算机却返回这个:\n你下意识觉得这可能是一个bug，然后在不同语言中反复求证，却一致地得到相同的答案：\n\n究竟是道德的沦丧还是人性的扭曲\n这一切都要从一个盛行了三十多年的标准IEEE-754讲起，IEEE-754定义了浮点数的格式、存储和运算：\n它对浮点数的表示和我们熟知的科学计数法如出一辙\n\n\n\n\n一个浮点数会被分成两部分存储,第一部分尾数(mantissa)也叫做有效数字(signigicand)，也就是下图用红色高亮的部分，第二部分指数(exponent)也就是这里黄色高亮的部分：\n由于尾数和指数分开存储，使得浮点数天生可以表示很大范围的数字，你可以用它表示整个星系的大小，也可以表示微观粒子的半径，并且现代计算机对浮点数做了大量优化，能够在很短时间内进行相当复杂的运算，一个典型的例子就图形渲染，每秒60帧的画面，每帧几百万的像素点同时参与光照计算，大家可以想想这个计算量\n为了了解计算机中的浮点数，我们先来看看十进制世界的我们是如何表示小数的\n首先在整数部分，我们有个位，十位，百位，千位，同样在小数部分我们有1/10,1/100,1/1000等等：\n比如我们写上在个位写0，在小数部分的1/10上写1就可以精确表示0.1，但是计算机使用的是二进制，每一位只能是0或者1，并且逢二进一，因此整数位分别表示有多少个一，多少个二，多少个四多少个八，其实这对应着2的一次方，2的二次方，2的三次方等等，小数部分则表示1/2,1/4,1/8,1/16等等：\n在二进制中，我们可以轻易地表示1/2,1/4或者3/4没有任何问题，但是二进制中没有1/10,求出的答案与1十分接近但却不等于1:\n虽然计算机不总是能精确地表示小数，但在大多数情况下这并不是问题，比如在物理引擎中，我们会用到浮点数来计算物体的坐标，假设误差导致每一帧中物体的位置偏离0.00001，由于这个量实在太小，即便累加一秒，可能还不及一个像素点的长度，用户根本无法察觉，但是另一方面如果银行使用浮点数来表示货币，每存入0.1块钱，由于浮点误差的存在，导致账号中会多累加这么多钱:\n在频繁的交易下，这种误差积少成多对银行来说就是巨大的损失\n\n要解决这个问题，最容易想到的就是用整型来替代浮点数\n\n比如1块钱当作整型数100来存储，这样1分钱就可以准确无误地用数值1来表示，最后我们只需要在显示货币的时候除以一百即可：\n另外现代的编程语言或者数据库中都提供一个特殊的数据类型decimal(十进制定点数),专门用来表示任意精度的十进制数：\n\n用它来进行运算不会产生任何的精度问题\n\n当然在大多数时候，我们依然会用到浮点数，因为浮点数能高效地进行运算，并且节省内存空间，只要我们心里有数，知道程序出现误差可能会导致出现逻辑错误，并且加以防范就好了，比如直接用等号去判断两个浮点数是否相等，这种用操作是很不可靠的，正确的做法应当是去计算这两个数的差别是否小于某个误差范围：\n\n在现代的编程语言中大多都内置了判断浮点数是否相等的工具函数，比如python中的isclose：\n使用他们可以规避很多由浮点误差而导致的程序逻辑错误：\n浮点数的这些奇怪特性可能一开始让很多人摸不着头脑，但在了解之后发现他不过是一个基本的数学概念，科学计数法的二进制版本，仅此而已：\n由于0.1在二进制中是无限循环小数，计算机没有办法精确表示，从而丢失了精度，也就造就了为什么我们输入0.1+0.2但计算机返回的却不是0.3的情况：\n"},{"title":"记一次sourcetree推送代码进度条一直在动可就是推不上去的错误解决方法","url":"/2022/01/07/%E8%AE%B0%E4%B8%80%E6%AC%A1sourcetree%E6%8E%A8%E9%80%81%E4%BB%A3%E7%A0%81%E8%BF%9B%E5%BA%A6%E6%9D%A1%E4%B8%80%E7%9B%B4%E5%9C%A8%E5%8A%A8%E5%8F%AF%E5%B0%B1%E6%98%AF%E6%8E%A8%E4%B8%8D%E4%B8%8A%E5%8E%BB%E7%9A%84%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","content":"今天在某个本地仓库新增了一些数据，然后想着把数据提交一下，然后在使用sourcetree的时候提交进度条在移动然后始终推送不上去，后面在网上查阅资料说可能是安装了git但是没有给surcetree权限:\nhttps://blog.csdn.net/Baron0071/article/details/84062638?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-84062638.pc_agg_new_rank&amp;utm_term=sourcetree%E6%8E%A8%E9%80%81%E4%B8%80%E7%9B%B4%E8%BD%AC&amp;spm=1000.2123.3001.4430\n我照着他的步骤执行了一遍发现我确实是这么配置的但是在我点击确定后就能推送上去了，这可能是soucetree的一个小bug叭\n"},{"title":"Git+Github10分钟完全入门以及Git图形界面GitKraken的基础使用","url":"/2022/01/07/Git+Github10%E5%88%86%E9%92%9F%E5%AE%8C%E5%85%A8%E5%85%A5%E9%97%A8%E4%BB%A5%E5%8F%8AGit%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2GitKraken%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/","content":"大家也许听说过git是一款使用人数众多的分布式版本控制系统，可是到底什么是版本控制系统，git和github又有什么区别和联系呢\n今天，我们来用一个全新的视角来了解这款必备工具，并解密这些被复杂化的概念和生僻术语\n在我们码代码的时候，我们可能经常会有这样的需求，我们可能希望保存源代码的不同版本，当软件出现bug时我们可以回溯到之前的状态，比较版本之间的差别从而找出bug的源头，并且，再多人分工协作的时候，我们也会经常修改到相同的文件，这时候，如果有一个工具能够帮助我们完成修改的合并，也许就可以帮我们节省不少的时间，那么版本控制系统也应运而生:\n如果你只是经常写一些脚本或者简单程序的话，版本控制软件可能用得比较少，但是项目规模一旦大起来，或者涉及到团队协作的时候，版本控制系统可以说是必不可少的，git其实也只是众多版本控制系统中的一种，其它的你可能听过的还包括CVS、Subversion、Mecurial、Perforce、Bazaar等等:\n其实它们都有各自的优缺点，并且应用的领域也稍有不同，git可以说是应用最为广泛，并且最适合于中小项目开发的工具之一，而且版本控制的许多概念其实是互通的，如果你还没接触过相关软件的话，我也非常推荐从git这一款入门，另外git本身其实是一款命令行工具，可能很多人更加推崇使用命令行工具而不是图形化工具，这个我觉得是仁者见仁智者见智，这两个我自己平时也都会用到，命令行更方便于写脚本、自动化，图形化工具的操作通常更直观，入门也更加轻松；当然在这里最重要的还是掌握git以及版本控制系统的核心概念,因此作为入门我推荐的是一个叫做GitKraKen的图形化客户端它支持主流的操作系统，界面很漂亮，功能也很全面，并且对个人的开发是完全免费的，大家可以通过下面的链接在官网上下载对应的版本安装：\n\n第一次使用GitKraKen它会提示你进行登录\n\n这里我推荐大家用自己的GitHbu账号登录，如果还没有GitHub账号的小伙伴现在可以去注册一个，因为早晚都会用到的，登录完成之后呢，他会提示你输入一些个人信息，比如你的用户名称和邮件地址，这个信息和签名档很像，他会附带在你每一次的代码提交上\n\n信息填写完毕之后呢，我们就来到了GitKraKen的主界面，接下来的第一步是创建一个代码仓库(Repository)\n\n仓库这个术语指的是与项目相关的所有文件，包括源代码、工程文件、资源文件和一些配置信息，它可以是本地的仓库，可以是保存在远程服务器上的仓库，仓库之间可以相互同步，比如你可以把本地计算机上的代码同步到远程的服务器上\n\ngithub上就保存了很多远程代码仓库，他也是当今最大的代码托管网站和开源社区\n这里创建代码仓库的时候呢，我们直接一步到位，点击这个按钮创建一个托管在GitHub上的代码仓库\n\n待会儿我们就不用再特别设置用于同步的远程服务器了\n\n这里，我们选择之前登录的GitHub账号，给仓库起一个名字\n\n并附上一个简短的介绍，最后点击下面绿色的按钮完成创建\n\n中间这个很大的区域显示了代码的所有提交历史，其中的每一项代表一个提交(commit)\n\n提交这个术语很像是游戏里面的检查点或者是一个快照，在每一次你对代码做出修改之后，你可以提交这一次的所有修改，此时git会保存当前的代码快照，在之后的若干次修改之后，我们也可以轻松地回溯到这一次修改的状态，可以看到，这里唯一的一个提交是在新建代码仓库时候自动创建的\n\n我们选中这个提交后，可以看到这个提交中修改的所有文件，比如这里可以看到有一个新文件README被创建(这里加号所代表的)\n\n那么接下来，我们新建一个代码文件，并完成一次新的提交，我们可以先点击文件菜单中的“在文件浏览器中打开”\n\n然后找到当前代码仓库在本地计算机上存放的位置，这里我们新创建一个文件并命名为hello.c,然后我们在里面随便写一个helloworld程序，保存文件之后，我们回到GitKraKen中，可以看到中间的“提交历史”中多出了一项WIP，代表这个提交”正在施工中”(working in progress)\n在右边我们可以看到多出来了一个我们刚刚创建的源代码文件，点击它也可以看到文件中被修改的具体内容\n\n接下来，我们来提交这个文件，我们首先点击这里的Stage\n\ngit要求再对修改的文件提交之前必须将它们Stage，你可以把它想象成提交之前的一个必经阶段，防止你误操作，然后你可以在下面输入你对这次代码提交的一个小总结，这个信息是必填的(在sourcetree不是必须的),你想想如果你面对的是大堆”无名的”历史提交，想从中找出你需要的如同是大海捞针\n\n最后点击下面的提交按钮完成这一次提交\n\n到目前为止，我们所有操作都是针对你本地计算机上的代码仓库的，如果我们去浏览GitHub上的远程仓库，可以看到还是处于最原始的状态\n\n如果我们希望将所有的提交都同步到远程的GitHub服务器上，让所有人都能看到你的修改的话，我们需要使用到Git中的Push功能\n\n在GitKraken中我们点工具栏中的Push按钮即可\n\n这里的origin通常指的是默认的远程的服务器，推送之后呢，如果我们再次刷新GitHub上的页面，可以看到所有的代码已经成功上传上去了\n\n如果我们点这里的commits也可以看到和本地一样的所有代码的提交历史\n\n我们既然可以把本地代码提交推送到远程服务器，就一定可以从远程服务器下载新的提交\n接下来我们来讲一下Git中与Push相对应的Pull(拉取)操作\n比如这里我的一个朋友小罗也往远程服务器上推送了一个提交\n\n我们点开后发现他对README.md文件进行了一点小修改\n\n如果我们切换到GitKraken中也可以看到提交历史的最上面多出来了这一条\n\n左边有两个小标签我们需要注意下，这个写有master并画有电脑图标的标签代表本地仓库中的提交，上面这个则是表示GitHub上远程仓库的提交，这里的master是一个分支branch，我们待会儿会讲到，那这个时候如果我们想把这位同学的修改同步到本地仓库的话我们可以点击GitKraken中的pull按钮\n\n之后呢这两个图标会重叠在一起，代表本地仓库和远程仓库的提交历史已经完全一样了\n\n这时候我们也打开本地仓库中的README.txt文件，也可以看到其中修改的内容，那可能有人问，比如当不同的人去修改相同的文件的时候git会怎么做呢，接下来，我们来看一下git中的合并操作(Merge),也是版本控制工具中非常重要的一环，这里在最新的提交中我们看到小罗同学修改了一下hello.c文件，往里面添加了一个函数multiply()\n\n\n接下来我们在本地也去修改同一个文件，将主函数中输出的字符串修改一下\n\n然后按照之前的步骤，在本地提交这一次修改，这里，我们看到提交的历史出现了一个分叉，下面这个显示了远程仓库中小罗同学的提交，上面这个是我刚才创建的本地提交，如果我们希望这两个对hello.c的修改同时应用在你本地的代码仓库中，我们则需要将这两个提交合并起来，合并其实在Git中有很多种方式，我们先讲一种最简单的，就是使用之前提到的Pull功能，git会在获取远程提交的同时将远程的提交合并到本地的提交中，这里我们可以点上面的Pull按钮，可以看到在窗口的最上面，git为我们自动生成了一个新提交，这个提交做的事情就是将之前的两个提交合并起来\n\n这时候如果我们打开hello.c也可以看到这两处的修改已经被git自动合并了\n这时候可能有人问了，如果两个人修改代码的同一处位置，git又会怎么做呢，我们一起来研究一下\n这里小罗同学修改了一下这里的字符串，在前面加了一个“Little”,我们也去修改同一行代码，把这里的“Yoyo”改成“Hey”，然后本地提交这一次修改，可以看到这里的提交又开始出现了分叉\n\n接下来我们来合并他们，按照之前的做法，我们可以之间点击Pull，不过这次git的自动合并失败了\n\n取而代之的是一个错误信息，告诉我们这里有冲突(conflict)需要我们手动解决，原因很简单，git也不知道应该如何合并了，毕竟我们修改的是同一行代码，我们可以点右边的冲突文件下的这个hello.c文件，左边窗口显示的是我们刚刚的修改，右边显示的是远程仓库上小罗的修改(还记得我们之前说的origin通常代表远程仓库嘛)，下面的这个窗口代表合并之后的结果，是我们手动解决冲突用的\n\n那我们看了代码当然明白，应该该将Yoyo改成Hey，并在后面加一个Little\n修改完成之后我们保存文件回到之前的窗口和之前一样描述一下这次合并的内容并完成这一次提交\n\n软件中对应的命令行指令:\n\n"},{"title":"10个Python编程技巧 让你的代码更上一层楼","url":"/2022/01/08/10%E4%B8%AAPython%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7%20%E8%AE%A9%E4%BD%A0%E7%9A%84%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%B8%8A%E4%B8%80%E5%B1%82%E6%A5%BC/","content":"Python可以说是近十年来增长速度最快、应用最广泛，并且是世界范围内最受欢迎的编程语言之一，今天，我来给大家讲10个我个人觉得非常实用，但可能并不是所有人都知道的Python编程技巧，保持这些良好的编程习惯，可以让我们写出更清晰、更优雅、更易读、更赏心悦目的代码\nPython语言其实在设计之初就有在考虑它语法的简洁性和可读性，可能有人听说过Python之禅(Zen of Python)这其实是Tim Peters在Python中留下的一个彩蛋，如果你进入Python，然后输入import this，你会看到作者留下的一条条编程建议:\n\n其中列出的这20条规制，就是在告诉你Python程序编写的指导方针，另外，大家如果听说过Pythonic这个词，它其实是用Python加上后缀ic创造出来的一个英语单词，它指的也是具有Python独特风格、简介而优雅的代码，最后甚至在Python语言的提案PEP8中也定义了一条条让代码更清晰、更简洁的代码规范，这里我筛选出了10个重要的技巧，接下来我们就用实例来一一讲解下叭:\n\n变量交换\n在很多编程语言中，如果我们需要交换变量a和b中的内容，通常我们可以定义一个临时变量，先将a的内容存放在其中，然后将a设置为b，再将b设置成这个临时变量:\n不过，上面这段代码在Python中其实可以被改成这样:\n\n这样的话，程序的可读性是不是提高了很多呢\n\n字符串格式化(String Formatting)\n通常在程序中我们需要组合或者拼接字符串的话，我们可以用加号来做字符串的连接:\n如果只是做两个字符串的拼接，这样写其实没有什么问题，不过如果字符串比较多的话，类似于这种情况:\n\n这样的程序会显得非常杂乱并且不易阅读，而且，当我们在连接整形数据的时候还需要进行类型的转换，不然程序也会报错:\n其实我们可以把程序写成这个样子:\n\n利用Python中的百分号语法来格式化字符串，其中%s代表这里的内容会被替换成一个字符串，这里的s是string的首字母，这里的%d会被替换成一个十进制数，d是decimal的缩写，最后面这个%()中定义了需要被替换的内容，虽然程序写成这样已经好看很多了，我们在这里还可以做的更好一些，我们可以利用Python中的format()函数和花括号语法，把程序写成这样:\n\nformat()在这里是字符串对象的一个方法，调用它会返回被格式化后的新字符串，而花括号中的内容会被最终替换成format()函数中传入的各个参数\n使用这种方式的另一个好处是，如果你有重复的需要被替换的内容，你可以在花括号中写入被替换参数的索引，就像这样:\n因此这里的两个花括号都会被替换成同一个内容，也就是这里索引为0的第一个参数name，最后如果你使用的是Python3.6以上的版本，这里有一个最简单的写法:\n也是我最喜欢的，叫做f-string，我们只需要在字符串开头写一个f，花括号中的内容就会被自动替换成指定表达式的值，注意，这里我说的是表达式，比如我们可以把这里的age改成age+1,Python将会把表达式运行的结果也就是29替换在字符串中，由于这里可以填写任意的表达式，所以你甚至可以调用一个函数返回一个数值，并替换在字符串中，这也是没有问题的\n\nPython中的yield语法\n比如在这里，我们定义了一个函数fibonacci()，来列举斐波那契数列中的前n个数\n\n斐波那契数列大家应该都听说过，简而言之，就是除了最前面两个数之外，其中每个数字都是前两个数字之和，比如这里的5是前面2跟3的和:\n这个程序里面有两个变量:a和b，他们分别代表前一个数和当前的数，这里的循环会执行n次，而每次循环，程序都会把之前的数存放在一个叫做nums的列表中，然后之前的数会被替换成当前这个数，当前这个数会被替换成前两个数之和，然后程序就会循环往复地执行下去，直到计算出第n个数为止，此时，如果我们使用print()在屏幕上显示这10个数，我们会得到这样的结果:\n\n\n在这里，我们可以修改这个fibonacci()函数来使用Python的yield语法\n我们首先把“list末尾添加元素”的操作替换成yield a\n\n然后删掉这里的nums列表，这样修改后的程序会完成和之前一样的操作:\n这里的yield表示每当我们计算出一个元素，就立马把这个元素给送出去，也就是说外面的for loop中就会立即输出这个数，因此使用yield的好处是，我们并不需要等待整个列表都生成完毕后再来一个一个地输出，yield在英文中的意思是产出，单从字面上来看还是比较抽象的，不过它和return的区别是，当你的函数yield一个数值以后，函数并不会立即停止，而会继续执行下去，yield的优势在于一些非常耗时的操作，比如我们可以写一个函数来从网络上下载一系列文档，并输入每个文档的内容，如果我们使用yield，则可以保证在一个文被下载成功后，就立马输出它的内容，而无需等待所有文档都下载完毕\n\n列表解析式(List Comprehension)\n比如在这里我们有一系列水果的名字\n\n存放在一个叫fruit的列表中，如果我们希望把这些名字都改为大写，这里有很多种办法，比如写一个for loop遍历所有名字，并把他们改写成大写\n\n其实这里有一个更为简单的语法，之前的代码可以直接被改写成这样\n\n后面这个方括号语法实际上是在构造一个新的列表，并把它赋值给之前的这个fruit变量，我们可以这样来理解这个语法，方括号的后半部分实际上是在告诉Python我需要枚举fruit变量中的所有元素，而其中的每一个元素的名字叫做x，而方括号里的前半部分x.upper()则是将这里的每个字符串x转换成大写，列表解析式其实还有另外一种应用，筛选或者过滤列表中的元素，比如，如果我们希望挑选出列表里以a开头的水果，那么一种常见的方法是写一个循环，然后挑选出需要的元素存放在一个新列表中，其实利用我们之前讲到的列表解析式，我们可以将程序改写成这样\n\n\nPython中关于循环的技巧:Enumerate()函数\n还是使用之前的例子，如果我们需要按顺序输出某一个列表中的所有元素，我们可以使用for…in的语法，如果我们希望同时得到每一个水果在列表中对应的索引值，比如apple的索引是0，pear是1，我们可以使用一个叫做enumerate()的函数，把程序改成这样\n\n这里的enumerate()函数会在每一次循环的过程中提供两个参数。第一个i代表列表元素的索引值，第二个x代表元素中的内容\n\n反向遍历\n这个其实是对上一个技巧的延伸，如果我们希望将fruit中的元素后往前依次输出，那么我们应该怎么做呢，其实我们只需要在遍历元素的时候加入reversed()函数就搞定了\n\n\n按顺序遍历\n这里我们再延伸一下，如果我们希望输出的元素是按照水果名字的字典顺序，也就是说名字以a开头的排在最前面，以z开头的排在最后面，应该怎么办呢，这里我们可以使用到Python中的一个内建函数sorted()，将fruit用这个函数括起来就好了，sorted()函数会返回一个新的并经过排序后的列表，因此我们在使用循环输出时，内容就已经被事先排序好了\n\n\n字典的合并操作\n比如在这里我们有两个字典，其中存放不同用户的用户名和密码\n\n这时候，我们可以写这么一个程序将这两个字典合并成一个字典，也就是这里的c\n\n不过我们可以将这里的5行代码，改成更加简洁的形式\n他们都会执行完全一样的操作，这里的这两个*在Python中叫做解包(unpacking)，也就是说这里的**a和**b相当于是将字典a和b中的内容直接填写到了这里\n\nPython中的三元运算符\n在Python程序中，我们经常会完成这么一项操作:\n\n将一个变量设置成不同的值，比如在这个例子中，我们会根据score里面存储的数值是否大于60，来决定s里面的内容是pass还是fail，其实这里的代码可以直接被改成这样\n\n这里的if…else称为Python中的三元运算符，当if后面的条件满足时，表达式会输出前面的这个值，当条件不满足时，表达式会输出后面这个值，它的功能等价于c或者java中的三元运算符，尽管它们的写法完全不一样\n\n\nPython中序列的解包\n比如我们在这里，我们定义了一个变量name，里面存储了张三同学的姓和名\n\n如果我们想单独提取出它的姓和名，并把它们存放在不同的变量里，我们可以利用字符串对象中的split()方法，把这个字符串按空格分割成多个字符串，然后我们再利用列表的索引提取出对应的姓和名\n\n不过这段程序可以被我们改成这个样子:\n\n这里，我们直接将split()函数返回的列表中的元素赋值给first_name和last_name,中间以逗号的形式隔开，这个操作在Python中被称作序列解包，需要注意的是，这里的”序列”其实并不一定需要是列表，它也可以是元组，甚至是range，因为它们都代表一系列元素，也就是序列\n\nPython中的with语句\n在Python中，如果我们想读取某一个文件的内容，我们可以使用open()函数打开一个文件，并利用返回的这个文件对象f来对文件进行操作\n\n不过，当我们完成对文件的读取，不在需要这个对象之后，一定不要忘记调用close()方法来关闭这个文件，如果你忘记关闭这个文件，Python将一直占用这个文件的系统资源，直到你的程序完全退出为止，对于一个小脚本来说，这不是什么大事，但是对于一个需要长时间在服务器里运行的程序，你的系统资源可能很快就被吃光，然后你的程序就会崩溃，所以一个好的习惯是使用Python的with语句，将程序改写成这种形式\n\n这样写的话，就不需要手动的调用close()函数了，当with语句之后的代码执行完毕之后，这个文件就会自动被Python关闭\n\n\n"},{"title":"2021 Web开发完全指南","url":"/2022/01/10/2021%20Web%E5%BC%80%E5%8F%91%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/","content":"过去的10年可以说是web技术变革最大，更新迭代最快的10年，如今的web已经不单单是信息展示的渠道，更是各种功能复杂应用的集合，这是一张2021年的web开发路线图\n\n可以看到其中囊括的知识点非常细碎和繁杂，可能也让许多刚接触web开发的小伙伴一头雾水，这里呢，我会从整体的角度出发，用实例向大家解释现代web开发中的各种概念以及它们的最佳学习路线\n那么首先web是如何运作的呢，简单来说，当我们在浏览器中输入网址的时候，浏览器会通过一系列网络操作找到我们要访问的服务器\n\n并向这个服务器发起一个http请求\n\n服务器在收到请求后，会根据请求的类型，将对应的文档返回给浏览器，浏览器会渲染该页面并最终显示在屏幕上，这个页面其实是一个HTML格式的文档\n\n大家可以通过”!”在vscode中快速创建一个HTML文档\n\nHTML文档通常由许多潜逃的标签组成，这些标签决定了我们页面的基本结构，通常一个页面会由头部标签&lt;head&gt;内容标签&lt;body&gt;构成，在````body```下面又可以放置标题、段落、列表、图片、表格、表单等等，你浏览器所做的事情就是去渲染这份HTML文档，并显示在你的电脑屏幕上，现如今，大家看到的绝大多数页面都使用的是HTML5的格式，它除了更加清晰的语法，以及良好的浏览器兼容性之外，还提供原生的音视频格式支持\n\n这也是flash能够逐渐淡出我们视线的原因，当然还有Canvas，WebGL这些图形API的支持，通过它们我们甚至可以在浏览器实现一款画质精良的三维游戏\n\n如果说HTML定义了文档的结构和内容，那css则是用来为页面添加不同的样式风格，也正是它名字“样式表的由来”，为页面添加样式有许多种方法，最简单的我们可以通过在HTML头部加入&lt;style&gt;标签，随后我们可以使用css的选择器(selector)来指定需要修改样式的元素，也就是这里我指定的button对象，后面花括号的每一行允许我们指定边距、边框、字体，背景颜色等等，通过组合css提供的各项属性，我们可以制作出非常漂亮的界面\n\n当然在实际使用中，我们也可以选择现成的css框架帮我们制作专业的跨平台用户界面，除了最广为人知的bootstrap，它可以用来快速实现对移动端友好的响应式布局，你也可以使用Materialize来实现统一的Material界面风格，如果你喜欢轻量级的框架，你还可以尝试只有4KB不到的Pure.css等等，除此之外，css还提供原生的补间动画支持，我们可以利用css的animation属性来定义动画的种类和时长，并利用@keyframes[动画名]{}定义动画中用到的所有关键帧\n\n\n另外值得一提的是css3中加入的新布局方式–FlexBox\n\n使用它可以轻易的实现传统css中很难实现的这些布局效果\n\n比如像导航栏，表单，大小不一的卡片等等\n\n如果说HTML和CSS决定了页面的外观，那JavaScript则允许我们给网页加入动态的行为，比如我们可以通过JavaScript来修改页面的内容，也就是我们平时所得DOM树操作\n或者使用JavaScript对鼠标键盘时间做出相应，JavaScript也可以用于请求远程服务器的数据，也就是我们经常听到的XHR/AJAX技术，它可以根据需要想服务器请求数据，并用来更新页面的部分内容\n\n通过JavaScript，我们甚至可以通过websocket或者webRTC来替代HTTP请求，他们可以用于实现更低延迟的网络通信，比如用作即时聊天，在线游戏等等，由于WdbGL的存在，我们还可以用JavaScript做三维的实时图像渲染，甚至用于在浏览器中训练深度神经网络，现在被主流浏览器支持的JavaScript版本是ES6，里面包含了类\n\n箭头表达式\n\nPromise\n\n模板字符串\n\n变量的解构赋值\n\n新的遍历语法\n\n新的导入导出语法等等，这些都是应当掌握的并且在实际开发中被广泛用到的新特性，另一个与JavaScript相关，虽然不一定马上用到，但是非常值得去了解的是TypeScript，简单来说它为JavaScript中的每一个对象加入了可选的类型标注，是JavaScript语言的一个超集\n\n这样做的好处是能够在编译时做到类型的检查，提前捕捉程序错误\n\n当然这些类型标记也同样给你的IDE提供了额外的类型信息，帮助它完成更好的代码提示和自动补全功能\n\n既然说到JavaScript，我们就不得不提到Node，Node是一个脱离浏览器运行的JavaScript运行时，它使用与Chrome完全一样的v8引擎，性能是相当地不错，你可以使用Node编写控制台程序，原生的桌面应用，服务器程序等等\n\n另外node自带一个包管理器–npm，类似于Python的pip，你可以用它来安装数不胜数的第三方库，这也是Node大获成功的重要原因之一，待会儿我们讲到的React就需要npm来安装，\n按照如今web发展的大趋势，与用户交互的逻辑都逐渐从后端向前端迁移，前端的逻辑通常都非常复杂，为了减轻前端开发的负担，我们往往会选择使用现成的前端界面框架，现在流行的前端界面框架基本是这三种:React、Angular和Vue，这三个框架都会将界面元素组件化，从而提高代码复用，我这里用React来做一个简单的示范\nReact允许我们通过函数式编程的方式来渲染用户界面，这里函数的输入是我们要显示的数据，他们被称为“属性”，或者“状态”\n\n函数的输出则是渲染之后的HTML标签，这样做的好处是渲染的结果会由输入的这些数据唯一决定\n\n也就是大家常说的“单向数据流”模式\n\n这种模式从源头上避免了组件之间数据的复杂传递，因此也更易于调试\n说完了前端，我们来看看后端开发\n也就是服务器的部分，后端其实有相当多的语言和框架可供我们选择，我这里以JavaScript以及Express.js为例来介绍一下后端服务器的部分，因为最近这几年在Web开发中有一个逐渐流行的技术栈–MERN，它代表数据库使用的MongoDB服务端的运行环境Node.js\n前端使用的React，以及后端的服务器框架Express.js\n\n这个技术栈的特点在于它所有的组件全都是使用JavaScript编写的，因此大大降低了开发和维护的成本，后端服务器做的主要事情是响应前端的请求，并向前端提供数据，现代的web应用通常都会通过API的方式与后端进行通信\n\nAPI简单来说就是预先商定好的通信协议或者数据格式，比如这里的这个/aip/zodiac用于返回当前的年份和生肖\n\n如果你在浏览器中手动访问这个地址，服务器会将数据以json格式返回\n\n通过API我们可以实现前后端逻辑的分离\n\n并且如果你的应用同时有安卓，ios客户端的话，也可以复用相同的API\n说到API，我们就不得不提到经典的REST风格的API，简单来说，他会根据不同的HTTP请求类型，来对数据做对应的增删改查操作，这里的jsonplaceholder是一个用于演示的REST API，接下来我们以它为例来快速了解下REST API的基本用法\n\n比如这里我们以GET方法去访问/todos这个地址\n\n服务器会将所有的“待办事项”以json格式返回\n并且我们可以通过在地址后面加上/10指明只需要返回第十条数据\n\n或者像这样传入额外的参数\n\n筛选出userid=5的所有数据，如果我们想添加一条新数据，我们可以使用POST方法去请求同一个地址，并将要添加的数据以json格式发送给服务器\n\n服务器在成功添加数据之后，会将新添加的数据直接返回给浏览器\n\n如果我们要更新某条数据，我们可以使用PATCH方法\n\n同样的如果要删除数据，我们可以使用DELETE方法\n\n顺便值得一提的是这几年逐渐流行的另一种API架构–GraphQL\n\nGraphQL允许使用一种相当灵活的查询语言，来精确获取你需要的数据\n\n它的灵活性和可扩展性会比REST API高出很多，正因为如此，GraphQL非常适合大型项目的API设计，当然如果你的项目只需要简单固定的API，GraphQL就显得有些大材小用了\n接下来我们来了解下数据库管理系统\n如果你的web应用需要对大规模数据进行并发的读取和修改，同时还要兼顾到数据的完整性和安全性，数据库将会是必不可少的一部分，现在的数据库系统大致可以分为两类，SQL和NoSQL类型的数据库\n\nSQL指的是传统的关系型数据库\n\n它使用结构化查询语言(SQL)对数据进行查询和修改\n\n关系型数据库对数据有相当严格的一致性和完整性检查，至今快50年的历史也足以证明它是相当可靠的\n相反，NoSQL的数据库减少了许多的强制检查，通常具有更优的读写性能，并且对数据的格式要求也更加松散，更能够适应日益变化的需求\n\n作为SQL和NoSQL的入门，我非常推荐使用PostgreSQL或者MongoDB，这两个数据库都是开源免费的，并且有相当数量的用户群，这里我以MongoDB为例来介绍下JavaScript中数据库的基本使用，我们可以使用一个叫做mongoose的包对mongoDB进行访问，在使用数据库之前，我们需要先定义数据的结构(Schema)\n\n比如这里的联系人Contact由姓名电话和一些其他信息组成，可以看到name是字符串，并且是必须填写的字段，cteateDate是一个日期对象，它会被自动设置成数据创建时的时间，在定义了数据的结构之后，我们可以利用之前讲到的REST API在POST请求时，我们可以使用new Contact创建一个新的联系人\n\n并使用save方法将数据保存至数据库，最后将新添加的Contact对象以json格式返回\n此时如果我们访问这个REST API，当数据被成功保存之后，可以看到这里返回的新联系人id以及它的创建时间\n\n最后在web开发中还有非常重要的一环，通常我们会听到这么一个词DevOps，它是“开发”和“运维”这两个词的组合\n\n它所解决的问题是如何将你写的web应用部署运行到最终的服务器上并让所有人访问，不过DevOps会通过各种自动化手段让整个部署流程更省事和可靠\n在最后，我想向大家推荐几个web的学习资源，它们都是GitHub上超高星标的仓库\n\nWeb开发路线图：https://github.com/ccloli/developer-roadmap-zh-CN\n现代Web开发魔法全书：https://github.com/dexteryy/spellbook-of-modern-webdev\n成为Web全栈工程师：https://github.com/bmorelli25/Become-A-Full-Stack-Web-Developer\nAwesome列表系列：https://github.com/sindresorhus/awesome\n\n"},{"title":"从0制作树莓派机器人","url":"/2022/01/11/%E4%BB%8E0%E5%88%B6%E4%BD%9C%E6%A0%91%E8%8E%93%E6%B4%BE%E6%9C%BA%E5%99%A8%E4%BA%BA/","content":"大家一定都听说过树莓派，Arduino，单片机，卡片电脑，嵌入式之类的术语\n\n这些到底有什么区别呢，并且我们可以用它们能做出哪些有趣的东西呢，今天我来带大家从零制作一个可以远程控制的树莓派机器人\n\n你可以通过手机远程访问，并实时监测家里的安全，当然除此之外，我们也可以用它来做一些有意识的应用，比如你可以把它当做一个可以人脸追踪的摄像头\n\n在你和亲朋好友的视频聊天中让机器人自动跟随你的视角，让你成为通话的焦点\n树莓派其实是一款单板电脑\n\n它使用的是博通ARM架构的64位处理器，和大家平时使用的智能手机芯片同属于一种架构，上面集成了可以用作图像渲染的GPU，1-4不等的LPDDR(Low Power DDR)内存，以及USB、HDMI、以太网接口等等，它可以运行包括Linux，甚至WIndows在内的多个操作系统，其实完全可以当做一台低配置电脑来使用，这里顺便提一下，经常拿来和树莓派作比较的Arduino其实是一款单板的微处理器，它的用途和功能相比树莓派来说要简单和纯粹许多，Arduino板搭载的基本是Atmel的8位微处理器，主频在16MHZ，速度还远不及树莓派的百分之一，不过这恰恰是Arduino的优点，造价便宜，耗电量低，由于没有操作系统的束缚，也非常适合拿来做一些实性很高的应用，大家如果玩过无人机，应该听说过这款著名的开源飞控(飞行控制器)APM，它就是基于Arduino开发的\n另外我们经常听到的一个术语是单片机，单片机又被称作微控制器，或者MCU(Microcontaoller Unit)它是将处理器，存储器，内存还有各种io端口都集成在芯片内部的电路上，严格意义上Arduino不能被称作是单片机，不过上面搭载的Ateml微控制器是单片机，树莓派上的博通芯片也不能称作单片机，因为他的复杂程度已经远远超过单片机的范畴，相反它被称作“”芯片上系统“，又叫做SOC(System on Chip),这里我使用树莓派作为主控板的主要原因是因为它开发效率高，工具库全，对新手也非常友好\n\n你想想几乎整个Linux生态的软件、工具库都可以拿来使用，它可以做的事情实在是太多了\n接下来我们来看一看机器人上其他硬件的组成\n电机驱动模块\n大家都知道，微处理器上的IO端口通常只能提供非常有限的电流，以树莓派为例，单个GPIO端口只能提供16mA的最大电流，这个电流用来驱动一个发光二极管(LED)绰绰有余，但直流电机的额定电流通常都比它高出一到两个数量级，直接用IO端口驱动电机是根本不可能实现的，且不谈电机换向的问题，这也为什么我们需要使用外部电路来驱动电机的原因，电机的驱动模块有很多种，比如大家经常听到的价格也很便宜的H桥电机驱动芯片L293D\n\n我这里使用的是类似的另一种，导通电阻很低，效率远超L293D的驱动芯片TB6612FNG，\n\n\n主要还是考虑到省电的原因，大家在选择驱动电路时，一定要结合自己的需要，比如你需要同时驱动多少个电机，最大电压和电流是多少，以及芯片待机时的功耗是多少等等，价格最贵的不一定是最合适的\n机器人的电池\n我使用的电池是从旧的移动电源里拆解下来的锂电池，这里的锂电池又叫做聚合物锂离子电池，锂电池的优点有很多: 循环寿命长、重量轻、容量大、并且能量密度高，这也是数码设备无一例外使用锂电池的原因，这里需要注意的是，我们并不能直接将锂电池连接到树莓派和电机驱动电路上\n\n因为锂电池的标称电压是3.7V，而电机驱动电路和树莓派都工作在5V上下，直接连接是不能够驱动设备的，当然这里还有一个原因是，锂电池都非常脆弱，过充和过放都会导致电池的永久损伤甚至是爆炸，因此，锂电池的使用必须搭配额外的保护电路，这里我使用的是一款带开关，支持microUSB充电的锂电池保护电路，它同时支持向两个USB接口输出2.5A的最大电流，刚好符合我们的要求，通常这类保护电路是为移动电源提供的，它们的功能比较单一，价格也很便宜，所以可以很轻松地在网上购买到\n机器人的运动系统\n机器人的运动系统可以分为很多种，有轮式的，履带式的，关节式的，还有仿生机器人式的，我这里使用的是双轮差速的驱动方式，也是在消费领域应用最广泛的，例如，家里的扫地机器人就是这种方式驱动的，它有两个显著的有点:机械构造简单，并且支持原地的旋转\n电机\n电机的部分，我使用的是型号为N20的直流减速电机，减速电机其实就是在普通电机的基础上，加上了齿轮减速箱，在功率恒定的情况下，虽然降低了电机的转速，但是可以提供了较大的力矩，由于我们的机器人使用的都是小功率的配件，并且安装上电池后会有一定的重量，在这种情况下，使用减速电机是非常适合的\n摄像头\n摄像头我使用的是带红外的USB摄像头\n\n这样在弱光或是夜间也可以正常使用，我们在使用USB摄像头的时候只需要看摄像头是否支持UVC(USB Video Class)协议即可，现在市面上已经很少见到不使用UVC协议的摄像头了，所以家里面闲置的摄像头，通常也可以直接拿来在树莓派上使用，当然在树莓派上也可以使用MIPI/CSI接口的摄像头模块\n\n这个接口在移动设备上会被广泛用到\n主要因为它支持更高带宽，更高分辨率图像的传输\n\n操作系统的安装\n首先，必须要准备一张空白的SD卡，当然读写速度越快越好\n\n然后去树莓派官网下载叫做Respbery Pi OS(Lite)的操作系统\n\n这个操作系统是基于Debian的，Debian是使用人数最多的Linux发行版之一，比如大家经常听到的Ubuntu就是基于Debian的，然后我们可以根据官网上提供的步骤，另外再下载一个Raspberry Pi Imager的工具，然后将下载的操作系统映像写入SD卡\n\n写入完毕之后呢，我们只需要将SD卡放回树莓派，接上USB电源启动即可\n\n你可以通过使用外接USB键盘和显示器的方式来使用树莓派，不过这样比较麻烦，因为你还得专门准备一个显示器和键盘，这里我是使用远程操作的方式来使用树莓派的，先让树莓派连接上家里的WiFi，然后用ssh来访问树莓派，ssh(secure shell)在Linux上是一个经常被用到的工具，它是用来和远程服务器通行的一种加密传输协议，在这里呢，我们会利用它从你的PC，Mac或者Linux系统里远程操作你的树莓派\n\n启用ssh的方式其实很简单，在操作系统被写入SD卡之后，先不要着急取下SD卡，我们可以在计算机上找到这个叫做boot的分区\n\n然后新建一个空文件\n\n并命名为ssh就好了，配置WiFi信息的方法也很类似，我们同样在这个分区里面创建一个wpa_supplicant.conf文件，然后把下面这段文字粘贴进去\n\n未完待续，参考自:https://www.bilibili.com/video/BV14g4y1q7yf?spm_id_from=333.999.0.0\n"},{"title":"一个10分钟的numpy入门教程","url":"/2022/01/11/%E4%B8%80%E4%B8%AA10%E5%88%86%E9%92%9F%E7%9A%84numpy%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","content":"如果你打算在Python中做数据分析、科学运算、数据处理，那你多少会用到numpy这个库，当然你肯定还听过pandas、scipy、PIL、amtplolib等等\n\n这些都是科学运算中非常常用的库，不过这些不是我们现在讲的重点，下面我们来看看numpy\nnumpy为我们提供了一个特殊的数组对象\n我们可以用它表示普通的一维数组\n\n或者二维的矩阵，或者任意维的数据\n并且它可以对数组中的数据进行非常高效的运算\n\n比如用作数据统计，图像处理，线性代数，傅里叶变换等等，我们都知道，Python是一个很慢很慢的语言，而numpy之所以能运行这么快的原因，是因为它底层是用C语言实现的目标代码，当然对于任何想要运算的数据，我们也需要预先将它们表示成numpy数组的形式，也就是所谓的向量化，当然如果你希望将运算速度再提升一个数量级，你甚至可以使用你的GPU来对这些数据做并行运算，那么接下来我们就用实例来讲解下numpy的基本使用叭\nnumpy中所有的计算都是围绕着数组进行的，因此在运算之前，我们需要将计算的数据表示成数组的形式，我们首先需要导入numpy这个库\n\n并起一个别名np，然后我们可以用np.array()来创建一个数组\n\n括号中是数组的初始化数据，当然我们也可以使用np.zeros()创建一个全零的数组\n\n这里传入的参数是数组的尺寸，(3, 2)代表一个三行二列的数组，在numpy中，数组可以是一维、二维、甚至是更高维度的\n\n二维数组可以用于存放矩阵或者表格数据，多维数组通常用来表示更加复杂的数据\n在numpy中，我们会用到shage来获取数组的尺寸，比如这里的3，是数组第一维的尺寸，我们可以理解为行数，2是数组的第二维的尺寸，我们可以理解为列的个数\n\n类似的，我们可以使用np.ones()创建一个全部是1的数组\n\n另外我们可以使用np.arange()创建一个递增或递减的数列\n\n类似于Python的range\nnp.linspace()会返回介于某个区间等间距分布的数\n\n前面两个是区间范围，第三个参数是输出样本的总数\n另外我们还可以通过np.random.rand(2, 4)生成一个随机的数组，\n\n在numpy中，数组默认的数据类型是64位的浮点数，不过我们可以在创建数组时，通过dtype指定其他的数据类型\n\n对于现有的数组，我们也可以通过satype()来转换数据类型\n\n在numpy中我们可以轻松地对数组进行常见的数学运算\n两个相同尺寸的数组可以直接进行四则运算\n\n他会将数组同位置的元素进行加减乘除\n在乘法运算中还有一个np.dot()，他会对两个向量进行点乘运算\n另一个 与乘法相关的是@符号，它会进行矩阵的乘法运算，等同于np.matmul()函数，而不是将相对应的元素直接相乘\n\n我们还可以使用np.sqrt对所有数依次求平方根\n\n使用np.sin()，np.cos()进行三角函数运算\n\n或者np.log()，log.power()进行对数和指数运算等等\n\n当然你也可以将一个numpy数组与单独的一个数做运算\n\nnumpy会分别计算各个元素与这个数的乘积，产生一个同尺寸的新数组，这个操作在numpy里面被称作广播\n比较有意思的是，不同尺寸的数组也可以直接做运算\n\n在运算之前，numpy会将这两个数组扩展至相同的尺寸，然后再将相同位置的元素相加\n\n另外，我们还可以通过min()或者max(),返回数组中最小或者最大的元素\n\nargmin()和argmax()会返回最小或者最大元素所在的索引\n\nsum会返回所有数据的总和\n\nmean()，median()会返回数据的平均值，中位数\n\nvar()和std()会返回数据的方差和标准方差\n\n对于以上提到的函数，如果你的数组是多维数组，你还可以指定一个额外的参数axis，当axis等于0时，它会将每一行中对应的数据相加，axis=0代表第一个维度，也就是行\n\n以此类推axis=1则代表第二个维度，也就是列\n\n如果你想要获取数组中的元素，你可以使用与Python list非常相似的语法，比如你要获取第1行第2列的元素，你可以使用下表0和1，中间以逗号分隔\n\n另外，我们还可以通过条件筛选出指定的元素，比如在方括号中输入a&lt;3则会返回所有小于3的元素\n\n我们还可以通过逻辑运算符组合不同的条件，比如下面这个例子将筛选出大于3并且是偶数的数\n\n这里需要注意的是，“与”运算需要用&amp;符号来表示，“或”运算则需要用竖线表示\n如果你要获取的第一行，但是1-2列的数据，你可以使用0:2这种切片的语法，这个和Python的列表是一样的\n\n如果你要获取第一行，但是所有列的元素，你可以单写一个冒号，然后将冒号前后的范围省略掉，当然你也可以直接把整个冒号给省略掉\n\n另外我们可以在冒号的后面再加一个冒号，第二个冒号后面可以跟一个跨度，也就是步长\n\n\n比较有意思的是，这个跨度还可以取负值，我们可以通过复苏的跨度，从右往左逆向返回这个数组，比如在numpy中会经常看到::-1的写法，其实它做的事情就是将数组翻转一下而已\n\n当然说了这么多，光看一堆数字确实也不够直观，不如我们来看一下numpy的一个典型应用图片处理，通常我们可以把一张灰度图看作是一个二维的数组， 数组中的每个元素用来表示像素点的亮度值\n\n\n对于彩色的图片，我们可以用三维数组来表示\n\n数组中的第三维分别存储了像素点的红绿蓝分量\n我们可以使用pillow这个库来读取图片文件\n\n随后我们可以通过np.array(im)将图片转换成一个numpy数组\n可以看到这个图片一共960行，1280列，并且有红绿蓝3个颜色分量，我们可以通过下表来访问某个像素点的颜色\n\n也可以通过这种方式单独提取出所有像素点的红色分量\n\n然后图片就成了这样\n\n我们也可以通过这样的方式将两张图按比例混合在一起，这里需要注意的是，运算的结果是浮点数，为了显示图片，我们需要将图片转换成整型数\n另外我们可以利用之前讲到的跨度来对图片进行降采样，如果我们想要翻转图片，我们可以选跨度-1\n\n这由于我们指定的是第一个维度，因此图片会上下翻转\n\n如果我们想要裁剪图片的某一部分，我们可以利用之前讲到的切片\n\n\n\n"},{"title":"计算机操作系统基础笔记","url":"/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0/","content":"此内容参考自今日头条:https://www.toutiao.com/a7051472133389713933/?log_from=f0ef8adb57f57_1641951133601\n"},{"title":"免费的内网穿透工具推荐(win)","url":"/2022/01/12/%E5%85%8D%E8%B4%B9%E7%9A%84%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90(win)/","content":"此内容参考自今日头条:https://www.toutiao.com/a7028937143393206815/?log_from=27e046c60a8e6_1641951433723\n"},{"title":"TCP/IP网络通信之Socket编程入门","url":"/2022/01/11/TCPIP%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E4%B9%8BSocket%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/","content":"大家好，在这里我会为大家讲解socket的基本工作原理，并用它来实现一个简单的服务器，客户端通信\nsocket是一套用于不同主机间通信的API，它工作在我们的TCP/IP协议栈上，它的应用无处不在，比如你的手机应用、用于服务器管理的ssh客户端\n\n全都是基于socket实现的，要通过socket与不同主机建立通信，我们只需要指定主机的IP地址和一个端口号\n\n显而易见，IP地址用于唯一标识你的网络设备，那我们为甚需要额外指定一个端口号呢\n如果没有端口号，操作系统则没有办法区分数据到底应该发送到哪一个应用上\n\n因此端口主要用于区分主机上的不同应用\n通过socket我们可以建立一条用于不同主机，不同应用之间的虚拟数据通道\n\n并且它是点对点(应用对应用)的\n一个形象的比喻是将一条数据线连接在不同应用的插槽上，这也是socket这个名字的由来\n\n这里不得不吐槽下socket的中文翻译”套接字”到底是什么鬼\n我们经常用到的socket有两种类型，名字你们一定听过，TCP和UDP，TCP是我们今天要讲的重点，它主要有两个特点，首先TCP协议是可靠的，它的底层会自动检测并回传丢失的数据包，因此对调用者来说，你发送的数据，对方一定会接收到\n\n其次，发送和接受到的数据顺序是完全一样的\n\n比如你发送了一串字符，对方就一定会原封不动地收到同一份字符串，这也是为什么大家说TCP是基于“数据流”的协议\n\n另外需要注意的是，TCP要求收发数据的双方扮演不同的角色:服务器和客户端，服务器会被动等待客户端的连接，它自己不会主动发起请求\n\n与TCP相反UDP正如它的名字，以报文(Datagram)为单位来收发数据，并且UDP不会自动回传丢失的数据包，因此不保证数据一定能被对方接收到\n\n正是因为缺少了这些检查，UDP通常具有更低的延迟并占用更少的系统资源，它也更适合像视频通话，这种实时性要求较高的应用\n下面我以Python为例来讲解socket编程的部分，但其实你可以完全使用自己喜欢的编程语言，几乎所有的编程语言都支持socket，除了语法不同，它们的用法都是完全一致的，首先我们来创建一个简单的服务器，这个服务器只做一件事，就是将接受到的消息原封不动地发送回去，\n第一行我们导入socket这个库\n\n然后我们调用socket中的socket()来创建一个socket s\nwith是Python中的一个语法糖，它单纯代表当代码离开with块的时候自动调用s.close()来销毁这个socket\n\n这里我们需要指定两个参数，第一个参数大家直接填写AF_INEF即可\n\n这个代表我们使用的是IPV4的地址家族(address family)\n第二个参数，SOCK_STREAM代表我们使用的是TCP协议，这里的STREAM也正是代表TCP是个“流式”协议，接下里爱的bind()将我们创建的这个socket关联到我们主机的某一个网卡(又:网络接口/network interface)和端口上，网卡我们可以通过IP地址指定，这里我使用的是0.0.0.0这个特殊的地址，它单纯代表你主机上的任意网卡都可以使用socket进行通信\n\n接下来的listen()将socket置为监听状态，并等待客户端的连接，在下面的accept()会接受来自任意客户端的连接，并返回一个新的socket c，以及客户端的IP地址，需要注意的是这个c是一个与之前s不同的socket，socket s主要用于监听，而socket c则用于与连接的客户端进行通信\n\n接下来的这几行代码，我们首先打印客户端的IP地址，然后是一个循环，这个循环会一直调用recv()接收客户端传来的信息，这里的1024代表一次性接收数据的最大长度1024个字节，然后只要数据不为空，我们就原封不动地将代码回传给客户端\n\n接下来，我们来简单测试一下这个服务器程序\n我们先运行代码\n\n然后新开一个窗口，这里我们会用到一个命令行工具netcat，它是Linux下非常常用的网络测试工具，可以用来读写TCP/UDP的数据，当然在windows下你也可以找到它的替代版nmap\n\n我们可以输入nc，后面直接跟上服务器的IP地址，127.0.0.1是一个回送地址(loopback address)\n\n代表本地计算机，再后面的1234是端口号，我们按下回车，可以看到服务器接收到了一个新连接\n\n这里我们随便输入字符串，服务器也会原封不动地返回回来\n\n这一步也验证了服务器代码是没有问题的\n接下来我们继续看看客户端的程序\n客户端的代码非常简单，这里我们用同样的方法创建一个socket s\n\n与服务器不同的是，这里我们直接调用connect()函数，并传入服务器的IP地址和端口号\n\n随后我们调用sendall()函数发送一条消息给服务器，需要注意的是，这里的参数是一个字节序列，并不是字符串，所以千万不要忘记这个b，然后我们调用recv()接受服务器的消息，并将结果打印出来\n\n这里我们新开一个窗口，测试一下客户端的代码，可以看到客户端也成功输出了发送的字符串，然后程序退出，以上我们就讲完了基本服务器和客户端的代码实现，不过这里的服务器有个很大的问题，它只能同时处理一个客户端的请求\n\n要并发地与多个客户端进行通信，这里有几种方法\n我们先来看看最简单的，多线程的服务器\n通过创建线程来响应不同客户端的请求\n首先前面bind和listen的部分和之前的代码完全一样，随后我们写一个循环，然后在循环中不停调用accept()接受来自客户端的连接，为了避免程序的阻塞(block)， 我们直接创建一个新的线程，也就是这里的handle_client()函数，并将客户端的socket c和地址传递给这个线程\n\n然后线程中的代码和之前的完全一样\n\n会不停地回传客户点端发送的信息\n最后我们运行服务器代码，然后新开两个窗口，使用之前讲到的nc命令同时与服务器建立连接，可以看到修改后的服务器可以同时完成这两个客户端的请求\n\n多线程显然能帮我们解决多连接并发的问题，不过它也有自身的局限性，由于GIL的存在，Python中的线程其实做不到真正的并发，并且线程自身也会占用额外的系统资源，除了线程之外，我们还可以使用基于事件驱动的seletors来实现多个连接的并发，或者通过asyncio来实现异步的socket代码\n总结一下:实现一个简单的HTTP服务器，HTTP是TCP协议的一个典型应用，也是浏览器与服务器交互的主要方式，通常服务器会监听80端口，然后等待客户端的连接，客户端在连上服务器以后，首先需要指定要访问的资源，然后客户端会提供一系列额外的信息，每一条都是以冒号分隔的键值对\n\n比如里面包括我们的浏览器的版本等待，这一部分也被称作消息的头部(header)，随后是一个空行，再之后是消息的主体(body)(如果有的话)\n\n服务器在收到消息后，会以同样的格式来响应客户端的请求，首先第一行是一个状态行(status line)，里面包含一个状态码，比如200代表请求成功，404代表请求的资源不存在等等，接着同样是一系列键值对，里面包含了请求资源的类型，服务器信息等等\n\n再后面是一个空行，最后紧跟消息的主体(body)(如果有的话)\n\n在了解了HTTP的基本原理之后，我们可以修改之前的代码来实现这个服务器，首先在handle_client中，我们读取客户端发来的消息，然后我们将消息拆分成一行一行的字符串，存放在header这个列表中，需要注意的是，HTTP标准中定义的换行符是“回车+换行”(CRLF)，这也是我这里用”\\r\\n”来进行字符串分割的原因，接着我们提取出请求的文件名，和一般的web服务器一样，如果客户请求的是根路径，我们则直接返回index.html\n\n随后我们读取文件内容，并返回一个状态号为200的消息\n\n如果请求的文件不存在则直接返回404\n\n最后我们运行代码，并在浏览器中输入本机的IP，可以看到这里成功显示了我本地创建的html测试文件\n\n如果我们去访问其他不存在的文件，则会收到一个错误信息\n这里说一句题外话，其实Python的标准库里已经实现了一个简易的HTTP服务器，它主要用在开发和测试中，调用起来也很方便，大家可以直接输入这个命令使用\npython -m http.server 8000\n\n最后这里附上代码\nsocket_test_server.py\nimport socketwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\ts.bind((&quot;0.0.0.0&quot;, 1235))\ts.listen()\tc, addr = s.accept()\twith c:\t\tprint(addr, &quot;connected.&quot;)\t\twhile True:\t\t\tdata = c.recv(1024)\t\t\tif not data:\t\t\t\tbreak\t\t\tc.sendall(data)\n\nsocket_test_client.py\nimport socketwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\ts.connect((&quot;127.0.0.1&quot;, 1235))\ts.sendall(b&quot;hello lhj&quot;)\tdata = s.recv(1024)\tprint(&quot;Received&quot;, repr(data))\n\n"},{"title":"一次性搞懂线程同步机制","url":"/2022/01/12/%E4%B8%80%E6%AC%A1%E6%80%A7%E6%90%9E%E6%87%82%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/","content":"使用线程，我们可以并发地在各个CPU核心上执行任务，最大化CPU的利用率，但线程也可能导致各种奇怪的资源竞争问题\n\n相信大家一定都看过这个经典案例\n\n用不同的线程去更新同一段内存数据，比如我们这里总共创建10个线程\n\n每个线程累加这个数字1000000次，运行程序你会发现得到的结果并不是预期的10000000，实际显示的数字可能会比它小很多，并且每次输出的结果还都不一样\n\n这里我会向大家解释为什么会出现这种情况，以及各种常见的线程同步机制\n\n我们先来回顾一下刚才的这段程序，其实问题就出在数字累加的这行代码上，虽然在程序中我们简单地写作n++，但是当程序被编译成机器代码时，n++其实被翻译成三条不同的机器指令(machine code)\n\n它们分别是，将内存中的数据加载到CPU的寄存器eax中，然后将eax中的数据+1，最后再将计算结果写回内存，换句话说，这里的n++并不是原子操作(atomic operation)，原子操作指的是不能被继续拆分、或者被其他操作打断的指令，这里顺带解释一下，寄存器(Registers)是CPU内部的小型存储器\n\n用来临时存放计算数据，CPU中的运算都离不开寄存器，它们的容量非常有限，但读写速度会比内存快很多，回到刚才的代码，如果不同的线程按照顺序依次执行\n比如线程A先将数据5读入寄存器，然后+1得到6并写回内存，然后线程B再将数据6读入寄存器，+1得到7并写回内存，这样没有任何问题，但问题在于线程是并发执行的\n\n可能线程A还未将累加后的数据写会内存，线程B就已经开始读取数据到寄存器，这样线程B就会读到修改之前的旧数据，最后的结果是数据只被累加了一次，这个就是我们平时说的线程资源竞争而导致的数据不一致问题，要解决这个问题，我们需要对线程进行同步，也就是让原先异步的操作依次有序地执行，而锁(lock)是我们接下来要讲的第一种，也是最最基本的线程同步机制，它的概念非常简单，在同一时间，只有一个线程可以获得(acquire)锁的拥有权(ownership)，此时其他的线程只能干等着，直到这个锁被持有者释放掉(release)\n\n锁的获取和释放有时候也被叫做上锁(lock)和解锁(unlock)，在不同的语言或者操作系统中，通常会用到不同的锁的实现，比如C++或者Go中的mutex互斥锁\n\n\njava则允许使用synchronized关键字来对某个函数、对象或者代码上锁\n\n当然更底层一些，我们甚至可以调用操作系统的API来实现锁的功能，其他的你可能听过的还包括自旋锁、读写锁等等\n\n总而言之，锁的核心概念是非常简单的\n我们只需要记住在访问共享资源之前上锁，并在结束之后解锁即可\n\n修改运行程序，我们可以看到，这里输出了我们的预期结果10000000，虽然这是一个样例程序，但是频繁加锁和解锁的操作是非常低效的\n\n这样会完全打破线程的并发执行\n其实我们完全可以在线程中创建一个临时变量做计算，然后再将最终的结果累加到全局的共享变量中，这样只有最后一个操作需要同步，而线程的主体仍能并发地执行，另外在使用锁的时候需要格外小心，多个锁的嵌套使用很可能导致线程的死锁(deadlock)现象\n比如这里有两个线程和两把锁\n\n线程1先获取锁1再获取锁2，线程2刚好相反，先获取锁2在获取锁1，如果这俩个线程同时运行，恰好线程q先获取了锁1，然后线程2获取了锁2，然后线程1继续执行，由于锁2被线程2占用，所以线程1会被阻塞，同时由于锁1被线程1占用，所以线程2也会被阻塞\n\n于是线程1和线程2同时被阻塞，也就造成了线程的死锁，这里关键的问题在于上锁的顺序，如果我们让所有线程都按照同样的顺序上锁，其实是可以避免这种情况的，不过实际情况肯恩远比这个复杂，每个线程会用到不同的锁，并且加锁和解锁的操作分散在代码的各个角落，所以另一种做法是，干脆就用单个锁来保护所有的共享资源\n\n并且仅仅在访问资源的时候再去上锁，虽然这么做会损失掉一部分线程的并发性(concurrency)，但好处在于程序的逻辑会更容易维护\n讲到这里，我们顺便提一下部分语言支持的atomic语法修饰，这是一种不使用锁(如果硬件支持)但依然能够解决资源竞争的方法，比如像之前简单的加减操作，在机器内部会直接翻译成硬件支持的原子操作\n\n\n也就说指令已经是不可拆分的最小步骤，因此不需要同步，它的效率通常比使用锁更高\n另外建立在锁之上，线程中还有其它更复杂、更高级的同步机制，比如信号量、条件变量等等，虽然它们也可以用来保护共享资源，但更主要的用途是在线程中传递信号(signaling)，比如使用条件变量，你可以让线程进入等待，直到某个条件成立后再继续执行，这个条件可能是网络资源被成功加载，或者某项数据准备完毕等等\n\n而信号量则更加灵活一点，你可以先让所有的线程进行等待，但在同一时间内，只让特定数量的线程被唤醒\n\n在后面我将再向大家详细解释信号量和条件变量的工作原理，因为它们很容易和锁混淆，但实际用途却完全不一样\n"},{"title":"“并发、并行、异步、同步”的区别","url":"/2022/01/12/%E2%80%9C%E5%B9%B6%E5%8F%91%E3%80%81%E5%B9%B6%E8%A1%8C%E3%80%81%E5%BC%82%E6%AD%A5%E3%80%81%E5%90%8C%E6%AD%A5%E2%80%9D%E7%9A%84%E5%8C%BA%E5%88%AB/","content":"并发、并行、异步、同步，这些术语之间到底有什么区别和联系呢\n\n首先并发是一个比较宽泛的概念，它单纯地代表计算机能够同时执行多项任务\n\n至于计算机怎么做到“并发”则有许多不同的形式，比如对于一个单核处理器，计算机可以通过分配时间片的方式，让一个任务运行一段时间，然后切换另一个任务，再运行一段时间，不同的任务会这样交替往复地一直执行下去，这个过程也被称作是进程或者线程的上下文切换(context switching)\n\n当然对于多核处理器，情况就有所不同了，我们可以在不同的核心上真正并行地执行任务，而不用通过分配时间片的方式运行，这种情况也就是我们所说的并行(parallelism)\n\n至于同步和异步则是两种不同的编程模型，“同步”代表需要等到必须前一个任务执行完毕之后才能进行下一个任务，因此在同步中并没有并发或者并行的概念，而“异步“”则代表不同的任务之间并不会相互等待，也就是说，你在执行任务A的时候，也可以同时运行任务B，一个典型实现异步的方式则是通过多线程编程，你可以创建多个线程，并且启动它们\n\n在多核的情况下，每个线程就会被分配到独立的核心上运行，实现真正的“并行”，当然如果你使用的是单核处理器，或者通过设置亲和力(Affinity)强制将线程绑定到某个核心上，操作系统则会通过分配时间片的方式来执行这些线程，这些线程依然是在“并发”地执行，当然像某些编程语言，比如JavaScript本身是没有多线程的概念的，不过通过它的函数回调(function callback)机制，我们依然能做到单线程的“并发”，比如你可以通过fetch()同时访问多个网络资源\n\n我们在调用fetch()函数的时候，程序并不会等待，而会直接继续执行下去，当获取到网路资源以后\n\n回调函数才会被掉起，需要注意的是，虽然主函数和回调函数看起来是同时进行的\n\n但它们依然是运行在同一个线程中\n\n因此通过这种异步编程方式，我们完全可以做到单线程的“并发”，而且这并不是JavaScript的专利，很多语言也都提供了原生的异步编程方式，比如C#，Rusut，C++2.0中的co_await，Python中的asyncio等等等等\n\n\n\n\n那到这里你肯定会问，对于多线程编程和这种单线程的异步编程，我们应当如何选择呢，简而言之，对于I/O密集型的应用程序，比如Web应用，就会经常执行网络操作，数据库访问，这类应用就非常适合使用异步编程的方式，反之如果我们使用多线程的方式，则会浪费不少的系统资源，因为每个线程的绝大多数时间都是在等待这些I/O操作，而线程自身会占用额外的内存，线程的切换也会有额外的开销，更不用说线程之间的资源竞争问题\n\n而多线程编程则非常适合于计算量密集的应用\n\n比如视频图像处理，科学计算等等，它能让每一个CPU核心发挥最大的功效，而不是消耗在空闲的等待上\n纠错:\n关于Python的例子我举得不太恰当，CPython中的GIL会导致Python代码的线程并不能做到真正并发，使用htop查看CPU使用率尽管在多核处理器也不会超过100%\n"},{"title":"Python实例方法、类方法、静态方法的区别与作用","url":"/2022/01/13/Python%E5%AE%9E%E4%BE%8B%E6%96%B9%E6%B3%95%E3%80%81%E7%B1%BB%E6%96%B9%E6%B3%95%E3%80%81%E9%9D%99%E6%80%81%E6%96%B9%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E4%BD%9C%E7%94%A8/","content":"\n实例方法\n定义: 第一个参数必须是实例对象，该参数名一般约定为“self”，通过它来传递实例的属性和方法(也可以传类的属性和方法)，简而言之，实例方法就是类的实例能够使用的方法\n调用: 只能由实例对象调用\n\n类方法\n定义: 使用装饰器@classmethod。第一个参数必须是当前类对象，该参数名一般约定为“cls”，通过它来传递类的属性和方法(不能传实例的属性和方法)，原则上，类方法是将类本身作为对象进行操作的方法。假设有个方法，且这个方法在逻辑上采用类本身作为对象来调用更合理，那么这个方法就可以定义为类方法。另外，如果需要继承，也可以定义为类方法\n调用: 实例对象和类对象都可以调用\n\n静态方法\n定义: 使用装饰器@staticmethod。参数随意，没有“self”和“cls”参数，但是方法体中不能使用类或实例的任何属性和方法\n调用: 实例对象和类对象都可以调用\n\n\n"},{"title":"软件构建CMake 快速入门","url":"/2022/01/13/%E8%BD%AF%E4%BB%B6%E6%9E%84%E5%BB%BACMake%20%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","content":"今天我们来讲一下软件构建工具，无论你用的是什么平台、什么编程语言，构建(Build)都是软件开发中必不可少的一个步骤\n\n如果你的项目只有一个源文件，我们当然可以用一行命令完成编译、链接的整个过程\n\n但如果你面对的是一个复杂的项目，其中包含不同的模块、组件，每个组件由若干个源文件组成，里面还用到了不少的第三方库\n\n\n这时候如果我们再去手动编译链接，将会非常的低效，而软件构建所做的就是全自动完成代码编译、链接、打包的整个过程，并且还能管理不同组件、甚至包括第三方库的关联，我们平时使用的IDE大多都内置了构建系统，只是我们没有留意罢了\n\n每一个构建工具通常有各自擅长的领域，如果你在VS中做C++开发，那么多半用到的是微软自己的MSBuild\n\n如果你使用Android Stuiod写移动端的程序，那么多半用到的是Gradle等等\n\n当然还有一些更复杂、更万能的构建系统，比如Bazel、BUCK\n\n\n它们试图使用单个工具来完成各种语言在不同环境下的构建，今天我会以CMake为例专门介绍一下C和C++程序的构建\n\n它是一个被广泛使用的、开源免费使用并且完全跨平台的构建工具，如果你希望在不同平台上编译运行你的软件，以后就不再需要手动配置Makefile，vs或者Xcode工程了，我们今天讲到的CMake会自动帮你做到这一切\n 首先我们看看CMake的安装，我们可以直接在官网下载最新的安装包\n\n也可以使用操作系统自带的包管理工具\n\n随后可以试着在命令行中输入CMake命令\n\n这里如果找不到命令的话可能还需要手动配置安装路径到PATH环境变量下\n\n另外我们要确保计算机上安装有C++的编译工具，比如windows下的MSBuild工具链或者直接安装Visual Studio，在Linux下则需要安装gcc或者clang等等，这是因为CMake自身是不带编译工具的，他会根据你编写的构建规则，也就是我们马上要讲道德CMakeLists文件，来自动生成目标平台下的原生工程文件\n\n比如windows下的VS工程或者Linux下的Makefile等等，因此要顺利完成编译，C++工具链是必不可少的，接下来我会从最简单的，只有单个源文件的例子来介绍CMake的基本用法，最后我会用之前视频中创建的一个黑洞渲染的工程，来讲解相对复杂一点的情况，刚好这个工程包含多个源文件、图片资源还会有一些第三方库，因此更加贴近与实际项目一些\n首先我们要做的第一件事是在项目的根目录下创建一个CMakeLists.txt文件，对于一个最简单的、只有一个源文件的工程，这三行代码是必不可少的\n\n首先第一行指定了构建项目所需的最低CMake版本，第二行指定了工程的名字，我们随后输出的可执行文件也会和它同一个名称\n\n第三行表示我们的项目需要构建一个可执行文件，并且它由main.cpp编译而成\n随后我们需要根据这个CMakeList文件生成目标平台下的原生工程，这个过程在CMake中叫做”配置”\n\n我们可以在菜单中找到CMake Configure命令\n\n或者VScode在打开项目时会自动提示你进行项目“配置”\n\n我们只需要选择平台原生的C++构建工具然后等待配置完成即可\n\n\n接下来到了真正构建环节\n这里我们可以使用快捷键F7，或者在菜单中运行CMake: Build命令\n\n如果一切顺利的话，面板中会输出成功编译的可执行文件\n\n\n另外我们所做的“配置”和“构建”操作都有对应的命令行指令，我们也可以在输出面板中找到它们\n\n在通常情况下，使用菜单或者图形界面自然更方便一些，但入股哦我们想在服务器上做持续继承(CI)，进行自动化的编译和测试，这里的命令行就格外有用了\n接下来，我们来看第二个相对复杂一点的工程配置，之前我们讲到这个工程包含了多个源文件、图片资源还有一些第三方库，因此这里的CmakeLists也会相对复杂一些\n\n首先前两行和我们之前讲到的完全一样，它们定义了CMake最低版本和工程文件名，随后映入眼帘的是一系列的find_package()命令，它会在你的计算机中寻找符合要求的第三方库\n\n首先你需要确保计算机中事先安装好了它们\n\n关于库的安装我后面再说\n其次这些库也需要支持用CMake进行构建，这个一般没有问题，因为大多数常见的C++库都提供了CMake的支持，这个命令的第一个参数是各个库的名字，后面的REQUIRED代表这个库是必须的，如果计算机中没有安装则会直接报错\n我们继续来看后面这个命令，由于这个项目由多个源文件组成，所以我们先调用file GLOB命令通过通配符匹配所有的C++源文件，并将它存放在变量SRC_FILE中，随后我们调用相同的add_executable()命令来构建一个可执行文件，第一个参数是工程文件的名字，这里的CMAKE_PROJECT_NAME是一个宏，会被自动替换成这里的工程名Blackhole，第二个禅师则是我们之前匹配的所有源文件\n由于我们项目用到了一些第三方库，所以自然少不了链接(Link)库的操作\n\n如果忘记了这个步骤，那么你应该会遇到经典的符号无法解析的错误\n\n并且由于我们项目用到了C++17以上的语法，所以这里需要通过target_compile_fetures()打开对C++17的支持，最后我们用到这个命令add_custom_command\n\n这里的POST_BUILD也就是字面意思代表编译之后要执行的操作，我们会调用CMake命令将根目录下的assets文件夹拷贝到输出路径下\n\n这一步只是一个简单的自动化，避免了文件的手动复制，这样在构建完成之后我们可以在输出路径下找到应用所需所有文件\n\n在最后我们来讲下C++第三方库的安装\n由于CMake只是一个构建工具，它并不包含库的安装和管理，如果我们的项目用到了第三方库，则需要确保计算机中事先安装好了它们，常见的安装方式有直接下载库的源文件，然后手动构建并指定CMake库的路径，当然对于Linux和mac我们也可以直接通过包管理工具安装，不过缺点是，每安装一个库都需要执行许多繁琐的步骤，并且不同平台下的配置过程也不太一样，因此这里推荐一个微软的开源工具vcpkg\n\n虽然名字叫vcpkg，不过它是一个跨平台的C++库管理工具，类似Python的pip，你要做的是先调用vcpkg install 安装第三方库\n\n然后在CMake构建的时候指定vcpkg工具链即可，如果你用过的是命令行，只需要额外传递一个参数CMAKE_TOOLCHAIN_FILE\n\n如果你用的是vscode插件，那么在设置中添加这个路径即可\n\n关于vcpkg的安装步骤大家可以参考官方详细的文档\nCMake其实是一个非常灵活但也非常复杂的工具，这个最好还是边学边用\n"},{"title":"js混淆-源码乱码题目详解","url":"/2022/01/13/js%E6%B7%B7%E6%B7%86-%E6%BA%90%E7%A0%81%E4%B9%B1%E7%A0%81%E9%A2%98%E7%9B%AE%E8%AF%A6%E8%A7%A3/","content":"我们打开猿人学的刷题网站:https://match.yuanrenxue.com/list\n我们先来看第一题，第一题是关于js混淆的，这题目看着就比较有意思，我们来看看\n首先我们打开一题，然后按F12打开调试，发现这边一打开就有个断点\n\n然后我们可以在设置间隔的函数中把debugger给跳过(右键点击Never pause here)\n\n我们过掉这个debug之后，重新抓下包，可以看到1到3页都是有的\n\n点击第四页就会弹出一个弹窗\n\n可以看到这边有个payload，我们主要要解这m参数\n\n这个参数的话竖线后面是一个时间戳\n"},{"title":"js混淆-动态cookie题目详解","url":"/2022/01/13/js%E6%B7%B7%E6%B7%86-%E5%8A%A8%E6%80%81cookie%E9%A2%98%E7%9B%AE%E8%AF%A6%E8%A7%A3/","content":"第二题是js混线，动态cookie，这也是提取全部5页的数据，题目链接:https://match.yuanrenxue.com/match/2\n\n我们先来抓下包叭，打开F12同样会在断点处断住，然后我们只需要右键点击Never parsed here即可，随后我们可以看到第一页的十条数据\n\n\n这是个xhr请求，而且它只有一个参数page\n\n实际上这个题它这边已经说了是个动态cookie，所以是一定要有cookie才能去访问的，然后，一般情况下，如果我们碰到一个类似的网页，如果只是当时即时使用的话可以直接复制这个cookie去拿数据，但我们都知道cookie是具有一定时效性的，时间久了这种操作是不可取的，所以我们就需要去分析cookie是怎么来的，是本地生成的还是服务器返回的一个set-cookie，如果是服务器返回的，那就可以模拟浏览器的请求去开一个session即可，如果是本地生成的话就得分析cookie是怎么本地生成的，然后把这个cookie给它凑出来，扣js或者是怎么样把这个cookie给生成出来，如果是两种方法都有的话那就两种方法结合起来用\n我们继续抓一下包，点击第二页会弹出一个框说cookie失效，说明合格cookie的有效期是比较短的，点击确定后就会获取一个新的cookie，然后进入页面，以下是第一页抓到的包，我们看到这边是有cookie的\n\n然后我们要拿到的数据就是它返回的数据，也就是Preview中的数据\n\n未完待续\n"},{"title":"Python十大高级用法","url":"/2022/01/13/Python%E5%8D%81%E5%A4%A7%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95/","content":"参考自:https://syjun.vip/archives/185.html\n"},{"title":"2022-1-13每日英语","url":"/2022/01/13/2022-1-13%E6%AF%8F%E6%97%A5%E8%8B%B1%E8%AF%AD/","content":"\ninterval n. 间隔，间隙；幕间休息；[ˈɪntərvl]\nquery n. 疑问，询问；问号；v. 质疑，对…表示疑问；询问，提问；[ˈkwɪri]\n\n"},{"title":"Python中format函数的用法","url":"/2022/01/14/Python%E4%B8%ADformat%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95/","content":"Python2.6开始便新增了一种格式化字符串的str.format()函数，基本语法是通过&#123;&#125;和:来代替以前的%\nformat函数可以接受不限个数的参数，位置可以不按顺序\n&gt;&gt;&gt;&quot;&#123;&#125; &#123;&#125;&quot;.format(&quot;hello&quot;, &quot;world&quot;)    # 不设置指定位置，按默认顺序&#x27;hello world&#x27; &gt;&gt;&gt; &quot;&#123;0&#125; &#123;1&#125;&quot;.format(&quot;hello&quot;, &quot;world&quot;)  # 设置指定位置&#x27;hello world&#x27; &gt;&gt;&gt; &quot;&#123;1&#125; &#123;0&#125; &#123;1&#125;&quot;.format(&quot;hello&quot;, &quot;world&quot;)  # 设置指定位置&#x27;world hello world&#x27;\n\n也可以设置参数\nprint(&quot;网站名：&#123;name&#125;, 地址 &#123;url&#125;&quot;.format(name=&quot;菜鸟教程&quot;, url=&quot;www.runoob.com&quot;)) # 通过字典设置参数site = &#123;&quot;name&quot;: &quot;菜鸟教程&quot;, &quot;url&quot;: &quot;www.runoob.com&quot;&#125;print(&quot;网站名：&#123;name&#125;, 地址 &#123;url&#125;&quot;.format(**site)) # 通过列表索引设置参数my_list = [&#x27;菜鸟教程&#x27;, &#x27;www.runoob.com&#x27;]print(&quot;网站名：&#123;0[0]&#125;, 地址 &#123;0[1]&#125;&quot;.format(my_list))  # &quot;0&quot; 是必须的\n\n也可以向str.format()传入对象\nclass AssignValue(object):    def __init__(self, value):        self.value = valuemy_value = AssignValue(6)print(&#x27;value 为: &#123;0.value&#125;&#x27;.format(my_value))  # &quot;0&quot; 是可选的\n\nformat还可以进行数字格式化，这个用到的不多\n"},{"title":"Python中eval函数的用法","url":"/2022/01/14/Python%E4%B8%ADeval%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95/","content":"eval()函数用来执行一个字符串表达式，并返回表达式的值\n以下是eval()函数的语法:\neval(expression[, globals[, locals]])\n\n实例:\n&gt;&gt;&gt;x = 7&gt;&gt;&gt; eval( &#x27;3 * x&#x27; )21&gt;&gt;&gt; eval(&#x27;pow(2,2)&#x27;)4&gt;&gt;&gt; eval(&#x27;2 + 2&#x27;)4&gt;&gt;&gt; n=81&gt;&gt;&gt; eval(&quot;n + 4&quot;)85\n\n"},{"title":"Python爬虫登录的恩恩怨怨","url":"/2022/01/14/Python%E7%88%AC%E8%99%AB%E7%99%BB%E5%BD%95%E7%9A%84%E6%81%A9%E6%81%A9%E6%80%A8%E6%80%A8/","content":"曾几何时，登录是一件很简单的事情，一个账户及其密码，POST给服务器，服务器验证通过即可。那是一个美好的朴素年代，服务器不设防，用户不贪婪。然而，时过境迁，人心变了。越来越多的人想要收集数据，爬虫也就越来越多；而网站就有了网络请求压力，也有了死守数据私心。天下熙熙，皆为利来；天下攘攘，皆为利往。现在的互联网，就成了一个利字当头、魔高一尺道高一丈的战场\n如今，各种网站都设置了复杂的登录这堵高高的墙来阻止爬虫大量甚至全部获取网站的数据。比如，12306的验证码是点选图片，微博是变形的字母验证码，知乎是点选倒立的汉字，哔哩哔哩通过拖动滑块拼图来验证。这些变态的验证过程都是加入人的交互来防止爬虫自动登录，从而阻止爬虫自动化的大批量抓取\n小猿们都已经知道，HTTP协议是无状态的，用户登录的状态靠cookies在浏览器和服务器之间来回传送来记录。完成登录后，cookies在一定时间范围内是保持不变的，直接获得这个cookies给爬虫用，就可以让爬虫有了登录的状态，进而进行后面的抓取，当然，这个抓取只能持续到cookies过期之前\n在这里我们来看看爬虫登录的三种层次，完成登录这个过程，最好是程序自动化实现，那么你写好程序就可以一边玩去了，然而好多时候，事情不是那么让人省心，登录还需要人工参与一下下；总结下来，实现登陆有以下三种层次:\n\n简单的PODT账户密码就可以实现自动化登录\n通过程序可以模拟出登录流程实现自动化登录\n登录需要人工智能介入，人工智能实现自动化登录\n\n第一个层次，使用requests模块加一两行代码就可以实现，关键是现如今很少有这样的良心网站了\n第二个层次，是很有挑战性的，也是爬虫界人士力求达到的层次\n第三个层次，就需要接入人工智能，利用人工智能识别验证码\n由此看来，登录状态的cookies的获取，主要还是靠模拟登录流程或者人工智能识别验证码为主\n"},{"title":"JS逆向的时候Python如何调用JavaScript代码呢","url":"/2022/01/14/JS%E9%80%86%E5%90%91%E7%9A%84%E6%97%B6%E5%80%99Python%E5%A6%82%E4%BD%95%E8%B0%83%E7%94%A8JavaScript%E4%BB%A3%E7%A0%81%E5%91%A2/","content":"今天在逛崔庆才博客的时候发现这个讲得还不错，是关于Python如何调用JS代码的，点击这里调转阅读\n"},{"title":"Python 中__new__和__init__的异同点","url":"/2022/01/14/Python%20%E4%B8%AD__new__%E5%92%8C__init__%E7%9A%84%E5%BC%82%E5%90%8C%E7%82%B9/","content":"同: 二者均是Python面向对象语言中的函数，__new__比较少用，__init__则用的比较多\n异: \n\n__new__是在实例创建之前被调用的，因为它的任务就是创建实例然后直接返回该实例对象，是个静态方法\n__init__是当实例对象创建完成后被调用的，然后设置对象属性的一些初始值，通常在初始化一个类实例的时候被调用，是一个实例方法\n\n总结来说也就是: __new__先被调用，__init__后被调用，__new__的返回值（实例）将传递给__init__方法的第一个参数，然后__init__给这个实例设置一些参数\n一些说明:\n\n继承自object的新式类才有__new__\n__new__至少要有一个参数cls，代表当前类，此参数在实例化时由Python解释器自动识别\n__new__必须要有返回值，返回实例化出来的实例，这点在自己实现__new__时要特别注意，可以return父类__new__出来的实例，或者是直接object__new__出来的 实例\n__init__有一个参数self，这个就是__new__返回的实例，__init__在__new__的基础上可以完成一些其它初始化的操作，__init__不需要返回值\n如果__new__创建的是当前类的实例，会自动调用__init__函数，通过return语句里面调用的__new__函数的第一个参数是cls来保证是当前类实例，如果是其它类的类名，那么实际创建返回的就是其他类的实例\n在定义子类时没有重新定义__new__时，Python默认是调用该类的直接父类的__new__来构造该类的实例，如果该类的父类也没有重写__new__，那么将一直按此规矩追溯至object的__new__方法，因为object是所有新式类的基类\n而如果子类中重写了__new__，那么你可以自由选择任意一个的其他新式类(必定要是新式类，只有新式类必定都有__new__，因为所有新式类都是object的后代，而经典类则没有__new__方法)的__new__方法来制造实例\n对于子类的__init__，其调用规制跟__new__是一致的，当然如果子类和父类的__init__都想调用，可以在子类的__init__中加入对父类__init__的调用\n我们在使用时，尽量使用__init__，不要去自定义__new__，因为这两者在继承派生时的特性还是很不一样的\n将类比作制造商，__new__方法就是前期的原料购买环节，__init__方法就是在原有材料的基础上加工、初始化商品化环节\n\n"},{"title":"理解Python asyncio原理和简洁使用方式","url":"/2022/01/14/%E7%90%86%E8%A7%A3Python%20asyncio%E5%8E%9F%E7%90%86%E5%92%8C%E7%AE%80%E6%B4%81%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/","content":"异步IO是个好东西，在网络读写场景中可以大大提高程序的并发能力，比如爬虫、web服务等；这样好的东西自然也要用到Python中，不过，在漫长的Python2时代，官方并没有推出一个自己的异步IO库，到了Python3.4才推出；我们先来看看异步IO在Python中的发展历史\nPython2的异步IO库\nPython2时代官方并没有异步IO的支持，但是有几个第三方库通过事件或者事件循环(Event Loop)实现了异步IO，它们是:\n\nPython3官方的异步IO库\nPython 3.4 加入了asyncio 库，使得Python有了支持异步IO的官方库。这个库，底层是事件循环(EventLoop)，上层是协程和任务。asyncio自从3.4 版本加入到最新的 3.7版一直在改进中，Python 3.4 刚开始的asyncio的协程还是基于生成器的，通过 yield from 语法实现，可以通过装饰器 @asyncio.coroutine (已过时)装饰一个函数来定义一个协程\n\nPython 3.5 引入了两个新的关键字 await 和 async 用来替换 @asyncio.coroutine 和 yield from ，从语言本身来支持异步IO。从而使得异步编程更加简洁，并和普通的生成器区别开来.\n注意： 对基于生成器的协程的支持已弃用，并计划在 Python 3.10 中移除。所以，写异步IO程序时只需使用 async 和 await 即可\nPython 3.7 又进行了优化，把API分组为高层级API和低层级API。我们先看看下面的代码，发现与上面的有什么不同？\n\n除了用 async 替换 @asyncio.coroutine 和用 await 替换 yield from 外，最大的变化就是关于eventloop的代码不见了，只有一个 async.run()。这就是 3.7 的改进，把eventloop相关的API归入到低层级API，新引进run()作为高层级API让写应用程序的开发者调用，而不用再关心eventloop。除非你要写异步库（比如MySQL异步库）才会和eventloop打交道\n理解asyncio\n理解asyncio并不难，关键是要动起手来，接下来我们以下面代码为例动手实践一番，通过实践来理解它\nimport timeimport asyncioasync def hi(msg, sec):\tprint(&#x27;enter hi(), &#123;&#125; @&#123;&#125;&#x27;.format(msg, time.strftime(&#x27;%H:%M:%S&#x27;)))\tawait asyncio.sleep(sec)\tprint(&#x27;exit hi() &#123;&#125; @&#123;&#125;&#x27;.format(msg, time.strftime(&#x27;%H:%M:%S&#x27;)))\treturn secasync def main():\tprint(&#x27;main() begin at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))\tfor i in range(1, 5):\t\tawait hi(i, i)\tprint(&#x27;main() end at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))asyncio.run(main())print(&#x27;done&#x27;)\n\n这段代码很简单，我们定义了两个协程函数(在def前面加上async)，其中hi()我们把它叫做功能函数，通过一个asyncio.sleep()来模拟一个耗时的异步IO操作，(比如下载网页)，main函数叫做入口函数，其实就是在main()里面调用hi()函数，通过不断改变main()的行为来理解异步IO()来理解异步IO(协程函数的调用)的运行过程\n1. 协程函数如何运行？\n首先我们要明确一个道理，hi()是一个协程函数，直接调用它返回的是一个协程对象，并没有真正运行它，把main函数改成如下，我们来仔细看看协程函数hi()的运行\nimport timeimport asyncioasync def hi(msg, sec):\tprint(&#x27;enter hi(), &#123;&#125; @&#123;&#125;&#x27;.format(msg, time.strftime(&#x27;%H:%M:%S&#x27;)))\tawait asyncio.sleep(sec)\tprint(&#x27;exit hi() &#123;&#125; @&#123;&#125;&#x27;.format(msg, time.strftime(&#x27;%H:%M:%S&#x27;)))\treturn secasync def main():\tprint(&#x27;main() begin at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))\ta = hi(&#x27;a&#x27;, 1)\tprint(&#x27;a is:&#x27;, a)\tb = await a\tprint(&#x27;b is:&#x27;, b)\t# for i in range(1, 5):\t# \tawait hi(i, i)\tprint(&#x27;main() end at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))asyncio.run(main())print(&#x27;done&#x27;)\n\n下面是运行结果:\nmain() begin at 15:56:58a is: &lt;coroutine object hi at 0x0000000002D6A9C8&gt;enter hi(), a @15:56:58exit hi() a @15:56:59b is: 1main() end at 15:56:59done\n\n代码12行，我们像运行普通函数一样运行hi()，得到的a只是一个协程对象:\na is: &lt;coroutine object hi at 0x0000000002D6A9C8&gt;\n\n这个协程对象a虽然生成了，但是还没有运行，它需要一个时机，也就是asyncio的时间循环正在运行main函数，还没有空去运行它，代码第14行，通过await关键字告诉event_loop(时间循环)，main协程停在这里，你去运行其他协程叭，这时候envent_loop就去执行a协程，也就是去执行hi()函数里面的代码，等hi()运行完，event_loop再回到main协程继续从14行开始执行，把hi()的返回值赋值给b，这个时候b的值是1\nenve_loop在整个异步IO的过程中扮演着一个管家的角色，在不同的协程之间切换运行代码，切换是通过事件来进行的，通过await离开当前协程，当await的协程完成后又回到之前的协程对应的地方继续执行\n2. 协程函数如何并发\n异步IO的好处就是并发，但如何实现呢?我们先来看一个不是并发的栗子\nimport timeimport asyncioasync def hi(msg, sec):    print(&#x27;enter hi(), &#123;&#125; @&#123;&#125;&#x27;.format(msg, time.strftime(&#x27;%H:%M:%S&#x27;)))    await asyncio.sleep(sec)    print(&#x27;exit hi() &#123;&#125; @&#123;&#125;&#x27;.format(msg, time.strftime(&#x27;%H:%M:%S&#x27;)))    return secasync def main():    print(&#x27;main() begin at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))    for i in range(1, 5):        b = await hi(i, i)        print(&quot;b is:&quot;, b)    print(&#x27;main() end at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))if __name__ == &#x27;__main__&#x27;:    asyncio.run(main())    print(&#x27;done&#x27;)\n\n这次，我们把main修改成一个for循环执行4次，看看它运行的结果\nmain() begin at 16:20:22enter hi(), 1 @16:20:22exit hi() 1 @16:20:23b is: 1enter hi(), 2 @16:20:23exit hi() 2 @16:20:25b is: 2enter hi(), 3 @16:20:25exit hi() 3 @16:20:28b is: 3enter hi(), 4 @16:20:28exit hi() 4 @16:20:32b is: 4main() end at 16:20:32done\n\n整个过程从16:20:22到16:20:32结束，用了10秒，而hi()的执行时间分别是1秒，2秒，3秒，4秒总共10秒，也就是4个hi()虽然是异步的，但是是顺序执行的，没有并发\n接下来，就到了真正并发实现了，通过asyncio.creat_task()即可:\nimport timeimport asyncioasync def hi(msg, sec):    print(&#x27;enter hi(), &#123;&#125; @&#123;&#125;&#x27;.format(msg, time.strftime(&#x27;%H:%M:%S&#x27;)))    await asyncio.sleep(sec)    print(&#x27;exit hi() &#123;&#125; @&#123;&#125;&#x27;.format(msg, time.strftime(&#x27;%H:%M:%S&#x27;)))    return secasync def main():    print(&#x27;main() begin at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))    tasks = list()    for i in range(1, 5):        t = asyncio.create_task(hi(i, i))        tasks.append(t)        # b = await hi(i, i)        # print(&quot;b is:&quot;, b)    for t in tasks:        b = await t        print(&quot;b is:&quot;, b)    print(&#x27;main() end at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))if __name__ == &#x27;__main__&#x27;:    asyncio.run(main())    print(&#x27;done&#x27;)\n\n通过create_task()我们在for循环里面生成了4个task(也就是协程对象)，但是这4个协程任务并没有被执行，他们需要等待一个时机:当前携程(main)遇到await\n第二个for循环开始逐一await协程，此时event_loop就可以空出手来去执行那4个协程，过程大致如下:\n先执行hi(1, 1) ，打印“enter hi(), 1 @16:30:18”，遇到await asyncio.sleep(1)，当前协程挂起；\n接着执行 hi(2, 2)，执行打印命令，遇到await asyncio.sleep(2) ，当前协程挂起；\n接着执行 hi(3, 3)，执行打印命令，遇到await asyncio.sleep(3) ，当前协程挂起；\n接着执行 hi(4, 4)，执行打印命令，遇到await asyncio.sleep(4) ，当前协程挂起；\n以上4步只是协程的切换和打印语句，执行非常快，我们可以任务它们是同时执行起来的。\n1秒后，hi(1,1)的sleep结束它会发出事件告诉 event_loop 我await结束了，过来执行我，event_loop 此时空闲就来执行它，继续执行sleep后面的打印语句；\n2秒后，hi(2,2)的sleep结束它会发出事件告诉 event_loop 我await结束了，过来执行我，event_loop 此时空闲就来执行它，继续执行sleep后面的打印语句；\n3秒后，hi(3,3)的sleep结束它会发出事件告诉 event_loop 我await结束了，过来执行我，event_loop 此时空闲就来执行它，继续执行sleep后面的打印语句；\n4秒后，hi(4,4)的sleep结束它会发出事件告诉 event_loop 我await结束了，过来执行我，event_loop 此时空闲就来执行它，继续执行sleep后面的打印语句；\n4秒后，生成的4个协程任务就都执行完毕。总耗时4秒，也就是我们的4个任务并发完成了。\n上面代码的运行结果为:\nmain() begin at 16:30:17enter hi(), 1 @16:30:17enter hi(), 2 @16:30:17enter hi(), 3 @16:30:17enter hi(), 4 @16:30:17exit hi() 1 @16:30:18b is: 1exit hi() 2 @16:30:19b is: 2exit hi() 3 @16:30:20b is: 3exit hi() 4 @16:30:21b is: 4main() end at 16:30:21done\n\n3. 错误的运行\n上面的并发很完美，但有时候你可能会犯错，比如下面的main()，你可能只是并发hi()，但不需要返回它的结果，于是就有了下面的main()\nimport timeimport asyncioasync def hi(msg, sec):    print(&#x27;enter hi(), &#123;&#125; @&#123;&#125;&#x27;.format(msg, time.strftime(&#x27;%H:%M:%S&#x27;)))    await asyncio.sleep(sec)    print(&#x27;exit hi() &#123;&#125; @&#123;&#125;&#x27;.format(msg, time.strftime(&#x27;%H:%M:%S&#x27;)))    return secasync def main():    print(&#x27;main() begin at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))    for i in range(1, 5):        asyncio.create_task(hi(i, i))    print(&#x27;main() end at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))if __name__ == &#x27;__main__&#x27;:    asyncio.run(main())    print(&#x27;done&#x27;)\n\n下面是运行结果:\nmain() begin at 16:45:42main() end at 16:45:42enter hi(), 1 @16:45:42enter hi(), 2 @16:45:42enter hi(), 3 @16:45:42enter hi(), 4 @16:45:42done\n\nmain()的for循环只是生成了4个task协程，然后就退出了，event_loop收到main退出的事件就空出来去执行了那4个协程，进去了但都碰到了sleep，然后envent_loop就空闲了，这个时候run()就收到了main()执行完毕的事件信号，run()就执行完了，最后执行print，整个程序就退出了，从main退出到整个程序退出那就是一瞬间的事情，那4个协程还在傻傻地睡着，如果把它们也加入任务列表就不会这样了，如果不加入，那默认任务列表就只有main函数，其他的只是微微带过，如果main函数结束了，它们也会立马结束\n我们如果在main()中加入一个sleep会出现什么结果:\nimport timeimport asyncioasync def hi(msg, sec):    print(&#x27;enter hi(), &#123;&#125; @&#123;&#125;&#x27;.format(msg, time.strftime(&#x27;%H:%M:%S&#x27;)))    await asyncio.sleep(sec)    print(&#x27;exit hi() &#123;&#125; @&#123;&#125;&#x27;.format(msg, time.strftime(&#x27;%H:%M:%S&#x27;)))    return secasync def main():    print(&#x27;main() begin at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))    for i in range(1, 5):        asyncio.create_task(hi(i, i))    print(&#x27;mian() sleep at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))    await asyncio.sleep(2)    print(&#x27;main() end at &#123;&#125;&#x27;.format(time.strftime(&#x27;%H:%M:%S&#x27;)))if __name__ == &#x27;__main__&#x27;:    asyncio.run(main())    print(&#x27;done&#x27;)\n\n运行结果:\nmain() begin at 17:06:59mian() sleep at 17:06:59enter hi(), 1 @17:06:59enter hi(), 2 @17:06:59enter hi(), 3 @17:06:59enter hi(), 4 @17:06:59exit hi() 1 @17:07:00exit hi() 2 @17:07:01main() end at 17:07:01done\n\n可以看到这边main函数sleep了两秒就让两次hi函数执行完毕，如果我们让main函数sleep更长时间那就4个hi函数都会执行完毕\n说明，功能函数如果不加入任务列表，那就要求入口函数有足够长的执行时间，因为在入口函数的长执行时间中就会有机会去执行功能函数\n4. 如何判断是否要把函数定义为协程函数\n定义一个协程函数很简单，在def前面加async即可，那么如何判断一个函数该不该定义为协程函数呢?\n记住一个原则: 如果该函数是要进行IO操作(读写网络、读写文件、读写数据库等)，就把它定义为协程函数，否则就是普通函数\n"},{"title":"js逆向百度翻译(小白练手案例)","url":"/2022/01/14/js%E9%80%86%E5%90%91%E7%99%BE%E5%BA%A6%E7%BF%BB%E8%AF%91(%E5%B0%8F%E7%99%BD%E7%BB%83%E6%89%8B%E6%A1%88%E4%BE%8B)/","content":"首先我们打开百度翻译然后按F12打开抓包工具，我们点击Fetch/XHR，然后我们随便输入一个中文，点击翻译，我们需要关注的是v2transapiform=zh&amp;to=en这个post请求\n首先我们输入你好然后回车(或者点击翻译触发)\n\n我们再翻译一个他们\n\n再翻译一个我们\n\n这个过程中我们不难发现，formdata中变的就两个，一个是query，另一个是sign\n现在我们知道了要构造请求的参数，以及变化且需要破解的参数，我们就可以着手去做了\n我们先全局搜索下sign这个参数，我们发现搜索出来的东西很多，但是我定睛一看，发现有一个js文件中出现了很多的sign字样，其他的出现得比较少而且很多assign混在其中，这使我有想法去看看这个js文件(或者试试搜索/v2transapi，这个搜出来应该只有一个，而且可以很快定位表单数据)\n\n那么我是如何定位到这个js文件的呢，首先看下面这个红框，我会记住这个js文件的名字和路径然后点击工具栏中的source，根据刚刚的路径就能快速定位到这个js文件\n定位到之后，这个js文件的排版是很乱的，我们可以点击左下角的花括号去做一次排版，使我们看得更舒服，然后我们同样在这个js文件中做一次搜索，CTRL+F，然后搜索sign，会发现一共有13个，我们一个一个筛选，最终发现了第10个是最符合我们预期的，因为它最完整，和前面的formdata都一一对上了\n我们在这个sign所在的行打上一个断点\n\n然后在网页中翻译一个词语，回车后会发现程序断在了刚刚打断点的前面，然后我们鼠标悬停在L(e)函数上，会出现一个悬浮框，然后我们点击悬浮框中的e(r)函数跳转进入e(r)函数\n\n跳转进e(r)函数是这样的\n\n\n这里我们发现e(r)中牵扯到了其他两个函数，一个是a(r)，另一个是n(r, o)，所以这两个三个函数都要扣出来，然后我们发现还有一个未知的是window[1]\n\n这里有一句关键的代码我们来分析下\nu = null !== i ? i : (i = window[l] || &quot;&quot;) || &quot;&quot;;// 这是一个js中的三元表达式，而我们看到下面定义了var i = null;所以null !== i 为假所以u的值为(i = window[l] || &quot;&quot;)，u的值也就是window[1]\n\n我们经过多次调试发现这个u是一个确定的值，u=320305.131321201，我们可以直接用一个变量代替\n下面就是我们抠出来的js代码\njsCode = &quot;&quot;&quot;    function a(r) &#123;        if (Array.isArray(r)) &#123;            for (var o = 0, t = Array(r.length); o &lt; r.length; o++)                t[o] = r[o];            return t        &#125;        return Array.from(r)    &#125;    function n(r, o) &#123;        for (var t = 0; t &lt; o.length - 2; t += 3) &#123;            var a = o.charAt(t + 2);            a = a &gt;= &quot;a&quot; ? a.charCodeAt(0) - 87 : Number(a),            a = &quot;+&quot; === o.charAt(t + 1) ? r &gt;&gt;&gt; a : r &lt;&lt; a,            r = &quot;+&quot; === o.charAt(t) ? r + a &amp; 4294967295 : r ^ a        &#125;        return r    &#125;    var i = null;    function e(r) &#123;        var t = r.length;        t &gt; 30 &amp;&amp; (r = &quot;&quot; + r.substr(0, 10) + r.substr(Math.floor(t / 2) - 5, 10) + r.substr(-10, 10))        var u = void 0, l = &quot;&quot; + String.fromCharCode(103) + String.fromCharCode(116) + String.fromCharCode(107);                u = null !== i ? i : (i = &#x27;320305.131321201&#x27; || &quot;&quot;) || &quot;&quot;;        for (var d = u.split(&quot;.&quot;), m = Number(d[0]) || 0, s = Number(d[1]) || 0, S = [], c = 0, v = 0; v &lt; r.length; v++) &#123;            var A = r.charCodeAt(v);            128 &gt; A ? S[c++] = A : (2048 &gt; A ? S[c++] = A &gt;&gt; 6 | 192 : (55296 === (64512 &amp; A) &amp;&amp; v + 1 &lt; r.length &amp;&amp; 56320 === (64512 &amp; r.charCodeAt(v + 1)) ? (A = 65536 + ((1023 &amp; A) &lt;&lt; 10) + (1023 &amp; r.charCodeAt(++v)),            S[c++] = A &gt;&gt; 18 | 240,            S[c++] = A &gt;&gt; 12 &amp; 63 | 128) : S[c++] = A &gt;&gt; 12 | 224,            S[c++] = A &gt;&gt; 6 &amp; 63 | 128),            S[c++] = 63 &amp; A | 128)        &#125;        for (var p = m, F = &quot;&quot; + String.fromCharCode(43) + String.fromCharCode(45) + String.fromCharCode(97) + (&quot;&quot; + String.fromCharCode(94) + String.fromCharCode(43) + String.fromCharCode(54)), D = &quot;&quot; + String.fromCharCode(43) + String.fromCharCode(45) + String.fromCharCode(51) + (&quot;&quot; + String.fromCharCode(94) + String.fromCharCode(43) + String.fromCharCode(98)) + (&quot;&quot; + String.fromCharCode(43) + String.fromCharCode(45) + String.fromCharCode(102)), b = 0; b &lt; S.length; b++)            p += S[b],            p = n(p, F);        return p = n(p, D),        p ^= s,        0 &gt; p &amp;&amp; (p = (2147483647 &amp; p) + 2147483648),        p %= 1e6,        p.toString() + &quot;.&quot; + (p ^ m)    &#125;&quot;&quot;&quot;import execjsquery = &#x27;汉语中文&#x27;sign = execjs.compile(jsCode).call(&quot;e&quot;, query)print(sign)\n\n执行结果如下\n\n接下就简单了，构造一个post请求然后解析json数据，拿到翻译结果\nimport requestsfrom test_baidu_jscode import get_word_signimport jsonpathurl = &quot;https://fanyi.baidu.com/v2transapi?from=zh&amp;to=en&quot;headers = &#123;    &#x27;Connection&#x27;: &#x27;keep-alive&#x27;,    &#x27;sec-ch-ua&#x27;: &#x27;&quot; Not;A Brand&quot;;v=&quot;99&quot;, &quot;Google Chrome&quot;;v=&quot;97&quot;, &quot;Chromium&quot;;v=&quot;97&quot;&#x27;,    &#x27;Accept&#x27;: &#x27;*/*&#x27;,    &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded; charset=UTF-8&#x27;,    &#x27;X-Requested-With&#x27;: &#x27;XMLHttpRequest&#x27;,    &#x27;sec-ch-ua-mobile&#x27;: &#x27;?0&#x27;,    &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &#x27;                  &#x27;Chrome/97.0.4692.71 Safari/537.36&#x27;,    &#x27;sec-ch-ua-platform&#x27;: &#x27;&quot;Windows&quot;&#x27;,    &#x27;Origin&#x27;: &#x27;https://fanyi.baidu.com&#x27;,    &#x27;Sec-Fetch-Site&#x27;: &#x27;same-origin&#x27;,    &#x27;Sec-Fetch-Mode&#x27;: &#x27;cors&#x27;,    &#x27;Sec-Fetch-Dest&#x27;: &#x27;empty&#x27;,    &#x27;Referer&#x27;: &#x27;https://fanyi.baidu.com/?aldtype=16047&#x27;,    &#x27;Accept-Language&#x27;: &#x27;zh-CN,zh;q=0.9&#x27;,    &#x27;Cookie&#x27;: &#x27;BIDUPSID=CF86A0FA51038D0CA02DA9FC43B164F5; PSTM=1639146064; &#x27;              &#x27;BAIDUID=CF86A0FA51038D0CFFCCCD08415508DA:FG=1; &#x27;              &#x27;__yjs_duid=1_689d947b2f957f0b0d895ae63c66114f1639229602485; &#x27;              &#x27;BAIDUID_BFESS=3A9FDFF925D6EA302A897713757BE825:FG=1; BDRCVFR[iqrboYocJ-C]=kRxlD0AvOmRPjIMTz4WUvY; &#x27;              &#x27;BDRCVFR[fq555l35Iot]=EBD6F1bEM2tXZKdrHn8mvqV; delPer=0; BDORZ=FFFB88E999055A3F8A630C64834BD6D0; &#x27;              &#x27;BDRCVFR[3lgytkvnri6]=mk3SLVN4HKm; H_PS_PSSID=; REALTIME_TRANS_SWITCH=1; FANYI_WORD_SWITCH=1; &#x27;              &#x27;HISTORY_SWITCH=1; SOUND_PREFER_SWITCH=1; SOUND_SPD_SWITCH=1; APPGUIDE_10_0_2=1; &#x27;              &#x27;Hm_lvt_64ecd82404c51e03dc91cb9e8c025574=1642227471,1642227478; PSINO=6; &#x27;              &#x27;BA_HECTOR=2hag052ha52h010lkt1gu4ujh0r; Hm_lpvt_64ecd82404c51e03dc91cb9e8c025574=1642233008; &#x27;              &#x27;ab_sr=1.0&#x27;              &#x27;.1_NjI2ZDk1Y2JmYzQ2ZTBiNTZmNWIyZjllNTU4ZjE4MmM1ZTI2ZmVjMjAyNmJhN2E5NGJhNWVjYmM2OWFmMTRjOTE0ZDQ2M2Y5MmY5N2RmNDUzNzYwNGJjZmZlYmVhZjZjMjgzYWI5YjhhZDJlNzg0NTNiZjRmNjhmMzU5ZDIxNzhkNzhiNDlmYTQyODhhMmZmOGM3MmM2NzhhMTlhZDU2NQ==; __yjs_st=2_NTA2ZGI3NzkyZGNmMzE4M2JkNzk0MTNkMWRmMzBkZmQwNjBlOTYzMDRhZjZmOTJhZGYzOGFjZWRlMTE1NjU4ZTA5ZDljMGQyMjA3Nzk0OWE3NmZhNThjY2YzYTBmMjVhMzAxYmQyZmFkM2VhMTc0YjE5MmJlM2VmZGZlMjhiMzkxMTQzMWY4NGYyNzZkNjM1YjE2ZjNhYjA4M2ViZmNmZDU2YWQzMzc0N2YzMGFiZGVhZTY5NzRiMjc0MzdlMjdjYTM2MGU2OGJmYTJhM2VhZWJiNzIxYWEyODc1ODZlZTBlOGYwOTM1ZWNkMjE4YzM0ZDFiMTY1YjgwMDNmZjhjZV83X2NjZDQ3NTdj &#x27;&#125;def get_word_means():    query = input(&#x27;Please input you query words:&#x27;)    sign = get_word_sign(query)    data = &#123;        &quot;from&quot;: &quot;zh&quot;,        &quot;to&quot;: &quot;en&quot;,        &quot;query&quot;: query,        &quot;transtype&quot;: &quot;translang&quot;,        &quot;simple_means_flag&quot;: &quot;3&quot;,        &quot;sign&quot;: sign,        &quot;token&quot;: &quot;cb25a0d7b1d3837fe7864c5c87559d98&quot;,    &#125;    response = requests.request(&quot;POST&quot;, url, headers=headers, data=data)    json_result = response.json()    result = jsonpath.jsonpath(json_result, &quot;$..word_means&quot;)[0]    print(result)if __name__ == &#x27;__main__&#x27;:    get_word_means()\n\n下面附上完整代码:\njs_reverse_baidufanyi:\nimport execjsjsCode = &quot;&quot;&quot;    function a(r) &#123;        if (Array.isArray(r)) &#123;            for (var o = 0, t = Array(r.length); o &lt; r.length; o++)                t[o] = r[o];            return t        &#125;        return Array.from(r)    &#125;    function n(r, o) &#123;        for (var t = 0; t &lt; o.length - 2; t += 3) &#123;            var a = o.charAt(t + 2);            a = a &gt;= &quot;a&quot; ? a.charCodeAt(0) - 87 : Number(a),            a = &quot;+&quot; === o.charAt(t + 1) ? r &gt;&gt;&gt; a : r &lt;&lt; a,            r = &quot;+&quot; === o.charAt(t) ? r + a &amp; 4294967295 : r ^ a        &#125;        return r    &#125;    var i = null;    function e(r) &#123;        var t = r.length;        t &gt; 30 &amp;&amp; (r = &quot;&quot; + r.substr(0, 10) + r.substr(Math.floor(t / 2) - 5, 10) + r.substr(-10, 10))        var u = void 0, l = &quot;&quot; + String.fromCharCode(103) + String.fromCharCode(116) + String.fromCharCode(107);        u = null !== i ? i : (i = &#x27;320305.131321201&#x27; || &quot;&quot;) || &quot;&quot;;        for (var d = u.split(&quot;.&quot;), m = Number(d[0]) || 0, s = Number(d[1]) || 0, S = [], c = 0, v = 0; v &lt; r.length; v++) &#123;            var A = r.charCodeAt(v);            128 &gt; A ? S[c++] = A : (2048 &gt; A ? S[c++] = A &gt;&gt; 6 | 192 : (55296 === (64512 &amp; A) &amp;&amp; v + 1 &lt; r.length &amp;&amp; 56320 === (64512 &amp; r.charCodeAt(v + 1)) ? (A = 65536 + ((1023 &amp; A) &lt;&lt; 10) + (1023 &amp; r.charCodeAt(++v)),            S[c++] = A &gt;&gt; 18 | 240,            S[c++] = A &gt;&gt; 12 &amp; 63 | 128) : S[c++] = A &gt;&gt; 12 | 224,            S[c++] = A &gt;&gt; 6 &amp; 63 | 128),            S[c++] = 63 &amp; A | 128)        &#125;        for (var p = m, F = &quot;&quot; + String.fromCharCode(43) + String.fromCharCode(45) + String.fromCharCode(97) + (&quot;&quot; + String.fromCharCode(94) + String.fromCharCode(43) + String.fromCharCode(54)), D = &quot;&quot; + String.fromCharCode(43) + String.fromCharCode(45) + String.fromCharCode(51) + (&quot;&quot; + String.fromCharCode(94) + String.fromCharCode(43) + String.fromCharCode(98)) + (&quot;&quot; + String.fromCharCode(43) + String.fromCharCode(45) + String.fromCharCode(102)), b = 0; b &lt; S.length; b++)            p += S[b],            p = n(p, F);        return p = n(p, D),        p ^= s,        0 &gt; p &amp;&amp; (p = (2147483647 &amp; p) + 2147483648),        p %= 1e6,        p.toString() + &quot;.&quot; + (p ^ m)    &#125;&quot;&quot;&quot;def get_word_sign(query):    sign = execjs.compile(jsCode).call(&quot;e&quot;, query)    return sign\n\ntest_baidu_jscode:\nimport requestsfrom test_baidu_jscode import get_word_signimport jsonpathurl = &quot;https://fanyi.baidu.com/v2transapi?from=zh&amp;to=en&quot;headers = &#123;    &#x27;Connection&#x27;: &#x27;keep-alive&#x27;,    &#x27;sec-ch-ua&#x27;: &#x27;&quot; Not;A Brand&quot;;v=&quot;99&quot;, &quot;Google Chrome&quot;;v=&quot;97&quot;, &quot;Chromium&quot;;v=&quot;97&quot;&#x27;,    &#x27;Accept&#x27;: &#x27;*/*&#x27;,    &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded; charset=UTF-8&#x27;,    &#x27;X-Requested-With&#x27;: &#x27;XMLHttpRequest&#x27;,    &#x27;sec-ch-ua-mobile&#x27;: &#x27;?0&#x27;,    &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &#x27;                  &#x27;Chrome/97.0.4692.71 Safari/537.36&#x27;,    &#x27;sec-ch-ua-platform&#x27;: &#x27;&quot;Windows&quot;&#x27;,    &#x27;Origin&#x27;: &#x27;https://fanyi.baidu.com&#x27;,    &#x27;Sec-Fetch-Site&#x27;: &#x27;same-origin&#x27;,    &#x27;Sec-Fetch-Mode&#x27;: &#x27;cors&#x27;,    &#x27;Sec-Fetch-Dest&#x27;: &#x27;empty&#x27;,    &#x27;Referer&#x27;: &#x27;https://fanyi.baidu.com/?aldtype=16047&#x27;,    &#x27;Accept-Language&#x27;: &#x27;zh-CN,zh;q=0.9&#x27;,    &#x27;Cookie&#x27;: &#x27;BIDUPSID=CF86A0FA51038D0CA02DA9FC43B164F5; PSTM=1639146064; &#x27;              &#x27;BAIDUID=CF86A0FA51038D0CFFCCCD08415508DA:FG=1; &#x27;              &#x27;__yjs_duid=1_689d947b2f957f0b0d895ae63c66114f1639229602485; &#x27;              &#x27;BAIDUID_BFESS=3A9FDFF925D6EA302A897713757BE825:FG=1; BDRCVFR[iqrboYocJ-C]=kRxlD0AvOmRPjIMTz4WUvY; &#x27;              &#x27;BDRCVFR[fq555l35Iot]=EBD6F1bEM2tXZKdrHn8mvqV; delPer=0; BDORZ=FFFB88E999055A3F8A630C64834BD6D0; &#x27;              &#x27;BDRCVFR[3lgytkvnri6]=mk3SLVN4HKm; H_PS_PSSID=; REALTIME_TRANS_SWITCH=1; FANYI_WORD_SWITCH=1; &#x27;              &#x27;HISTORY_SWITCH=1; SOUND_PREFER_SWITCH=1; SOUND_SPD_SWITCH=1; APPGUIDE_10_0_2=1; &#x27;              &#x27;Hm_lvt_64ecd82404c51e03dc91cb9e8c025574=1642227471,1642227478; PSINO=6; &#x27;              &#x27;BA_HECTOR=2hag052ha52h010lkt1gu4ujh0r; Hm_lpvt_64ecd82404c51e03dc91cb9e8c025574=1642233008; &#x27;              &#x27;ab_sr=1.0&#x27;              &#x27;.1_NjI2ZDk1Y2JmYzQ2ZTBiNTZmNWIyZjllNTU4ZjE4MmM1ZTI2ZmVjMjAyNmJhN2E5NGJhNWVjYmM2OWFmMTRjOTE0ZDQ2M2Y5MmY5N2RmNDUzNzYwNGJjZmZlYmVhZjZjMjgzYWI5YjhhZDJlNzg0NTNiZjRmNjhmMzU5ZDIxNzhkNzhiNDlmYTQyODhhMmZmOGM3MmM2NzhhMTlhZDU2NQ==; __yjs_st=2_NTA2ZGI3NzkyZGNmMzE4M2JkNzk0MTNkMWRmMzBkZmQwNjBlOTYzMDRhZjZmOTJhZGYzOGFjZWRlMTE1NjU4ZTA5ZDljMGQyMjA3Nzk0OWE3NmZhNThjY2YzYTBmMjVhMzAxYmQyZmFkM2VhMTc0YjE5MmJlM2VmZGZlMjhiMzkxMTQzMWY4NGYyNzZkNjM1YjE2ZjNhYjA4M2ViZmNmZDU2YWQzMzc0N2YzMGFiZGVhZTY5NzRiMjc0MzdlMjdjYTM2MGU2OGJmYTJhM2VhZWJiNzIxYWEyODc1ODZlZTBlOGYwOTM1ZWNkMjE4YzM0ZDFiMTY1YjgwMDNmZjhjZV83X2NjZDQ3NTdj &#x27;&#125;def get_word_means():    query = input(&#x27;Please input you query words:&#x27;)    sign = get_word_sign(query)    data = &#123;        &quot;from&quot;: &quot;zh&quot;,        &quot;to&quot;: &quot;en&quot;,        &quot;query&quot;: query,        &quot;transtype&quot;: &quot;translang&quot;,        &quot;simple_means_flag&quot;: &quot;3&quot;,        &quot;sign&quot;: sign,        &quot;token&quot;: &quot;cb25a0d7b1d3837fe7864c5c87559d98&quot;,    &#125;    response = requests.request(&quot;POST&quot;, url, headers=headers, data=data)    json_result = response.json()    result = jsonpath.jsonpath(json_result, &quot;$..word_means&quot;)[0]    print(result)if __name__ == &#x27;__main__&#x27;:    get_word_means()\n\n运行效果:\n\n"},{"title":"Goland编辑器配置GOROOT时报错The selected directory is not a valid home for Go SDK的解决方法","url":"/2022/01/15/Goland%E7%BC%96%E8%BE%91%E5%99%A8%E9%85%8D%E7%BD%AEGOROOT%E6%97%B6%E6%8A%A5%E9%94%99The%20selected%20directory%20is%20not%20a%20valid%20home%20for%20Go%20SDK%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","content":"操作系统: win10\nGo版本: 1.17.3\n集成开发环境版本: GoLand 2019.3\nGoLand指定Go版本报错: The selected directory is not a valid home for Go SDK\n解决方法:\n打开Go的安装目录，我这里的是: C:\\Program Files\\Go\n然后进入这个文件: src\\runtime\\internal\\sys\\zversion.go\n添加一条\nconst TheVersion = `go1.17.3`\n\n然后即可添加，添加C:\\Program Files\\Go这个路径即可\n"},{"title":"Git命令行提交代码到GitHub或GitLab的几个基础步骤","url":"/2022/01/15/Git%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%8F%90%E4%BA%A4%E4%BB%A3%E7%A0%81%E5%88%B0GitHub%E6%88%96GitLab%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9F%BA%E7%A1%80%E6%AD%A5%E9%AA%A4/","content":"首先我们有一个项目，它有如下文件:\n\n其实只有两个文件是真正属于我们项目中的，红框中的.idea是Jetbrain这一款编辑器自动生成的，这里由于我已经提交过所以生成了红框之外的.git文件，这里我们看到这个.git文件夹的颜色有点透明，这表明这个是个隐藏文件，只不过我设置了显示隐藏文件所以能看到，实际上它是由Git命令git init生成的\n这里我们假设项目中只有红框中的后两个文件，那么如何提交呢\n第一步: git init\n命令解释: 初始化(生成并做一些默认配置)一个空的git本地仓库，执行完上面的命令，当前目录下会自动生成.git隐藏文件夹，该隐藏文件夹就是git版本库\n第二步: git remote add origin 远程仓库地址\n命令解释: 这是一个添加远程仓库的命令，origin是给远程仓库起的一个别名\n命令格式:\ngit remote add [shortname] [url]\n\n第三步: git add 要上传的文件\n命令解释: 添加要上传的文件，提交到暂缓区，如果全部添加就git add .，这里的.就代表当前目录下的所有文件\n第四步: git commit -m &quot;备注信息&quot;\n命令解释: 这是将暂缓区内容提交到本地仓库，然后-m后面可以用引号包裹一些备注信息\n扩展一下，将-m改成-a的话，那下次如果修改这个文件就需要执行git add命令，直接就提交到本地仓库，后面仍然可以用引号包裹一些备注信息\n第五步: git push -u origin master\n命令格式: \ngit push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;\n\n命令解释: 上面的命令是将本地的master分支推送到origin仓库的master分支；如果后者不存在，则会被新建，比如git push origin master，同时**-u指定origin为默认主机，后面就可以不加任何参数使用git push直接提交**\n注意: 分支推送顺序的写法是&lt;来源地&gt;:&lt;目的地&gt;，所以git pull是&lt;远程分支&gt;:&lt;本地分支&gt;，而git push是&lt;本地分支&gt;:&lt;远程分支&gt;，上面命令没有写冒号，这表示本地和远程都是master分支，而如果带了冒号且省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支，下面的命令表示删除origin仓库的master分支\ngit push origin :master等同于:git push origin --delete master\n\n题外话: 在你接管别人的工作电脑之后，你需要重设提交的用户信息，包括用户名和邮箱:\ngit config --global user.name &#x27;username&#x27;git config --global user.email test@abc.com\n\n如果去掉 --global 参数就表示只对当前仓库有效\n"},{"title":"GoLand编辑器运行Go代码报错-package XXX is not in GOROOT (XXXXGosrcXXX)的解决方法","url":"/2022/01/16/GoLand%E7%BC%96%E8%BE%91%E5%99%A8%E8%BF%90%E8%A1%8CGo%E4%BB%A3%E7%A0%81%E6%8A%A5%E9%94%99-package%20XXX%20is%20not%20in%20GOROOT%20(XXXXGosrcXXX)%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","content":"操作系统: win10\nGo版本: 1.17.3\n集成开发环境版本: GoLand 2019.3\nGoLand编辑器运行Go代码报错: package XXX is not in GOROOT (XXXXGosrcXXX)\n问题分析:\n报错显示它是在寻找GOROOT下的包，应该是路径问题，或者环境设置问题，输入go env检查了一下环境，发现GO111MODULE=on，编译器没有去gopath下找包，在 gomod 模式下，查找包就不会去 gopath 查找\n解决方法:\n打开cmd，然后输入以下命令(设置GO111MODULE为off即可):\ngo env -w GO111MODULE=off\n\n"},{"title":"推荐一个面试题分享网站--来自鱼皮","url":"/2022/01/16/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AA%E9%9D%A2%E8%AF%95%E9%A2%98%E5%88%86%E4%BA%AB%E7%BD%91%E7%AB%99--%E6%9D%A5%E8%87%AA%E9%B1%BC%E7%9A%AE/","content":"鱼皮大神新上线了一个面试题分享网站，感觉挺有意思的，点击跳转\n"},{"title":"CSDN的社区板块--一块宝地","url":"/2022/01/16/CSDN%E7%9A%84%E7%A4%BE%E5%8C%BA%E6%9D%BF%E5%9D%97--%E4%B8%80%E5%9D%97%E5%AE%9D%E5%9C%B0/","content":"CSDN的社区板块真是一块宝地，点击跳转\n"},{"title":"关于Go的学习资讯宝藏站点--Go语言中文网","url":"/2022/01/16/%E5%85%B3%E4%BA%8EGo%E7%9A%84%E5%AD%A6%E4%B9%A0%E8%B5%84%E8%AE%AF%E5%AE%9D%E8%97%8F%E7%AB%99%E7%82%B9--Go%E8%AF%AD%E8%A8%80%E4%B8%AD%E6%96%87%E7%BD%91/","content":"今天在查资料的时候偶然访问到这个站点，发现挺不错的，有各种优质的文章和技术分享，项目以及图书，还有关于Go的官方文档，点击跳转\n\n"},{"title":"Sublime如何添加Gobuildsystem并运行Go代码","url":"/2022/01/17/Sublime%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0Gobuildsystem%E5%B9%B6%E8%BF%90%E8%A1%8CGo%E4%BB%A3%E7%A0%81/","content":"今天早上来到公司，这边电脑是没有Goland编辑器的，这边有Sublime然后就想着在Sublime上写示例代码，下面来讲讲如何在Sublime上运行Go代码:\n首先你需要安装Go的开发环境，并添加到环境变量，一般在安装的时候会默认添加，然后就看以下操作了:\n\n打开Sublime然后点击tools再点击Build System再点击New Build System:\n\n\n然后复制以下代码并保存(可以命名为go-sublime-build):\n&#123;    &quot;cmd&quot;: [&quot;go&quot;, &quot;run&quot;, &quot;$file_name&quot;],     &quot;file_regex&quot;: &quot;^[ ]*File \\&quot;(…*?)\\&quot;, line ([0-9]*)&quot;,     &quot;working_dir&quot;: &quot;$file_path&quot;,     &quot;selector&quot;: &quot;source.go&quot; &#125;\n\n注意：文件直接保存在默认打开的位置，不要另存到新的文件夹\n\n然后便可以运行Go代码啦(CTRL+B运行)\n\n\n\n"},{"title":"推荐一个关于Go文档以及面试题的网站--来自Go学习群","url":"/2022/01/18/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AA%E5%85%B3%E4%BA%8EGo%E6%96%87%E6%A1%A3%E4%BB%A5%E5%8F%8A%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9A%84%E7%BD%91%E7%AB%99--%E6%9D%A5%E8%87%AAGo%E5%AD%A6%E4%B9%A0%E7%BE%A4/","content":"今天在Go语言中文网的QQ群中发现了一个分享Go文档以及面试题的网站，感觉挺不错的，点击跳转:\n\n关于Go面试题，点这里直达\n"},{"title":"Python装饰器详解","url":"/2022/01/17/Python%E8%A3%85%E9%A5%B0%E5%99%A8%E8%AF%A6%E8%A7%A3/","content":"首先我们看看什么是装饰器:\nPython装饰器(decorator)就是用于拓展原来函数功能的一种函数，目的是在不改变原函数名(或类名)的情况下，给函数增加新的功能；在代码运行期间动态增加功能的方式，称之为”装饰器”\n这个函数的特殊之处在于它的返回值也是一个函数，这个函数是内嵌原函数的函数\n一般而言，我们要想拓展原来函数代码以达到扩展功能的目的，最直接的办法就是侵入代码里面修改，例如:\nimport timedef f():    print(&quot;hello&quot;)    time.sleep(1)    print(&quot;world&quot;)\n\n上面是我们最原始的一个函数，打印hello等待1秒钟然后再打印world，然后我们要增加一个功能(记录这个函数执行的总时间)，那最简单的做法就是改动原来的代码，改动之后是这样的:\nimport timedef f():    start_time = time.time()    print(&quot;hello&quot;)    time.sleep(1)    print(&quot;world&quot;)    end_time = time.time()    execution_time = (end_time - start_time)*1000    print(&quot;time is %d ms&quot; %execution_time)\n\n但是实际工作中，有些时候核心代码并不可以直接去改，所以在不改动原代码的情况下，我们可以再定义一个函数(就比如下面的deco函数)去包裹另外一个函数(f函数)，从而在deco函数中增加功能(嵌入了计时功能)，就比如下面的例子:\nimport timedef deco(func):    start_time = time.time()    f()    end_time = time.time()    execution_time = (end_time - start_time)*1000    print(&quot;time is %d ms&quot; %execution_time)def f():    print(&quot;hello&quot;)    time.sleep(1)    print(&quot;world&quot;)if __name__ == &#x27;__main__&#x27;:    deco(f)    print(&quot;f.__name__ is&quot;,f.__name__)    print()\n\n这确实实现了不修改原来函数代码的情况下给函数增加功能，调用deco函数就会执行f函数，然后执行实现新增功能的代码，既然要在deco函数中执行f函数，那就需要把f函数作为参数传入deco函数中，上面的代码实际上传的是f函数的地址，但一个函数名就指代着这个函数在内存中存放的地址，但是这看来表面调用的还是deco函数，既然要装饰那就是修饰函数并就调用这个函数，所以接下来我们试着用装饰器来实现以上计时功能，先来看看装饰器最原始的面貌:\nimport timedef deco(f):    def wrapper():        start_time = time.time()        f()        end_time = time.time()        execution_time = (end_time - start_time)*1000        print(&quot;time is %d ms&quot; %execution_time )    return wrapper@decodef f():    print(&quot;hello&quot;)    time.sleep(1)    print(&quot;world&quot;)if __name__ == &#x27;__main__&#x27;:    f()\n\n这里的deco函数就是最原始的装饰器，它的参数是一个函数，然后返回值也是一个函数；其中作为参数的这个函数f()就在返回函数wrapper()的内部执行。然后在函数f()前面加上@deco；f()函数就相当于被注入了计时功能，现在只要调用f()，它就已经变身为“新的功能更多”的函数了，把@deco放在f()函数前，相当于执行了语句:\nf = deco(f)\n\n现在同名的f变量指向了新的函数，于是调用f()将执行新函数，即在deco()函数中返回的wrapper()函数\n扩展1: 带有固定参数的装饰器\nimport timedef deco(f):    def wrapper(a,b):        start_time = time.time()        f(a,b)        end_time = time.time()        execution_time = (end_time - start_time)*1000        print(&quot;time is %d ms&quot; % execution_time)    return wrapper@decodef f(a,b):    print(&quot;be on&quot;)    time.sleep(1)    print(&quot;result is %d&quot; %(a+b))if __name__ == &#x27;__main__&#x27;:    f(3,4)\n\n扩展1: 无固定参数的装饰器\nimport timedef deco(f):    def wrapper(*args, **kwargs):        start_time = time.time()        f(*args, **kwargs)        end_time = time.time()        execution_time_ = (end_time - start_time)*1000        print(&quot;time is %d ms&quot; %execution_time)    return wrapper@decodef f(a,b):    print(&quot;be on&quot;)    time.sleep(1)    print(&quot;result is %d&quot; %(a+b))@decodef f2(a,b,c):    print(&quot;be on&quot;)    time.sleep(1)    print(&quot;result is %d&quot; %(a+b+c))if __name__ == &#x27;__main__&#x27;:    f2(3,4,5)    f(3,4)\n\n扩展3: 使用多个装饰器，装饰一个函数\nimport timedef deco01(f):    def wrapper(*args, **kwargs):        print(&quot;this is deco01&quot;)        start_time = time.time()        f(*args, **kwargs)        end_time = time.time()        execution_time = (end_time - start_time)*1000        print(&quot;time is %d ms&quot; % execution_time)        print(&quot;deco01 end here&quot;)    return wrapperdef deco02(f):    def wrapper(*args, **kwargs):        print(&quot;this is deco02&quot;)        f(*args, **kwargs)        print(&quot;deco02 end here&quot;)    return wrapper@deco01@deco02def f(a,b):    print(&quot;be on&quot;)    time.sleep(1)    print(&quot;result is %d&quot; %(a+b))if __name__ == &#x27;__main__&#x27;:    f(3,4)\n\n装饰器的调用顺序:\n像上面的代码中，装饰器是可以叠加使用的，那么使用装饰器以后代码是啥顺序呢?\n对于Python中的”@”语法糖，装饰器的调用顺序与使用”@”语法糖的顺序相反，在上面的例子中，”f(3, 4) = deco01(deco02(f(3, 4)))”\nPython内置装饰器:\n在Python中有三个内置的装饰器，都是跟class相关的：staticmethod、classmethod 和property\n\nstaticmethod 是类静态方法，其跟成员方法的区别是没有 self 参数，并且可以在类不进行实例化的情况下调用\n\nclassmethod 与成员方法的区别在于所接收的第一个参数不是 self(指向当前类实例，也就是指向当前对象)，而是cls(指向当前类)\n\nproperty 是属性的意思，通过 @property 装饰器，可以直接通过方法名来访问方法，不需要在方法名后添加一对”()”小括号\n@property的语法格式如下:\n@propertydef 方法名(self)    代码块\n\n例如，定义一个矩形类，并定义用 @property 修饰的方法操作类中的 area 私有属性，代码如下:\nclass Rect:    def __init__(self,area):        self.__area = area    @property    def area(self):        return self.__arearect = Rect(30)#直接通过方法名来访问 area 方法print(&quot;矩形的面积是：&quot;,rect.area)\n\n运行结果为:\n矩形的面积为： 30\n\n上面程序中，使用 ＠property 修饰了 area() 方法，这样就使得该方法变成了 area 属性的 getter 方法。需要注意的是，如果类中只包含该方法，那么 area 属性将是一个只读属性，也就是说，在使用 Rect 类时，无法对 area 属性重新赋值，即运行如下代码会报错:\nrect.area = 90print(&quot;修改后的面积：&quot;,rect.area)\n\n报错信息为:\nTraceback (most recent call last):  File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 10, in &lt;module&gt;    rect.area = 90AttributeError: can&#x27;t set attribute\n\n而要想实现修改 area 属性的值，还需要为 area 属性添加 setter 方法，就需要用到 setter 装饰器，它的语法格式如下:\n@方法名.setterdef 方法名(self, value):    代码块\n\n例如，为 Rect 类中的 area 方法添加 setter 方法，代码如下:\n@area.setterdef area(self, value):    self.__area = value\n\n再次运行如下代码:\nrect.area = 90print(&quot;修改后的面积：&quot;,rect.area)\n\n运行结果为:\n修改后的面积: 90\n\n这样，area 属性就有了 getter 和 setter 方法，该属性就变成了具有读写功能的属性\n除此之外，还可以使用 deleter 装饰器来删除指定属性，其语法格式为:\n@方法名.deleterdef 方法名(self):    代码块\n\n例如，在 Rect 类中，给 area() 方法添加 deleter 方法，实现代码如下:\n@area.deleterdef area(self):    self.__area = 0\n\n然后运行如下代码:\ndel rect.area    print(&quot;删除后的area值为：&quot;,rect.area)\n\n运行结果为:\n删除后的area值为： 0\n\n\n 案例: 不使用property装饰器实现分页\n\n  1 #不使用property装饰器实现分页 2  3 li=[x for x in range(100)] 4 class PageBean: 5     def __init__(self,value): 6         if value.isdigit(): 7             self.page=int(value) 8         else: 9             self.page=1       10     def start(self):11         return (self.page-1)*1012     def end(self):13         return self.page*1014 while True:15    p=input(&quot;请输入你要查看的页码(退出请按0):&quot;)16    if not(p.isdigit()):17        print(&quot;输入错误，请重新输入&quot;)18    else:19        if int(p)==0:20            break21        else:22            pageBean=PageBean(p)23            liP=li[pageBean.start():pageBean.end()]24            print(liP)\n\n\n案例: 使用property装饰器实现分页\n1 #利用property装饰器实现分页 2  3 li=[x for x in range(100)] 4 class PageBean: 5     def __init__(self,value): 6         if value.isdigit(): 7             self.page=int(value) 8         else: 9             self.page=110     #使用property装饰器进行装饰11     @property 12     def start(self):13         return (self.page-1)*1014     @property15     def end(self):16         return self.page*1017 while True:18    p=input(&quot;请输入你要查看的页码(退出请按0):&quot;)19    if not(p.isdigit()):20        print(&quot;输入错误，请重新输入&quot;)21    else:22        if int(p)==0:23            break24        else:25            pageBean=PageBean(p)26            liP=li[pageBean.start:pageBean.end]#此处调用不用括号，形式上和属性一直27            print(liP)\n\n"},{"title":"Python爬虫框架Scrapy的运行流程详解","url":"/2022/01/17/Python%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy%E7%9A%84%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3/","content":"首先来看看Scrapy框架的介绍:\nScrapy是用纯Python语言实现的一个为爬取网站数据、提取结构性数据而编写的应用框架，Scrapy使用了Twisted异步网络框架来处理网络通信，可以加快我们的下载速度，不用自己去实现异步框架，并且包含了各种中间件接口，可以灵活地实现各种需求；Scrapy可以应用在包括数据挖掘、信息处理或存储历史数据等一系列的程序中，其最初是为页面抓取(更确切地说是网络抓取)而设计的，也可以应用于获取API所返回的数据(例如Amazon Associates Web Services)或者通用的网络爬虫\nScrapy框架的安装方法:\n\n通过anaconda安装: 通过anaconda→environments→最右边界面的第一个选项all，在搜索框里搜索scrapy→选择安装\n\n在terminal或者cmd中使用pip安装:\npip install scrapy\n\nScrapy内部实现了包括并发请求、免登录、URL去重等很多复杂操作，用户不需要明白Scrapy内部具体的爬取策略，只需要根据自己的需求去编写小部分的代码，就能抓取到所需要的数据\nScrapy框架整体流程图如下所示:\n\n上图所表达的大致意思为: 首先从初始URL开始，调度器(Scheduler)会将其交给下载器(Downloader)，下载器向网络服务器(Internet)发送服务请求以进行下载，得到响应后将下载的数据交给爬虫(Spider，爬虫会对网页进行分析，分析出来的结果有两种：一种是需要进一步抓取的链接，这些链接会被传回调度器；另一种是需要保存的数据，它们则被送到项目管道（Item Pipeline），Item会定义数据格式，最后由Pipeline对数据进行清洗、去重等处理，继而存储到文件或数据库，这里面的引擎是负责统筹协调\nScrapy框架内组件及其作用:\n\n爬虫中间件(Spider Middleware):位于Scrapy引擎和爬虫之间的框架，主要用于处理爬虫的请求输入和响应输出\n调度器中间件(Scheduler Middleware): 位于Scrapy引擎和调度器之间的框架，主要用于处理从Scrapy引擎发送到调度器的请求和响应\n调度器：用来接收引擎发过来的请求，压入队列中，并在引擎再次请求的时候返回。它就像是一个URL的优先队列，由它来决定下一个要抓取的网址是什么，同时在这里会去除重复的网址\n下载器中间件(Downloader Middleware): 位于Scrapy引擎和下载器之间的框架，主要用于处理Scrapy引擎与下载器之间的请求及响应; 代理IP和用户代理可以在这里设置\n下载器：用于下载网页内容，并将网页内容返回给爬虫\nScrapy引擎(ScrapyEngine): 用来控制整个系统的数据处理流程，并进行事务处理的触发\n爬虫主要是干活的，用于从特定网页中提取自己需要的信息，即所谓的项目(又称实体); 也可以从中提取URL，让Scrapy继续爬取下一个页面\n项目管道：负责处理爬虫从网页中爬取的项目，主要的功能就是持久化项目(保存数据)、验证项目的有效性、清除不需要的信息。当页面被爬虫解析后，将被送到项目管道，并经过几个特定的次序来处理其数据\n\nScrapy框架运行流程如下:\n\n引擎从调度器中取出一个URL用于接下来的抓取\n引擎把URL封装成一个请求（request）传给下载器\n下载器把资源下载下来，并封装成一个响应(response)\n爬虫解析响应\n解析出的是项目，则交给项目管道进行进一步的处理(持久化存储)\n解析出的是链接URL，则把URL交给调度器等待下一步的抓取\n\nScrapy框架数据流向:\nScrapy数据流是由执行流程的核心引擎来控制的，如下图所示:\n\n引擎打开网站，找到处理该网站的爬虫并要求该爬虫请求第一个要爬取的URL(入口URL)\n引擎从爬虫中获取到第一个要爬取的URL，并在调度器中以请求调度\n引擎向调度器请求下一个要爬取的URL\n调度器返回下一个要爬取的URL给引擎，引擎通过下载中间件转给下载器\n一旦页面下载完毕，下载器便会生成一个该页面的响应，并通过下载器中间件将其发送给引擎\n引擎从下载器中接收到响应并通过爬虫中间件发送给爬虫处理\n爬虫处理响应，并返回爬取到的项目及新的请求给引擎\n引擎将爬虫爬取到的项目传给项目管道，将爬虫返回的请求传给调度器\n从第2步重复直到调度器中没有更多的请求，引擎便会关闭该网站\n\nScrapy框架中的Selector\n当我们取得了网页的响应之后，最关键的就是如何从繁杂的网页中把我们需要的数据提取出来，Python中常用以下模块来处理HTTP文本解析问题\n\nBeautifulSoup: 作为程序员间非常流行的网页分析库，它通常基于HTML代码的结构来构造一个Python对象，对不良标记的处理也非常合理，但它有一个缺点，就是“慢”\nlxml: 一个基于ElementTree的Python化的XML解析库\n\n我们可以在Scrapy中使用任意熟悉的网页数据提取工具，如上面的两种，但是，Scrapy本身也为我们提供了一套提取数据的机制，我们称之为选择器Selector，它通过特定的XPath或者CSS表达式来选择HTML文件中的某个部分\nXPath是一门用来在XML文件中选择节点的语言，也可以用在HTML上。CSS是一门将HTML文档样式化的语言。选择器由它定义，并与特定的HTML元素的样式相关连\nSelector是基于lxml来构建的，支持XPath选择器、CSS选择器以及正则表达式，功能全面、解析速度快且和准确度高\n"},{"title":"Python获取本机IP、Mac地址和计算机名","url":"/2022/01/18/Python%E8%8E%B7%E5%8F%96%E6%9C%AC%E6%9C%BAIP%E3%80%81mac%E5%9C%B0%E5%9D%80%E3%80%81%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%90%8D/","content":"获得本机Mac地址:\nimport uuiddef get_mac_address():     mac=uuid.UUID(int = uuid.getnode()).hex[-12:]     return &quot;:&quot;.join([mac[e:e+2] for e in range(0,11,2)])\n\n\n获得本机IP(内网IP)和计算机名:\nimport socket#获取本机电脑名myname = socket.getfqdn(socket.gethostname())#获取本机ipmyaddr = socket.gethostbyname(myname)print (myname)print (myaddr)\n\n\n"},{"title":"使用jsonpath.jsonpath()来解析json字符串的坑","url":"/2022/01/18/%E4%BD%BF%E7%94%A8jsonpath.jsonpath()%E6%9D%A5%E8%A7%A3%E6%9E%90json%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%9D%91/","content":"今天在爬网站的时候，由于页面的detail_url在json字符串中，所以用到了jsonpath.jsonpa()这个方法来解析，这个方法解析字符串是很方便的，但是今天遇到了一个坑，下面来详细说明下:\n首先我们来说下这个方法的使用:\nimport jsonpathjsonstr = &#x27;&#123;&quot;ok&quot;:true,&quot;code&quot;:200,&quot;msg&quot;:null,&quot;data&quot;:&#123;&quot;totalHits&quot;:92,&quot;resultList&quot;:[&#123;&quot;summary&quot;:&quot;相关链接 国家烟草专卖局关于印发深化 证照分离 改革进一步激发市场主体发展活力实施方案的通知 国家烟草专卖&quot;,&quot;dreDate&quot;:1638251577000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;图解：《国家烟草专卖局关于印发深化“证照分离”改革进一步激发市场主体发展活力实施方案的通知》政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-11-30&quot;,&quot;title&quot;:&quot;图解：《国家烟草专卖局关于印发深化“证照分离”改革进一步激发市场主体发展活力实施方案的通知》政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202111/00fd8aac999443c2963d2714c10c26b2.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;D69C44FE5971BE1672E2BDE4BA9562BC&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-11-30T06:02:40.050&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202111/00fd8aac999443c2963d2714c10c26b2.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;图解：《国家烟草专卖局关于印发深化“证照分离”改革进一步激发市场主体发展活力实施方案的通知》政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;相关链接 国家烟草专卖局关于印发深化 证照分离 改革进一步激发市场主体发展活力实施方案的通知        国家烟草专卖&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1638251577&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;专卖业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;E43D6D583F742C59F73173EA305E0B8D&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;图解 国家烟草专卖局关于印发深化 证照分离 改革进一步激发市场主体发展活力实施方案的通知 政策解读&quot;,&quot;MD5TITLE&quot;:&quot;F1DEDFBA3D25A848EFAA312948A6E771&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;   相关链接 国家烟草专卖局关于印发深化 证照分离 改革进一步激发市场主体发展活力实施方案的通知        国家烟草专卖局关于印发深化 证照分离 改革进一步激发市场主体发展活力实施方案的通知 政策解读&quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;D69C44FE5971BE1672E2BDE4BA9562BC&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-11-30 13:52:57&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E29E654EF36AC5EEFFF56BD21DF28EFF7BBA4B400CF734F62934AE927F760C40E902559609C9965735295CA877351025F6E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;一 背景依据 今年5月 国务院印发了 关于深化 证照分离 改革进一步激发市场主体发展活力的通知 国发 2021 7号&quot;,&quot;dreDate&quot;:1637803246000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;《国家烟草专卖局关于印发深化“证照分离”改革进一步激发市场主体发展活力实施方案的通知》政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-11-25&quot;,&quot;title&quot;:&quot;《国家烟草专卖局关于印发深化“证照分离”改革进一步激发市场主体发展活力实施方案的通知》政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202111/6b0064505b89450b8c965781ba24d1dd.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;C4B055582B5865A17CEABA4703757497&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-11-30T06:02:40.057&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202111/6b0064505b89450b8c965781ba24d1dd.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;《国家烟草专卖局关于印发深化“证照分离”改革进一步激发市场主体发展活力实施方案的通知》政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;一 背景依据  今年5月 国务院印发了 关于深化 证照分离 改革进一步激发市场主体发展活力的通知  国发 2021 7号&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1637803246&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;专卖业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;D68F3CF9C6B9B7E6EF504BE93A98B68A&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;国家烟草专卖局关于印发深化 证照分离 改革进一步激发市场主体发展活力实施方案的通知 政策解读&quot;,&quot;MD5TITLE&quot;:&quot;9093B824D4212053CA21B413450F4E30&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;一 背景依据  今年5月 国务院印发了 关于深化 证照分离 改革进一步激发市场主体发展活力的通知  国发 2021 7号 以下简称 通知   明确了 证照分离 改革的主要目标 基本内容 配套措施 并对如何创新和加强事中事后监管等提出了要求 按照 通知 要求 国务院有关部门要制定实施方案 对中央层面设定的涉企经营许可事项逐项细化改革举措 并向社会公布 根据上述要求 我们结合烟草行业实际 制定印发了 深化 证照分离 改革进一步激发市场主体发展活力实施方案  以下简称 实施方案    二  实施方案 &quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;C4B055582B5865A17CEABA4703757497&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-11-25 09:20:46&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E29E654EF36AC5EEF1E2CD4BBE7A913209BC2F508952E92BD99DEAF78EA8C4AEC55DF4C4FE058EF85F016BE7F7F856C8F6E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;相关链接 国家烟草专卖局关于印发 新时代国家烟草专卖局对口支援兴国县实施方案 的通知 国家烟草专卖局关于&quot;,&quot;dreDate&quot;:1631779320000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;图解：《国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知》的政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-09-16&quot;,&quot;title&quot;:&quot;图解：《国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知》的政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202109/1c6b919c5e3e4a508dda8e07df480eb8.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;3A6748BC7FAFEB972C7748DFAC3312AD&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-09-28T01:32:00.007&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202109/1c6b919c5e3e4a508dda8e07df480eb8.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;图解：《国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知》的政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;相关链接 国家烟草专卖局关于印发 新时代国家烟草专卖局对口支援兴国县实施方案 的通知         国家烟草专卖局关于&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1631779320&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;综合业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;0852298E65D012FECB8DB7E323453781&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;图解 国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知 的政策解读&quot;,&quot;MD5TITLE&quot;:&quot;F2FCA05339837A57685F3687C7A643DE&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;      相关链接 国家烟草专卖局关于印发 新时代国家烟草专卖局对口支援兴国县实施方案 的通知         国家烟草专卖局关于印发的通知 的政策解读    &quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;3A6748BC7FAFEB972C7748DFAC3312AD&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-09-16 16:02:00&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E0D9CD9DD7D6C287A8A32719516DE22DD9E0C33F4BC6BCA48459DFF88F7A6F1D99BA5617CB7EA9E0AF69BCAA7D2CF59616E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;一 国家烟草专卖局关于印发的通知 背景是什么 答 2020年 革命老区兴国县在国家烟草专卖局的助力下 成功脱贫摘帽并&quot;,&quot;dreDate&quot;:1630890520000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;《国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知》的政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-09-06&quot;,&quot;title&quot;:&quot;《国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知》的政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202109/df15e15f738b4c6bb108690f1eebc6ba.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;436700871BF74E853A04248AB5167423&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-09-28T01:17:00.010&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202109/df15e15f738b4c6bb108690f1eebc6ba.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;《国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知》的政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;一  国家烟草专卖局关于印发的通知 背景是什么  答 2020年 革命老区兴国县在国家烟草专卖局的助力下 成功脱贫摘帽并&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1630890520&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;综合业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;5B80A8582470AD3838DE267467BF3FF5&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知 的政策解读&quot;,&quot;MD5TITLE&quot;:&quot;B9B077DAC99F25BDC32271D874861AC6&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;  一  国家烟草专卖局关于印发的通知 背景是什么  答 2020年 革命老区兴国县在国家烟草专卖局的助力下 成功脱贫摘帽并迈入了小康社会 正扬帆启航 向第二个百年奋斗目标进军 革命老区是党和人民军队的根 是中国人民选择中国共产党的历史见证 兴国县是赣南等原中央苏区核心区域 位于多省交界地区 为中国革命作出了巨大贡献和牺牲 目前仍属于欠发达地区 全面建设社会主义现代化国家 实现中华民族伟大复兴 最艰巨最繁重的任务依然在农村 最广泛最深厚的基础依然在农村  对口支援是党中央 国务院确定的乡村振兴重&quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;436700871BF74E853A04248AB5167423&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-09-06 09:08:40&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E0D9CD9DD7D6C287A01BDE8575BB794709865B07DFDD9B03BCFD688859E397CDDA36164114DBD3FF13C9D6C4CD5F466176E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;相关链接 国家烟草专卖局关于印发涉案烟草制品价格管理规定的通知 涉案烟草制品价格管理规&quot;,&quot;dreDate&quot;:1625459828000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;图解：《涉案烟草制品价格管理规定》政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-07-05&quot;,&quot;title&quot;:&quot;图解：《涉案烟草制品价格管理规定》政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202107/6feaebb9c9804b12831f963c8f351265.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;B8F39E42862E282FCD5A1869C2F4DE62&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-07-05T04:45:00.044&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202107/6feaebb9c9804b12831f963c8f351265.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;图解：《涉案烟草制品价格管理规定》政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;相关链接  国家烟草专卖局关于印发涉案烟草制品价格管理规定的通知                 涉案烟草制品价格管理规&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1625459828&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;综合业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;D1F434D44B1CD8A2F863E9A40096E0A9&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;图解 涉案烟草制品价格管理规定 政策解读&quot;,&quot;MD5TITLE&quot;:&quot;F11D3EB1CBD11B69B1269442A11CB467&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;    相关链接  国家烟草专卖局关于印发涉案烟草制品价格管理规定的通知                 涉案烟草制品价格管理规定 政策解读 &quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;B8F39E42862E282FCD5A1869C2F4DE62&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-07-05 12:37:08&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E0D9CD9DD7D6C287A4D2643F7D93F49167FF59D48DE8B2DEEFED96E74DA43B0BB3ADB3FFBEC1E8628A5AB9504D6783C766E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;相关链接 保护未成年人免受烟侵害 守护成长 专项行动方案 政策解读 相关链接 国家烟草专卖局 国家市场监管总局关于&quot;,&quot;dreDate&quot;:1624932097000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;图解：《保护未成年人免受烟侵害“守护成长”专项行动方案》政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-06-29&quot;,&quot;title&quot;:&quot;图解：《保护未成年人免受烟侵害“守护成长”专项行动方案》政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202106/bb6c082ac38443bc9e8b8db6fcbf7f89.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;6121A012BD2698C252B9A4168F78389A&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-06-29T02:45:40.059&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202106/bb6c082ac38443bc9e8b8db6fcbf7f89.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;图解：《保护未成年人免受烟侵害“守护成长”专项行动方案》政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;相关链接  保护未成年人免受烟侵害 守护成长 专项行动方案 政策解读   相关链接 国家烟草专卖局 国家市场监管总局关于&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1624932097&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;专卖业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;C0698BD368F189D3EDA7BFD3A57A26C5&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;图解 保护未成年人免受烟侵害 守护成长 专项行动方案 政策解读&quot;,&quot;MD5TITLE&quot;:&quot;C440B225898302466CF9078A7F27D89A&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;      相关链接  保护未成年人免受烟侵害 守护成长 专项行动方案 政策解读   相关链接 国家烟草专卖局 国家市场监管总局关于印发保护未成年人免受烟侵害 守护成长 专项行动方案的通知 &quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;6121A012BD2698C252B9A4168F78389A&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-06-29 10:01:37&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E29E654EF36AC5EEFDCF30FB9AE09DE8D24D24F9A34728E67B057421018963278E1AC3305CE48020012DDFDB9FD88CD5A6E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;一 修订背景 过程和目的 2011年 为贯彻落实 最高人民法院最高人民检察院关于办理非法生产 销售烟草专卖品等刑事案件具&quot;,&quot;dreDate&quot;:1624259104000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;《涉案烟草制品价格管理规定》政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-06-21&quot;,&quot;title&quot;:&quot;《涉案烟草制品价格管理规定》政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202106/49522d0974f54727aceabc98ba244b2b.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;C5541A612CB84ED024376AA3BBAA5277&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-07-05T04:45:40.069&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202106/49522d0974f54727aceabc98ba244b2b.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;《涉案烟草制品价格管理规定》政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;一 修订背景 过程和目的 2011年 为贯彻落实 最高人民法院最高人民检察院关于办理非法生产 销售烟草专卖品等刑事案件具&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1624259104&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;综合业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;7002C5756236B5DD0F02D62D798148E8&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;涉案烟草制品价格管理规定 政策解读&quot;,&quot;MD5TITLE&quot;:&quot;25886DE15FC2C299BD648B6ED4EB7AF6&quot;,&quot;QUICKDESCRIPTION&quot;:&quot; 一 修订背景 过程和目的 2011年 为贯彻落实 最高人民法院最高人民检察院关于办理非法生产 销售烟草专卖品等刑事案件具体应用法律若干问题的解释  法释 2010 7号 要求 国家烟草专卖局印发了 国家烟草专卖局关于印发涉案卷烟价格管理规定的通知  国烟计 2011 73号  提升了涉案卷烟价格管理工作的水平 随着烟草行业发展的变化 在工作实践中存在现行的管理规定无法全面涵盖各种情况 同时部分条款也不够清晰等问题 有必要进行修订完善 通过开展调研和集中座谈 向社会公开征求意见 充分听取 吸纳行&quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;C5541A612CB84ED024376AA3BBAA5277&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-06-21 15:05:04&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E0D9CD9DD7D6C287A32E51F0BD012ADB53FD65FD6C02468C0D32C633A2B76E33DCD13C032462544EE5E225D74C58E4CAD6E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;为贯彻落实新修订的 中华人民共和国未成年人保护法 关于保护未成年人免受烟 含电子烟 下同 侵害的规定 依法保障和维护未成&quot;,&quot;dreDate&quot;:1623984409000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;《保护未成年人免受烟侵害“守护成长”专项行动方案》政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-06-18&quot;,&quot;title&quot;:&quot;《保护未成年人免受烟侵害“守护成长”专项行动方案》政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202106/47402742590d4e5e9d570894b38d93d8.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;C4FC16F3515CB836A83C5E362A4C869B&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-06-29T02:30:40.054&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202106/47402742590d4e5e9d570894b38d93d8.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;《保护未成年人免受烟侵害“守护成长”专项行动方案》政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;为贯彻落实新修订的 中华人民共和国未成年人保护法 关于保护未成年人免受烟 含电子烟 下同 侵害的规定 依法保障和维护未成&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1623984409&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;专卖业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;A8F96BDC17B46ACB767331CF53EC1430&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;保护未成年人免受烟侵害 守护成长 专项行动方案 政策解读&quot;,&quot;MD5TITLE&quot;:&quot;B6A19CDEF5C13FAAAE5E9CF5280C17B8&quot;,&quot;QUICKDESCRIPTION&quot;:&quot; 为贯彻落实新修订的 中华人民共和国未成年人保护法 关于保护未成年人免受烟 含电子烟 下同 侵害的规定 依法保障和维护未成年人身体健康和合法权益 国家烟草专卖局和国家市场监督管理总局决定联合开展保护未成年人免受烟侵害 守护成长 专项行动 并发布了 保护未成年人免受烟侵害 守护成长 专项行动方案  国烟专 2021 89号  就专项行动的总体要求 主要任务 时间安排和工作要求进行了部署 提出了明确要求  一 开展专项行动的背景和目的 党中央 国务院高度重视未成年人保护工作 尤其关注烟对未成年人身心&quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;C4FC16F3515CB836A83C5E362A4C869B&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-06-18 10:46:49&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E29E654EF36AC5EEF0B5DF92276C560F2DE2DCABBE79E9D732B11513224560F9F49099F430584CE572011B9DF6CD6D65B6E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;相关链接 国家烟草专卖局2021年政务公开工作要点&quot;,&quot;dreDate&quot;:1622615267000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;图解：《国家烟草专卖局2021年政务公开工作要点》&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-06-02&quot;,&quot;title&quot;:&quot;图解：《国家烟草专卖局2021年政务公开工作要点》&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202106/b3c779abbb4846eea148ce1186ca61da.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;F0D77E403013A9DCFB534903E89DC5DE&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-06-24T10:58:39.549&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202106/b3c779abbb4846eea148ce1186ca61da.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;C3&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;图解：《国家烟草专卖局2021年政务公开工作要点》&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;相关链接  国家烟草专卖局2021年政务公开工作要点&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1622615267&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;综合业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;FFA8E61BF4EBCF8F48A4DFC849D33454&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;图解 国家烟草专卖局2021年政务公开工作要点&quot;,&quot;MD5TITLE&quot;:&quot;B157D8F349E113F9D5F4A4F20CDC616A&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;    相关链接  国家烟草专卖局2021年政务公开工作要点 &quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;F0D77E403013A9DCFB534903E89DC5DE&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-06-02 14:27:47&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E0D9CD9DD7D6C287A8CE6DB033156C9BD0224CD11F0C2D97E95B04CD2BC9939187A8577F81E0C121D246FBD8609E652C76E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;相关链接 国家烟草专卖局关于印发政府信息公开工作办法的通知 国家烟草专卖局政府信息公开办法 解读说明&quot;,&quot;dreDate&quot;:1620887499000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;图解：《国家烟草专卖局政府信息公开办法》解读说明&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-05-13&quot;,&quot;title&quot;:&quot;图解：《国家烟草专卖局政府信息公开办法》解读说明&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202105/982c1e243ac74e8d93ff8433c286aa28.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;B5B2AF9A5F591B806C10CB6CC7F87AD6&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-06-24T10:58:39.395&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202105/982c1e243ac74e8d93ff8433c286aa28.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;C3&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;图解：《国家烟草专卖局政府信息公开办法》解读说明&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;相关链接 国家烟草专卖局关于印发政府信息公开工作办法的通知         国家烟草专卖局政府信息公开办法 解读说明&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1620887499&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;综合业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;D8C41078776891CD8F9618E8D744D84E&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;图解 国家烟草专卖局政府信息公开办法 解读说明&quot;,&quot;MD5TITLE&quot;:&quot;1D83886A4B409229532D25315E5B8F96&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;    相关链接 国家烟草专卖局关于印发政府信息公开工作办法的通知         国家烟草专卖局政府信息公开办法 解读说明&quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;B5B2AF9A5F591B806C10CB6CC7F87AD6&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-05-13 14:31:39&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E0D9CD9DD7D6C287A848ACD56F03E88B6D0338752E0E6073C30CAAB2420459C2F009F84B28CC2059BF21D3E3EE050FF5E6E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;]&#125;&#125;&#x27;res = jsonpath.jsonpath(jsonstr, &#x27;$..url&#x27;)print(res)\n\n其实就两步，第一导入jsonpath，然后使用jsonpath.jsonpath()解析\n但是这里需要注意上面代码中的jsonstr，是需要经过转换的，它这里只接受字典对象，而不接受字符串对象，json是字符串，我们需要用json.loads()把json这个字符串对象转化为Python字典对象，但是我在测试的时候又发现一点错误，如下所示:\n这个报错我搜索了下，说是需要在代码的最开头加入以下代码:\n# -*- coding:utf-8 -*-\n\n加上这个表示这个.py文件由utf-8编码，可是编辑器默认的编码就是utf-8，不管了，反正遇到这个报错就加上即可;\n完整代码如下:\nimport jsonpathimport jsonjsonstr = &#x27;&#123;&quot;ok&quot;:true,&quot;code&quot;:200,&quot;msg&quot;:null,&quot;data&quot;:&#123;&quot;totalHits&quot;:92,&quot;resultList&quot;:[&#123;&quot;summary&quot;:&quot;相关链接 国家烟草专卖局关于印发深化 证照分离 改革进一步激发市场主体发展活力实施方案的通知 国家烟草专卖&quot;,&quot;dreDate&quot;:1638251577000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;图解：《国家烟草专卖局关于印发深化“证照分离”改革进一步激发市场主体发展活力实施方案的通知》政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-11-30&quot;,&quot;title&quot;:&quot;图解：《国家烟草专卖局关于印发深化“证照分离”改革进一步激发市场主体发展活力实施方案的通知》政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202111/00fd8aac999443c2963d2714c10c26b2.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;D69C44FE5971BE1672E2BDE4BA9562BC&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-11-30T06:02:40.050&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202111/00fd8aac999443c2963d2714c10c26b2.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;图解：《国家烟草专卖局关于印发深化“证照分离”改革进一步激发市场主体发展活力实施方案的通知》政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;相关链接 国家烟草专卖局关于印发深化 证照分离 改革进一步激发市场主体发展活力实施方案的通知        国家烟草专卖&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1638251577&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;专卖业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;E43D6D583F742C59F73173EA305E0B8D&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;图解 国家烟草专卖局关于印发深化 证照分离 改革进一步激发市场主体发展活力实施方案的通知 政策解读&quot;,&quot;MD5TITLE&quot;:&quot;F1DEDFBA3D25A848EFAA312948A6E771&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;   相关链接 国家烟草专卖局关于印发深化 证照分离 改革进一步激发市场主体发展活力实施方案的通知        国家烟草专卖局关于印发深化 证照分离 改革进一步激发市场主体发展活力实施方案的通知 政策解读&quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;D69C44FE5971BE1672E2BDE4BA9562BC&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-11-30 13:52:57&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E29E654EF36AC5EEFFF56BD21DF28EFF7BBA4B400CF734F62934AE927F760C40E902559609C9965735295CA877351025F6E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;一 背景依据 今年5月 国务院印发了 关于深化 证照分离 改革进一步激发市场主体发展活力的通知 国发 2021 7号&quot;,&quot;dreDate&quot;:1637803246000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;《国家烟草专卖局关于印发深化“证照分离”改革进一步激发市场主体发展活力实施方案的通知》政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-11-25&quot;,&quot;title&quot;:&quot;《国家烟草专卖局关于印发深化“证照分离”改革进一步激发市场主体发展活力实施方案的通知》政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202111/6b0064505b89450b8c965781ba24d1dd.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;C4B055582B5865A17CEABA4703757497&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-11-30T06:02:40.057&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202111/6b0064505b89450b8c965781ba24d1dd.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;《国家烟草专卖局关于印发深化“证照分离”改革进一步激发市场主体发展活力实施方案的通知》政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;一 背景依据  今年5月 国务院印发了 关于深化 证照分离 改革进一步激发市场主体发展活力的通知  国发 2021 7号&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1637803246&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;专卖业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;D68F3CF9C6B9B7E6EF504BE93A98B68A&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;国家烟草专卖局关于印发深化 证照分离 改革进一步激发市场主体发展活力实施方案的通知 政策解读&quot;,&quot;MD5TITLE&quot;:&quot;9093B824D4212053CA21B413450F4E30&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;一 背景依据  今年5月 国务院印发了 关于深化 证照分离 改革进一步激发市场主体发展活力的通知  国发 2021 7号 以下简称 通知   明确了 证照分离 改革的主要目标 基本内容 配套措施 并对如何创新和加强事中事后监管等提出了要求 按照 通知 要求 国务院有关部门要制定实施方案 对中央层面设定的涉企经营许可事项逐项细化改革举措 并向社会公布 根据上述要求 我们结合烟草行业实际 制定印发了 深化 证照分离 改革进一步激发市场主体发展活力实施方案  以下简称 实施方案    二  实施方案 &quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;C4B055582B5865A17CEABA4703757497&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-11-25 09:20:46&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E29E654EF36AC5EEF1E2CD4BBE7A913209BC2F508952E92BD99DEAF78EA8C4AEC55DF4C4FE058EF85F016BE7F7F856C8F6E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;相关链接 国家烟草专卖局关于印发 新时代国家烟草专卖局对口支援兴国县实施方案 的通知 国家烟草专卖局关于&quot;,&quot;dreDate&quot;:1631779320000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;图解：《国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知》的政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-09-16&quot;,&quot;title&quot;:&quot;图解：《国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知》的政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202109/1c6b919c5e3e4a508dda8e07df480eb8.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;3A6748BC7FAFEB972C7748DFAC3312AD&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-09-28T01:32:00.007&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202109/1c6b919c5e3e4a508dda8e07df480eb8.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;图解：《国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知》的政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;相关链接 国家烟草专卖局关于印发 新时代国家烟草专卖局对口支援兴国县实施方案 的通知         国家烟草专卖局关于&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1631779320&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;综合业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;0852298E65D012FECB8DB7E323453781&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;图解 国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知 的政策解读&quot;,&quot;MD5TITLE&quot;:&quot;F2FCA05339837A57685F3687C7A643DE&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;      相关链接 国家烟草专卖局关于印发 新时代国家烟草专卖局对口支援兴国县实施方案 的通知         国家烟草专卖局关于印发的通知 的政策解读    &quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;3A6748BC7FAFEB972C7748DFAC3312AD&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-09-16 16:02:00&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E0D9CD9DD7D6C287A8A32719516DE22DD9E0C33F4BC6BCA48459DFF88F7A6F1D99BA5617CB7EA9E0AF69BCAA7D2CF59616E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;一 国家烟草专卖局关于印发的通知 背景是什么 答 2020年 革命老区兴国县在国家烟草专卖局的助力下 成功脱贫摘帽并&quot;,&quot;dreDate&quot;:1630890520000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;《国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知》的政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-09-06&quot;,&quot;title&quot;:&quot;《国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知》的政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202109/df15e15f738b4c6bb108690f1eebc6ba.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;436700871BF74E853A04248AB5167423&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-09-28T01:17:00.010&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202109/df15e15f738b4c6bb108690f1eebc6ba.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;《国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知》的政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;一  国家烟草专卖局关于印发的通知 背景是什么  答 2020年 革命老区兴国县在国家烟草专卖局的助力下 成功脱贫摘帽并&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1630890520&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;综合业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;5B80A8582470AD3838DE267467BF3FF5&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;国家烟草专卖局关于印发＜新时代国家烟草专卖局对口支援兴国县实施方案＞的通知 的政策解读&quot;,&quot;MD5TITLE&quot;:&quot;B9B077DAC99F25BDC32271D874861AC6&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;  一  国家烟草专卖局关于印发的通知 背景是什么  答 2020年 革命老区兴国县在国家烟草专卖局的助力下 成功脱贫摘帽并迈入了小康社会 正扬帆启航 向第二个百年奋斗目标进军 革命老区是党和人民军队的根 是中国人民选择中国共产党的历史见证 兴国县是赣南等原中央苏区核心区域 位于多省交界地区 为中国革命作出了巨大贡献和牺牲 目前仍属于欠发达地区 全面建设社会主义现代化国家 实现中华民族伟大复兴 最艰巨最繁重的任务依然在农村 最广泛最深厚的基础依然在农村  对口支援是党中央 国务院确定的乡村振兴重&quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;436700871BF74E853A04248AB5167423&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-09-06 09:08:40&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E0D9CD9DD7D6C287A01BDE8575BB794709865B07DFDD9B03BCFD688859E397CDDA36164114DBD3FF13C9D6C4CD5F466176E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;相关链接 国家烟草专卖局关于印发涉案烟草制品价格管理规定的通知 涉案烟草制品价格管理规&quot;,&quot;dreDate&quot;:1625459828000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;图解：《涉案烟草制品价格管理规定》政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-07-05&quot;,&quot;title&quot;:&quot;图解：《涉案烟草制品价格管理规定》政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202107/6feaebb9c9804b12831f963c8f351265.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;B8F39E42862E282FCD5A1869C2F4DE62&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-07-05T04:45:00.044&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202107/6feaebb9c9804b12831f963c8f351265.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;图解：《涉案烟草制品价格管理规定》政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;相关链接  国家烟草专卖局关于印发涉案烟草制品价格管理规定的通知                 涉案烟草制品价格管理规&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1625459828&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;综合业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;D1F434D44B1CD8A2F863E9A40096E0A9&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;图解 涉案烟草制品价格管理规定 政策解读&quot;,&quot;MD5TITLE&quot;:&quot;F11D3EB1CBD11B69B1269442A11CB467&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;    相关链接  国家烟草专卖局关于印发涉案烟草制品价格管理规定的通知                 涉案烟草制品价格管理规定 政策解读 &quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;B8F39E42862E282FCD5A1869C2F4DE62&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-07-05 12:37:08&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E0D9CD9DD7D6C287A4D2643F7D93F49167FF59D48DE8B2DEEFED96E74DA43B0BB3ADB3FFBEC1E8628A5AB9504D6783C766E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;相关链接 保护未成年人免受烟侵害 守护成长 专项行动方案 政策解读 相关链接 国家烟草专卖局 国家市场监管总局关于&quot;,&quot;dreDate&quot;:1624932097000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;图解：《保护未成年人免受烟侵害“守护成长”专项行动方案》政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-06-29&quot;,&quot;title&quot;:&quot;图解：《保护未成年人免受烟侵害“守护成长”专项行动方案》政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202106/bb6c082ac38443bc9e8b8db6fcbf7f89.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;6121A012BD2698C252B9A4168F78389A&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-06-29T02:45:40.059&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202106/bb6c082ac38443bc9e8b8db6fcbf7f89.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;图解：《保护未成年人免受烟侵害“守护成长”专项行动方案》政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;相关链接  保护未成年人免受烟侵害 守护成长 专项行动方案 政策解读   相关链接 国家烟草专卖局 国家市场监管总局关于&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1624932097&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;专卖业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;C0698BD368F189D3EDA7BFD3A57A26C5&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;图解 保护未成年人免受烟侵害 守护成长 专项行动方案 政策解读&quot;,&quot;MD5TITLE&quot;:&quot;C440B225898302466CF9078A7F27D89A&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;      相关链接  保护未成年人免受烟侵害 守护成长 专项行动方案 政策解读   相关链接 国家烟草专卖局 国家市场监管总局关于印发保护未成年人免受烟侵害 守护成长 专项行动方案的通知 &quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;6121A012BD2698C252B9A4168F78389A&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-06-29 10:01:37&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E29E654EF36AC5EEFDCF30FB9AE09DE8D24D24F9A34728E67B057421018963278E1AC3305CE48020012DDFDB9FD88CD5A6E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;一 修订背景 过程和目的 2011年 为贯彻落实 最高人民法院最高人民检察院关于办理非法生产 销售烟草专卖品等刑事案件具&quot;,&quot;dreDate&quot;:1624259104000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;《涉案烟草制品价格管理规定》政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-06-21&quot;,&quot;title&quot;:&quot;《涉案烟草制品价格管理规定》政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202106/49522d0974f54727aceabc98ba244b2b.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;C5541A612CB84ED024376AA3BBAA5277&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-07-05T04:45:40.069&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202106/49522d0974f54727aceabc98ba244b2b.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;《涉案烟草制品价格管理规定》政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;一 修订背景 过程和目的 2011年 为贯彻落实 最高人民法院最高人民检察院关于办理非法生产 销售烟草专卖品等刑事案件具&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1624259104&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;综合业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;7002C5756236B5DD0F02D62D798148E8&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;涉案烟草制品价格管理规定 政策解读&quot;,&quot;MD5TITLE&quot;:&quot;25886DE15FC2C299BD648B6ED4EB7AF6&quot;,&quot;QUICKDESCRIPTION&quot;:&quot; 一 修订背景 过程和目的 2011年 为贯彻落实 最高人民法院最高人民检察院关于办理非法生产 销售烟草专卖品等刑事案件具体应用法律若干问题的解释  法释 2010 7号 要求 国家烟草专卖局印发了 国家烟草专卖局关于印发涉案卷烟价格管理规定的通知  国烟计 2011 73号  提升了涉案卷烟价格管理工作的水平 随着烟草行业发展的变化 在工作实践中存在现行的管理规定无法全面涵盖各种情况 同时部分条款也不够清晰等问题 有必要进行修订完善 通过开展调研和集中座谈 向社会公开征求意见 充分听取 吸纳行&quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;C5541A612CB84ED024376AA3BBAA5277&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-06-21 15:05:04&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E0D9CD9DD7D6C287A32E51F0BD012ADB53FD65FD6C02468C0D32C633A2B76E33DCD13C032462544EE5E225D74C58E4CAD6E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;为贯彻落实新修订的 中华人民共和国未成年人保护法 关于保护未成年人免受烟 含电子烟 下同 侵害的规定 依法保障和维护未成&quot;,&quot;dreDate&quot;:1623984409000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;《保护未成年人免受烟侵害“守护成长”专项行动方案》政策解读&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-06-18&quot;,&quot;title&quot;:&quot;《保护未成年人免受烟侵害“守护成长”专项行动方案》政策解读&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202106/47402742590d4e5e9d570894b38d93d8.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;C4FC16F3515CB836A83C5E362A4C869B&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-06-29T02:30:40.054&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zmyw/202106/47402742590d4e5e9d570894b38d93d8.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;《保护未成年人免受烟侵害“守护成长”专项行动方案》政策解读&quot;,&quot;C3&quot;:&quot;&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;为贯彻落实新修订的 中华人民共和国未成年人保护法 关于保护未成年人免受烟 含电子烟 下同 侵害的规定 依法保障和维护未成&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1623984409&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;专卖业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;A8F96BDC17B46ACB767331CF53EC1430&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;保护未成年人免受烟侵害 守护成长 专项行动方案 政策解读&quot;,&quot;MD5TITLE&quot;:&quot;B6A19CDEF5C13FAAAE5E9CF5280C17B8&quot;,&quot;QUICKDESCRIPTION&quot;:&quot; 为贯彻落实新修订的 中华人民共和国未成年人保护法 关于保护未成年人免受烟 含电子烟 下同 侵害的规定 依法保障和维护未成年人身体健康和合法权益 国家烟草专卖局和国家市场监督管理总局决定联合开展保护未成年人免受烟侵害 守护成长 专项行动 并发布了 保护未成年人免受烟侵害 守护成长 专项行动方案  国烟专 2021 89号  就专项行动的总体要求 主要任务 时间安排和工作要求进行了部署 提出了明确要求  一 开展专项行动的背景和目的 党中央 国务院高度重视未成年人保护工作 尤其关注烟对未成年人身心&quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;C4FC16F3515CB836A83C5E362A4C869B&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-06-18 10:46:49&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E29E654EF36AC5EEF0B5DF92276C560F2DE2DCABBE79E9D732B11513224560F9F49099F430584CE572011B9DF6CD6D65B6E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;相关链接 国家烟草专卖局2021年政务公开工作要点&quot;,&quot;dreDate&quot;:1622615267000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;图解：《国家烟草专卖局2021年政务公开工作要点》&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-06-02&quot;,&quot;title&quot;:&quot;图解：《国家烟草专卖局2021年政务公开工作要点》&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202106/b3c779abbb4846eea148ce1186ca61da.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;F0D77E403013A9DCFB534903E89DC5DE&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-06-24T10:58:39.549&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202106/b3c779abbb4846eea148ce1186ca61da.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;C3&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;图解：《国家烟草专卖局2021年政务公开工作要点》&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;相关链接  国家烟草专卖局2021年政务公开工作要点&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1622615267&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;综合业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;FFA8E61BF4EBCF8F48A4DFC849D33454&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;图解 国家烟草专卖局2021年政务公开工作要点&quot;,&quot;MD5TITLE&quot;:&quot;B157D8F349E113F9D5F4A4F20CDC616A&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;    相关链接  国家烟草专卖局2021年政务公开工作要点 &quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;F0D77E403013A9DCFB534903E89DC5DE&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-06-02 14:27:47&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E0D9CD9DD7D6C287A8CE6DB033156C9BD0224CD11F0C2D97E95B04CD2BC9939187A8577F81E0C121D246FBD8609E652C76E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;,&#123;&quot;summary&quot;:&quot;相关链接 国家烟草专卖局关于印发政府信息公开工作办法的通知 国家烟草专卖局政府信息公开办法 解读说明&quot;,&quot;dreDate&quot;:1620887499000,&quot;dbName&quot;:&quot;cps&quot;,&quot;dreTitle&quot;:&quot;图解：《国家烟草专卖局政府信息公开办法》解读说明&quot;,&quot;includeImg&quot;:false,&quot;weight&quot;:null,&quot;docDate&quot;:&quot;2021-05-13&quot;,&quot;title&quot;:&quot;图解：《国家烟草专卖局政府信息公开办法》解读说明&quot;,&quot;combins&quot;:0,&quot;domainSiteName&quot;:&quot;中国烟草总公司&quot;,&quot;url&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202105/982c1e243ac74e8d93ff8433c286aa28.shtml&quot;,&quot;domainSite&quot;:&quot;tobacco.gov.cn&quot;,&quot;reference&quot;:&quot;B5B2AF9A5F591B806C10CB6CC7F87AD6&quot;,&quot;myValues&quot;:&#123;&quot;INCLUDEIMAGE&quot;:&quot;0&quot;,&quot;DOMAINSITENAME&quot;:&quot;中国烟草总公司&quot;,&quot;SPIDERTIME&quot;:&quot;2021-06-24T10:58:39.395&quot;,&quot;URL&quot;:&quot;http://www.tobacco.gov.cn/gjyc/zhyw/202105/982c1e243ac74e8d93ff8433c286aa28.shtml&quot;,&quot;C1&quot;:&quot;政府信息公开&quot;,&quot;C2&quot;:&quot;&quot;,&quot;C3&quot;:&quot;&quot;,&quot;DRETITLEO&quot;:&quot;图解：《国家烟草专卖局政府信息公开办法》解读说明&quot;,&quot;C4&quot;:&quot;&quot;,&quot;C5&quot;:&quot;&quot;,&quot;C6&quot;:&quot;&quot;,&quot;SUMMARY&quot;:&quot;相关链接 国家烟草专卖局关于印发政府信息公开工作办法的通知         国家烟草专卖局政府信息公开办法 解读说明&quot;,&quot;C7&quot;:&quot;&quot;,&quot;C8&quot;:&quot;&quot;,&quot;C9&quot;:&quot;&quot;,&quot;DOMAINSITE&quot;:&quot;tobacco.gov.cn&quot;,&quot;WEBSITENAME&quot;:&quot;www.tobacco.gov.cn&quot;,&quot;DREDATE&quot;:&quot;1620887499&quot;,&quot;L1&quot;:&quot;政府信息公开&quot;,&quot;L2&quot;:&quot;法定主动公开内容&quot;,&quot;L3&quot;:&quot;政策解读&quot;,&quot;L4&quot;:&quot;综合业务&quot;,&quot;L5&quot;:&quot;&quot;,&quot;L6&quot;:&quot;&quot;,&quot;DREDBNAME&quot;:&quot;cps&quot;,&quot;FILETYPE&quot;:&quot;.html&quot;,&quot;L7&quot;:&quot;&quot;,&quot;N9&quot;:&quot;1&quot;,&quot;L8&quot;:&quot;&quot;,&quot;MD5URL&quot;:&quot;D8C41078776891CD8F9618E8D744D84E&quot;,&quot;L9&quot;:&quot;开普接口同步&quot;,&quot;DRETITLE&quot;:&quot;图解 国家烟草专卖局政府信息公开办法 解读说明&quot;,&quot;MD5TITLE&quot;:&quot;1D83886A4B409229532D25315E5B8F96&quot;,&quot;QUICKDESCRIPTION&quot;:&quot;    相关链接 国家烟草专卖局关于印发政府信息公开工作办法的通知         国家烟草专卖局政府信息公开办法 解读说明&quot;,&quot;_INDEX&quot;:&quot;cps_new0&quot;,&quot;_TYPE&quot;:&quot;_doc&quot;,&quot;_ID&quot;:&quot;B5B2AF9A5F591B806C10CB6CC7F87AD6&quot;,&quot;WEBSITE&quot;:&quot;www.tobacco.gov.cn&quot;&#125;,&quot;indexDate&quot;:&quot;2021-05-13 14:31:39&quot;,&quot;encodeUrl&quot;:&quot;816D9628B2B6451D752E6EE8E2E94092FDDB37D65E32473A22AB54CCC441042E0D9CD9DD7D6C287A848ACD56F03E88B6D0338752E0E6073C30CAAB2420459C2F009F84B28CC2059BF21D3E3EE050FF5E6E5833E95ACFB8C8&quot;,&quot;snapshot&quot;:&quot;&quot;&#125;]&#125;&#125;&#x27;res = jsonpath.jsonpath(json.loads(jsonstr), &quot;$..url&quot;)print(res)\n\n运行结果:\n[&#x27;http://www.tobacco.gov.cn/gjyc/zmyw/202111/00fd8aac999443c2963d2714c10c26b2.shtml&#x27;, &#x27;http://www.tobacco.gov.cn/gjyc/zmyw/202111/6b0064505b89450b8c965781ba24d1dd.shtml&#x27;, &#x27;http://www.tobacco.gov.cn/gjyc/zhyw/202109/1c6b919c5e3e4a508dda8e07df480eb8.shtml&#x27;, &#x27;http://www.tobacco.gov.cn/gjyc/zhyw/202109/df15e15f738b4c6bb108690f1eebc6ba.shtml&#x27;, &#x27;http://www.tobacco.gov.cn/gjyc/zhyw/202107/6feaebb9c9804b12831f963c8f351265.shtml&#x27;, &#x27;http://www.tobacco.gov.cn/gjyc/zmyw/202106/bb6c082ac38443bc9e8b8db6fcbf7f89.shtml&#x27;, &#x27;http://www.tobacco.gov.cn/gjyc/zhyw/202106/49522d0974f54727aceabc98ba244b2b.shtml&#x27;, &#x27;http://www.tobacco.gov.cn/gjyc/zmyw/202106/47402742590d4e5e9d570894b38d93d8.shtml&#x27;, &#x27;http://www.tobacco.gov.cn/gjyc/zhyw/202106/b3c779abbb4846eea148ce1186ca61da.shtml&#x27;, &#x27;http://www.tobacco.gov.cn/gjyc/zhyw/202105/982c1e243ac74e8d93ff8433c286aa28.shtml&#x27;]\n\n"},{"title":"js逆向37网游登录接口参数","url":"/2022/01/18/js%E9%80%86%E5%90%9137%E7%BD%91%E6%B8%B8%E7%99%BB%E5%BD%95%E6%8E%A5%E5%8F%A3%E5%8F%82%E6%95%B0/","content":"目标网站: 37网游\n抓包分析\n首先我们随便输入一个账号密码，点击登陆，抓包定位到登录接口为: https://my.37.com/api/login.php，这是一个Get请求，然后我们来分析下Payload里面的参数:\n\ncallback 是一个回调参数，它的格式为 jQuery + 20位数字 + _ + 13位时间戳，使用 Python 很容易构建；login_account 是登录的账户名；password 是加密后的密码；_ 是13位时间戳\n参数逆向\n需要我们逆向的参数就只有一个 password， 我们尝试直接全局搜索此关键字，会发现出来的结果非常多，不利于分析，这里就有一个小技巧，加个等号，搜索 password=，这样就极大地缩短了查找范围，当然也可以搜索 password:，也可以在关键字和符号之间加个空格，还可以搜索 var password 等，这些都是可以尝试的，要具体情况具体分析，一种没有结果就换另一种；在本案例中，我们搜索 password=然后我们定位到了以下结果:\n\n进入到js文件后我们再次搜索password=，然后我们定位到了h.password = td(f)，疑似加密代码，在此处埋下断点进行调试，可以看到返回的值确实是加密后的密码:\n\n\n鼠标悬停在td函数上，然后我们跳转进入td函数中，可以看到是用到了一个自写的 RSA 加密，很简单明了，我们直接将其复制下来使用 Python 调用即可:\nencrypt_password_js:\nvar ch = &quot;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/&quot;;function __rsa(str) &#123;    var out, i, len;    var c1, c2, c3;    len = str.length;    i = 0;    out = &quot;&quot;;    while (i &lt; len) &#123;        c1 = str.charCodeAt(i++) &amp; 0xff;        if (i == len) &#123;            out += ch.charAt(c1 &gt;&gt; 2);            out += ch.charAt((c1 &amp; 0x3) &lt;&lt; 4);            out += &quot;==&quot;;            break        &#125;        c2 = str.charCodeAt(i++);        if (i == len) &#123;            out += ch.charAt(c1 &gt;&gt; 2);            out += ch.charAt(((c1 &amp; 0x3) &lt;&lt; 4) | ((c2 &amp; 0xF0) &gt;&gt; 4));            out += ch.charAt((c2 &amp; 0xF) &lt;&lt; 2);            out += &quot;=&quot;;            break        &#125;        c3 = str.charCodeAt(i++);        out += ch.charAt(c1 &gt;&gt; 2);        out += ch.charAt(((c1 &amp; 0x3) &lt;&lt; 4) | ((c2 &amp; 0xF0) &gt;&gt; 4));        out += ch.charAt(((c2 &amp; 0xF) &lt;&lt; 2) | ((c3 &amp; 0xC0) &gt;&gt; 6));        out += ch.charAt(c3 &amp; 0x3F)    &#125;    return out&#125;function getEncryptedPassword(a) &#123;    var maxPos = ch.length - 2      , w = [];    for (i = 0; i &lt; 15; i++) &#123;        w.push(ch.charAt(Math.floor(Math.random() * maxPos)));        if (i === 7) &#123;            w.push(a.substr(0, 3))        &#125;        if (i === 12) &#123;            w.push(a.substr(3))        &#125;    &#125;    return __rsa(w.join(&quot;&quot;))&#125;// 测试样例// console.log(getEncryptedPassword(&quot;34343434&quot;))\n\n37_login:\n#!/usr/bin/env python3# -*- coding: utf-8 -*-import timeimport randomimport execjsimport requestslogin_url = &#x27;https://my.37.com/api/login.php&#x27;def get_encrypted_password(password):    with open(&#x27;37_encrypt.js&#x27;, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as f:        www_37_js = f.read()    encrypted_pwd = execjs.compile(www_37_js).call(&#x27;getEncryptedPassword&#x27;, password)    return encrypted_pwddef login(username, encrypted_password):    timestamp = str(int(time.time() * 1000))    jsonp = &#x27;&#x27;    for _ in range(20):        jsonp += str(random.randint(0, 9))    callback = &#x27;jQuery&#x27; + jsonp + &#x27;_&#x27; + timestamp    params = &#123;        &#x27;callback&#x27;: callback,        &#x27;action&#x27;: &#x27;login&#x27;,        &#x27;login_account&#x27;: username,        &#x27;password&#x27;: encrypted_password,        &#x27;ajax&#x27;: 0,        &#x27;remember_me&#x27;: 1,        &#x27;save_state&#x27;: 1,        &#x27;ltype&#x27;: 1,        &#x27;tj_from&#x27;: 100,        &#x27;s&#x27;: 1,        &#x27;tj_way&#x27;: 1,        &#x27;_&#x27;: timestamp    &#125;    headers = &#123;        &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36&#x27;,        &#x27;sec-ch-ua&#x27;: &#x27;&quot; Not;A Brand&quot;;v=&quot;99&quot;, &quot;Google Chrome&quot;;v=&quot;91&quot;, &quot;Chromium&quot;;v=&quot;91&quot;&#x27;    &#125;    response = requests.post(url=login_url, headers=headers, params=params)    print(response.text)def main():    username = input(&#x27;请输入登录账号: &#x27;)    password = input(&#x27;请输入登录密码: &#x27;)    encrypted_password = get_encrypted_password(password)    login(username, encrypted_password)if __name__ == &#x27;__main__&#x27;:    main()\n\n\n\n"},{"title":"js逆向模拟登录搜狐案例--关于md5但未解决cookie版","url":"/2022/01/17/js%E9%80%86%E5%90%91%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%E6%90%9C%E7%8B%90%E6%A1%88%E4%BE%8B/","content":"需求: js逆向模拟登录搜狐网\n首先我们点击登录打开登录框，抓包找接口，发现POST接口:https://v4.passport.sohu.com/i/login/116005，其中的Payload下面的Form Data中的userid是输入的用户名，password是加密后的密码:\n\n没有找到调用对象，那么CTRL+F全局搜索password:\n\n这里搜出了三个，大家觉得会是在哪个，其中有一个passport什么什么.js，我猜测就是在这里面，因为passport意为护照，就是表示通行证，所以我猜测就在这里面有我们想要的东西\n\n(不好意思哈，上图标错了)按路径找到这个文件后，进去我们再搜索password\n\n上图红框中的已经很明显了哈，是一个MD5加密，我们打断点然后跳转到md5函数中:\n我们新建一个html文件然后把上图的md5函数复制到html文件中，单单复制一个函数能在浏览器中运行嘛，答案是不能的，所以我们起码要加个body，然后把md5:去点，然后在function后面加个md5:\n&lt;body&gt;    &lt;script&gt;function md5(args) &#123;            function hex_md5(s) &#123;                return binl2hex(core_md5(str2binl(s), s.length * chrsz))            &#125;            function core_md5(x, len) &#123;                x[len &gt;&gt; 5] |= 128 &lt;&lt; len % 32,                x[14 + (len + 64 &gt;&gt;&gt; 9 &lt;&lt; 4)] = len;                for (var a = 1732584193, b = -271733879, c = -1732584194, d = 271733878, i = 0; i &lt; x.length; i += 16) &#123;                    var olda = a                      , oldb = b                      , oldc = c                      , oldd = d;                    a = md5_ff(a, b, c, d, x[i + 0], 7, -680876936),                    d = md5_ff(d, a, b, c, x[i + 1], 12, -389564586),                    c = md5_ff(c, d, a, b, x[i + 2], 17, 606105819),                    b = md5_ff(b, c, d, a, x[i + 3], 22, -1044525330),                    a = md5_ff(a, b, c, d, x[i + 4], 7, -176418897),                    d = md5_ff(d, a, b, c, x[i + 5], 12, 1200080426),                    c = md5_ff(c, d, a, b, x[i + 6], 17, -1473231341),                    b = md5_ff(b, c, d, a, x[i + 7], 22, -45705983),                    a = md5_ff(a, b, c, d, x[i + 8], 7, 1770035416),                    d = md5_ff(d, a, b, c, x[i + 9], 12, -1958414417),                    c = md5_ff(c, d, a, b, x[i + 10], 17, -42063),                    b = md5_ff(b, c, d, a, x[i + 11], 22, -1990404162),                    a = md5_ff(a, b, c, d, x[i + 12], 7, 1804603682),                    d = md5_ff(d, a, b, c, x[i + 13], 12, -40341101),                    c = md5_ff(c, d, a, b, x[i + 14], 17, -1502002290),                    b = md5_ff(b, c, d, a, x[i + 15], 22, 1236535329),                    a = md5_gg(a, b, c, d, x[i + 1], 5, -165796510),                    d = md5_gg(d, a, b, c, x[i + 6], 9, -1069501632),                    c = md5_gg(c, d, a, b, x[i + 11], 14, 643717713),                    b = md5_gg(b, c, d, a, x[i + 0], 20, -373897302),                    a = md5_gg(a, b, c, d, x[i + 5], 5, -701558691),                    d = md5_gg(d, a, b, c, x[i + 10], 9, 38016083),                    c = md5_gg(c, d, a, b, x[i + 15], 14, -660478335),                    b = md5_gg(b, c, d, a, x[i + 4], 20, -405537848),                    a = md5_gg(a, b, c, d, x[i + 9], 5, 568446438),                    d = md5_gg(d, a, b, c, x[i + 14], 9, -1019803690),                    c = md5_gg(c, d, a, b, x[i + 3], 14, -187363961),                    b = md5_gg(b, c, d, a, x[i + 8], 20, 1163531501),                    a = md5_gg(a, b, c, d, x[i + 13], 5, -1444681467),                    d = md5_gg(d, a, b, c, x[i + 2], 9, -51403784),                    c = md5_gg(c, d, a, b, x[i + 7], 14, 1735328473),                    b = md5_gg(b, c, d, a, x[i + 12], 20, -1926607734),                    a = md5_hh(a, b, c, d, x[i + 5], 4, -378558),                    d = md5_hh(d, a, b, c, x[i + 8], 11, -2022574463),                    c = md5_hh(c, d, a, b, x[i + 11], 16, 1839030562),                    b = md5_hh(b, c, d, a, x[i + 14], 23, -35309556),                    a = md5_hh(a, b, c, d, x[i + 1], 4, -1530992060),                    d = md5_hh(d, a, b, c, x[i + 4], 11, 1272893353),                    c = md5_hh(c, d, a, b, x[i + 7], 16, -155497632),                    b = md5_hh(b, c, d, a, x[i + 10], 23, -1094730640),                    a = md5_hh(a, b, c, d, x[i + 13], 4, 681279174),                    d = md5_hh(d, a, b, c, x[i + 0], 11, -358537222),                    c = md5_hh(c, d, a, b, x[i + 3], 16, -722521979),                    b = md5_hh(b, c, d, a, x[i + 6], 23, 76029189),                    a = md5_hh(a, b, c, d, x[i + 9], 4, -640364487),                    d = md5_hh(d, a, b, c, x[i + 12], 11, -421815835),                    c = md5_hh(c, d, a, b, x[i + 15], 16, 530742520),                    b = md5_hh(b, c, d, a, x[i + 2], 23, -995338651),                    a = md5_ii(a, b, c, d, x[i + 0], 6, -198630844),                    d = md5_ii(d, a, b, c, x[i + 7], 10, 1126891415),                    c = md5_ii(c, d, a, b, x[i + 14], 15, -1416354905),                    b = md5_ii(b, c, d, a, x[i + 5], 21, -57434055),                    a = md5_ii(a, b, c, d, x[i + 12], 6, 1700485571),                    d = md5_ii(d, a, b, c, x[i + 3], 10, -1894986606),                    c = md5_ii(c, d, a, b, x[i + 10], 15, -1051523),                    b = md5_ii(b, c, d, a, x[i + 1], 21, -2054922799),                    a = md5_ii(a, b, c, d, x[i + 8], 6, 1873313359),                    d = md5_ii(d, a, b, c, x[i + 15], 10, -30611744),                    c = md5_ii(c, d, a, b, x[i + 6], 15, -1560198380),                    b = md5_ii(b, c, d, a, x[i + 13], 21, 1309151649),                    a = md5_ii(a, b, c, d, x[i + 4], 6, -145523070),                    d = md5_ii(d, a, b, c, x[i + 11], 10, -1120210379),                    c = md5_ii(c, d, a, b, x[i + 2], 15, 718787259),                    b = md5_ii(b, c, d, a, x[i + 9], 21, -343485551),                    a = safe_add(a, olda),                    b = safe_add(b, oldb),                    c = safe_add(c, oldc),                    d = safe_add(d, oldd)                &#125;                return Array(a, b, c, d)            &#125;            function md5_cmn(q, a, b, x, s, t) &#123;                return safe_add(bit_rol(safe_add(safe_add(a, q), safe_add(x, t)), s), b)            &#125;            function md5_ff(a, b, c, d, x, s, t) &#123;                return md5_cmn(b &amp; c | ~b &amp; d, a, b, x, s, t)            &#125;            function md5_gg(a, b, c, d, x, s, t) &#123;                return md5_cmn(b &amp; d | c &amp; ~d, a, b, x, s, t)            &#125;            function md5_hh(a, b, c, d, x, s, t) &#123;                return md5_cmn(b ^ c ^ d, a, b, x, s, t)            &#125;            function md5_ii(a, b, c, d, x, s, t) &#123;                return md5_cmn(c ^ (b | ~d), a, b, x, s, t)            &#125;            function safe_add(x, y) &#123;                var lsw = (65535 &amp; x) + (65535 &amp; y);                return (x &gt;&gt; 16) + (y &gt;&gt; 16) + (lsw &gt;&gt; 16) &lt;&lt; 16 | 65535 &amp; lsw            &#125;            function bit_rol(num, cnt) &#123;                return num &lt;&lt; cnt | num &gt;&gt;&gt; 32 - cnt            &#125;            function str2binl(str) &#123;                for (var bin = Array(), mask = (1 &lt;&lt; chrsz) - 1, i = 0; i &lt; str.length * chrsz; i += chrsz)                    bin[i &gt;&gt; 5] |= (str.charCodeAt(i / chrsz) &amp; mask) &lt;&lt; i % 32;                return bin            &#125;            function binl2hex(binarray) &#123;                for (var hex_tab = hexcase ? &quot;0123456789ABCDEF&quot; : &quot;0123456789abcdef&quot;, str = &quot;&quot;, i = 0; i &lt; 4 * binarray.length; i++)                    str += hex_tab.charAt(binarray[i &gt;&gt; 2] &gt;&gt; i % 4 * 8 + 4 &amp; 15) + hex_tab.charAt(binarray[i &gt;&gt; 2] &gt;&gt; i % 4 * 8 &amp; 15);                return str            &#125;            var hexcase = 0              , chrsz = 8;            return hex_md5(args)        &#125;    &lt;/script&gt;&lt;/body&gt;\n\n然后我们在浏览器中的consle执行下md5函数:\n对比下之前payload中的fomdata中的加密password，会发现长度是一样的，只不过时间不一样然后结果就不一样\n那下面我们就来登录下:\nunction md5(args) &#123;            function hex_md5(s) &#123;                return binl2hex(core_md5(str2binl(s), s.length * chrsz))            &#125;            function core_md5(x, len) &#123;                x[len &gt;&gt; 5] |= 128 &lt;&lt; len % 32,                x[14 + (len + 64 &gt;&gt;&gt; 9 &lt;&lt; 4)] = len;                for (var a = 1732584193, b = -271733879, c = -1732584194, d = 271733878, i = 0; i &lt; x.length; i += 16) &#123;                    var olda = a                      , oldb = b                      , oldc = c                      , oldd = d;                    a = md5_ff(a, b, c, d, x[i + 0], 7, -680876936),                    d = md5_ff(d, a, b, c, x[i + 1], 12, -389564586),                    c = md5_ff(c, d, a, b, x[i + 2], 17, 606105819),                    b = md5_ff(b, c, d, a, x[i + 3], 22, -1044525330),                    a = md5_ff(a, b, c, d, x[i + 4], 7, -176418897),                    d = md5_ff(d, a, b, c, x[i + 5], 12, 1200080426),                    c = md5_ff(c, d, a, b, x[i + 6], 17, -1473231341),                    b = md5_ff(b, c, d, a, x[i + 7], 22, -45705983),                    a = md5_ff(a, b, c, d, x[i + 8], 7, 1770035416),                    d = md5_ff(d, a, b, c, x[i + 9], 12, -1958414417),                    c = md5_ff(c, d, a, b, x[i + 10], 17, -42063),                    b = md5_ff(b, c, d, a, x[i + 11], 22, -1990404162),                    a = md5_ff(a, b, c, d, x[i + 12], 7, 1804603682),                    d = md5_ff(d, a, b, c, x[i + 13], 12, -40341101),                    c = md5_ff(c, d, a, b, x[i + 14], 17, -1502002290),                    b = md5_ff(b, c, d, a, x[i + 15], 22, 1236535329),                    a = md5_gg(a, b, c, d, x[i + 1], 5, -165796510),                    d = md5_gg(d, a, b, c, x[i + 6], 9, -1069501632),                    c = md5_gg(c, d, a, b, x[i + 11], 14, 643717713),                    b = md5_gg(b, c, d, a, x[i + 0], 20, -373897302),                    a = md5_gg(a, b, c, d, x[i + 5], 5, -701558691),                    d = md5_gg(d, a, b, c, x[i + 10], 9, 38016083),                    c = md5_gg(c, d, a, b, x[i + 15], 14, -660478335),                    b = md5_gg(b, c, d, a, x[i + 4], 20, -405537848),                    a = md5_gg(a, b, c, d, x[i + 9], 5, 568446438),                    d = md5_gg(d, a, b, c, x[i + 14], 9, -1019803690),                    c = md5_gg(c, d, a, b, x[i + 3], 14, -187363961),                    b = md5_gg(b, c, d, a, x[i + 8], 20, 1163531501),                    a = md5_gg(a, b, c, d, x[i + 13], 5, -1444681467),                    d = md5_gg(d, a, b, c, x[i + 2], 9, -51403784),                    c = md5_gg(c, d, a, b, x[i + 7], 14, 1735328473),                    b = md5_gg(b, c, d, a, x[i + 12], 20, -1926607734),                    a = md5_hh(a, b, c, d, x[i + 5], 4, -378558),                    d = md5_hh(d, a, b, c, x[i + 8], 11, -2022574463),                    c = md5_hh(c, d, a, b, x[i + 11], 16, 1839030562),                    b = md5_hh(b, c, d, a, x[i + 14], 23, -35309556),                    a = md5_hh(a, b, c, d, x[i + 1], 4, -1530992060),                    d = md5_hh(d, a, b, c, x[i + 4], 11, 1272893353),                    c = md5_hh(c, d, a, b, x[i + 7], 16, -155497632),                    b = md5_hh(b, c, d, a, x[i + 10], 23, -1094730640),                    a = md5_hh(a, b, c, d, x[i + 13], 4, 681279174),                    d = md5_hh(d, a, b, c, x[i + 0], 11, -358537222),                    c = md5_hh(c, d, a, b, x[i + 3], 16, -722521979),                    b = md5_hh(b, c, d, a, x[i + 6], 23, 76029189),                    a = md5_hh(a, b, c, d, x[i + 9], 4, -640364487),                    d = md5_hh(d, a, b, c, x[i + 12], 11, -421815835),                    c = md5_hh(c, d, a, b, x[i + 15], 16, 530742520),                    b = md5_hh(b, c, d, a, x[i + 2], 23, -995338651),                    a = md5_ii(a, b, c, d, x[i + 0], 6, -198630844),                    d = md5_ii(d, a, b, c, x[i + 7], 10, 1126891415),                    c = md5_ii(c, d, a, b, x[i + 14], 15, -1416354905),                    b = md5_ii(b, c, d, a, x[i + 5], 21, -57434055),                    a = md5_ii(a, b, c, d, x[i + 12], 6, 1700485571),                    d = md5_ii(d, a, b, c, x[i + 3], 10, -1894986606),                    c = md5_ii(c, d, a, b, x[i + 10], 15, -1051523),                    b = md5_ii(b, c, d, a, x[i + 1], 21, -2054922799),                    a = md5_ii(a, b, c, d, x[i + 8], 6, 1873313359),                    d = md5_ii(d, a, b, c, x[i + 15], 10, -30611744),                    c = md5_ii(c, d, a, b, x[i + 6], 15, -1560198380),                    b = md5_ii(b, c, d, a, x[i + 13], 21, 1309151649),                    a = md5_ii(a, b, c, d, x[i + 4], 6, -145523070),                    d = md5_ii(d, a, b, c, x[i + 11], 10, -1120210379),                    c = md5_ii(c, d, a, b, x[i + 2], 15, 718787259),                    b = md5_ii(b, c, d, a, x[i + 9], 21, -343485551),                    a = safe_add(a, olda),                    b = safe_add(b, oldb),                    c = safe_add(c, oldc),                    d = safe_add(d, oldd)                &#125;                return Array(a, b, c, d)            &#125;            function md5_cmn(q, a, b, x, s, t) &#123;                return safe_add(bit_rol(safe_add(safe_add(a, q), safe_add(x, t)), s), b)            &#125;            function md5_ff(a, b, c, d, x, s, t) &#123;                return md5_cmn(b &amp; c | ~b &amp; d, a, b, x, s, t)            &#125;            function md5_gg(a, b, c, d, x, s, t) &#123;                return md5_cmn(b &amp; d | c &amp; ~d, a, b, x, s, t)            &#125;            function md5_hh(a, b, c, d, x, s, t) &#123;                return md5_cmn(b ^ c ^ d, a, b, x, s, t)            &#125;            function md5_ii(a, b, c, d, x, s, t) &#123;                return md5_cmn(c ^ (b | ~d), a, b, x, s, t)            &#125;            function safe_add(x, y) &#123;                var lsw = (65535 &amp; x) + (65535 &amp; y);                return (x &gt;&gt; 16) + (y &gt;&gt; 16) + (lsw &gt;&gt; 16) &lt;&lt; 16 | 65535 &amp; lsw            &#125;            function bit_rol(num, cnt) &#123;                return num &lt;&lt; cnt | num &gt;&gt;&gt; 32 - cnt            &#125;            function str2binl(str) &#123;                for (var bin = Array(), mask = (1 &lt;&lt; chrsz) - 1, i = 0; i &lt; str.length * chrsz; i += chrsz)                    bin[i &gt;&gt; 5] |= (str.charCodeAt(i / chrsz) &amp; mask) &lt;&lt; i % 32;                return bin            &#125;            function binl2hex(binarray) &#123;                for (var hex_tab = hexcase ? &quot;0123456789ABCDEF&quot; : &quot;0123456789abcdef&quot;, str = &quot;&quot;, i = 0; i &lt; 4 * binarray.length; i++)                    str += hex_tab.charAt(binarray[i &gt;&gt; 2] &gt;&gt; i % 4 * 8 + 4 &amp; 15) + hex_tab.charAt(binarray[i &gt;&gt; 2] &gt;&gt; i % 4 * 8 &amp; 15);                return str            &#125;            var hexcase = 0              , chrsz = 8;            return hex_md5(args)        &#125;\n\n\n\n\n\n\n\n\n\n\n\n"},{"title":"2022-1-17每日英语","url":"/2022/01/17/2022-1-17%E6%AF%8F%E6%97%A5%E8%8B%B1%E8%AF%AD/","content":"\npassport n.护照，途径，手段\n\n"},{"title":"js逆向市场建筑监督管理平台企业数据","url":"/2022/01/19/js%E9%80%86%E5%90%91%E5%B8%82%E5%9C%BA%E5%BB%BA%E7%AD%91%E7%9B%91%E7%9D%A3%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%E4%BC%81%E4%B8%9A%E6%95%B0%E6%8D%AE/","content":"逆向目标\n\n目标: 住房和城乡建设部&amp;全国建筑市场监管公共服务平台的企业数据\n网站主页: http://jzsc.mohurd.gov.cn/data/company\n需要逆向的参数: 请求返回的加密数据\n\n逆向过程\n本次的逆向目标是建筑市场监管平台的企业数据，来到全国建筑市场监管公共服务平台首页，依次点击数据服务 —&gt; 企业数据，尝试抓包一下所有企业的数据，可以看到返回的数据是经过加密的:\n\n这种response一般是该返回json字符串的，这里却进行加密了，所以我们搜索JSON.parse，然后我们定位到疑似加密代码:\n\n可以看到 e 就是解密后的数据，观察语句 var e = JSON.parse(h(t.data));，直接跟进 h 函数，可以看到很明显的 AES 加密:这里先来了解下js的JSON.parse()函数:\nJSON.parse()方法用来解析JSON字符串，JSON.parse()将字符串转成json对象\n\n这便是我们需要的加密函数，然后我们把它抠出来:\nfunction h(t) &#123;    var e = d.a.enc.Hex.parse(t)    , n = d.a.enc.Base64.stringify(e)    , a = d.a.AES.decrypt(n, f, &#123;        iv: m,        mode: d.a.mode.CBC,        padding: d.a.pad.Pkcs7    &#125;)    , r = a.toString(d.a.enc.Utf8);    return r.toString()&#125;\n\n加密模式为CBC，填充方式为Pkcs7，而缺少的偏移量 m、f 的值，在上面也可以找到:\nf = d.a.enc.Utf8.parse(&quot;jo8j9wGw%6HbxfFn&quot;)m = d.a.enc.Utf8.parse(&quot;0123456789ABCDEF&quot;)\n\n我们可以直接引入CryptoJS，重写这个函数即可:\njzsc_decrypt.js:\n// 引用 crypto-js 加密模块var CryptoJS = require(&#x27;crypto-js&#x27;)function getDecryptedData(t) &#123;    var m = CryptoJS.enc.Utf8.parse(&quot;0123456789ABCDEF&quot;),        f = CryptoJS.enc.Utf8.parse(&quot;jo8j9wGw%6HbxfFn&quot;),        e = CryptoJS.enc.Hex.parse(t),        n = CryptoJS.enc.Base64.stringify(e),        a = CryptoJS.AES.decrypt(n, f, &#123;            iv: m,            mode: CryptoJS.mode.CBC,            padding: CryptoJS.pad.Pkcs7    &#125;),        r = a.toString(CryptoJS.enc.Utf8);    return r.toString()&#125;// 测试样例// var t = &#x27;95780ba094xxxxxxxxxx&#x27;// console.log(getDecryptedData(t))\n\njzsc.py:\n#!/usr/bin/env python3# -*- coding: utf-8 -*-import jsonimport execjsimport requestsdata_url = &#x27;http://jzsc.mohurd.gov.cn/api/webApi/dataservice/query/comp/list?pg=%s&amp;pgsz=15&amp;total=450&#x27;def get_encrypted_data(page):    headers = &#123;        &#x27;Host&#x27;: &#x27;jzsc.mohurd.gov.cn&#x27;,        &#x27;Referer&#x27;: &#x27;http://jzsc.mohurd.gov.cn/data/company&#x27;,        &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#x27;    &#125;    encrypted_data = requests.get(url=data_url % page, headers=headers).text    return encrypted_datadef get_decrypted_data(encrypted_data):    with open(&#x27;jzsc_mohurd_decrypt.js&#x27;, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as f:        jzsc_mohurd_js = f.read()    decrypted_data = execjs.compile(jzsc_mohurd_js).call(&#x27;getDecryptedData&#x27;, encrypted_data)    return json.loads(decrypted_data)def main():    # 30页数据    for page in range(30):        encrypted_data = get_encrypted_data(page)        decrypted_data = get_decrypted_data(encrypted_data)        print(decrypted_data)if __name__ == &#x27;__main__&#x27;:    main()\n\n"},{"title":"Chrome开发者工具使用技巧总结","url":"/2022/01/19/Chrome%E5%BC%80%E5%8F%91%E8%80%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/","content":"总览浏览器开发者工具在爬虫中常用来进行简单的抓包分析、JS逆向调试，打开方式如下:\n\nF12\n快捷键 Ctrl+Shift+I\n鼠标右键检查\n点击浏览器右上角三个点 —&gt; 更多工具 —&gt; 开发者工具\n\n常见禁用开发者工具手段，参考这里\n关于Chrome开发者工具的官方文档(需要科学上网)，参考这里\n下面就来看看面板:\n\n上图红框中的项依次表示:\n\n**Elements(元素面板)**：使用“元素”面板可以通过自由操纵 DOM 和 CSS 来重您网站的布局和设计\n**Console(控制台面板)**：在开发期间，可以使用控制台面板记录诊断信息，或者使用它作为 shell，在页面上与 JavaScript 交互\n**Sources(源代码面板)**：在源代码面板中设置断点来调试 JavaScript ，或者通过 Workspaces（工作区）连接本地文件来使用开发者工具的实时编辑器\n**Network(网络面板)**：从发起网页页面请求 Request 后得到的各个请求资源信息（包括状态、资源类型、大小、所用时间等），并可以根据这个进行网络性能优化\n**Performance(性能面板)**：使用时间轴面板，可以通过记录和查看网站生命周期内发生的各种事件来提高页面运行时的性能\n**Memory(内存面板)**：分析 web 应用或者页面的执行时间以及内存使用情况\n**Application(应用面板)**：记录网站加载的所有资源信息，包括存储数据（Local Storage、Session Storage、IndexedDB、Web SQL、Cookies）、缓存数据、字体、图片、脚本、样式表等\n**Security(安全面板)**：使用安全面板调试混合内容问题，证书问题等等\n**Lighthouse(诊断面板)**：对当前网页进行网络利用情况、网页性能方面的诊断，并给出一些优化建议\n\n\n上图红框中的按钮表示元素选择，可以直接点击页面中的文字、按钮或者图片，会自动跳转到对应的源代码，如下图所示:\n\n\n上图红框中的按钮表示终端模拟，可以模拟各种终端设备，支持自定义终端，其中Responsive是自适应模式，如下图所示:\n\n\n上图红框中的按钮表示设置，开发者工具设置，包括一些外观、快捷置、终端设备、地理位置设置等，如下图所示:\n\n\n上图红框中的按钮表示自定义，自定义和控制开发者工具，包括调整工具的位置、全局搜索、运行命令、其他工具等，如下图所示:\n\nNetwork面板\nControls(控制器)\nPreserve log：是否在页面重加载后，清除请求列表，勾选表示保留之前的请求列表，不勾选则会在下一次请求的时候清除(Preserve这个单词就表示保留)\nDisable cache：是否启用缓存，勾选表示不启用缓存，不勾选就表示启用缓存\n\n\n上图红框中的按钮表示是否开启抓包，开启抓包这个按钮的状态是红色，未开启则是灰色\n\n上图红框中的按钮表示是否清除请求，也就是清除清除列表\n\n上图红框中的按钮表示是否隐藏Filter(过滤器)窗格，点击即可关闭过滤器或者打开\n\n上图红框中的按钮表示搜索\n\n上图中红框中的按钮表示网络条件(Network conditions)，允许在各种网络环境中测试网站，包括 3G，离线等，还可以自定义限制最大下载和上传流量\n\n上图中红框中的按钮表示导入导出抓包数据(Import/Export HAR file)\nFilter过滤器\nHide data URLs: data URLs 指一些嵌入到文档中的小型文件，在请求表里面以 data: 开头的文件就是，如较为常见的 svg 文件；勾选 Hide data URLs复选框即可隐藏此类文件\nAll: 显示所有请求\nXHR: 全称 XMLHttpRequest，是一种创建 AJAX 请求的 JavaScript API，通常抓取 Ajax 请求可以选择 XHR\nWS: 全称 WebSocket，是 HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议\nManifest: 安卓开发文件名，属于 AndroidManifest.xml 文件，在简单的 Android 系统的应用中提出了重要的信息码\nHas blocked cookies: 仅显示具有阻止响应 cookie 的请求\nBlocked Requests: 只显示被阻止的请求\n\n断点调试常规断点调试适用于分析关键函数代码逻辑\n\n\nCtrl+Shift+F 或者右上角三个点打开全局搜索，搜索关键字\n定位到可疑代码，点击行号打下断点\n调试代码，分析逻辑，其中console模板可以直接编写 JS 代码进行调试\n\n调试时各个选项的功能:\n\n上图红框中的按钮表示执行到下一个断点\n\n上图红框中的按钮表示执行下一步，但不会进入所调用的函数内部\n\n上图红框中的按钮表示进入所调用的函数内部\n上图红框中的按钮表示跳出函数内部\n\n上图红框中的按钮表示一步步执行代码，遇到有函数调用，则进入函数\n\n上图红框中的按钮表示停用断点\n\n上图红框中的按钮表示不要在出现异常时暂停\n\n下面看看上图红框中的三个功能，这是比较常用的:\n\nBreakpoints：可以看到已经埋下的断点，可以看到在哪个函数打下了断点而且在哪一行\n可以看到当前局部或者全局变量的值，可对值进行修改\n可以看到当前代码调用的堆栈信息，代码执行顺序为由下至上\n\nXHR断点匹配 url 中关键词，匹配到则跳转到参数生成处，适用 于url 中的加密参数全局搜索搜不到，可采用这种方式拦截，如下图所示:\n\n行为断点Event Listener Breakpoints，事件侦听器断点，当鼠标点击、移动、键盘按键等行为或者其他事件发生时可以触发断点，比如Mouse —&gt; click，可快速定位点击按钮后，所执行的 JS，如下图所示:\n\n插入JS在 sources —&gt; snippets 下可以新建 JS 脚本:\n\n\n\n无限debugger防调试某些页面打开调试工具会出现无限 debugger 的现象\n\n中间人拦截替换无限debug函数查看调用栈，点击第二行跳转到原函数:\n\n可以看到红框中的两个函数分别对应debu和gger，连起来就是debugger，在本地重写这个JS，直接将这两个值置空:\n\n然后使用插件ReRes，编写规则，遇到此JS，就替换成我们本地经过修改的JS，替换后无限debugger就不存在了:\n\n\n方法置空直接在Console中将无限debugger的函数重写置空也可以破解无限debugger，缺点是刷新后失效\n本总结参考自: https://blog.csdn.net/kdl_csdn/article/details/119035208?spm=1001.2014.3001.5502\n后面还有关于hook的请移步上面的链接\n"},{"title":"关于HTTP状态码","url":"/2022/01/19/%E5%85%B3%E4%BA%8EHTTP%E7%8A%B6%E6%80%81%E7%A0%81/","content":"各类常见状态码:\n\n2xx(3种)\n200 OK: 表示从客户端发送给服务器的请求被正常处理并返回\n204 No Content: 表示客户端发送给客户端的请求得到了成功处理，但在返回的响应报文中不含实体的主体部分(没有资源可以返回)\n206 Patial Content: 表示客户端进行了范围请求，并且服务器成功执行了这部分的GET请求，响应报文中包含由Content-Range指定范围的实体内容\n\n3xx(5种)\n301 Moved Permanently: 永久性重定向，表示请求的资源被分配了新的URL，之后应使用更改的URL\n302 Found: 临时性重定向，表示请求的资源被分配了新的URL，希望本次访问使用新的URL；301与302的区别：前者是永久移动，后者是临时移动(之后可能还会更改URL)\n303 See Other: 表示请求的资源被分配了新的URL，应使用GET方法定向获取请求的资源；302与303的区别：后者明确表示客户端应当采用GET方式获取资源\n304 Not Modified: 关于这个状态码请见: https://blog.csdn.net/franknotbad/article/details/79399809\n307 Temporary Redirect: 临时重定向，与303有着相同的含义，307会遵照浏览器标准不会从POST变成GET；(不同浏览器可能会出现不同的情况)\n\n4XX(4种)\n400 Bad Request: 表示请求报文中存在语法错误\n401 Unauthorized: 未经许可，需要通过HTTP认证\n403 Forbidden: 服务器拒绝该次访问(访问权限出现问题)\n404 Not Found: 表示服务器上无法找到请求的资源，除此之外，也可以在服务器拒绝请求但不想给拒绝原因时使用\n\n5xx(2种)\n500 Inter Server Error: 表示服务器在执行请求时发生了错误，也有可能是web应用存在的bug或某些临时的错误时，服务器内部错误\n503 Server Unavailable: 表示服务器暂时处于超负载或正在进行停机维护，无法处理请求，服务器不可用，服务器当前超负荷\n\n\n"},{"title":"使用sourcetree提交代码显示 hint Updates were rejected because the remote contains work that you do的解决方法","url":"/2022/01/20/%E4%BD%BF%E7%94%A8sourcetree%E6%8F%90%E4%BA%A4%E4%BB%A3%E7%A0%81%E6%98%BE%E7%A4%BA%20hint%20Updates%20were%20rejected%20because%20the%20remote%20contains%20work%20that%20you%20do%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","content":"今天由于在GitLab上修改了远程仓库的代码，然后忘了同步到本地，使用sourcetree提交就出现了上传错误:\nhint Updates were rejected because the remote contains work that you do\n\n其实报错已经说的很明白了，就是远端还有在进行的工作，也就是我们的代码远程和本地不一致，所以我们就需要先同步下:\n\n再次提交即可提交成功!\n"},{"title":"Linux把脉之查看内存、磁盘、CPU、网络","url":"/2022/01/20/Linux%E6%8A%8A%E8%84%89%E4%B9%8B%E6%9F%A5%E7%9C%8B%E5%86%85%E5%AD%98%E3%80%81%E7%A3%81%E7%9B%98%E3%80%81CPU%E3%80%81%E7%BD%91%E7%BB%9C/","content":"核心命令之psps命令用于查看系统中的进程状态:\n在命令行中键入ps aux会看到如下画面:\n\n我们来看看上图红框中的参数:\n\nUSER: 进程所有者的用户名\nPID: 进程号，可以唯一标识该进程\n%CPU: 进程自最近一次刷新以来所占用的CPU时间和总时间的百分比\n%MEM: 进程使用内存的百分比\nVSZ: 进程使用的虚拟内存大小，以K为单位\nRSS: 进程占用的物理内存的总数量，以K为单位\nTTY: 进程相关的终端名\nSTAT: 进程状态，用(R–运行或准备运行；S–睡眠状态；I–空闲；Z–冻结；D–不间断睡眠；W-进程没有驻留页；T–停止或跟踪)这些字母来表示\nSTART: 进程开始运行时间\nTIME: 进程使用的总CPU时间\nCOMMAND，被执行的命令行\n\n核心命令之toptop命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器\n红框上半部分，显示了整体系统负载情况:\n\ntop一行: 从左到右依次为当前系统时间，系统运行的时间，系统在之前1min、5min和15min内cpu的平均负载值\nTask一行: 该行给出进程整体的统计信息，包括统计周期内进程总数、运行状态进程数、休眠状态进程数、停止状态进程数和僵死状态进程数(僵尸进程)\n%Cpu(s)一行: cpu整体统计信息，包括用户态下进程、系统态下进程占用cpu时间比，nice值大于0的进程在用户态下占用cpu时间比，cpu处于idle状态、wait状态的时间比，以及处理硬中断、软中断的时间比\nKiB Mem一行: 该行提供了内存统计信息，包括物理内存总量，已用内存、空闲内存以及用作缓存区的内存量\nKIB Swap一行: 虚拟统计信息，包括交换空间总量，已用交换区大小，空闲交换区大小以及用作缓存的交换空间大小\n\n红框下半部分显示了各个进程的运行情况:\n\nPID: 进程pid\nUSER: 拉起进程的用户\nPR: 该列值加100为进程优先级，若优先级小于100，则该进程为实时(real-time)进程，否则为普通(normal)进程，实时进程的优先级更高，更容易获得cpu调度,0为最高优先级\nNI: 进程的nice优先级值，该列中，实时进程的nice值为0，普通进程的nice值范围为-20~19\nVIRT: 进程所占虚拟内存大小(默认单位kB)\nRES: 进程所占物理内存大小(默认单位kB)\nSHR: 进程所占共享内存大小(默认单位kB)\nS: 进程的运行状态\n%CPU: 采样周期内进程所占cpu百分比\n%MEM: 采样周期内进程所占内存百分比\nTIME+: 进程使用的cpu时间总计\nCOMMAND: 拉起进程的命令\n\n其他常用命令:关于内存条数: \ndmidecode|grep -A5 &#x27;Memory Device&#x27;|grep Size | grep -v Installed |wc -l\n\n每条大小:\ndmidecode|grep -A5 &#x27;Memory Device&#x27;|grep Size | grep -v Installed |uniq\n\n内存类型:\ndmidecode | grep -A16 &quot;Memory Device&quot; | grep &#x27;Type:&#x27; |grep -v Unknown |uniq\n\n内存频率(在我的腾讯云服务器上不管用):\ndmidecode | grep -A16 &quot;Memory Device&quot; | grep &#x27;Speed&#x27; |grep -v Unknown |uniq\n\n关于硬盘块数和大小(在我的腾讯云服务器上不管用):\nfdisk -l | grep &quot;Disk /dev/sd&quot;\n\n查看哪个进程占用哪个端口(输入端口查看):\n查看进程资源先使用进程加-l获取进程id，然后使用-heap 加进程id查看\n查看CPU个数cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l\n\n查看CPU核数cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq\n\n查看CPU主频cat /proc/cpuinfo| grep &quot;model name&quot;| uniq\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"title":"Python50个实用代码","url":"/2022/01/20/Python50%E4%B8%AA%E5%AE%9E%E7%94%A8%E4%BB%A3%E7%A0%81/","content":"Python版本: 3.7.7\n字母异位词两个单词如果包含相同的字母，次序不同，则称为字母易位词(anagram)，例如，“silent”和“listen”是字母易位词，而“apple”和“aplee”不是易位词:\nfrom collections import Counters1 = &#x27;below&#x27;s2 = &#x27;elbow&#x27;print(&#x27;anagram&#x27;) if Counter(s1) == Counter(s2) else print(&#x27;not an anagram&#x27;)\n\n二进制转十进制decimal = int(&#x27;1010&#x27;, 2)print(decimal) #10\n\n将字符串转换为小写print(&quot;Hi my name is XiaoF&quot;.lower())# &#x27;hi my name is xiaof&#x27;print(&quot;Hi my name is XiaoF&quot;.casefold())# &#x27;hi my name is xiaof&#x27;\n\n将字符串转换为大写print(&quot;hi my name is XiaoF&quot;.upper())# &#x27;HI MY NAME IS XIAOF&#x27;\n\n将字符串转换为字节print(&quot;convert string to bytes using encode method&quot;.encode())# b&#x27;convert string to bytes using encode method&#x27;\n\n拷贝文件import shutilshutil.copyfile(&#x27;source.txt&#x27;, &#x27;dest.txt&#x27;)\n\n快速排序qsort = lambda l: l if len(l) &lt;= 1 else qsort([x for x in l[1:] if x &lt; l[0]]) + [l[0]] + qsort(\t[x for x in l[1:] if x &gt;= l[0]])print(qsort([17, 29, 11, 97, 103, 5]))# [5, 11, 17, 29, 97, 103]\n\nn个连续数的和n = 10print(sum(range(0, n + 1)))# 55\n\n交换两个变量的值a = 1b = 2a,b = b,aprint(&#x27;a: &#x27;, a)print(&#x27;b: &#x27;, b)print(f&#x27;a的值为:&#123;a&#125;&#x27;)print(f&#x27;b的值为:&#123;b&#125;&#x27;)print(&#x27;a的值为:&#123;&#125;&#x27;.format(a))print(&#x27;b的值为:&#123;&#125;&#x27;.format(b))\n\n斐波那契数列fib = lambda x: x if x&lt;=1 else fib(x-1) + fib(x-2)print(fib(20))# 6765\n\n将嵌套列表合并为一个列表main_list = [[0, 1, 2], [11, 12, 13], [52, 53, 54]]result = [item for sublist in main_list for item in sublist]print(result)# [0, 1, 2, 11, 12, 13, 52, 53, 54]\n\n运行一个HTTP服务器python3 -m http.server 8000python2 -m SimpleHTTPServer\n\n\n\n反转列表numbers = [0, 1, 2, 11, 12, 13, 52, 53, 54]print(numbers[::-1])# [54, 53, 52, 13, 12, 11, 2, 1, 0]\n\n阶乘import mathfact_5 = math.factorial(5)print(fact_5)# 120\n\n在列表推导式中使用for和ifeven_list = [number for number in [1, 2, 3, 4] if number % 2 == 0]print(even_list)# [2, 4]\n\n列表中最长的字符串words = [&#x27;This&#x27;, &#x27;is&#x27;, &#x27;a&#x27;, &#x27;list&#x27;, &#x27;of&#x27;, &#x27;words&#x27;]result = max(words, key=len)print(result)# &#x27;words&#x27;\n\n列表推导式li = [num for num in range(0, 10)]print(li)# [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n集合推导式num_set = &#123;num for num in range(0, 10)&#125;print(num_set)# &#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125;\n\n字典推导式dict_numbers = &#123;x: x * x for x in range(1, 5)&#125;print(dict_numbers)# &#123;1: 1, 2: 4, 3: 9, 4: 16&#125;\n\nif-elseprint(&quot;even&quot;) if 4 % 2==0 else print(&quot;odd&quot;)\n\n无限循环while True:\tprint(1)# while 1:0\n\n检查数据类型print(isinstance(2, int))# Trueprint(isinstance(&quot;allwin&quot;, str))# Trueprint(isinstance([3, 4, 1997], list))# True\n\nwhile循环a = 5while a &gt; 0:\ta = a - 1print(a)# 0\n\n使用print语句写入文件print(&quot;Hello, World!&quot;, file=open(&#x27;file.txt&#x27;, &#x27;w&#x27;))\n\n\n\n计算一个字符在字符串中出现的频率print(&quot;umbrella&quot;.count(&#x27;l&#x27;))# 2\n\n合并列表(extend)这里注意区别于append方法\nlist1 = [1, 2, 4]list2 = [&#x27;XiaoF&#x27;]list1.extend(list2)print(list1)# [1, 2, 4, &#x27;XiaoF&#x27;]\n\n合并字典(update)dict1 = &#123;&#x27;name&#x27;: &#x27;weiwei&#x27;, &#x27;age&#x27;: 23&#125;dict2 = &#123;&#x27;city&#x27;: &#x27;Beijing&#x27;&#125;dict1.update(dict2)print(dict1)# &#123;&#x27;name&#x27;: &#x27;weiwei&#x27;, &#x27;age&#x27;: 23, &#x27;city&#x27;: &#x27;Beijing&#x27;&#125;\n\n合并集合(update)set1 = &#123;0, 1, 2&#125;set2 = &#123;11, 12, 13&#125;set1.update(set2)print(set1)# &#123;0, 1, 2, 11, 12, 13&#125;\n\n时间戳import timeprint(time.time())\n\n列表中出现次数最多的元素test_list = [9, 4, 5, 4, 4, 5, 9, 5, 4]most_frequent_element = max(set(test_list), key=test_list.count)print(most_frequent_element)# 4\n\n嵌套列表numbers = [[num] for num in range(10)]print(numbers)# [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]]\n\n八进制转十进制print(int(&#x27;30&#x27;, 8)) # 24\n\n将键值对转换为字典result = dict(name=&#x27;XiaoF&#x27;, age=23)print(result)# &#123;&#x27;name&#x27;: &#x27;XiaoF&#x27;, &#x27;age&#x27;: 23&#125;\n\n求商和余数quotient, remainder = divmod(4, 5)print(quotient, remainder)# 0 4\n\n删除列表中的重复项print(list(set([4, 4, 5, 5, 6])))# [4, 5, 6]\n\n按升序排序列表print(sorted([5, 2, 9, 1]))# [1, 2, 5, 9]\n\n按降序排序列表print(sorted([5, 2, 9, 1], reverse=True))# [9, 5, 2, 1]\n\n获取小写字母表import stringprint(string.ascii_lowercase)# abcdefghijklmnopqrstuvwxyz\n\n获取大写字母表import stringprint(string.ascii_uppercase)# ABCDEFGHIJKLMNOPQRSTUVWXYZ\n\n获取0到9字符串import stringprint(string.digits)# 0123456789\n\n十六进制转十进制print(int(&#x27;da9&#x27;, 16))# 3497\n\n返回日期和时间import timeprint(time.ctime())# Thu Aug 13 20:00:00 2021\n\n将列表中的字符串转换为整数(map())print(list(map(int, [&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;])))# [1, 2, 3]\n\n用键对字典进行排序d = &#123;&#x27;one&#x27;: 1, &#x27;four&#x27;: 4, &#x27;eight&#x27;: 8&#125;result = &#123;key: d[key] for key in sorted(d.keys())&#125;print(result)# &#123;&#x27;eight&#x27;: 8, &#x27;four&#x27;: 4, &#x27;one&#x27;: 1&#125;\n\n用值对字典进行排序x = &#123;1: 2, 3: 4, 4: 3, 2: 1, 0: 0&#125;result = &#123;k: v for k, v in sorted(x.items(), key=lambda item: item[1])&#125;print(result)# &#123;0: 0, 2: 1, 1: 2, 4: 3, 3: 4&#125;\n\n列表旋转li = [1, 2, 3, 4, 5]l = len(li)if l % 2 == 0:\tprint(li[l//2:] + li[:l//2])print(li[l//2 + 1:] + [li[l//2]] + li[:l//2])\n\n将字符串中的数字移除(isalpha())message = &#x27;&#x27;.join(list(filter(lambda x: x.isalpha(), &#x27;abc123def4fg56vcg2&#x27;)))print(message)# abcdeffgvcg\n\n矩阵变换(zip()+*解包)old_list = [[1, 2, 3], [3, 4, 6], [5, 6, 7]]result = list(list(x) for x in zip(*old_list)) print(result)# [[1, 3, 5], [2, 4, 6], [3, 6, 7]]\n\n列表过滤result = list(filter(lambda x: x % 2 == 0, [1, 2, 3, 4, 5, 6]))print(result)# [2, 4, 6]\n\n解包a, *b, c = [1, 2, 3, 4, 5]print(a)  # 1print(b)  # [2, 3, 4]print(c)  # 5\n\n\n\n\n\n\n\n\n\n"},{"title":"Python导入包的语法'from module import *'一定能导入包下面的所有方法嘛?","url":"/2022/01/20/Python%E5%AF%BC%E5%85%A5%E5%8C%85%E7%9A%84%E8%AF%AD%E6%B3%95'from%20module%20import'%E7%9C%9F%E7%9A%84%E8%83%BD%E5%AF%BC%E5%85%A5%E4%B8%8B%E9%9D%A2%E7%9A%84%E6%89%80%E6%9C%89%E6%96%B9%E6%B3%95%E5%98%9B/","content":"在一个模块中，以单下划线_开头命名的函数(方法)是定义为受保护的，用from module import *是导入不了这些受保护的方法；那么还有一种方法就是在__all__列表中去除不想导入的函数(方法)，如下所示以_开头命名的函数就不会导入到其他代码中(这是一个自写日志模板):\nimport sysimport tracebackimport datetimedef getnowtime():    return datetime.datetime.now().strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)def _log(content, level, *args):    sys.stdout.write(&quot;%s - %s - %s\\n&quot; % (getnowtime(), level, content))    for arg in args:        sys.stdout.write(&quot;%s\\n&quot; % arg)def debug(content, *args):    _log(content, &#x27;DEBUG&#x27;, *args)def info(content, *args):    _log(content, &#x27;INFO&#x27;, *args)def warn(content, *args):    _log(content, &#x27;WARN&#x27;, *args)def error(content, *args):    _log(content, &#x27;ERROR&#x27;, *args)def exception(content):    sys.stdout.write(&quot;%s - %s\\n&quot; % (getnowtime(), content))    traceback.print_exc(file=sys.stdout)\n\n\n\n"},{"title":"Python中不存在严格意义上的私有成员","url":"/2022/01/20/Python%E7%9A%84%E7%B1%BB%E6%9C%89%E9%9A%90%E7%A7%81%E5%98%9B/","content":"首先，Python并没有对私有成员听严格的保护机制\n\n在定义类的成员时，如果成员名以两个下划线__或更多下划线开头而不以两个或更多下划线结束则表示是私有成员\n私有成员在类的外部不能直接访问，需要通过调用对象的公开成员来访问，也可以通过Python支持的特殊方法来访问(如property装饰器)\n\n我们需要知道的是，在类中，以_开头的属性或者方法为受保护的，但这只是一个说法，受保护的在类外也一样访问，但是私有属性或者方法在类外就要处理一下了，其实它也不是真正的私有:\nclass A:    def __init__(self, value1 = 0, value2 = 0):        self._value1 = value1        self.__value2 = value2    def setValue(self, value1, value2):        self._value1 = value1        self.__value2 = value2    def show(self):        print(self._value1)        print(self.__value2)&gt;&gt;&gt; a = A()&gt;&gt;&gt; a._value10&gt;&gt;&gt; a._A__value2 # 在外部访问对象的私有数据成员0\n\n在Python中，以下划线开头的变量名和方法名有特殊的含义，尤其是在类的定义中:\n\n_XXX: 受保护的成员，不能用from module import *导入\n__XXX__: 私有成员，只有类对象自己能访问，子类对象不能直接访问到这个成员，但在类外部可以通过对象名._类名__xxx这样的特殊方式来访问，或者直接使用property装饰器暴露出来\n\nPython中不存在严格意义上的私有成员，如下例子就体现了:\nclass Fruit:     def __init__(self):         self.__color = &#x27;Red&#x27;         self.price = 1 &gt;&gt;&gt; apple = Fruit() &gt;&gt;&gt; apple.price                               # 显示对象公开数据成员的值 1 &gt;&gt;&gt; print(apple.price, apple._Fruit__color)   # 显示对象私有数据成员的值 1 Red &gt;&gt;&gt; apple.price = 2                           # 修改对象公开数据成员的值 &gt;&gt;&gt; apple._Fruit__color = &quot;Blue&quot;              # 修改对象私有数据成员的值 &gt;&gt;&gt; print(apple.price, apple._Fruit__color) 2 Blue &gt;&gt;&gt; print(apple.__color)                      # 不能直接访问对象的私有数据成员，出错 AttributeError:Fruit instance has no attribute &#x27;__color&#x27;\n\n在程序中，可以使用一个下划线_来表示不关心该变量的值(约定俗成):\nfor _ in range(5):     print(3, end=&#x27; &#x27;)     # 此处的3可以为任意值，输出结果为重复5次的值。若改为print(_, end=&#x27; &#x27;);&gt;&gt;&gt;0 1 2 3 4 3 3 3 3 3 &gt;&gt;&gt; a, _ = divmod(60, 18) # 只关心整商，不关心余数。 &gt;&gt;&gt; a                     # 即等价于a = 60//18 3\n\n\n\n"},{"title":"Python日志终极解决方案--Loguru","url":"/2022/01/20/Python%E6%97%A5%E5%BF%97%E7%BB%88%E6%9E%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88--Loguru/","content":"为什么要有日志日志的作用非常重要，日志可以记录用户的操作、程序的异常，还可以为数据分析提供依据，日志的存在意义就是为了能够在程序在运行过程中记录错误，方便维护和调试，能够快速定位出错的地方，减少维护成本；每个程序员都应该知道，不是为了记录日志而记录日志，日志也不是随意记的；要实现能够只通过日志文件还原整个程序执行的过程，达到能透明地看到程序里执行情况，每个线程、每个过程到底执行到哪的目的；日志就像飞机的黑匣子一样，应当能够复原异常的整个现场乃至细节!\n常见的日志记录方式print()最常见的是把输出函数 print() 当作日志记录的方式，直接打印各种提示信息，常见于个人练习项目里，通常是懒得单独配置日志，而且项目太小不需要日志信息，不需要上线，不需要持续运行，完整的项目不推荐直接打印日志信息，现实中也几乎没有人这么做\n自写模板我们可以在不少小项目里面看到作者自己写了一个日志模板，通常利用print()或者sys.stdout稍微封装一下即可实现简单的日志输出，这里的sys.stdout是Python中的标准输出流,print()函数是对sys.stdout的高级封装，当我们在Python中打印对象调用 print(obj)时候，事实上是调用了 sys.stdout.write(obj+&#39;\\n&#39;)，print()将内容打印到了控制台，然后追加了一个换行符 \\n;\n一个简单的自写日志模板举例:\n日志模板log.py:\nimport sysimport tracebackimport datetimedef getnowtime():    return datetime.datetime.now().strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)def _log(content, level, *args):    sys.stdout.write(&quot;%s - %s - %s\\n&quot; % (getnowtime(), level, content))    for arg in args:        sys.stdout.write(&quot;%s\\n&quot; % arg)def debug(content, *args):    _log(content, &#x27;DEBUG&#x27;, *args)def info(content, *args):    _log(content, &#x27;INFO&#x27;, *args)def warn(content, *args):    _log(content, &#x27;WARN&#x27;, *args)def error(content, *args):    _log(content, &#x27;ERROR&#x27;, *args)def exception(content):    sys.stdout.write(&quot;%s - %s\\n&quot; % (getnowtime(), content))    traceback.print_exc(file=sys.stdout)\n\n调用日志模块:\nimport loglog.info(&quot;This is log info!&quot;)log.warn(&quot;This is log warn!&quot;)log.error(&quot;This is log error!&quot;)log.debug(&quot;This is log debug!&quot;)people_info = &#123;&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 20&#125;try:    gender = people_info[&quot;gender&quot;]except Exception as error:    log.exception(error)\n\n日志输出:\n2021-10-19 09:50:58 - INFO - This is log info!2021-10-19 09:50:58 - WARN - This is log warn!2021-10-19 09:50:58 - ERROR - This is log error!2021-10-19 09:50:58 - DEBUG - This is log debug!2021-10-19 09:50:58 - &#x27;gender&#x27;Traceback (most recent call last):  File &quot;D:/python3Project/test.py&quot;, line 18, in &lt;module&gt;    gender = people_info[&quot;gender&quot;]KeyError: &#x27;gender&#x27;\n\nLogging在一个完整的项目中，大多数人都会引入专门的日志记录库，而 Python自带的标准库logging就是专门为日志记录而生的，logging模块定义的函数和类为应用程序和库的开发实现了一个灵活的事件日志系统；由标准库模块提供日志记录API的关键好处是所有Python模块都可以使用这个日志记录功能；所以，你的应用日志可以将你自己的日志信息与来自第三方模块的信息整合起来\nlogging模块虽然强大，但是其配置也是比较繁琐的，在大型项目中通常需要单独初始化日志、配置日志格式等等，在日常使用中通常都会对logging做如下的封装写法，使日志可以按天保存，保留15天的日志，可以配置是否输出到控制台和文件，如下所示:\n# 实现按天分割保留日志import osimport sysimport loggingfrom logging import handlersPARENT_DIR = os.path.split(os.path.realpath(__file__))[0]  # 父目录LOGGING_DIR = os.path.join(PARENT_DIR, &quot;log&quot;)              # 日志目录LOGGING_NAME = &quot;test&quot;                                      # 日志文件名LOGGING_TO_FILE = True                                     # 日志输出文件LOGGING_TO_CONSOLE = True                                  # 日志输出到控制台LOGGING_WHEN = &#x27;D&#x27;                                         # 日志文件切分维度LOGGING_INTERVAL = 1                                       # 间隔少个 when 后，自动重建文件LOGGING_BACKUP_COUNT = 15                                  # 日志保留个数，0 保留所有日志LOGGING_LEVEL = logging.DEBUG                              # 日志等级LOGGING_suffix = &quot;%Y.%m.%d.log&quot;                            # 旧日志文件名# 日志输出格式LOGGING_FORMATTER = &quot;%(levelname)s - %(asctime)s - process:%(process)d - %(filename)s - %(name)s - line:%(lineno)d - %(module)s - %(message)s&quot;def logging_init():    if not os.path.exists(LOGGING_DIR):        os.makedirs(LOGGING_DIR)    logger = logging.getLogger()    logger.setLevel(LOGGING_LEVEL)    formatter = logging.Formatter(LOGGING_FORMATTER)    if LOGGING_TO_FILE:        file_handler = handlers.TimedRotatingFileHandler(filename=os.path.join(LOGGING_DIR, LOGGING_NAME), when=LOGGING_WHEN, interval=LOGGING_INTERVAL, backupCount=LOGGING_BACKUP_COUNT)        file_handler.suffix = LOGGING_suffix        file_handler.setFormatter(formatter)        logger.addHandler(file_handler)    if LOGGING_TO_CONSOLE:        stream_handler = logging.StreamHandler(sys.stderr)        stream_handler.setFormatter(formatter)        logger.addHandler(stream_handler)def logging_test():    logging.info(&quot;This is log info!&quot;)    logging.warning(&quot;This is log warn!&quot;)    logging.error(&quot;This is log error!&quot;)    logging.debug(&quot;This is log debug!&quot;)    people_info = &#123;&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 20&#125;    try:        gender = people_info[&quot;gender&quot;]    except Exception as error:        logging.exception(error)if __name__ == &quot;__main__&quot;:    logging_init()    logging_test()\n\n输出日志:\nINFO - 2021-10-19 11:28:10,103 - process:15144 - test.py - root - line:52 - test - This is log info!WARNING - 2021-10-19 11:28:10,105 - process:15144 - test.py - root - line:53 - test - This is log warn!ERROR - 2021-10-19 11:28:10,105 - process:15144 - test.py - root - line:54 - test - This is log error!DEBUG - 2021-10-19 11:28:10,105 - process:15144 - test.py - root - line:55 - test - This is log debug!ERROR - 2021-10-19 11:28:10,105 - process:15144 - test.py - root - line:61 - test - &#x27;gender&#x27;Traceback (most recent call last):  File &quot;D:/python3Project/test.py&quot;, line 59, in logging_test    gender = people_info[&quot;gender&quot;]KeyError: &#x27;gender&#x27;\n\n在控制台中是这样的:\n\n当然，如果你不需要很复杂的功能，希望简洁一点，仅仅需要在控制台输出日志的话，也可以只进行简单的配置:\nimport logginglogging.basicConfig(level=logging.DEBUG, format=&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;)logging.getLogger()\n\n更优雅的解决方案对于logging模块，即便是简单地使用，也需要自己定义格式，这里介绍一个更加优雅、高效、简洁的第三方模块: loguru，官方的介绍是: Loguru is a library which aims to bring enjoyable logging in Python. Loguru旨在为Python带来愉快的日志记录\n安装Loguru只支持Python3.5及以上的版本，使用pip安装即可:\npip insall loguru\n\n开箱即用Loguru的主要概念是只有一个logger:\n\n可以看到不需要手动设置，Loguru会提前配置一些基础信息，自动输出时间，日志级别，模块名，行号等等；而且还根据级别的不同，自动设置了不同的颜色，方便观察，真正做到了开箱即用!\nadd()/remove()如果想自定义日志级别，自定义日志格式，保存到文件该怎么办?与logging模块不同，不需要Handler，不需要Formatter，只需要一个add函数即可，例如我们想把日志存储到文件:\n我们不需要像logging模块一样再声明一个FileHandler了，就一行add()语句搞定，运行之后会发现目录下test.log里面同样出现了刚刚控制台输出的debug信息:\n与add()语句相反，remove()语句可以删除我们添加的配置(就写入文件来说就是不写入文件了):\n这个时候控制台还是4条log，但是由于我们在最后一个debug的log前删除了配置也就是说debug的log不再会写入文件:\n所以test_log.log中后面只有三条log:\n\n完整参数Loguru对输出到文件的配置有非常强大的支持，比如支持输出到多个文件，分级别分别输出，过大创建新文件，过久自动删除等等，下面我们来详细看一下add()语句的详细参数:\n基本语法:\nadd(sink, *, level=&#x27;DEBUG&#x27;, format=&#x27;&lt;green&gt;&#123;time:YYYY-MM-DD HH:mm:ss.SSS&#125;&lt;/green&gt; | &lt;level&gt;&#123;level: &lt;8&#125;&lt;/level&gt; | &lt;cyan&gt;&#123;name&#125;&lt;/cyan&gt;:&lt;cyan&gt;&#123;function&#125;&lt;/cyan&gt;:&lt;cyan&gt;&#123;line&#125;&lt;/cyan&gt; - &lt;level&gt;&#123;message&#125;&lt;/level&gt;&#x27;, filter=None, colorize=None, serialize=False, backtrace=True, diagnose=True, enqueue=False, catch=True, **kwargs)\n\n详细见: https://blog.csdn.net/kdl_csdn/article/details/121146354?spm=1001.2014.3001.5502\n"},{"title":"计算机网络知识扫盲--转载自头条","url":"/2022/01/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E6%89%AB%E7%9B%B2--%E8%BD%AC%E8%BD%BD%E8%87%AA%E5%A4%B4%E6%9D%A1/","content":"详情点击跳转\n"},{"title":"Leetcode160.相交链表","url":"/2022/01/21/Leetcode160.%E7%9B%B8%E4%BA%A4%E9%93%BE%E8%A1%A8/","content":"今天我们来看看一道简单的题，题意点击跳转，分析之后我们得知，这道题给定两个单链表的头结点headA和headB，然后要我们找出并返回这两个单链表相交的第一个节点，如果两个链表不存在节点，便返回null\n我们可以分析下，两个链表，既然要相交，那么相交之前的那段链表必然有长有短或者是同样长度，相交的定义就是这两个单链表的某个值相同那就在这个地方相交，既然要判断值是否相同那就需要一个一个去对比，我们就需要在两个单链表都有值的地方开始遍历去判断值是否相同，所以我们可以有如下思路:\n\n这里有两个链表A和B，headA指向链表A的头节点，headB指向链表B的头结点\n\n初始化两个指针，flagA和flagB，以及链表的长度lenA和lenB\n\n然后求得链表A和B的长度分别为lenA和lenB\n\n求完两个长度之后，两个指针都重新指向链表头部\n\n然后如果A是长链表，则指针flagA后移到和B链表同等长度的位置上\n\n如果B是长链表，则指针flagB后移到和A链表同等长度的位置上\n\n然后两个指针flagA和flagB同时遍历，如果遇到相同的就返回，遍历完没有遇到，就返回None\n\n\nPython代码实现:\n# Definition for singly-linked list.# class ListNode:#     def __init__(self, x):#         self.val = x#         self.next = Noneclass Solution:    def getIntersectionNode(self, headA: ListNode, headB: ListNode) -&gt; ListNode:        # 链表A和B任一为空，链表不相交        if not headA or not headB:            return None        # 初始化headA、headB的指针和长度        flagA, flagB = headA, headB        lenA, lenB = 0, 0        # 求链表 A 的长度        while flagA:            flagA = flagA.next            lenA += 1        # 求链表 B 的长度        while flagB:            flagB = flagB.next            lenB += 1        # 重新指向表头        flagA, flagB = headA, headB        # 为了让大家看的明白点，我就不用华丽花哨的写法了，用最笨的写法表示。        # 当A是长链表，则指针flagA后移到和B链表同等长度的位置上。        if lenA &gt; lenB:            d_value = lenA - lenB            while d_value:                flagA = flagA.next                d_value -= 1        # 当B是长链表，则指针flagB后移到和A链表同等长度的位置上。        else:            d_value = lenB - lenA            while d_value:                flagB = flagB.next                d_value -= 1        # 然后两个指针flagA和flagB同时遍历        while flagA:            if flagA == flagB:                return flagA            else:                flagA = flagA.next                flagB = flagB.next        # 如果没有相遇，返回 None        return None\n\n\n\n"},{"title":"Leetcode141.环形链表","url":"/2022/01/21/Leetcode141.%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8/","content":"我们来看下LeetCode上一个相对简单的题，环形链表，这里给定一个链表，要求我们判断链表中是否有环\n这道题的思路就是快慢指针，快慢指针这种算法证明，一快一慢两个指针肯定是会相遇的，快的指针一定会追上慢的指针，可以理解为操场上跑步，跑得快的人会超圈追上跑得慢的人，一般使用fast定义快指针，用slow定义慢指针，速度不同是指fast每次多走几步，slow少走几步，一般的设定都是fast走2步，slow走1步；本题就是使用快慢指针\n\n若是链表无环，那么fast指针回先指向Null\n若是链表有环，fast和slow迟早会在环中相遇\n\nPython代码实现:\n# Definition for singly-linked list.# class ListNode:#     def __init__(self, x):#         self.val = x#         self.next = Noneclass Solution:    def hasCycle(self, head: ListNode) -&gt; bool:        # 空链表或链表只有一个节点，无环        if not head or head.next == None:            return False        # 初始化快慢指针        fast = slow = head        # 如果不存在环，肯定 fast 先指向 null        # 细节：fast 每次走 2 步，所以要确定 fast 和 fast.next 不为空，不然会报执行出错。        while fast and fast.next:            # 快指针移动 2 步，慢指针移动 1 步            fast = fast.next.next            slow = slow.next            # 快慢指针相遇，有环            if fast == slow:                return True        return False\n\n"},{"title":"稷生科技爬虫项目Apollo配置","url":"/2022/01/21/%E7%A8%B7%E7%94%9F%E7%A7%91%E6%8A%80%E7%88%AC%E8%99%AB%E9%A1%B9%E7%9B%AEApollo%E9%85%8D%E7%BD%AE/","content":"﻿﻿### 第一个App_ID\nMONGO_HOST = 192.168.3.85MONGO_PORT = 27017# 数据库地址MONGO_DATABASE = popular_industryMYSQL_HOST = 192.168.3.85MYSQL_PORT = 3306MYSQL_DATABASE = industryMYSQL_USER = rootMYSQL_PASSWORD = 123456MYSQL_CHARSET = utf8# 文件上传地址send_url = http://192.168.3.85:8500/file/upload/# 代理地址PROXY_GET_URL = http://192.168.3.85:5010/get/# 卡夫卡地址KAFKA_URL = 192.168.0.11:9092# 开启爬虫监控EXTENSIONS = &#123;&quot;pybase.monitor_extension.Monitor&quot;: 300&#125;\n\n第二个App_ID# 表名MONGO_TABLE = xxx_xxx_xxx# 去重字段MONGO_TABLE_UNIQUE_INDEX = [&quot;title&quot;,&quot;content_url&quot;]\n\n\n注意：要先在本地和docker上安装最新版  pycommon-pro-x.x.x.tar.gz\n"},{"title":"基本可以取代Postman的命令行工具curl使用简介","url":"/2022/01/21/%E5%9F%BA%E6%9C%AC%E5%8F%AF%E4%BB%A5%E5%8F%96%E4%BB%A3Postman%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7curl%E4%BD%BF%E7%94%A8%E7%AE%80%E4%BB%8B/","content":"此文转载自今日头条，详情点击跳转\n"},{"title":"js逆向登录OSCHINA案例","url":"/2022/01/21/js%E9%80%86%E5%90%91%E7%99%BB%E5%BD%95OSCHINA%E6%A1%88%E4%BE%8B/","content":"我们首先打开OSCHINA的网站，然后我们点击登录，打开登录界面，随便输入一个手机号和密码，然后在点击登录前F12打开控制台，调到xhr/fetch去监控ajax请求，登录过程一般都是ajax完成的，我们会看到如下一个请求，并且看到这个请求所带的参数:\n\n我用postman测试了下这个请求，发现只有前两个是必选的参数:\n\n选中的这些数据都可以去掉\n然后我们就只剩下一个加密参数了也就是pwd，我们全局搜索下pwd，发现它只出现在一个js文件中，我们进入这个js文件，然后再在文件内局部搜索下pwd，很快就定位到了加密的代码:\n\n然后在pwd的那一行打个断点，点击登录验证一下，确实就是我们登录那个POST请求所要求携带的pwd参数，我们把上图加密的代码扣下来看看:\npwd: CryptoJS.SHA1(passwordInput.val()).toString()\n\n从上面代码我们很容易发现这是个SHA1的加密方式，然后我们用代码实现下，其中参考了这个博客，代码如下:\nimport execjsjs_code = &#x27;&#x27;&#x27;const CryptoJS = require(&#x27;crypto-js&#x27;);function get_pwd()&#123;pwd = CryptoJS.SHA1(&#x27;zx360828htc&#x27;).toString()return pwd&#125;&#x27;&#x27;&#x27;ctx = execjs.compile(js_code, cwd=r&quot;C:\\Users\\Administrator\\node_modules\\crypto-js&quot;)encrypted_password = ctx.call(&quot;get_pwd&quot;)print(encrypted_password)print(len(encrypted_password))# 运行结果:# 256666b697279162f5299bc24c6f321bc284b0e0# 40\n\n有了加密后的密码我们就可以进行模拟登录了，下面来看看如何用Python进行模拟登录:\nimport requestsfrom decrypt_pwd_ofoschina import get_login_pwdimport jsonurl = &quot;https://www.oschina.net/action/user/hash_login?from=&quot;pwd = get_login_pwd()payload = f&quot;email=18979685341&amp;pwd=&#123;pwd&#125;&quot;headers = &#123;    &#x27;Connection&#x27;: &#x27;keep-alive&#x27;,    &#x27;sec-ch-ua&#x27;: &#x27;&quot; Not;A Brand&quot;;v=&quot;99&quot;, &quot;Google Chrome&quot;;v=&quot;97&quot;, &quot;Chromium&quot;;v=&quot;97&quot;&#x27;,    &#x27;Accept&#x27;: &#x27;*/*&#x27;,    &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded; charset=UTF-8&#x27;,    &#x27;X-Requested-With&#x27;: &#x27;XMLHttpRequest&#x27;,    &#x27;sec-ch-ua-mobile&#x27;: &#x27;?0&#x27;,    &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&#x27;,    &#x27;sec-ch-ua-platform&#x27;: &#x27;&quot;Windows&quot;&#x27;,    &#x27;Origin&#x27;: &#x27;https://www.oschina.net&#x27;,    &#x27;Sec-Fetch-Site&#x27;: &#x27;same-origin&#x27;,    &#x27;Sec-Fetch-Mode&#x27;: &#x27;cors&#x27;,    &#x27;Sec-Fetch-Dest&#x27;: &#x27;empty&#x27;,    &#x27;Referer&#x27;: &#x27;https://www.oschina.net/home/login&#x27;,    &#x27;Accept-Language&#x27;: &#x27;zh-CN,zh;q=0.9&#x27;,    &#x27;Cookie&#x27;: &#x27;_user_behavior_=869ac9fb-a9c0-4b89-b84c-f3bd9b9e657e; __gads=ID=e804becd9a702ae8-2294f8f86ecc0047:T=1634122318:RT=1634122318:S=ALNI_MYpfoD33y1FqNGvewkr-WD0UROc7w; yp_riddler_id=eea8a882-b254-4e26-9e34-82dcc3ff5f5c; _reg_key_=pNX1Xow6usH8HciTyIjR; Hm_lvt_a411c4d1664dd70048ee98afe7b28f0b=1642068454,1642127481,1642736864; Hm_lpvt_a411c4d1664dd70048ee98afe7b28f0b=1642736864; oscid=9I1JeAH9dWYUkGb%2Fhmkhg5wb6PWH8sQSbjFU1yL96oZ4%2Ftn5l%2BoR%2FuOWEEMrD3gFoV7TwIofZyT%2Bk8Ii7KgZjEHIs%2FkSc6cZf9rTcCvUltmDLUZDlD5gRtVB63Kq6feyjasfipeSeXnrCMvUVOA7Rw%3D%3D&#x27;&#125;response = requests.request(    &quot;POST&quot;,    url,    headers=headers,    data=payload)print(response.text)\n\n\n\n\n\n"},{"title":"关于Ajax","url":"/2022/01/22/%E5%85%B3%E4%BA%8EAjax/","content":"Ajax介绍从数据的角度考虑，网页上呈现出来的数据的来源:\n\nhtml文件 60%\nAjax接口 30%\nJavaScript加载 10%\n\n那么Ajax是什么，Ajax是异步的JavaScript和XML的英文翻译缩写，这个技术可以在页面不刷新的情况下，利用js和后端服务器进行交互，将内容显示在前端页面上，优点是可以大大提高网页的打开速度，从开发角度可以做到前后端分离，提高开发速度\nAjax的工作步骤\n发送请求: 通过接口，js向服务器发送xmlhttp请求(XHR)\n解析内容: js得到响应后，返回的内容可能是html，也可能是json格式\n渲染网页: js通过操纵dom树，改变dom节点的内容，达到修改网页的目的\n\n如何找接口浏览器的开发者工具\n利用官方接口比如Facebook的graph api\nrestful api风格接口\n"},{"title":"2022-1-21每日英语","url":"/2022/01/21/2022-1-21%E6%AF%8F%E6%97%A5%E8%8B%B1%E8%AF%AD/","content":"\ncandidate n. 候选人[‘kændədets]\n\n"},{"title":"Pycharm激活方法","url":"/2022/01/22/Pycharm%E6%BF%80%E6%B4%BB%E6%96%B9%E6%B3%95/","content":"激活方式选择License server，然后填入以下服务器地址任意一个:\nhttp://39.105.114.41:1027http://36.110.99.11:3456\n\n如果License server激活不了下面介绍activation code激活方式:\n\nhosts文件加入:\n0.0.0.0 account.jetbrains.com\n输入激活码:(注意放入第二个选项activation code选项里面)\nK71U8DBPNE-eyJsaWNlbnNlSWQiOiJLNzFVOERCUE5FIiwibGljZW5zZWVOYW1lIjoibGFuIHl1IiwiYXNzaWduZWVOYW1lIjoiIiwiYXNzaWduZWVFbWFpbCI6IiIsImxpY2Vuc2VSZXN0cmljdGlvbiI6IkZvciBlZHVjYXRpb25hbCB1c2Ugb25seSIsImNoZWNrQ29uY3VycmVudFVzZSI6ZmFsc2UsInByb2R1Y3RzIjpbeyJjb2RlIjoiSUkiLCJwYWlkVXBUbyI6IjIwMTktMDUtMDQifSx7ImNvZGUiOiJSUzAiLCJwYWlkVXBUbyI6IjIwMTktMDUtMDQifSx7ImNvZGUiOiJXUyIsInBhaWRVcFRvIjoiMjAxOS0wNS0wNCJ9LHsiY29kZSI6IlJEIiwicGFpZFVwVG8iOiIyMDE5LTA1LTA0In0seyJjb2RlIjoiUkMiLCJwYWlkVXBUbyI6IjIwMTktMDUtMDQifSx7ImNvZGUiOiJEQyIsInBhaWRVcFRvIjoiMjAxOS0wNS0wNCJ9LHsiY29kZSI6IkRCIiwicGFpZFVwVG8iOiIyMDE5LTA1LTA0In0seyJjb2RlIjoiUk0iLCJwYWlkVXBUbyI6IjIwMTktMDUtMDQifSx7ImNvZGUiOiJETSIsInBhaWRVcFRvIjoiMjAxOS0wNS0wNCJ9LHsiY29kZSI6IkFDIiwicGFpZFVwVG8iOiIyMDE5LTA1LTA0In0seyJjb2RlIjoiRFBOIiwicGFpZFVwVG8iOiIyMDE5LTA1LTA0In0seyJjb2RlIjoiR08iLCJwYWlkVXBUbyI6IjIwMTktMDUtMDQifSx7ImNvZGUiOiJQUyIsInBhaWRVcFRvIjoiMjAxOS0wNS0wNCJ9LHsiY29kZSI6IkNMIiwicGFpZFVwVG8iOiIyMDE5LTA1LTA0In0seyJjb2RlIjoiUEMiLCJwYWlkVXBUbyI6IjIwMTktMDUtMDQifSx7ImNvZGUiOiJSU1UiLCJwYWlkVXBUbyI6IjIwMTktMDUtMDQifV0sImhhc2giOiI4OTA4Mjg5LzAiLCJncmFjZVBlcmlvZERheXMiOjAsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-Owt3/+LdCpedvF0eQ8635yYt0+ZLtCfIHOKzSrx5hBtbKGYRPFDrdgQAK6lJjexl2emLBcUq729K1+ukY9Js0nx1NH09l9Rw4c7k9wUksLl6RWx7Hcdcma1AHolfSp79NynSMZzQQLFohNyjD+dXfXM5GYd2OTHya0zYjTNMmAJuuRsapJMP9F1z7UTpMpLMxS/JaCWdyX6qIs+funJdPF7bjzYAQBvtbz+6SANBgN36gG1B2xHhccTn6WE8vagwwSNuM70egpahcTktoHxI7uS1JGN9gKAr6nbp+8DbFz3a2wd+XoF3nSJb/d2f/6zJR8yJF8AOyb30kwg3zf5cWw==-MIIEPjCCAiagAwIBAgIBBTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE1MTEwMjA4MjE0OFoXDTE4MTEwMTA4MjE0OFowETEPMA0GA1UEAwwGcHJvZDN5MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxcQkq+zdxlR2mmRYBPzGbUNdMN6OaXiXzxIWtMEkrJMO/5oUfQJbLLuMSMK0QHFmaI37WShyxZcfRCidwXjot4zmNBKnlyHodDij/78TmVqFl8nOeD5+07B8VEaIu7c3E1N+e1doC6wht4I4+IEmtsPAdoaj5WCQVQbrI8KeT8M9VcBIWX7fD0fhexfg3ZRt0xqwMcXGNp3DdJHiO0rCdU+Itv7EmtnSVq9jBG1usMSFvMowR25mju2JcPFp1+I4ZI+FqgR8gyG8oiNDyNEoAbsR3lOpI7grUYSvkB/xVy/VoklPCK2h0f0GJxFjnye8NT1PAywoyl7RmiAVRE/EKwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQC9WZuYgQedSuOc5TOUSrRigMw4/+wuC5EtZBfvdl4HT/8vzMW/oUlIP4YCvA0XKyBaCJ2iX+ZCDKoPfiYXiaSiH+HxAPV6J79vvouxKrWg2XV6ShFtPLP+0gPdGq3x9R3+kJbmAm8w+FOdlWqAfJrLvpzMGNeDU14YGXiZ9bVzmIQbwrBA+c/F4tlK/DV07dsNExihqFoibnqDiVNTGombaU2dDup2gwKdL81ua8EIcGNExHe82kjF4zwfadHk3bQVvbfdAwxcDy4xBjs3L4raPLU3yenSzr/OEur1+jfOxnQSmEcMXKXgrAQ9U55gwjcOFKrgOxEdek/Sk1VfOjvS+nuM4eyEruFMfaZHzoQiuw4IqgGc45ohFH0UUyjYcuFxxDSU9lMCv8qdHKm+wnPRb0l9l5vXsCBDuhAGYD6ss+Ga+aDY6f/qXZuUCEUOH3QUNbbCUlviSz6+GiRnt1kA9N2Qachl+2yBfaqUqr8h7Z2gsx5LcIf5kYNsqJ0GavXTVyWh7PYiKX4bs354ZQLUwwa/cG++2+wNWP+HtBhVxMRNTdVhSm38AknZlD+PTAsWGu9GyLmhti2EnVwGybSD2Dxmhxk3IPCkhKAK+pl0eWYGZWG3tJ9mZ7SowcXLWDFAk0lRJnKGFMTggrWjV8GYpw5bq23VmIqqDLgkNzuoog==\n\n注意: hosts中只加入0.0.0.0 account.jetbrains.com这一行\nhost文件路径: C\\Windows\\System32\\drives\\etc\\hosts，如果增加完毕不让保存，可以将文件另存到桌面(不需要添加后缀名)，然后修改，在拷贝替换host文件就可以了\n\n\n"},{"title":"Python如何安装.whl文件(当pip安装不了时)","url":"/2022/01/22/Python%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85.whl%E6%96%87%E4%BB%B6(%E5%BD%93pip%E5%AE%89%E8%A3%85%E4%B8%8D%E4%BA%86%E6%97%B6)/","content":"有时候我们通过pip install xxx的方式并不能成功安装想要的包，会出现如下所示报错:\n\n然后我们就需要去pypi这个网站上寻找我们想要的包，几乎都是可以找到的，比如我刚刚通过pip没安安装上fonttools，所以我在这边搜索并下载:\n\n然后我们点进去点击Download files找到以.whl后缀的包再点击下载即可:\n\n下载好之后我们点击在文件夹中显示:\n\n进入.whl包所在文件夹后，我们在路径一栏输入cmd，然后进入命令行(这个时候命令行就定位到了当前文件夹):\n\n然后以下键入命令:\npip install xxx.whl\n\nxxx.whl就是我们刚刚下载的.whl包的全名，然后回车即可安装:\n\n"},{"title":"关于Pycharm如何添加代码模板(脚本)","url":"/2022/01/22/%E5%85%B3%E4%BA%8EPycharm%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF(%E8%84%9A%E6%9C%AC)/","content":"我们看到有些人的Pycharm编辑器每个代码的顶端都有一个提示或者每次都是复用同一个代码，这个操作是怎么完成的呢，我们来看看:\n\n打开设置\n\n\n直接找不好找，机智的我们就开搜\n\n可以看到HTMLFile是已经默认配置了的，HTMLFile下方的我们都可以配置，配置完点击Apply再点击OK，或者直接点击OK都行\n\n下面这是我配置的\n&quot;&quot;&quot;@Description : @File        : 11@Project     : test@Time        : 2022/1/22 15:52@Author      : LiHouJian@Software    : PyCharm@issue       : @change      : @reason      : &quot;&quot;&quot;import hashlibimport reimport urllibimport scrapyimport asyncioimport datetimeimport osimport tracebackimport jsonfrom scrapy.utils import requestfrom lxml import etreefrom scrapy.utils.project import get_project_settingsfrom pybase.util import send_file\n\n效果:\n\n\n\n"},{"title":"解决猫眼字体反爬","url":"/2022/01/21/%E8%A7%A3%E5%86%B3%E7%8C%AB%E7%9C%BC%E5%AD%97%E4%BD%93%E5%8F%8D%E7%88%AC/","content":"目标网站: https://piaofang.maoyan.com/dashboard\n首先我们来看看字体反爬的效果是咋样的:\n我们要拿的数据是综合票房，然后我们点进浏览器自带的抓包工具看看:\n\n我们定位到票房的数据，但是在代码中显示的却是几个特殊符号，这是源文件都无法显示票房信息，在每次刷新的时候都会加载一个xxxx.woff字体文件，类似于这样的:\n\n我们可以在请求中找到相关字体的链接，复制这个链接(复制链接的时候不要把链接最后的/给复制进去了)然后把该字体文件下载下来然后用High-Logic FontCreator打开(或者直接用在线字体解析网站打开)，直接拖动进去\n\n\n再使用fontTools把该字体保存为XML格式查看:\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;ttFont sfntVersion=&quot;\\x00\\x01\\x00\\x00&quot; ttLibVersion=&quot;4.28&quot;&gt;  &lt;GlyphOrder&gt;    &lt;!-- The &#x27;id&#x27; attribute is only for humans; it is ignored when parsed. --&gt;    &lt;GlyphID id=&quot;0&quot; name=&quot;glyph00000&quot;/&gt;    &lt;GlyphID id=&quot;1&quot; name=&quot;x&quot;/&gt;    &lt;GlyphID id=&quot;2&quot; name=&quot;uniF69E&quot;/&gt;    &lt;GlyphID id=&quot;3&quot; name=&quot;uniE10C&quot;/&gt;    &lt;GlyphID id=&quot;4&quot; name=&quot;uniE04D&quot;/&gt;    &lt;GlyphID id=&quot;5&quot; name=&quot;uniF434&quot;/&gt;    &lt;GlyphID id=&quot;6&quot; name=&quot;uniEF3B&quot;/&gt;    &lt;GlyphID id=&quot;7&quot; name=&quot;uniE42C&quot;/&gt;    &lt;GlyphID id=&quot;8&quot; name=&quot;uniE95D&quot;/&gt;    &lt;GlyphID id=&quot;9&quot; name=&quot;uniF55F&quot;/&gt;    &lt;GlyphID id=&quot;10&quot; name=&quot;uniE06B&quot;/&gt;    &lt;GlyphID id=&quot;11&quot; name=&quot;uniE773&quot;/&gt;  &lt;/GlyphOrder&gt;  &lt;head&gt;    &lt;!-- Most of this table will be recalculated by the compiler --&gt;    &lt;tableVersion value=&quot;1.0&quot;/&gt;    &lt;fontRevision value=&quot;1.0&quot;/&gt;    &lt;checkSumAdjustment value=&quot;0x4345525d&quot;/&gt;    &lt;magicNumber value=&quot;0x5f0f3cf5&quot;/&gt;    &lt;flags value=&quot;00000000 00001011&quot;/&gt;    &lt;unitsPerEm value=&quot;700&quot;/&gt;    &lt;created value=&quot;Sat Jan 22 04:00:30 2022&quot;/&gt;    &lt;modified value=&quot;Sat Jan 22 04:00:30 2022&quot;/&gt;    &lt;xMin value=&quot;0&quot;/&gt;    &lt;yMin value=&quot;-20&quot;/&gt;    &lt;xMax value=&quot;389&quot;/&gt;    &lt;yMax value=&quot;500&quot;/&gt;    &lt;macStyle value=&quot;00000000 00000000&quot;/&gt;    &lt;lowestRecPPEM value=&quot;8&quot;/&gt;    &lt;fontDirectionHint value=&quot;2&quot;/&gt;    &lt;indexToLocFormat value=&quot;0&quot;/&gt;    &lt;glyphDataFormat value=&quot;0&quot;/&gt;  &lt;/head&gt;  &lt;hhea&gt;    &lt;tableVersion value=&quot;0x00010000&quot;/&gt;    &lt;ascent value=&quot;560&quot;/&gt;    &lt;descent value=&quot;-140&quot;/&gt;    &lt;lineGap value=&quot;63&quot;/&gt;    &lt;advanceWidthMax value=&quot;389&quot;/&gt;    &lt;minLeftSideBearing value=&quot;0&quot;/&gt;    &lt;minRightSideBearing value=&quot;0&quot;/&gt;    &lt;xMaxExtent value=&quot;389&quot;/&gt;    &lt;caretSlopeRise value=&quot;1&quot;/&gt;    &lt;caretSlopeRun value=&quot;0&quot;/&gt;    &lt;caretOffset value=&quot;0&quot;/&gt;    &lt;reserved0 value=&quot;0&quot;/&gt;    &lt;reserved1 value=&quot;0&quot;/&gt;    &lt;reserved2 value=&quot;0&quot;/&gt;    &lt;reserved3 value=&quot;0&quot;/&gt;    &lt;metricDataFormat value=&quot;0&quot;/&gt;    &lt;numberOfHMetrics value=&quot;12&quot;/&gt;  &lt;/hhea&gt;  &lt;maxp&gt;    &lt;!-- Most of this table will be recalculated by the compiler --&gt;    &lt;tableVersion value=&quot;0x10000&quot;/&gt;    &lt;numGlyphs value=&quot;12&quot;/&gt;    &lt;maxPoints value=&quot;44&quot;/&gt;    &lt;maxContours value=&quot;3&quot;/&gt;    &lt;maxCompositePoints value=&quot;0&quot;/&gt;    &lt;maxCompositeContours value=&quot;0&quot;/&gt;    &lt;maxZones value=&quot;2&quot;/&gt;    &lt;maxTwilightPoints value=&quot;0&quot;/&gt;    &lt;maxStorage value=&quot;10&quot;/&gt;    &lt;maxFunctionDefs value=&quot;10&quot;/&gt;    &lt;maxInstructionDefs value=&quot;0&quot;/&gt;    &lt;maxStackElements value=&quot;255&quot;/&gt;    &lt;maxSizeOfInstructions value=&quot;0&quot;/&gt;    &lt;maxComponentElements value=&quot;0&quot;/&gt;    &lt;maxComponentDepth value=&quot;0&quot;/&gt;  &lt;/maxp&gt;  &lt;OS_2&gt;    &lt;!-- The fields &#x27;usFirstCharIndex&#x27; and &#x27;usLastCharIndex&#x27;         will be recalculated by the compiler --&gt;    &lt;version value=&quot;1&quot;/&gt;    &lt;xAvgCharWidth value=&quot;365&quot;/&gt;    &lt;usWeightClass value=&quot;400&quot;/&gt;    &lt;usWidthClass value=&quot;5&quot;/&gt;    &lt;fsType value=&quot;00000000 00001000&quot;/&gt;    &lt;ySubscriptXSize value=&quot;246&quot;/&gt;    &lt;ySubscriptYSize value=&quot;489&quot;/&gt;    &lt;ySubscriptXOffset value=&quot;0&quot;/&gt;    &lt;ySubscriptYOffset value=&quot;98&quot;/&gt;    &lt;ySuperscriptXSize value=&quot;246&quot;/&gt;    &lt;ySuperscriptYSize value=&quot;489&quot;/&gt;    &lt;ySuperscriptXOffset value=&quot;0&quot;/&gt;    &lt;ySuperscriptYOffset value=&quot;336&quot;/&gt;    &lt;yStrikeoutSize value=&quot;34&quot;/&gt;    &lt;yStrikeoutPosition value=&quot;180&quot;/&gt;    &lt;sFamilyClass value=&quot;0&quot;/&gt;    &lt;panose&gt;      &lt;bFamilyType value=&quot;2&quot;/&gt;      &lt;bSerifStyle value=&quot;0&quot;/&gt;      &lt;bWeight value=&quot;5&quot;/&gt;      &lt;bProportion value=&quot;3&quot;/&gt;      &lt;bContrast value=&quot;0&quot;/&gt;      &lt;bStrokeVariation value=&quot;0&quot;/&gt;      &lt;bArmStyle value=&quot;0&quot;/&gt;      &lt;bLetterForm value=&quot;0&quot;/&gt;      &lt;bMidline value=&quot;0&quot;/&gt;      &lt;bXHeight value=&quot;0&quot;/&gt;    &lt;/panose&gt;    &lt;ulUnicodeRange1 value=&quot;00000000 00000000 00000000 00000000&quot;/&gt;    &lt;ulUnicodeRange2 value=&quot;00000000 00000000 00000000 00000000&quot;/&gt;    &lt;ulUnicodeRange3 value=&quot;00000000 00000000 00000000 00000000&quot;/&gt;    &lt;ulUnicodeRange4 value=&quot;00000000 00000000 00000000 00000000&quot;/&gt;    &lt;achVendID value=&quot;PfEd&quot;/&gt;    &lt;fsSelection value=&quot;00000000 01000000&quot;/&gt;    &lt;usFirstCharIndex value=&quot;120&quot;/&gt;    &lt;usLastCharIndex value=&quot;63134&quot;/&gt;    &lt;sTypoAscender value=&quot;560&quot;/&gt;    &lt;sTypoDescender value=&quot;-140&quot;/&gt;    &lt;sTypoLineGap value=&quot;63&quot;/&gt;    &lt;usWinAscent value=&quot;560&quot;/&gt;    &lt;usWinDescent value=&quot;140&quot;/&gt;    &lt;ulCodePageRange1 value=&quot;00000000 00000000 00000000 00000001&quot;/&gt;    &lt;ulCodePageRange2 value=&quot;00000000 00000000 00000000 00000000&quot;/&gt;  &lt;/OS_2&gt;  &lt;hmtx&gt;    &lt;mtx name=&quot;glyph00000&quot; width=&quot;389&quot; lsb=&quot;0&quot;/&gt;    &lt;mtx name=&quot;uniE04D&quot; width=&quot;389&quot; lsb=&quot;0&quot;/&gt;    &lt;mtx name=&quot;uniE06B&quot; width=&quot;389&quot; lsb=&quot;0&quot;/&gt;    &lt;mtx name=&quot;uniE10C&quot; width=&quot;389&quot; lsb=&quot;0&quot;/&gt;    &lt;mtx name=&quot;uniE42C&quot; width=&quot;389&quot; lsb=&quot;0&quot;/&gt;    &lt;mtx name=&quot;uniE773&quot; width=&quot;389&quot; lsb=&quot;0&quot;/&gt;    &lt;mtx name=&quot;uniE95D&quot; width=&quot;389&quot; lsb=&quot;0&quot;/&gt;    &lt;mtx name=&quot;uniEF3B&quot; width=&quot;389&quot; lsb=&quot;0&quot;/&gt;    &lt;mtx name=&quot;uniF434&quot; width=&quot;389&quot; lsb=&quot;0&quot;/&gt;    &lt;mtx name=&quot;uniF55F&quot; width=&quot;389&quot; lsb=&quot;0&quot;/&gt;    &lt;mtx name=&quot;uniF69E&quot; width=&quot;389&quot; lsb=&quot;0&quot;/&gt;    &lt;mtx name=&quot;x&quot; width=&quot;100&quot; lsb=&quot;0&quot;/&gt;  &lt;/hmtx&gt;  &lt;cmap&gt;    &lt;tableVersion version=&quot;0&quot;/&gt;    &lt;cmap_format_4 platformID=&quot;0&quot; platEncID=&quot;3&quot; language=&quot;0&quot;&gt;      &lt;map code=&quot;0x78&quot; name=&quot;x&quot;/&gt;&lt;!-- LATIN SMALL LETTER X --&gt;      &lt;map code=&quot;0xe04d&quot; name=&quot;uniE04D&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe06b&quot; name=&quot;uniE06B&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe10c&quot; name=&quot;uniE10C&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe42c&quot; name=&quot;uniE42C&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe773&quot; name=&quot;uniE773&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe95d&quot; name=&quot;uniE95D&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xef3b&quot; name=&quot;uniEF3B&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xf434&quot; name=&quot;uniF434&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xf55f&quot; name=&quot;uniF55F&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xf69e&quot; name=&quot;uniF69E&quot;/&gt;&lt;!-- ???? --&gt;    &lt;/cmap_format_4&gt;    &lt;cmap_format_12 platformID=&quot;0&quot; platEncID=&quot;4&quot; format=&quot;12&quot; reserved=&quot;0&quot; length=&quot;148&quot; language=&quot;0&quot; nGroups=&quot;11&quot;&gt;      &lt;map code=&quot;0x78&quot; name=&quot;x&quot;/&gt;&lt;!-- LATIN SMALL LETTER X --&gt;      &lt;map code=&quot;0xe04d&quot; name=&quot;uniE04D&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe06b&quot; name=&quot;uniE06B&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe10c&quot; name=&quot;uniE10C&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe42c&quot; name=&quot;uniE42C&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe773&quot; name=&quot;uniE773&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe95d&quot; name=&quot;uniE95D&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xef3b&quot; name=&quot;uniEF3B&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xf434&quot; name=&quot;uniF434&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xf55f&quot; name=&quot;uniF55F&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xf69e&quot; name=&quot;uniF69E&quot;/&gt;&lt;!-- ???? --&gt;    &lt;/cmap_format_12&gt;    &lt;cmap_format_0 platformID=&quot;1&quot; platEncID=&quot;0&quot; language=&quot;0&quot;&gt;      &lt;map code=&quot;0x78&quot; name=&quot;x&quot;/&gt;    &lt;/cmap_format_0&gt;    &lt;cmap_format_4 platformID=&quot;3&quot; platEncID=&quot;1&quot; language=&quot;0&quot;&gt;      &lt;map code=&quot;0x78&quot; name=&quot;x&quot;/&gt;&lt;!-- LATIN SMALL LETTER X --&gt;      &lt;map code=&quot;0xe04d&quot; name=&quot;uniE04D&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe06b&quot; name=&quot;uniE06B&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe10c&quot; name=&quot;uniE10C&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe42c&quot; name=&quot;uniE42C&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe773&quot; name=&quot;uniE773&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe95d&quot; name=&quot;uniE95D&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xef3b&quot; name=&quot;uniEF3B&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xf434&quot; name=&quot;uniF434&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xf55f&quot; name=&quot;uniF55F&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xf69e&quot; name=&quot;uniF69E&quot;/&gt;&lt;!-- ???? --&gt;    &lt;/cmap_format_4&gt;    &lt;cmap_format_12 platformID=&quot;3&quot; platEncID=&quot;10&quot; format=&quot;12&quot; reserved=&quot;0&quot; length=&quot;148&quot; language=&quot;0&quot; nGroups=&quot;11&quot;&gt;      &lt;map code=&quot;0x78&quot; name=&quot;x&quot;/&gt;&lt;!-- LATIN SMALL LETTER X --&gt;      &lt;map code=&quot;0xe04d&quot; name=&quot;uniE04D&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe06b&quot; name=&quot;uniE06B&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe10c&quot; name=&quot;uniE10C&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe42c&quot; name=&quot;uniE42C&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe773&quot; name=&quot;uniE773&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xe95d&quot; name=&quot;uniE95D&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xef3b&quot; name=&quot;uniEF3B&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xf434&quot; name=&quot;uniF434&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xf55f&quot; name=&quot;uniF55F&quot;/&gt;&lt;!-- ???? --&gt;      &lt;map code=&quot;0xf69e&quot; name=&quot;uniF69E&quot;/&gt;&lt;!-- ???? --&gt;    &lt;/cmap_format_12&gt;  &lt;/cmap&gt;  &lt;loca&gt;    &lt;!-- The &#x27;loca&#x27; table will be calculated by the compiler --&gt;  &lt;/loca&gt;  &lt;glyf&gt;    &lt;!-- The xMin, yMin, xMax and yMax values         will be recalculated by the compiler. --&gt;    &lt;TTGlyph name=&quot;glyph00000&quot;/&gt;&lt;!-- contains no outline data --&gt;    &lt;TTGlyph name=&quot;uniE04D&quot; xMin=&quot;0&quot; yMin=&quot;-12&quot; xMax=&quot;355&quot; yMax=&quot;500&quot;&gt;      &lt;contour&gt;        &lt;pt x=&quot;120&quot; y=&quot;268&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;45&quot; y=&quot;296&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;45&quot; y=&quot;370&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;45&quot; y=&quot;426&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;123&quot; y=&quot;500&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;255&quot; y=&quot;500&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;335&quot; y=&quot;422&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;335&quot; y=&quot;369&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;335&quot; y=&quot;296&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;260&quot; y=&quot;268&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;307&quot; y=&quot;253&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;355&quot; y=&quot;186&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;355&quot; y=&quot;140&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;355&quot; y=&quot;75&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;264&quot; y=&quot;-12&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;116&quot; y=&quot;-12&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;25&quot; y=&quot;74&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;25&quot; y=&quot;141&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;25&quot; y=&quot;190&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;74&quot; y=&quot;256&quot; on=&quot;0&quot;/&gt;      &lt;/contour&gt;      &lt;contour&gt;        &lt;pt x=&quot;108&quot; y=&quot;372&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;108&quot; y=&quot;336&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;154&quot; y=&quot;292&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;190&quot; y=&quot;292&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;224&quot; y=&quot;292&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;272&quot; y=&quot;336&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;272&quot; y=&quot;402&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;225&quot; y=&quot;449&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;153&quot; y=&quot;449&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;108&quot; y=&quot;404&quot; on=&quot;0&quot;/&gt;      &lt;/contour&gt;      &lt;contour&gt;        &lt;pt x=&quot;88&quot; y=&quot;141&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;88&quot; y=&quot;114&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;112&quot; y=&quot;66&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;138&quot; y=&quot;52&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;162&quot; y=&quot;39&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;190&quot; y=&quot;39&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;213&quot; y=&quot;39&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;249&quot; y=&quot;53&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;263&quot; y=&quot;67&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;292&quot; y=&quot;95&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;292&quot; y=&quot;184&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;233&quot; y=&quot;242&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;145&quot; y=&quot;242&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;88&quot; y=&quot;185&quot; on=&quot;0&quot;/&gt;      &lt;/contour&gt;      &lt;instructions/&gt;    &lt;/TTGlyph&gt;    &lt;TTGlyph name=&quot;uniE06B&quot; xMin=&quot;0&quot; yMin=&quot;-12&quot; xMax=&quot;354&quot; yMax=&quot;500&quot;&gt;      &lt;contour&gt;        &lt;pt x=&quot;284&quot; y=&quot;370&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;275&quot; y=&quot;407&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;260&quot; y=&quot;423&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;235&quot; y=&quot;449&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;199&quot; y=&quot;449&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;169&quot; y=&quot;449&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;147&quot; y=&quot;433&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;118&quot; y=&quot;411&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;102&quot; y=&quot;371&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;93&quot; y=&quot;351&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;84&quot; y=&quot;293&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;84&quot; y=&quot;255&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;106&quot; y=&quot;289&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;170&quot; y=&quot;321&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;206&quot; y=&quot;321&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;267&quot; y=&quot;321&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;354&quot; y=&quot;230&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;354&quot; y=&quot;159&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;354&quot; y=&quot;112&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;313&quot; y=&quot;31&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;243&quot; y=&quot;-12&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;197&quot; y=&quot;-12&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;120&quot; y=&quot;-12&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;23&quot; y=&quot;99&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;23&quot; y=&quot;231&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;23&quot; y=&quot;377&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;76&quot; y=&quot;442&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;123&quot; y=&quot;500&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;202&quot; y=&quot;500&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;262&quot; y=&quot;500&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;337&quot; y=&quot;434&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;345&quot; y=&quot;375&quot; on=&quot;1&quot;/&gt;      &lt;/contour&gt;      &lt;contour&gt;        &lt;pt x=&quot;94&quot; y=&quot;159&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;94&quot; y=&quot;128&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;121&quot; y=&quot;69&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;169&quot; y=&quot;39&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;196&quot; y=&quot;39&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;234&quot; y=&quot;39&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;291&quot; y=&quot;102&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;291&quot; y=&quot;155&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;291&quot; y=&quot;207&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;235&quot; y=&quot;267&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;153&quot; y=&quot;267&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;94&quot; y=&quot;207&quot; on=&quot;0&quot;/&gt;      &lt;/contour&gt;      &lt;instructions/&gt;    &lt;/TTGlyph&gt;    &lt;TTGlyph name=&quot;uniE10C&quot; xMin=&quot;0&quot; yMin=&quot;-12&quot; xMax=&quot;355&quot; yMax=&quot;500&quot;&gt;      &lt;contour&gt;        &lt;pt x=&quot;94&quot; y=&quot;118&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;102&quot; y=&quot;76&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;144&quot; y=&quot;39&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;177&quot; y=&quot;39&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;207&quot; y=&quot;39&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;248&quot; y=&quot;64&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;275&quot; y=&quot;108&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;285&quot; y=&quot;145&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;289&quot; y=&quot;163&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;294&quot; y=&quot;201&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;294&quot; y=&quot;220&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;294&quot; y=&quot;225&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;294&quot; y=&quot;228&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;293&quot; y=&quot;232&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;276&quot; y=&quot;203&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;212&quot; y=&quot;167&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;174&quot; y=&quot;167&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;111&quot; y=&quot;167&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;26&quot; y=&quot;256&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;26&quot; y=&quot;407&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;115&quot; y=&quot;500&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;183&quot; y=&quot;500&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;231&quot; y=&quot;500&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;313&quot; y=&quot;447&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;355&quot; y=&quot;349&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;355&quot; y=&quot;258&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;355&quot; y=&quot;161&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;314&quot; y=&quot;48&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;231&quot; y=&quot;-12&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;176&quot; y=&quot;-12&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;116&quot; y=&quot;-12&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;42&quot; y=&quot;53&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;35&quot; y=&quot;113&quot; on=&quot;1&quot;/&gt;      &lt;/contour&gt;      &lt;contour&gt;        &lt;pt x=&quot;287&quot; y=&quot;333&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;287&quot; y=&quot;386&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;230&quot; y=&quot;449&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;149&quot; y=&quot;449&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;89&quot; y=&quot;383&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;89&quot; y=&quot;328&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;89&quot; y=&quot;279&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;147&quot; y=&quot;221&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;232&quot; y=&quot;221&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;287&quot; y=&quot;281&quot; on=&quot;0&quot;/&gt;      &lt;/contour&gt;      &lt;instructions/&gt;    &lt;/TTGlyph&gt;    &lt;TTGlyph name=&quot;uniE42C&quot; xMin=&quot;0&quot; yMin=&quot;-4&quot; xMax=&quot;355&quot; yMax=&quot;492&quot;&gt;      &lt;contour&gt;        &lt;pt x=&quot;29&quot; y=&quot;432&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;29&quot; y=&quot;491&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;354&quot; y=&quot;491&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;354&quot; y=&quot;443&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;330&quot; y=&quot;418&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;283&quot; y=&quot;350&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;235&quot; y=&quot;265&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;200&quot; y=&quot;179&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;186&quot; y=&quot;134&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;169&quot; y=&quot;71&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;163&quot; y=&quot;-3&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;99&quot; y=&quot;-3&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;100&quot; y=&quot;26&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;112&quot; y=&quot;97&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;123&quot; y=&quot;139&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;145&quot; y=&quot;223&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;186&quot; y=&quot;301&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;207&quot; y=&quot;341&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;252&quot; y=&quot;405&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;275&quot; y=&quot;432&quot; on=&quot;1&quot;/&gt;      &lt;/contour&gt;      &lt;instructions/&gt;    &lt;/TTGlyph&gt;    &lt;TTGlyph name=&quot;uniE773&quot; xMin=&quot;0&quot; yMin=&quot;-13&quot; xMax=&quot;355&quot; yMax=&quot;500&quot;&gt;      &lt;contour&gt;        &lt;pt x=&quot;88&quot; y=&quot;137&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;98&quot; y=&quot;85&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;148&quot; y=&quot;39&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;186&quot; y=&quot;39&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;229&quot; y=&quot;39&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;288&quot; y=&quot;99&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;288&quot; y=&quot;186&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;232&quot; y=&quot;241&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;190&quot; y=&quot;241&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;172&quot; y=&quot;241&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;147&quot; y=&quot;234&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;154&quot; y=&quot;288&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;164&quot; y=&quot;287&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;204&quot; y=&quot;287&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;266&quot; y=&quot;328&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;266&quot; y=&quot;371&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;266&quot; y=&quot;405&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;222&quot; y=&quot;449&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;148&quot; y=&quot;449&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;101&quot; y=&quot;405&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;94&quot; y=&quot;359&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;32&quot; y=&quot;370&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;43&quot; y=&quot;433&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;124&quot; y=&quot;500&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;183&quot; y=&quot;500&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;223&quot; y=&quot;500&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;293&quot; y=&quot;465&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;330&quot; y=&quot;403&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;330&quot; y=&quot;336&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;295&quot; y=&quot;284&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;260&quot; y=&quot;268&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;305&quot; y=&quot;258&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;354&quot; y=&quot;193&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;354&quot; y=&quot;144&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;354&quot; y=&quot;79&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;258&quot; y=&quot;-13&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;186&quot; y=&quot;-13&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;119&quot; y=&quot;-13&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;32&quot; y=&quot;66&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;26&quot; y=&quot;129&quot; on=&quot;1&quot;/&gt;      &lt;/contour&gt;      &lt;instructions/&gt;    &lt;/TTGlyph&gt;    &lt;TTGlyph name=&quot;uniE95D&quot; xMin=&quot;0&quot; yMin=&quot;-4&quot; xMax=&quot;349&quot; yMax=&quot;500&quot;&gt;      &lt;contour&gt;        &lt;pt x=&quot;349&quot; y=&quot;55&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;349&quot; y=&quot;-3&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;18&quot; y=&quot;-3&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;18&quot; y=&quot;18&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;25&quot; y=&quot;39&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;32&quot; y=&quot;57&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;51&quot; y=&quot;90&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;79&quot; y=&quot;123&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;119&quot; y=&quot;160&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;146&quot; y=&quot;182&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;186&quot; y=&quot;216&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;242&quot; y=&quot;267&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;256&quot; y=&quot;288&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;285&quot; y=&quot;327&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;285&quot; y=&quot;398&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;232&quot; y=&quot;449&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;146&quot; y=&quot;449&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;93&quot; y=&quot;397&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;92&quot; y=&quot;348&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;29&quot; y=&quot;355&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;36&quot; y=&quot;426&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;120&quot; y=&quot;500&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;264&quot; y=&quot;500&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;348&quot; y=&quot;420&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;348&quot; y=&quot;361&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;348&quot; y=&quot;329&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;325&quot; y=&quot;275&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;295&quot; y=&quot;240&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;281&quot; y=&quot;224&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;234&quot; y=&quot;180&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;200&quot; y=&quot;152&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;172&quot; y=&quot;129&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;137&quot; y=&quot;97&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;121&quot; y=&quot;81&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;109&quot; y=&quot;64&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;103&quot; y=&quot;55&quot; on=&quot;1&quot;/&gt;      &lt;/contour&gt;      &lt;instructions/&gt;    &lt;/TTGlyph&gt;    &lt;TTGlyph name=&quot;uniEF3B&quot; xMin=&quot;0&quot; yMin=&quot;-12&quot; xMax=&quot;353&quot; yMax=&quot;500&quot;&gt;      &lt;contour&gt;        &lt;pt x=&quot;26&quot; y=&quot;244&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;26&quot; y=&quot;335&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;43&quot; y=&quot;386&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;62&quot; y=&quot;441&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;134&quot; y=&quot;500&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;189&quot; y=&quot;500&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;269&quot; y=&quot;500&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;310&quot; y=&quot;436&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;330&quot; y=&quot;407&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;341&quot; y=&quot;362&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;352&quot; y=&quot;320&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;352&quot; y=&quot;244&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;352&quot; y=&quot;200&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;344&quot; y=&quot;128&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;334&quot; y=&quot;101&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;315&quot; y=&quot;46&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;244&quot; y=&quot;-12&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;189&quot; y=&quot;-12&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;117&quot; y=&quot;-12&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;75&quot; y=&quot;40&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;26&quot; y=&quot;102&quot; on=&quot;0&quot;/&gt;      &lt;/contour&gt;      &lt;contour&gt;        &lt;pt x=&quot;89&quot; y=&quot;244&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;89&quot; y=&quot;120&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;146&quot; y=&quot;39&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;231&quot; y=&quot;39&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;289&quot; y=&quot;120&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;289&quot; y=&quot;367&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;232&quot; y=&quot;449&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;146&quot; y=&quot;449&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;120&quot; y=&quot;413&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;89&quot; y=&quot;367&quot; on=&quot;0&quot;/&gt;      &lt;/contour&gt;      &lt;instructions/&gt;    &lt;/TTGlyph&gt;    &lt;TTGlyph name=&quot;uniF434&quot; xMin=&quot;0&quot; yMin=&quot;-4&quot; xMax=&quot;353&quot; yMax=&quot;498&quot;&gt;      &lt;contour&gt;        &lt;pt x=&quot;223&quot; y=&quot;-3&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;223&quot; y=&quot;116&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;6&quot; y=&quot;116&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;6&quot; y=&quot;173&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;234&quot; y=&quot;498&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;284&quot; y=&quot;498&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;284&quot; y=&quot;173&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;352&quot; y=&quot;173&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;352&quot; y=&quot;116&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;284&quot; y=&quot;116&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;284&quot; y=&quot;-3&quot; on=&quot;1&quot;/&gt;      &lt;/contour&gt;      &lt;contour&gt;        &lt;pt x=&quot;223&quot; y=&quot;173&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;223&quot; y=&quot;399&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;66&quot; y=&quot;173&quot; on=&quot;1&quot;/&gt;      &lt;/contour&gt;      &lt;instructions/&gt;    &lt;/TTGlyph&gt;    &lt;TTGlyph name=&quot;uniF55F&quot; xMin=&quot;0&quot; yMin=&quot;-4&quot; xMax=&quot;258&quot; yMax=&quot;500&quot;&gt;      &lt;contour&gt;        &lt;pt x=&quot;258&quot; y=&quot;-3&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;196&quot; y=&quot;-3&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;196&quot; y=&quot;389&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;174&quot; y=&quot;368&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;101&quot; y=&quot;326&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;73&quot; y=&quot;314&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;73&quot; y=&quot;374&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;124&quot; y=&quot;398&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;163&quot; y=&quot;433&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;182&quot; y=&quot;450&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;210&quot; y=&quot;484&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;218&quot; y=&quot;500&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;258&quot; y=&quot;500&quot; on=&quot;1&quot;/&gt;      &lt;/contour&gt;      &lt;instructions/&gt;    &lt;/TTGlyph&gt;    &lt;TTGlyph name=&quot;uniF69E&quot; xMin=&quot;0&quot; yMin=&quot;-12&quot; xMax=&quot;358&quot; yMax=&quot;491&quot;&gt;      &lt;contour&gt;        &lt;pt x=&quot;90&quot; y=&quot;133&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;97&quot; y=&quot;85&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;148&quot; y=&quot;39&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;186&quot; y=&quot;39&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;231&quot; y=&quot;39&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;293&quot; y=&quot;107&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;293&quot; y=&quot;214&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;232&quot; y=&quot;274&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;186&quot; y=&quot;274&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;155&quot; y=&quot;274&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;109&quot; y=&quot;248&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;95&quot; y=&quot;226&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;36&quot; y=&quot;233&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;85&quot; y=&quot;491&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;334&quot; y=&quot;491&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;334&quot; y=&quot;432&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;134&quot; y=&quot;432&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;107&quot; y=&quot;298&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;130&quot; y=&quot;313&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;177&quot; y=&quot;329&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;202&quot; y=&quot;329&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;267&quot; y=&quot;329&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;358&quot; y=&quot;239&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;358&quot; y=&quot;167&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;358&quot; y=&quot;99&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;318&quot; y=&quot;49&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;270&quot; y=&quot;-12&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;186&quot; y=&quot;-12&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;118&quot; y=&quot;-12&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;32&quot; y=&quot;65&quot; on=&quot;0&quot;/&gt;        &lt;pt x=&quot;26&quot; y=&quot;128&quot; on=&quot;1&quot;/&gt;      &lt;/contour&gt;      &lt;instructions/&gt;    &lt;/TTGlyph&gt;    &lt;TTGlyph name=&quot;x&quot; xMin=&quot;0&quot; yMin=&quot;-20&quot; xMax=&quot;50&quot; yMax=&quot;20&quot;&gt;      &lt;contour&gt;        &lt;pt x=&quot;20&quot; y=&quot;20&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;50&quot; y=&quot;20&quot; on=&quot;1&quot;/&gt;        &lt;pt x=&quot;50&quot; y=&quot;-20&quot; on=&quot;1&quot;/&gt;      &lt;/contour&gt;      &lt;instructions/&gt;    &lt;/TTGlyph&gt;  &lt;/glyf&gt;  &lt;name&gt;    &lt;namerecord nameID=&quot;0&quot; platformID=&quot;1&quot; platEncID=&quot;0&quot; langID=&quot;0x0&quot; unicode=&quot;True&quot;&gt;        Created by font-carrier      &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;1&quot; platformID=&quot;1&quot; platEncID=&quot;0&quot; langID=&quot;0x0&quot; unicode=&quot;True&quot;&gt;      Untitled    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;2&quot; platformID=&quot;1&quot; platEncID=&quot;0&quot; langID=&quot;0x0&quot; unicode=&quot;True&quot;&gt;      Regular    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;3&quot; platformID=&quot;1&quot; platEncID=&quot;0&quot; langID=&quot;0x0&quot; unicode=&quot;True&quot;&gt;      Untitled-Regular    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;4&quot; platformID=&quot;1&quot; platEncID=&quot;0&quot; langID=&quot;0x0&quot; unicode=&quot;True&quot;&gt;      Untitled-Regular    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;5&quot; platformID=&quot;1&quot; platEncID=&quot;0&quot; langID=&quot;0x0&quot; unicode=&quot;True&quot;&gt;      Version 1.0    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;6&quot; platformID=&quot;1&quot; platEncID=&quot;0&quot; langID=&quot;0x0&quot; unicode=&quot;True&quot;&gt;      Untitled-Regular    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;10&quot; platformID=&quot;1&quot; platEncID=&quot;0&quot; langID=&quot;0x0&quot; unicode=&quot;True&quot;&gt;      Generated by svg2ttf from Fontello project.    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;11&quot; platformID=&quot;1&quot; platEncID=&quot;0&quot; langID=&quot;0x0&quot; unicode=&quot;True&quot;&gt;      http://fontello.com    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;0&quot; platformID=&quot;3&quot; platEncID=&quot;1&quot; langID=&quot;0x409&quot;&gt;        Created by font-carrier      &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;1&quot; platformID=&quot;3&quot; platEncID=&quot;1&quot; langID=&quot;0x409&quot;&gt;      Untitled    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;2&quot; platformID=&quot;3&quot; platEncID=&quot;1&quot; langID=&quot;0x409&quot;&gt;      Regular    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;3&quot; platformID=&quot;3&quot; platEncID=&quot;1&quot; langID=&quot;0x409&quot;&gt;      Untitled-Regular    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;4&quot; platformID=&quot;3&quot; platEncID=&quot;1&quot; langID=&quot;0x409&quot;&gt;      Untitled-Regular    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;5&quot; platformID=&quot;3&quot; platEncID=&quot;1&quot; langID=&quot;0x409&quot;&gt;      Version 1.0    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;6&quot; platformID=&quot;3&quot; platEncID=&quot;1&quot; langID=&quot;0x409&quot;&gt;      Untitled-Regular    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;10&quot; platformID=&quot;3&quot; platEncID=&quot;1&quot; langID=&quot;0x409&quot;&gt;      Generated by svg2ttf from Fontello project.    &lt;/namerecord&gt;    &lt;namerecord nameID=&quot;11&quot; platformID=&quot;3&quot; platEncID=&quot;1&quot; langID=&quot;0x409&quot;&gt;      http://fontello.com    &lt;/namerecord&gt;  &lt;/name&gt;  &lt;post&gt;    &lt;formatType value=&quot;2.0&quot;/&gt;    &lt;italicAngle value=&quot;0.0&quot;/&gt;    &lt;underlinePosition value=&quot;7&quot;/&gt;    &lt;underlineThickness value=&quot;0&quot;/&gt;    &lt;isFixedPitch value=&quot;0&quot;/&gt;    &lt;minMemType42 value=&quot;0&quot;/&gt;    &lt;maxMemType42 value=&quot;0&quot;/&gt;    &lt;minMemType1 value=&quot;0&quot;/&gt;    &lt;maxMemType1 value=&quot;0&quot;/&gt;    &lt;psNames&gt;      &lt;!-- This file uses unique glyph names based on the information           found in the &#x27;post&#x27; table. Since these names might not be unique,           we have to invent artificial names in case of clashes. In order to           be able to retain the original information, we need a name to           ps name mapping for those cases where they differ. That&#x27;s what           you see below.            --&gt;      &lt;psName name=&quot;glyph00000&quot; psName=&quot;&quot;/&gt;    &lt;/psNames&gt;    &lt;extraNames&gt;      &lt;!-- following are the name that are not taken from the standard Mac glyph order --&gt;      &lt;psName name=&quot;&quot;/&gt;      &lt;psName name=&quot;x&quot;/&gt;      &lt;psName name=&quot;uniF69E&quot;/&gt;      &lt;psName name=&quot;uniE10C&quot;/&gt;      &lt;psName name=&quot;uniE04D&quot;/&gt;      &lt;psName name=&quot;uniF434&quot;/&gt;      &lt;psName name=&quot;uniEF3B&quot;/&gt;      &lt;psName name=&quot;uniE42C&quot;/&gt;      &lt;psName name=&quot;uniE95D&quot;/&gt;      &lt;psName name=&quot;uniF55F&quot;/&gt;      &lt;psName name=&quot;uniE06B&quot;/&gt;      &lt;psName name=&quot;uniE773&quot;/&gt;    &lt;/extraNames&gt;  &lt;/post&gt;  &lt;GSUB&gt;    &lt;Version value=&quot;0x00010000&quot;/&gt;    &lt;ScriptList&gt;      &lt;!-- ScriptCount=1 --&gt;      &lt;ScriptRecord index=&quot;0&quot;&gt;        &lt;ScriptTag value=&quot;DFLT&quot;/&gt;        &lt;Script&gt;          &lt;DefaultLangSys&gt;            &lt;ReqFeatureIndex value=&quot;0&quot;/&gt;            &lt;!-- FeatureCount=1 --&gt;            &lt;FeatureIndex index=&quot;0&quot; value=&quot;0&quot;/&gt;          &lt;/DefaultLangSys&gt;          &lt;!-- LangSysCount=0 --&gt;        &lt;/Script&gt;      &lt;/ScriptRecord&gt;    &lt;/ScriptList&gt;    &lt;FeatureList&gt;      &lt;!-- FeatureCount=1 --&gt;      &lt;FeatureRecord index=&quot;0&quot;&gt;        &lt;FeatureTag value=&quot;liga&quot;/&gt;        &lt;Feature&gt;          &lt;!-- LookupCount=1 --&gt;          &lt;LookupListIndex index=&quot;0&quot; value=&quot;0&quot;/&gt;        &lt;/Feature&gt;      &lt;/FeatureRecord&gt;    &lt;/FeatureList&gt;    &lt;LookupList&gt;      &lt;!-- LookupCount=1 --&gt;      &lt;Lookup index=&quot;0&quot;&gt;        &lt;LookupType value=&quot;4&quot;/&gt;        &lt;LookupFlag value=&quot;0&quot;/&gt;        &lt;!-- SubTableCount=1 --&gt;        &lt;LigatureSubst index=&quot;0&quot;&gt;        &lt;/LigatureSubst&gt;      &lt;/Lookup&gt;    &lt;/LookupList&gt;  &lt;/GSUB&gt;&lt;/ttFont&gt;\n\n我们在FontCreater中发现比如数字1所对应的uniE06B\n\n在XML格式里面的GlyphOrder组中正好对应的是index:9:\n\n\n我们再搜索每个数字对应的TTGlyph，可以找到每个数字每一笔每一画的坐标，并且可以看到on属性:\n\n通过对字体XML文件的分析和坐标的对比，我们可以通过&quot;on属性&quot;&quot;列表匹配法来解决字体加密，因为我们通过多组字体文件对比发现，每个数字坐标下都有一个on属性，on属性是文件字体之间唯一的共同点，比如当前数字1的on属性列表on_list=[‘1’, ‘1’, ‘1’, ‘0’, ‘0’, ‘1’, ‘1’, ‘0’, ‘1’, ‘0’, ‘0’, ‘1’, ‘1’]，通过对比on列表的相似度，可以准确地匹配出数字1，那么下面我们就来看看如何使用&quot;on属性&quot;列表匹配法解决字体加密:\n首先我们需要获得on属性的值就要对XML文件进行解析，读取其子节点:\nfrom fontTools.ttLib import TTFont  # 字体文件库from xml.etree.ElementTree import parse  # 解析xmlfont = TTFont(r&#x27;F:\\downloads\\57e1d0e6.woff&#x27;)font.saveXML(&#x27;maoyan_dashboard.xml&#x27;)  # 将字体保存为xml格式xml = parse(&#x27;maoyan_dashboard.xml&#x27;)root = xml.getroot()  # 获取xml树的根元素for i in root:\tif i.tag == &#x27;glyf&#x27;:  # 找到glyf元素\t\tdict_0 = dict()\t\tfor j in i:  # 遍历glyf元素，找到每个坐标对应的元素\t\t\tif j.get(&#x27;name&#x27;) == &#x27;glyph00000&#x27; or j.get(&#x27;name&#x27;) == &#x27;x&#x27;:  # 跳过非数字元素\t\t\t\tcontinue\t\t\tlist_1 = list()\t\t\tfor k in j:  # 遍历TTGlyph元素下的多个contour元素\t\t\t\tfor l in k:  # 提取每个坐标下pt元素里面的on属性值\t\t\t\t\tlist_1.append(l.get(&#x27;on&#x27;))\t\t\tdict_0[j.get(&#x27;name&#x27;)] = list_1  # 将on列表加入到字典print(dict_0)\n\n如下图所示:\n\n程序实现:\n步骤:\n\n得到数字–on列表的关系字典\n爬取json数据以及下载所用到的加密字体\n将字体文字保存为XML格式，并且用getBestCmap()方法获得字体关系映射表\n获取加载字体的on列表，并与样本列表进行匹配\n匹配成功后得到数字–加密代码的字典\n对加密字体进行替换得到正确内容\n可能要不断学习on列表来保证稳定性\n\n首先我们写一个工具文件:\nMyPyClass.py:\nfrom difflib import SequenceMatcherimport randomdef Judge_Similarity(a, b):    &quot;&quot;&quot;    对比a，b序列，返回相似度(0~1.0)    eg:    list1 = [1, 2, 3, 4, 5]    list2 = [1, 2, 3]    similarity(list1, list2)    return 0.75    :param a: 序列a    :param b: 序列b    :return: 相似度:(0~1.0)    &quot;&quot;&quot;    return SequenceMatcher(None, a, b).ratio()  # 引用ratio方法，返回序列相似性的度量def GetUserAgent():    &quot;&quot;&quot;    从User-Agent列表中随机获得一个user-agent    :return: 返回一个随机的str类型的user-agent    &quot;&quot;&quot;    ua_list = [        # Safari        &#x27;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2&#x27;,        # 360浏览器        &#x27;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.101 Safari/537.36&#x27;,        # 搜狗浏览器        &#x27;Mozilla/5.0 (Windows NT 5.1) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.84 Safari/535.11 SE 2.X MetaSr 1.0&#x27;,        # UC浏览器        &#x27;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 UBrowser/4.0.3214.0 Safari/537.36&#x27;    ]    return random.choice(ua_list)  # 从ua列表中随机选择一个\n\n然后我们来着手写主要代码:\nget_maoyan_dashboard.py:\nimport requestsimport urllib.request as downimport jsonimport refrom fontTools.ttLib import TTFont  # 字体解析库from xml.etree.ElementTree import parseimport MyPyClass# 下面是on字典nums_matching = &#123;\t0: [[&#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;,\t\t &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;]],\t1: [[&#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;1&#x27;]],\t2: [[&#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;,\t\t &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;]],\t3: [[&#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;1&#x27;,\t\t &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;]],\t4: [[&#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;]],\t5: [[&#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;,\t\t &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;]],\t6: [[&#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;,\t\t &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;]],\t7: [[&#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;]],\t8: [[&#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;,\t\t &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;]],\t9: [[&#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;,\t\t &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;0&#x27;]]&#125;debug = False  # 是否调试打印# 下面爬取json以及字体文件url = &#x27;https://piaofang.maoyan.com/dashboard-ajax?orderType=0&amp;uuid=17e7c24ee17c8-014a02ede30105-5c123c18-240000-17e7c24ee17c8&amp;timeStamp=1642833053200&amp;User-Agent=TW96aWxsYS81LjAgKFdpbmRvd3MgTlQgNi4xOyBXaW42NDsgeDY0KSBBcHBsZVdlYktpdC81MzcuMzYgKEtIVE1MLCBsaWtlIEdlY2tvKSBDaHJvbWUvOTcuMC40NjkyLjcxIFNhZmFyaS81MzcuMzY%3D&amp;index=629&amp;channelId=40009&amp;sVersion=2&amp;signKey=b194fe8bbd47e376d24339c8b39d3ae4&#x27;ua = MyPyClass.GetUserAgent()# 爬取内容fileName = &#x27;maoyan&#x27;def getMovieinfos(url, filename=&#x27;maoyan&#x27;, ua=None, timeout=2, debug=False):\t&quot;&quot;&quot;\t获得电影信息\t:param url: 爬取链接\t:param filename: 字体文件保存的文件名\t:param ua: user-agent\t:param timeout: 超时时间(s)\t:param debug: 是否调试\t:return: 爬取的电影数据内容\t&quot;&quot;&quot;\ttry:\t\twith requests.get(url, headers=&#123;&#x27;user-agent&#x27;: ua&#125;, timeout=timeout) as response:\t\t\t# 获取存放字体的json字段，并提取字体url\t\t\tfontStyle = json.loads(response.content)[&#x27;fontStyle&#x27;]\t\t\tfontStyle = re.findall(&#x27;\\&quot;([\\s\\S]*?)\\&quot;&#x27;, fontStyle[::-1])  # 提取url的一部分\t\t\tfonturl = &#x27;http:&#x27; + fontStyle[0][::-1]  # 拼接字体url链接\t\t\tif debug:\t\t\t\tprint(fonturl)\t\t\t# 将加载的字体下载保存到本地，并对其进行分析\t\t\t# 下面这个方法我也第一次遇到，查百度给出的解释是:此方法用于将URL指向的网络对象复制到本地文件\t\t\tdown.urlretrieve(fonturl, fileName + &#x27;.woff&#x27;)\t\t\t# 爬取电影数据内容，list中即为页面中所呈现的电影数据\t\t\tcontent = json.loads(response.content)[&#x27;movieList&#x27;][&#x27;data&#x27;][&#x27;list&#x27;]\t\t\treturn content\texcept TimeoutError as err:  # 捕获异常并打印异常\t\tprint(err)content = getMovieinfos(url, filename=fileName, ua=ua, debug=debug, timeout=5)  # 函数调用，获得电影数据内容# 获得字体对象with TTFont(fileName + &#x27;.woff&#x27;) as fontnew:\tfontnew.saveXML(fileName + &#x27;.xml&#x27;)  # 保存为xml格式\tf = fontnew.getBestCmap()  # 获取字体关系映射，name=&quot;uniE06B&quot;--code=&quot;0xe06b&quot;# 将获得到的字体关系映射保存为字典fontMaps = dict()for code, name in f.items():\tif name == &#x27;x&#x27;:\t\tcontinue\tfontMaps[name] = hex(code)# 获取加载字体的on属性列表字典def readingXml_on(filename=&#x27;maoyan&#x27;, debug=False):\t&quot;&quot;&quot;\t获取加载字体的on属性列表字典\t:param filename: 读取的xml文件名\t:param debug: 是否调试\t:return: on列表字典\t&quot;&quot;&quot;\txml = parse(filename + &#x27;.xml&#x27;)\troot = xml.getroot()\tfor i in root:  # 获取xml树的根元素\t\tif i.tag == &#x27;glyf&#x27;:  # 找到glyf元素\t\t\tnums_on_dict = dict()\t\t\tfor j in i:  # 遍历glyf元素，找到每个坐标对应的元素\t\t\t\tif j.get(&#x27;name&#x27;) == &#x27;glyph00000&#x27; or j.get(&#x27;name&#x27;) == &#x27;x&#x27;:  # 跳过非数字元素\t\t\t\t\tcontinue\t\t\t\ton_list = list()\t\t\t\tfor k in j:  # 遍历TTGlyph元素下的多个contour元素在(可能有时候就一个)\t\t\t\t\tfor l in k:  # 提取每个坐标下pt元素里面的on属性值\t\t\t\t\t\ton_list.append(l.get(&#x27;on&#x27;))\t\t\t\tnums_on_dict[j.get(&#x27;name&#x27;)] = on_list  # 将on列表加入到字典\t\t\tbreak\tif debug:\t\tprint(nums_on_dict)\treturn nums_on_dictnums_on_dict = readingXml_on(fileName, debug)  # 获得muns--on对应的字典num_code = dict()# 对数字进行匹配，当匹配相似度&gt;=0.9时，则匹配成功# 进行三层遍历，进行数字匹配for num, matching in nums_matching.items():\tfor _num, _matching in nums_on_dict.items():\t\tfor i in matching:\t\t\tif MyPyClass.Judge_Similarity(i, _matching) &gt;= 0.9:  # &gt;=0.9 则成功匹配\t\t\t\tnum_code[fontMaps[_num].replace(&#x27;0x&#x27;, &#x27;&amp;#x&#x27;)] = num.__str__()\t\t\t\tbreakif debug:\tprint(num_code)# 设置需要的json元素movieNum = &#123;&#125;  # 综合票房数字典movieDayOne = &#123;&#125;  # 上映首日数量movieRate = &#123;&#125;  # 票房占比movieshowCount = &#123;&#125;  # 排片场次movieViewerAvg = &#123;&#125;  # 场均人数movieinfos = &#123;&#125;# 页面内容for i in content:\tmoviename = i[&#x27;movieIndo&#x27;][&#x27;movieName&#x27;]\tmovieNum[moviename] = i[&#x27;boxSplitUnit&#x27;][&#x27;num&#x27;]\tmovieDayOne[moviename] = i[&#x27;sumBoxDesc&#x27;]\tmovieRate[moviename] = i[&#x27;splitBoxRate&#x27;]\tmovieshowCount[moviename] = i[&#x27;showCount&#x27;]\tmovieViewerAvg[moviename] = i[&#x27;avgShowView&#x27;]# 替换加密字体，获得正确数字，并输出结果# 对加密的字体遍历分组，并去除无用字符for name, numbercode in movieNum.items():\tmovieNum[name] = re.findall(&#x27;([\\S]*?);&#x27;, numbercode)# 根据得到的fontcodes映射对加密字体进行替换，得到正确数值for index, (name, numbercodelist) in enumerate(movieNum.items()):\tnum = []\t# 替换操作\tfor code in numbercodelist:\t\tif &#x27;.&#x27; in code:\t\t\tcode = code.replace(&#x27;.&#x27;, &#x27;&#x27;)\t\t\tnum.append(&#x27;.&#x27; + num_code[code])\t\telse:\t\t\tnum.append(num_code[code])\tinfos = [&#x27;排行:&#x27; + str(index + 1),\t\t\t &#x27;片名&#x27;, name,\t\t\t &#x27;上映首日&#x27;, movieDayOne[name],\t\t\t &#x27;票房&#x27;, &#x27;&#x27;.join(num) + &#x27;万&#x27;,\t\t\t &#x27;票房占比&#x27;, movieRate[name],\t\t\t &#x27;场均人数&#x27;, movieViewerAvg[name] + &#x27;人&#x27;,\t\t\t &#x27;排片场次&#x27;, movieshowCount[name]]\tprint(infos)\n\n上面有一个方法(urlretrieve())，这个链接做了一些解释\n这里的on字典我们就一个个对照着前面解析XML的结果来:\n\n本文参考自: https://blog.csdn.net/xyl192960/article/details/113795224\n"},{"title":"GitHub如何获取Token","url":"/2022/01/23/GitHub%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96Token/","content":"今天使用PicX图床的时候，发现突然要填Token，这里我就记录下如何生成GitHubToken:\n\n打开GitHub，然后点击setting\n\n\n然后找到Developer settings\n\n\n点击Developer settings，再点击Personal access tokens\n\n\n如果没有就点击Generate new token，然后选择对应的仓库，如果已经有对应仓库的token，可以点进去更新token\n\n\n\n\n"},{"title":"验证码识别简单基础案例","url":"/2022/01/23/%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB%E6%A1%88%E4%BE%8B/","content":"案例网站，点击跳转\n所用到的库: tesserocr\n步骤:\n\n在网页上保存验证码图片到本地\n然后调用tesserocr.image_to_text()方法进行解析\n\n\n代码如下:\nimport tesserocrfrom PIL import Imageimage = Image.open(r&#x27;C:\\Users\\Administrator\\Pictures\\verificationcode-example.png&#x27;)result = tesserocr.image_to_text(image)print(result)\n\n运行效果如下:\n\n在安装tesserocr之前要先安装Tesseract，可以参考这里，然后我在测试上面代码的时候出现了以下错误:\nFailed to init API, possibly an invalid tessdata path: C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python37\\/tessdata/\n\n通过这个博客我解决了这个问题，也就是需要把tessdata放在Python的目录下\n"},{"title":"2022-1-22每日英语","url":"/2022/01/22/2022-1-22%E6%AF%8F%E6%97%A5%E8%8B%B1%E8%AF%AD/","content":"\nevaluation [ɪˌvæljuˈeɪʃn] n. 评价，评估\n\n"},{"title":"简单字体反爬之起点小说网","url":"/2022/01/24/%E7%AE%80%E5%8D%95%E5%AD%97%E4%BD%93%E5%8F%8D%E7%88%AC%E4%B9%8B%E8%B5%B7%E7%82%B9%E5%B0%8F%E8%AF%B4%E7%BD%91/","content":"这两天在搞字体反爬，然后在网上看了看有哪些案例，就挑了这个来记录下，这个算是比较简单的，我们来看看:\n首先打开起点小说网，然后我们打开开发者工具，定位到书籍的字数那里，我们发现显示出来的是乱码:\n\n但是查看源代码却发现显示的是这样的:\n\n我抓了下包发现，有好两个.woff后缀的文件，我每个都试，发现关于数字和小数点的字体文件在第二个.woff的文件中:\n复制链接下载然后用在线字体解析网站打开后发现是这样的:\n\n 之所以说它简单是因为它就是英文字母对应其数字，我们先写一个字典(单词与数字的对应关系)，方便待会儿的对照:\n&#123;    &#x27;zero&#x27;: &#x27;0&#x27;,    &#x27;one&#x27;: &#x27;1&#x27;,    &#x27;two&#x27;: &#x27;2&#x27;,    &#x27;three&#x27;: &#x27;3&#x27;,    &#x27;four&#x27;: &#x27;4&#x27;,    &#x27;five&#x27;: &#x27;5&#x27;,    &#x27;six&#x27;: &#x27;6&#x27;,    &#x27;seven&#x27;: &#x27;7&#x27;,    &#x27;eight&#x27;: &#x27;8&#x27;,    &#x27;nine&#x27;: &#x27;9&#x27;&#125;\n\n然后我们通过Python库的fonttools工具包，找出字体文件中包含的映射关系，代码如下:\n&quot;&quot;&quot;@Description : @File        : test_cmap@Project     : test@Time        : 2022/1/22 18:54@Author      : LiHouJian@Software    : PyCharm@issue       : @change      : @reason      : &quot;&quot;&quot;import hashlibimport reimport urllibimport scrapyimport asyncioimport datetimeimport osimport tracebackimport jsonfrom scrapy.utils import requestfrom lxml import etreefrom scrapy.utils.project import get_project_settingsfrom pybase.util import send_filefrom fontTools.ttLib import TTFontfrom io import BytesIOimport requestsurl_ziti = &quot;https://qidian.gtimg.com/qd_anti_spider/vuPlalqg.woff&quot;ziti = requests.get(url_ziti)# 下载ttf字体文件，然后通过BytesIO转化为内存文件，使用TTFont处理font = TTFont(BytesIO(ziti.content))cmap = font.getBestCmap()print(cmap)\n\n结果如下:\n&#123;100495: &#x27;period&#x27;, 100497: &#x27;six&#x27;, 100498: &#x27;zero&#x27;, 100499: &#x27;five&#x27;, 100500: &#x27;eight&#x27;, 100501: &#x27;nine&#x27;, 100502: &#x27;four&#x27;, 100503: &#x27;two&#x27;, 100504: &#x27;seven&#x27;, 100505: &#x27;one&#x27;, 100506: &#x27;three&#x27;&#125;\n\n然后我们可以用这两个字典组合一个新的字典:\ncode_num_dict = &#123;x: Eng_num_dict[cmap[x]] for x in cmap.keys()&#125;\n\n然后找出源码中所有的数字code，并进行筛选:\ncom = re.compile(r&quot;&amp;#\\d+&quot;)codes = com.findall(content)codes_pure = [i for i in codes if len(i) == 8]\n\n然后进行替换:\nfor i in codes_pure:    content = content.replace(i + &#x27;;&#x27;, code_num_dict[int(i[2:])])\n\n最后再获取我们想要的小说名称和字数:\ncontent_parsed_tree = etree.HTML(content)info_dict = dict()novel_title = content_parsed_tree.xpath(    &quot;//div[@class=&#x27;book-mid-info&#x27;]/h2/a/text()&quot;)novel_words_num = content_parsed_tree.xpath(    f&quot;//div[@class=&#x27;book-mid-info&#x27;]/p[@class=&#x27;update&#x27;]/span/span[@class=&#x27;&#123;font_family&#125;&#x27;]/text()&quot;)novel = &#123;novel_title[i]: novel_words_num[i] for i in range(len(novel_title))&#125;\n\n这里需要注意，这个网站的字体链接是时刻在变化的，链接对应的里面的字体资源也不一样，所以我们每次请求都需要再构造一个字体链接\n全部代码:\n&quot;&quot;&quot;@Description :@File        : test_cmap@Project     : test@Time        : 2022/1/24 14:13@Author      : LiHouJian@Software    : PyCharm@issue       :@change      :@reason      :&quot;&quot;&quot;import refrom fontTools.ttLib import TTFontfrom io import BytesIOimport requestsfrom lxml import etree# url_ziti = &quot;https://qidian.gtimg.com/qd_anti_spider/vuPlalqg.woff&quot;url_content = &quot;https://www.qidian.com/all/&quot;headers = &#123;    &quot;user-agent&quot;: &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&quot;&#125;content = requests.get(url=url_content, headers=headers).texttree = etree.HTML(content)font_family = tree.xpath(    &#x27;//*[@id=&quot;book-img-text&quot;]/ul/li[1]/div[2]/p[3]/span/span/@class&#x27;)[0]url_ziti = &quot;https://qidian.gtimg.com/qd_anti_spider/&quot; + font_family + &quot;.woff&quot;ziti = requests.get(url=url_ziti, headers=headers)# 下载ttf字体文件，然后通过BytesIO转化为内存文件，使用TTFont方法处理font = TTFont(BytesIO(ziti.content))cmap = font.getBestCmap()Eng_num_dict = &#123;    &#x27;zero&#x27;: &#x27;0&#x27;,    &#x27;one&#x27;: &#x27;1&#x27;,    &#x27;two&#x27;: &#x27;2&#x27;,    &#x27;three&#x27;: &#x27;3&#x27;,    &#x27;four&#x27;: &#x27;4&#x27;,    &#x27;five&#x27;: &#x27;5&#x27;,    &#x27;six&#x27;: &#x27;6&#x27;,    &#x27;seven&#x27;: &#x27;7&#x27;,    &#x27;eight&#x27;: &#x27;8&#x27;,    &#x27;nine&#x27;: &#x27;9&#x27;,    &#x27;period&#x27;: &#x27;.&#x27;&#125;code_num_dict = &#123;x: Eng_num_dict[cmap[x]] for x in cmap.keys()&#125;com = re.compile(r&quot;&amp;#\\d+&quot;)codes = com.findall(content)codes_pure = [i for i in codes if len(i) == 8]for i in codes_pure:    content = content.replace(i + &#x27;;&#x27;, code_num_dict[int(i[2:])])content_parsed_tree = etree.HTML(content)info_dict = dict()novel_title = content_parsed_tree.xpath(    &quot;//div[@class=&#x27;book-mid-info&#x27;]/h2/a/text()&quot;)novel_words_num = content_parsed_tree.xpath(    f&quot;//div[@class=&#x27;book-mid-info&#x27;]/p[@class=&#x27;update&#x27;]/span/span[@class=&#x27;&#123;font_family&#125;&#x27;]/text()&quot;)novel = &#123;novel_title[i]: novel_words_num[i] for i in range(len(novel_title))&#125;print(novel)\n\n"},{"title":"MySQL常用命令","url":"/2022/01/24/MySQL%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","content":"连接MySQL格式:\nmysql -h主机地址 -u用户名 －p用户密码\n\n\n连接到本地的MySQL(-h主机地址可以省略)\n用户密码和-p之间不要有空格，否则会把空格当做密码的一部分，会再次要求你输入密码:\n\n下面则是正确格式的命令:\n\n\n连接到远程主机上的MySQL\n具体见这里\n\n\n"},{"title":"Python操作各数据库的代码示例","url":"/2022/01/24/Python%E6%93%8D%E4%BD%9C%E5%90%84%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/","content":"操作MySQL首先安装pymysql包:\npip install pymysql\n\n然后在mysql里创建数据库名为test，然后在里面创建一个Product表:\nDROP TABLE IF EXISTS `Product`;/*!40101 SET @saved_cs_client     = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `Product` (  `id` int NOT NULL AUTO_INCREMENT,  `name` varchar(40) NOT NULL,    /* 商品名称 */  `remark` varchar(1000) NULL,  `isBuy` int(1) DEFAULT 1,      /* 1: 在售 2:卖出 */  `version` int(11) NOT null default 1000,   PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1000 DEFAULT CHARSET=utf8;\n\n直接在Navicat Premium中打开一个连接然后新建一个test数据库用于测试，然后右键运行SQL文件即可完成数据表的创建:\n\n下面先来看看首秀，首先mysql获得connection，然后从connection获得cursor进行操作:\nimport pymysqlhost = &#x27;localhost&#x27;port = 3306db = &#x27;test&#x27;user = &#x27;root&#x27;password = &#x27;123456&#x27;# ---- 用pymysql 操作数据库def get_connection():    conn = pymysql.connect(host=host, port=port, db=db, user=user, password=password)    return conndef check_it():    conn = get_connection()    # 使用 cursor() 方法创建一个 dict 格式的游标对象 cursor    cursor = conn.cursor(pymysql.cursors.DictCursor)    # 使用 execute()  方法执行 SQL 查询    cursor.execute(&quot;select count(id) as total from Product&quot;)    # 使用 fetchone() 方法获取单条数据.以字典显示    data = cursor.fetchone()    print(&quot;-- 当前数量: %d &quot; % data[&#x27;total&#x27;])    # 关闭数据库连接    cursor.close()    conn.close()if __name__ == &#x27;__main__&#x27;:    check_it()\n\n以上只是个简单小案例，具体请移步这里\n操作Mongodb这里直接上我工作的代码:\nimport scrapyimport pymongofrom scrapy.utils.project import get_project_settingsimport requestsimport loggingimport jsonlogger = logging.getLogger(__name__)class UploadInfo(scrapy.Spider):    name = &#x27;zscq-uploadinfo&#x27;    start_urls = []    config = get_project_settings()    def __init__(*args,**kwargs):        mongo = pymongo.MongoClient(host=&#x27;192.168.3.85&#x27;, port=27017)        # mongo = pymongo.MongoClient(host=self.config.get(&#x27;MONGO_HOST&#x27;), port=self.config.get(&#x27;MONGO_PORT&#x27;))        db = mongo[&#x27;popular_industry&#x27;]  # 选择数据库        collection = db[&#x27;lhj_kcpt_zscq&#x27;]  # 获取collection        url_info = &#x27;http://192.168.3.85:8066/datainsertApp/policy/insertToMongo&#x27;        count = 0        # 资讯的        for item in collection.find(filter=&#123;&#x27;cleaning_status&#x27;: 0&#125;, no_cursor_timeout=True):            if &#x27;issue_time&#x27; not in dict(item).keys() or item[&#x27;issue_time&#x27;] == &#x27;&#x27;:                item[&#x27;issue_time&#x27;] = &#x27;0-0-0&#x27;            time_split = item[&#x27;issue_time&#x27;].split(&#x27; &#x27;)[0].split(&#x27;-&#x27;)            data_day = time_split[2]            data_month = time_split[1]            data_year = time_split[0]            form_data = [&#123;                &quot;_id&quot;: str(item[&#x27;_id&#x27;]),                &#x27;content&#x27;: item[&#x27;content_url&#x27;] if &#x27;content&#x27; not in dict(item).keys() else item[&#x27;content&#x27;],                &#x27;content_url&#x27;: item[&#x27;content_url&#x27;],                &#x27;day&#x27;: data_day,                &quot;paper_abstract&quot;: &#x27;&#x27; if &#x27;paper_abstract&#x27; not in dict(item).keys() else item[&#x27;paper_abstract&#x27;],                &#x27;month&#x27;: data_month,                &#x27;year&#x27;: data_year,                &quot;author&quot;: &#x27;&#x27; if &#x27;author&#x27; not in dict(item).keys() else item[&#x27;author&#x27;],                &#x27;information_source&#x27;: &#x27;&#x27; if &#x27;information_source&#x27; not in dict(item).keys() else item[&#x27;information_source&#x27;],                &#x27;path&#x27;: [item[&#x27;category&#x27;], item[&#x27;sub_category&#x27;], &#x27;科创平台&#x27;, item[&#x27;information_categories&#x27;]],                &#x27;tags&#x27;: &#x27;&#x27; if &#x27;tags&#x27; not in dict(item).keys() else item[&#x27;tags&#x27;],                &#x27;title&#x27;: item[&#x27;title&#x27;],                &#x27;title_image&#x27;: &#x27;&#x27; if &#x27;title_image&#x27; not in dict(item).keys() else item[&#x27;title_image&#x27;],            &#125;]            # 设置重连次数            requests.adapters.DEFAULT_RETRIES = 15            # 设置连接活跃状态为False            s = requests.session()            s.keep_alive = False            req = requests.post(url_info, headers=&#123;&#x27;Content-Type&#x27;: &#x27;application/json;charset=UTF-8&#x27;&#125;,                                json=form_data)            response = json.loads(req.text)            if response[&#x27;code&#x27;] != 1:                logger.error(&#x27;上传出错，返回：&#123;&#125;&#x27;.format(response))                continue            collection.update_one(filter=&#123;&#x27;_id&#x27;: item[&#x27;_id&#x27;]&#125;, update=&#123;&#x27;$set&#x27;: &#123;&#x27;cleaning_status&#x27;: 5&#125;&#125;)            logger.info(&#x27;&#123;&#125;，上传成功！！！！！！！&#x27;.format(item[&#x27;title&#x27;]))            count += 1        logger.info(&#x27;上传完成，共上传：&#123;&#125; 条数据。。。。。&#x27;.format(count))        mongo.close()if __name__ == &#x27;__main__&#x27;:    from scrapy import cmdline    cmdline.execute(&#x27;scrapy crawl zscq-uploadinfo&#x27;.split())\n\n操作redis安装:\npip install redis\n\n测试是否安装成功:\nimport redisr = redis.StrictRedis(host=&#x27;localhost&#x27;, port=6379, db=0)r.set(&#x27;foo&#x27;, &#x27;bar&#x27;)print(r.get(&#x27;foo&#x27;))# &#x27;bar&#x27;\n\n具体参考这里\n"},{"title":"Ubuntu云服务器如何安装MySQL","url":"/2022/01/24/Ubuntu%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85MySQL/","content":"安装MySQL首先验证下是否安装，键入mysql:\n\n像这样就是没有安装\n然后下面我们就开始安装\n\n首先更新软件包(这个命令很常用)\nsudo apt-get update\n\n如果当前系统已经是root用户则不用键入sudo，输入也是没关系的:\n\n\n开始安装MySQL服务端和客户端(中间会有确认，输入y或者Y):\nsudo apt-get install mysql-server mysql-client\n\n\n\n然后我们查看下数据库版本，如果出现数据库版本则安装成功:\n\n\n修改密码\n\n进入配置文件，在在mysqld.cnf中添加skip-grant-tables便可跳过登录认证(要记得保存):\nsudo vi /etc/mysql/mysql.conf.d/mysqld.cnf\n\n\n\n重启数据库服务，并登录数据库，不要输入密码，直接回车；登录数据库之后，进入mysql数据库，修改user表中user=’root’的密码:\n\n来看看这上面出现的命令:\nservice mysql restart  # 重启mysql服务mysql -u root -p  # 以root用户在本地登录，这个时候我们没设置密码但在安装mysql的时候自动生成了一个，我们可以用这个自动生成的去登录，但是我们之前有个操作让我们跳过了登录认证，所以这里可以不输入密码直接登录use mysql;  # 使用mysql这个数据库select user,plugin from user;  # 选出user和plguin这两列update user set authentication_string=password(&quot;yourCode&quot;),plugin=&#x27;mysql_native_password&#x27; where user=&quot;root&quot;;  # 设置root用户登录密码flush privileges;  # 更新权限\n进入刚刚那个配置文件，将skip-grant-tables注释掉(在skip-grant-tables前添加#)，保存退出，这一步是关闭刚刚不输入密码就登录mysql的操作，确保登录数据库必须使用密码:\nvi /etc/mysql/mysql.conf.d/mysqld.cnf\n\n\n\n\n\n\n开放远程连接权限\n进入刚刚的那个配置文件，将bind-address          = 127.0.0.1这一行注释掉，保存并退出:\nvi /etc/mysql/mysql.conf.d/mysqld.cnf\n\n\n\n登录数据库，配置root用户远程权限\n\n重复的命令这里就不赘述了，讲一条关键的命令:\nGRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;yourCode&#x27; WITH GRANT OPTION;  # 让所有的地址都可以使用root用户，远程访问数据库\n云服务器控制台开放MySQL数据库3306端口，按下图操作点击确定即可:\n\n\n\n用客户端连接查看是否安装成功:\n因为我们刚配置完，我们最好在云服务器中重启下mysql的服务，使用命令:\nsudo service mysql restart  # 这个命令一定要root权限\n\n上面这个命令一定要root权限，如果没有就会报如下错误:\n\n然后我们来测试下，这样成功开放远程链接了:\n\n\n新增guest用户并设置访问权限\n登录数据库，进入mysql库\n创建guest用户，并设置登录密码\n为gest用户开放select、insert、update权限\n刷新生效\n\n上面的命令对应如下:\n#创建用户mysql&gt; grant usage on *.* to &#x27;guest&#x27;@&#x27;%&#x27;identified by &#x27;yourguestcode&#x27; with grant option;#设置权限mysql&gt; grant select,insert,update on *.* to &#x27;guest&#x27;@&#x27;%&#x27; with grant option;#刷新mysql&gt; flush privileges;\n\n这上面我的密码搞错了，这里就不改了，密码直接是yourguestcode，修改密码可以使用以下语句:\nSET PASSWORD FOR &#x27;guest&#x27;@&#x27;%&#x27; = PASSWORD(&#x27;123456&#x27;);  # 修改密码FLUSH PRIVILEGES;  # 刷新权限\n\n这里之所以是@&#39;%&#39;，因为上面设置了远程的访问权限\n为验证guest用户设置是否生效，可以试试guest用户新建一个库，或者新建一个表，数据库会报错，因为我们没有给guest用户create权限:\n\n然后我们来验证下:\n\n"},{"title":"端口大全介绍","url":"/2022/01/25/%E7%AB%AF%E5%8F%A3%E5%A4%A7%E5%85%A8%E4%BB%8B%E7%BB%8D/","content":"此文转载自头条，点击跳转\n"},{"title":"2022-1-24每日英语","url":"/2022/01/24/2022-1-24%E6%AF%8F%E6%97%A5%E8%8B%B1%E8%AF%AD/","content":"\ndashboard n. (汽车的)仪表板; 总览板 [ˈdæʃbɔːrd]\ncredential n. 资格证明; 资格证书; 证件; 国书 [krəˈdenʃl]\nwizard n. 向导程序 n. 巫师，术士；adj. 卓越的, 杰出的, 巫术的[ˈwɪzərd]\n\n"},{"title":"利用aiohttp和asyncio写异步爬虫","url":"/2022/01/25/%E5%88%A9%E7%94%A8aiohttp%E5%92%8Casyncio%E5%86%99%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB/","content":"关于asyncio(异步io)，我在前面的别的文章介绍过，点击这里查看，这里我们来看看如何利用aiohttp和asyncio完成一个异步爬虫，我实习的第一家公司就是全部使用异步爬虫\n什么是aiohttpaiohttp是一个异步的HTTP客户端\\服务端框架，基于asyncio的异步模块，可用于实现异步爬虫，更快与requests的同步爬虫\naiohttp的安装pip install aiohttp \n\naiohttp用作客户端的案例import aiohttpimport asyncio# 这个函数用来发请求async def fetch(session, url):    async with session.get(url) as response:        return await response.text()# 这个函数用来下载网页async def main():    async with aiohttp.ClientSession() as session:        html = await fetch(session, &quot;http://httpbin.org/headers&quot;)        print(html)asyncio.run(main())&quot;&quot;&quot;输出结果：&#123;  &quot;headers&quot;: &#123;    &quot;Accept&quot;: &quot;*/*&quot;,     &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;,     &quot;Host&quot;: &quot;httpbin.org&quot;,     &quot;User-Agent&quot;: &quot;Python/3.7 aiohttp/3.6.2&quot;  &#125;&#125;&quot;&quot;&quot;\n\naiohttp用作服务端的案例from aiohttp import web# 下面是一个处理函数async def handle(request):    name = request.match_info.get(&#x27;name&#x27;, &quot;Anonymous&quot;)    text = &quot;Hello, &quot; + name    return web.Response(text=text)app = web.Application()app.add_routes([web.get(&#x27;/&#x27;, handle),                web.get(&#x27;/&#123;name&#125;&#x27;, handle)])if __name__ == &#x27;__main__&#x27;:    web.run_app(app)\n\n运行这个代码，然后访问http://127.0.0.1:8080就可以看到你的网站了，很基础的一个网页，你可以在url后面跟上你的名字，然后会在网页上显示出来\naiohttp用作客户端参数详解我们来看看客户端，也就是用来发送http请求的方法，首先看一段代码:\n&quot;&quot;&quot;@Description : @File        : aiohttp-test@Project     : test@Time        : 2022/1/25 17:18@Author      : LiHouJian@Software    : PyCharm@issue       : @change      : @reason      : &quot;&quot;&quot;import aiohttpimport asyncioasync def main():\tasync with aiohttp.ClientSession() as session:\t\tasync with session.get(&#x27;http://www.baidu.com&#x27;) as resp:\t\t\tprint(resp.status)\t\t\tprint(await resp.text())asyncio.run(main())\n\n代码解释:\n在网络请求中，一个请求就是一个会话，aiohttp使用的是ClientSession来管理会话，上面的代码就是实例化一个ClientSession类然后命名为session，然后用session去发送请求，当然上面出现的是get请求，其他的还有post，put啥的都支持的:\nsession.put(&#x27;http://httpbin.org/put&#x27;, data=b&#x27;data&#x27;)session.delete(&#x27;http://httpbin.org/delete&#x27;)session.head(&#x27;http://httpbin.org/get&#x27;)session.options(&#x27;http://httpbin.org/get&#x27;)session.patch(&#x27;http://httpbin.org/patch&#x27;, data=b&#x27;data&#x27;)\n\n在url中传递参数有时候在发起网络请求的时候需要附加一些参数到url中，这一点也是支持的:\nparams = &#123;&#x27;key1&#x27;: &#x27;value1&#x27;, &#x27;key2&#x27;: &#x27;value2&#x27;&#125;async with session.get(&#x27;http://httpbin.org/get&#x27;,                       params=params) as resp:    expect = &#x27;http://httpbin.org/get?key2=value2&amp;key1=value1&#x27;    assert str(resp.url) == expect\n\n我们可以通过params参数来指定要传递的参数\n那么post如何传参数呢，我用上面的代码改变了下，做个示例:\n&quot;&quot;&quot;@Description :@File        : aiohttp-test@Project     : test@Time        : 2022/1/25 17:18@Author      : LiHouJian@Software    : PyCharm@issue       :@change      :@reason      :&quot;&quot;&quot;import aiohttpimport asyncioimport jsondata = &#123;&#x27;key1&#x27;: &#x27;value1&#x27;&#125;async def main():    async with aiohttp.ClientSession() as session:        async with session.post(&#x27;http://www.baidu.com&#x27;, data=json.dumps(data)) as resp:            print(resp.status)            print(await resp.text())asyncio.run(main())\n\n读取响应内容通过status来获取响应状态码，通过text来获取响应内容，当然也可以直接指明编码格式:\nasync def main():    async with aiohttp.ClientSession() as session:        async with session.get(&#x27;http://httpbin.org/get&#x27;) as resp:            print(resp.status)            print(await resp.text(encoding=utf-8))            &quot;&quot;&quot;输出结果：200&lt;!doctype html&gt;&lt;html lang=&quot;zh-CN&quot;&gt;&lt;head&gt;......&quot;&quot;&quot;\n\n对于非文本内容格式，比如一张图片，这种返回值是二进制也是可以读取到的:\nawait resp.read()\n\n将text()换为read()即可\n自定义headersheaders = &#123;        &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) &quot;                      &quot;AppleWebKit/537.36 (KHTML, like Gecko)&quot;                      &quot; Chrome/78.0.3904.108 Safari/537.36&quot;    &#125;await session.post(url, headers=headers)\n\n自定义cookie发送你自己的cookies给服务器，你可以为ClientSession对象指定cookies参数:\nurl = &#x27;http://httpbin.org/cookies&#x27;cookies = &#123;&#x27;cookies_are&#x27;: &#x27;working&#x27;&#125;async with ClientSession(cookies=cookies) as session:    async with session.get(url) as resp:        assert await resp.json() == &#123;           &quot;cookies&quot;: &#123;&quot;cookies_are&quot;: &quot;working&quot;&#125;&#125;\n\n使用代理我们在写爬虫的时候可能需要使用到代理，aiohttp也是支持使用代理的，我们可以在发起请求的时候使用代理，只需要使用关键字proxy来指明即可，但是有一个不太好的地方就是它只支持http代理，不支持https代理，下面只是一个简单的使用，我们真正在项目中需要去购买一些优质代理:\nproxy = “http://127.0.0.1:10809” async with aiohttp.ClientSession(headers=headers) as session:    async with session.get(url=login_url, proxy=proxy) as response:        resu = await response.text()\n\n和asyncio结合起来使用速度对比使用asyncio和aiohttp:\n&quot;&quot;&quot;@Description :@File        : SpeedCompare-Notuseaio@Project     : test@Time        : 2022/1/25 17:52@Author      : LiHouJian@Software    : PyCharm@issue       :@change      :@reason      :&quot;&quot;&quot;import hashlibimport reimport urllibimport scrapyimport asyncioimport datetimeimport osimport tracebackimport jsonfrom scrapy.utils import requestfrom lxml import etreefrom scrapy.utils.project import get_project_settingsfrom pybase.util import send_fileimport aiohttpfrom datetime import datetimeheaders = &#123;    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&quot;&#125;async def parse(url):    async with aiohttp.ClientSession(headers=headers) as resp:        async with resp.get(url) as res:            print(await res.text())async def main():    for i in range(1, 3):        url = f&quot;https://www.puercn.com/news/zhengce/p&#123;i&#125;/&quot;        await parse(url)if __name__ == &#x27;__main__&#x27;:    start_time = datetime.now()    asyncio.run(main())    print(&#x27;time:&#x27;, datetime.now() - start_time)\n\n不使用asyncio和aiohttp:\n&quot;&quot;&quot;@Description :@File        : SpeedCompare-Notuseaio@Project     : test@Time        : 2022/1/25 17:52@Author      : LiHouJian@Software    : PyCharm@issue       :@change      :@reason      :&quot;&quot;&quot;import hashlibimport reimport urllibimport scrapyimport asyncioimport datetimeimport osimport tracebackimport jsonfrom scrapy.utils import requestfrom lxml import etreefrom scrapy.utils.project import get_project_settingsfrom pybase.util import send_fileimport aiohttpfrom datetime import datetimeimport requestsheaders = &#123;    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&quot;&#125;def parse(url):    # async with aiohttp.ClientSession(headers=headers) as resp:    #     async with resp.get(url) as res:    #         print(await res.text())    res = requests.get(url=url, headers=headers).text    print(res)def main():    for i in range(1, 6):        url = f&quot;https://www.puercn.com/news/zhengce/p&#123;i&#125;/&quot;        parse(url)if __name__ == &#x27;__main__&#x27;:    start_time = datetime.now()    main()    print(&#x27;time:&#x27;, datetime.now() - start_time)\n\n可以看到使用asyncio的速度会快，虽然这里的案例差别不大\n使用案例:\n&quot;&quot;&quot;@Description : @File        : grasp_douban@Project     : test@Time        : 2022/1/26 9:18@Author      : LiHouJian@Software    : PyCharm@issue       : @change      : @reason      : &quot;&quot;&quot;import asynciofrom datetime import datetimeimport aiohttpfrom lxml import etreeheaders = &#123;&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&quot;                         &quot;/537.36 (KHTML, like Gecko) &quot;                         &quot;Chrome/72.0.3626.121 Safari/537.36&quot;&#125;async def get_movie_url():    req_url = &quot;https://movie.douban.com/chart&quot;    async with aiohttp.ClientSession(headers=headers) as session:        async with session.get(url=req_url, headers=headers) as response:            result = await response.text()            result = etree.HTML(result)        return result.xpath(&quot;//*[@id=&#x27;content&#x27;]/div/div[1]/div/div/table/tr/td/a/@href&quot;)async def get_movie_content(movie_url):    async with aiohttp.ClientSession(headers=headers) as session:        async with session.get(url=movie_url, headers=headers) as response:            result = await response.text()            result = etree.HTML(result)        movie = dict()        name = result.xpath(&#x27;//*[@id=&quot;content&quot;]/h1/span[1]//text()&#x27;)        author = result.xpath(&#x27;//*[@id=&quot;info&quot;]/span[1]/span[2]//text()&#x27;)        movie[&quot;name&quot;] = name        movie[&quot;author&quot;] = author    return movieif __name__ == &#x27;__main__&#x27;:    start = datetime.now()    loop = asyncio.get_event_loop()    movie_url_list = loop.run_until_complete(get_movie_url())    tasks = [get_movie_content(url) for url in movie_url_list]    movies = loop.run_until_complete(asyncio.gather(*tasks))    print(movies)\n\n\n\n"},{"title":"关于asyncio异步编程","url":"/2022/01/26/%E5%85%B3%E4%BA%8Easyncio%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/","content":"协程&amp;异步编程(asyncio)协程(Coroutine)，也可以被称为微线程，是一种用户态内的上下文切换技术。简而言之，其实就是通过一个线程实现代码块相互切换执行，例如:\ndef func1():    print(1)    ...    print(2)def func2():    print(3)    ...    print(4)func1()func2()\n\n上述代码是普通的函数定义和执行，按流程分别执行两个函数中的代码，并先后会输出：1、2、3、4。但如果介入协程技术那么就可以实现函数见代码切换执行，最终输入：1、3、2、4\n协程的实现在Python中有多种方式可以实现协程，例如:\n\ngreenlet，是一个第三方模块，用于实现协程代码(Gevent协程就是基于greenlet实现)\nyield，生成器，借助生成器的特点也可以实现协程代码\nasyncio，在Python3.4中引入的模块用于编写协程代码\nasync &amp; awiat，在Python3.5中引入的两个关键字，结合asyncio模块可以更方便的编写协程代码\n\ngreenletgreentlet是一个第三方模块，需要提前安装 pip3 install greenlet才能使用，来看一个例子:\nfrom greenlet import greenletdef func1():    print(1)        # 第1步：输出 1    gr2.switch()    # 第3步：切换到 func2 函数    print(2)        # 第6步：输出 2    gr2.switch()    # 第7步：切换到 func2 函数，从上一次执行的位置继续向后执行def func2():    print(3)        # 第4步：输出 3    gr1.switch()    # 第5步：切换到 func1 函数，从上一次执行的位置继续向后执行    print(4)        # 第8步：输出 4gr1 = greenlet(func1)gr2 = greenlet(func2)gr1.switch() # 第1步：去执行 func1 函数\n\n程序输出:\n1324\n\n注意: switch中也可以传递参数用于在切换执行时相互传递值\nyield基于Python的生成器的yield和yield form关键字实现协程代码:\ndef func1():    yield 1    yield from func2()    yield 2def func2():    yield 3    yield 4f1 = func1()for item in f1:    print(item)\n\n程序输出:\n1342\n\n注意: yield form关键字是在Python3.3中引入的\nasyncio在Python3.4之前官方未提供协程的类库，一般大家都是使用greenlet等其他来实现。在Python3.4发布后官方正式支持协程，即:asyncio模块\nimport asyncio@asyncio.coroutinedef func1():    print(1)    yield from asyncio.sleep(2)  # 遇到IO耗时操作，自动化切换到tasks中的其他任务    print(2)@asyncio.coroutinedef func2():    print(3)    yield from asyncio.sleep(2) # 遇到IO耗时操作，自动化切换到tasks中的其他任务    print(4)tasks = [    asyncio.ensure_future( func1() ),    asyncio.ensure_future( func2() )]loop = asyncio.get_event_loop()  # 创建一个事件循环loop.run_until_complete(asyncio.wait(tasks))  # asyncio.wait会把task这个列表列表里的每一个Task对象也转化成一个Task对象，所以这里是重复了，可以看看以下代码，和这个代码的效果是一样的\n\nimport asyncio@asyncio.coroutinedef func1():    print(1)    yield from asyncio.sleep(2)  # 遇到IO耗时操作，自动化切换到tasks中的其他任务    print(2)@asyncio.coroutinedef func2():    print(3)    yield from asyncio.sleep(2) # 遇到IO耗时操作，自动化切换到tasks中的其他任务    print(4)tasks = [    func1(),    func2()]loop = asyncio.get_event_loop()  # 创建一个事件循环loop.run_until_complete(asyncio.wait(tasks))\n\n注意: 基于asyncio模块实现的协程比之前的要更厉害，因为他的内部还集成了遇到IO耗时操作自动切花的功能\nasync&amp;awaitasync &amp; awit 关键字在Python3.5版本中正式引入，基于他编写的协程代码其实就是 上一示例的加强版，让代码可以更加简便，Python3.8之后 @asyncio.coroutine 装饰器就会被移除，推荐使用async &amp; awit 关键字实现协程代码\nimport asyncioasync def func1():    print(1)    await asyncio.sleep(2)    print(2)async def func2():    print(3)    await asyncio.sleep(2)    print(4)tasks = [    asyncio.ensure_future(func1()),  # asyncio.ensure_future()将会把协程对象封装成一个Task对象    asyncio.ensure_future(func2())]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks))\n\n程序输出:\n1324\n\n小结关于协程有多种实现方式，目前主流使用是Python官方推荐的asyncio模块和async&amp;await关键字的方式，例如: 在tonado、sanic、fastapi、django3 中均已支持，接下来，我们也会针对 asyncio模块 + async &amp; await 关键字进行更加详细的讲解\n协程的意义以及使用通过学习，我们已经了解到协程可以通过一个线程在多个上下文中进行来回切换执行，但是，协程来回切换执行的意义何在呢?(网上看到很多文章舔协程，协程牛逼之处是哪里呢?)\n计算型的操作，利用协程来回切换执行，没有任何意义，来回切换并保存状态 反倒会降低性能。IO型的操作，利用协程在IO等待时间就去切换执行其他任务，当IO操作结束后再自动回调，那么就会大大节省资源并提供性能，从而实现异步编程(不等待任务结束就可以去执行其他代码)\n\n爬虫案例例如：用代码实现下载 url_list 中的图片:\n\n方式一，同步编程实现\nimport requestsdef download_image(url):\tprint(&quot;开始下载:&quot;,url)    # 发送网络请求，下载图片    response = requests.get(url)\tprint(&quot;下载完成&quot;)    # 图片保存到本地文件    file_name = url.rsplit(&#x27;_&#x27;)[-1]    with open(file_name, mode=&#x27;wb&#x27;) as file_object:        file_object.write(response.content)if __name__ == &#x27;__main__&#x27;:    url_list = [        &#x27;https://www3.autoimg.cn/newsdfs/g26/M02/35/A9/120x90_0_autohomecar__ChsEe12AXQ6AOOH_AAFocMs8nzU621.jpg&#x27;,        &#x27;https://www2.autoimg.cn/newsdfs/g30/M01/3C/E2/120x90_0_autohomecar__ChcCSV2BBICAUntfAADjJFd6800429.jpg&#x27;,        &#x27;https://www3.autoimg.cn/newsdfs/g26/M0B/3C/65/120x90_0_autohomecar__ChcCP12BFCmAIO83AAGq7vK0sGY193.jpg&#x27;    ]    for item in url_list:        download_image(item)\n方式二，基于协程的异步编程实现:\nimport aiohttpimport asyncioasync def fetch(session, url):    print(&quot;发送请求：&quot;, url)    async with session.get(url, verify_ssl=False) as response:        content = await response.content.read()        file_name = url.rsplit(&#x27;_&#x27;)[-1]        with open(file_name, mode=&#x27;wb&#x27;) as file_object:            file_object.write(content)async def main():    async with aiohttp.ClientSession() as session:        url_list = [            &#x27;https://www3.autoimg.cn/newsdfs/g26/M02/35/A9/120x90_0_autohomecar__ChsEe12AXQ6AOOH_AAFocMs8nzU621.jpg&#x27;,            &#x27;https://www2.autoimg.cn/newsdfs/g30/M01/3C/E2/120x90_0_autohomecar__ChcCSV2BBICAUntfAADjJFd6800429.jpg&#x27;,            &#x27;https://www3.autoimg.cn/newsdfs/g26/M0B/3C/65/120x90_0_autohomecar__ChcCP12BFCmAIO83AAGq7vK0sGY193.jpg&#x27;        ]        tasks = [asyncio.create_task(fetch(session, url)) for url in url_list]  # asyncio.create_task()将会把协程对象封装成一个Task对象        await asyncio.wait(tasks)if __name__ == &#x27;__main__&#x27;:    asyncio.run(main())\n\n上述两种的执行对比之后会发现，基于协程的异步编程 要比 同步编程的效率高了很多。因为:\n\n同步编程，按照顺序逐一排队执行，如果图片下载时间为2分钟，那么全部执行完则需要6分钟\n异步编程，几乎同时发出了3个下载任务的请求（遇到IO请求自动切换去发送其他任务请求），如果图片下载时间为2分钟，那么全部执行完毕也大概需要2分钟左右就可以了\n\n\n\n小结协程一般应用在有IO操作的程序中，因为协程可以利用IO等待的时间去执行一些其他的代码，从而提升代码执行效率\n异步编程基于async &amp; await关键字的协程可以实现异步编程，这也是目前python异步相关的主流技术\n想要真正的了解Python中内置的异步编程，根据下文的顺序一点点来看\n事件循环事件循环，可以把他当做是一个while循环，这个while循环在周期性地运行并执行一些任务，在特定条件下终止循环\n# 伪代码任务列表 = [ 任务1, 任务2, 任务3,... ]while True:    可执行的任务列表，已完成的任务列表 = 去任务列表中检查所有的任务，将&#x27;可执行&#x27;和&#x27;已完成&#x27;的任务返回    for 就绪任务 in 已准备就绪的任务列表:        执行已就绪的任务    for 已完成的任务 in 已完成的任务列表:        在任务列表中移除 已完成的任务    如果 任务列表 中的任务都已完成，则终止循环\n\n在编写程序的时候可以通过如下代码来获取和创建事件循环:\nimport asyncioloop = asyncio.get_event_loop()\n\n协程和异步编程协程函数，定义形式为async def的函数；协程对象，调用协程函数所返回的对象\n# 定义一个协程函数async def func():    pass# 调用协程函数，返回一个协程对象result = func()\n\n注意: 调用协程函数时，函数内部代码不会执行，只是会返回一个协程对象\n基本应用程序中，如果想要执行协程函数的内部代码，需要 事件循环 和 协程对象 配合才能实现，如:\nimport asyncioasync def func():    print(&quot;协程内部代码&quot;)# 调用协程函数，返回一个协程对象(任务对象)result = func()# 方式一# loop = asyncio.get_event_loop() # 创建一个事件循环# loop.run_until_complete(result) # 将协程对象当做任务提交到事件循环的任务列表中(这里只有一个协程对象，所以就直接把这个协程对象传进去)，任务列表中的所有协程对象执行完之后就终止# 方式二# 本质上方式一是一样的，内部先 创建事件循环 然后执行 run_until_complete，一个简便的写法。# asyncio.run 函数在 Python 3.7 中加入 asyncio 模块，asyncio.run(result)\n\n这个过程可以简单理解为：将协程对象当做任务添加到 事件循环 的任务列表，然后事件循环检测列表中的协程对象是否 已准备就绪(默认可理解为就绪状态)，如果准备就绪则执行其内部代码\nawaitawait是一个只能在协程函数中使用的关键字，用于遇到IO操作时挂起当前协程(任务)，当前协程(任务)挂起过程中 事件循环可以去执行其他的协程(任务)，当前协程IO处理完成时，可以再次切换回来执行await之后的代码；代码如下:\n示例1:\nimport asyncioasync def func():    print(&quot;执行协程函数内部代码&quot;)    # 遇到IO操作挂起当前协程（任务），等IO操作完成之后再继续往下执行。    # 当前协程挂起时，事件循环可以去执行其他协程（任务）。    response = await asyncio.sleep(2)    print(&quot;IO请求结束，结果为：&quot;, response)result = func()asyncio.run(result)\n\n程序输出:\n执行协程函数内部代码IO请求结束，结果为： None\n\n示例2:\nimport asyncioasync def others():    print(&quot;start&quot;)    await asyncio.sleep(2)    print(&#x27;end&#x27;)    return &#x27;返回值&#x27;async def func():    print(&quot;执行协程函数内部代码&quot;)    # 遇到IO操作挂起当前协程（任务），等IO操作完成之后再继续往下执行。当前协程挂起时，事件循环可以去执行其他协程（任务）。    response = await others()    print(&quot;IO请求结束，结果为：&quot;, response)asyncio.run(func())\n\n程序输出:\n执行协程函数内部代码startendIO请求结束，结果为： 返回值\n\n示例3:\nimport asyncioasync def others():    print(&quot;start&quot;)    await asyncio.sleep(2)    print(&#x27;end&#x27;)    return &#x27;返回值&#x27;async def func():    print(&quot;执行协程函数内部代码&quot;)    # 遇到IO操作挂起当前协程（任务），等IO操作完成之后再继续往下执行。当前协程挂起时，事件循环可以去执行其他协程（任务）。    response1 = await others()    print(&quot;IO请求结束，结果为：&quot;, response1)    response2 = await others()    print(&quot;IO请求结束，结果为：&quot;, response2)asyncio.run(func())\n\n上述的所有示例都只是创建了一个任务(协程对象)，即: 事件循环的任务列表中只有一个任务(协程对象)，所以在IO等待时无法演示切换到其他任务效果\n程序想要创建多个任务对象，需要使用Task对象来实现\nTask对象Tasks用于并发调度协程，通过asyncio.create_task(协程对象)的方式创建Task对象，这样可以让协程加入事件循环中等待被调度执行。除了使用 asyncio.create_task() 函数以外，还可以用低层级的 loop.create_task() 或 ensure_future() 函数，不建议手动实例化Task对象\n本质上是将协程对象们封装成task对象，一个协程对象列表，并将协程立即加入事件循环，同时追踪协程的状态\n注意: asyncio.create_task() 函数在 Python 3.7 中被加入。在 Python 3.7 之前，可以改用低层级的 asyncio.ensure_future() 函数\n示例1:\nimport asyncioasync def func():    print(1)    await asyncio.sleep(2)    print(2)    return &quot;返回值&quot;async def main():    print(&quot;main开始&quot;)    # 创建协程，将协程封装到一个Task对象中并立即添加到事件循环的任务列表中，等待事件循环去执行（默认是就绪状态）。    task1 = asyncio.create_task(func())    # 创建协程，将协程封装到一个Task对象中并立即添加到事件循环的任务列表中，等待事件循环去执行（默认是就绪状态）。    task2 = asyncio.create_task(func())    print(&quot;main结束&quot;)    # 当执行某协程遇到IO操作时，会自动化切换执行其他任务。    # 此处的await是等待相对应的协程全都执行完毕并获取结果    ret1 = await task1    ret2 = await task2    print(ret1, ret2)asyncio.run(main())\n\n示例2:\nimport asyncioasync def func():    print(1)    await asyncio.sleep(2)    print(2)    return &quot;返回值&quot;async def main():    print(&quot;main开始&quot;)    # 创建协程，将协程封装到Task对象中并添加到事件循环的任务列表中，等待事件循环去执行（默认是就绪状态）。    # 在调用    task_list = [        asyncio.create_task(func(), name=&quot;n1&quot;),        asyncio.create_task(func(), name=&quot;n2&quot;)    ]    print(&quot;main结束&quot;)    # 当执行某协程遇到IO操作时，会自动化切换执行其他任务。    # 此处的await是等待所有协程执行完毕，并将所有协程的返回值保存到done    # 如果设置了timeout值，则意味着此处最多等待的秒，完成的协程返回值写入到done中，未完成则写到pending中。    done, pending = await asyncio.wait(task_list, timeout=None)    print(done, pending)asyncio.run(main())\n\n注意: asyncio.wait源码内部也会对列表中的每个协程执行ensure_future从而封装为Task对象，所以在和wait配合使用时task_list的值为[func(),func()] 也是可以的，如下示例所示:\n示例3:\nimport asyncioasync def func():    print(&quot;执行协程函数内部代码&quot;)    # 遇到IO操作挂起当前协程（任务），等IO操作完成之后再继续往下执行。当前协程挂起时，事件循环可以去执行其他协程（任务）。    response = await asyncio.sleep(2)    print(&quot;IO请求结束，结果为：&quot;, response)coroutine_list = [func(), func()]# 错误：coroutine_list = [ asyncio.create_task(func()), asyncio.create_task(func()) ]  # 此处不能直接 asyncio.create_task，因为将Task立即加入到事件循环的任务列表，# 但此时事件循环还未创建，所以会报错。# 使用asyncio.wait将列表封装为一个协程，并调用asyncio.run实现执行两个协程# asyncio.wait内部会对列表中的每个协程执行ensure_future，封装为Task对象。done,pending = asyncio.run( asyncio.wait(coroutine_list) )\n\n综合案例:&quot;&quot;&quot;@Description : 抓取交易侠中的天然气期货的收盘价@File        : NGAS_close_price@Project     : aiostarload@Time        : 2021/11/11/0011 19:17@Author      : LiHouJian@Software    : PyCharm@issue       : http://120.76.207.186/jin10ts/2021issues/-/issues/707#note_114637@change      : @reason      : &quot;&quot;&quot;import hashlibimport jsonimport reimport urllibimport timefrom aiostarlord.utils import md5import asyncioimport datetimeimport osimport tracebackimport aiohttpfrom lxml import etreefrom aiostarlord.spiders import BaseSpiderclass Spider(BaseSpider):    proxy = None    _type = &quot;快讯&quot;    headers = &#123;        &#x27;pragma&#x27;: &#x27;no-cache&#x27;,        &#x27;cache-control&#x27;: &#x27;no-cache&#x27;,        &#x27;upgrade-insecure-requests&#x27;: &#x27;1&#x27;,        &#x27;user-agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36 Edg/89.0.774.63&#x27;,        &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36 Edg/89.0.774.63&#x27;,    &#125;    time_tuple = time.localtime(time.time())    today = time.strftime(&quot;%Y-%m-%d&quot;, time_tuple)    n_api = &#x27;http://114.55.255.71:9088/index/klineData&#x27;    n_headers = &#123;        &#x27;Content-Type&#x27;: &#x27;application/json&#x27;    &#125;    n_data = json.dumps(&#123;        &quot;symbols&quot;: [            &quot;NGAS&quot;        ],        &quot;type&quot;: 1440&#125;)    up_id = &#x27;5505&#x27;    def getYesterday(self):        today = datetime.date.today()        oneday = datetime.timedelta(days=1)        yesterday = today - oneday        yesterday = str(today - oneday)        return yesterday    async def fetch(self, url, headers, data=None, retry=0):        try:            async with aiohttp.ClientSession() as session:                async with session.post(                        url=url,                        headers=headers,                        data=data,                        timeout=10,                ) as resp:                    html = await resp.json()                    return html        except:            retry += 1            if retry &lt; 2:                await self.fetch(url, headers, data, retry)            else:                self.logger(f&quot;req_err: &#123;url&#125;&quot;)                return    def read_data(self):        if os.path.exists(self.history_path):            with open(self.history_path, &#x27;r&#x27;) as f:                his_data = json.load(f)        else:            his_data = &#123;&#125;        return his_data    async def get_price_info(self):        price_info = await self.fetch(self.n_api, self.n_headers, data=self.n_data)        # print(price_info)        close_time = price_info[&#x27;data&#x27;][1][&#x27;list&#x27;][0][&#x27;close_time&#x27;].split(&quot; &quot;)[0]        # print(close_time)        close_price = price_info[&#x27;data&#x27;][1][&#x27;list&#x27;][0][&#x27;close&#x27;]        # print(close_price)        data = &#123;&#x27;pub_date&#x27;: close_time, &#x27;pub_price&#x27;: close_price&#125;        self.logger(&#x27;got yes-close-price successfully!&#x27;)        with open(self.history_path, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as f:            # f.write()            json.dump(data, f)        return close_price, close_time    def judge_upload(self):        history_data = self.read_data()        if len(history_data) == 0:            # self.logger(&#x27;Today data has uploaded yet!&#x27;)            return False        elif history_data[&#x27;pub_date&#x27;] != self.getYesterday():            return False        else:            return True    async def upload_info(self):        if self.judge_upload():            self.logger(&#x27;Data has uploaded yet!&#x27;)            return        pub_price, pub_date = await self.get_price_info()        data_id = self.up_id        up_url = &#x27;http://09636cb288b4456385f023a597399ec6.z3c.jin10.com/admin/api/data/insert/batch&#x27;        up_headers = &#123;            &quot;sync-token&quot;: &quot;3CD24FB0D6963F7D&quot;,            &quot;x-app-id&quot;: &quot;KYEcsGhEkPo9EMg3&quot;,            &quot;x-version&quot;: &quot;1.0.0&quot;,  # 正式服            # &quot;x-version&quot;: &quot;1000&quot;,  # 测试服            &quot;Content-Type&quot;: &quot;application/json&quot;,        &#125;        # &quot;data&quot;: [&#123;&quot;x_axis&quot;: date_info, &quot;y_axis&quot;: f&quot;&#123;end_price&#125;&quot;, &quot;status&quot;: 1&#125;]&#125;        pub_date = pub_date.replace(&#x27;-&#x27;, &#x27;.&#x27;)        data = &#123;&quot;data_set_id&quot;: data_id,                &quot;data&quot;: [&#123;&quot;x_axis&quot;: pub_date, &quot;y_axis&quot;: f&quot;&#123;pub_price&#125;&quot;, &quot;status&quot;: 1&#125;]&#125;        upload_return_value = await self.fetch(up_url, up_headers, data=json.dumps(data))        if upload_return_value[&#x27;status&#x27;] == 200:            self.logger(f&#x27;&#123;data_id&#125; up ok!&#x27;)        # print(upload_return_value)    async def on_message(self, msg):        self.history_path = os.path.join(self.spider_cache_dir, &#x27;ngas_history.json&#x27;)        self.his_data = self.read_data()        await self.upload_info()if __name__ == &#x27;__main__&#x27;:    loop = asyncio.get_event_loop()    s = Spider()    loop.run_until_complete(s.on_message(&#x27;a&#x27;))\n\nloop = asyncio.get_event_loop()创建一个事件循环，然后再把这个协程对象放到loop.run_until_complete()函数中，这个函数会把协程封装成task对象，然后在放进事件循环中去执行\n讲了这么多，主要记住以下三步:\n本文参考自:https://zhuanlan.zhihu.com/p/137057192\n"},{"title":"js逆向腾讯动漫","url":"/2022/01/26/js%E9%80%86%E5%90%91%E8%85%BE%E8%AE%AF%E5%8A%A8%E6%BC%AB/","content":"目标网站点击跳转\n网站分析首先我们打开开发者工具，然后下滑动漫画，会发现一张张图片被加载出来:\n\n但是它又不是ajax方式的:\n\n然后来看看是不是在js代码中，我们先取一部分搜索下:\n\n发现是没有的:\n\n然后就只有一种可能，那就是在页面的代码中，这种方式肯定涉及到加密:\n\n如上图，在页面的代码中发现了一段可疑的代码，怀疑这里有猫腻\n然后我们就搜索这个DATA，搜素的时候注意大小写:\n然后我们发现只有一个js文件中出现了DATA:\n\n我们定位到这个js文件然后格式化下，继续搜索:\n\n我们发现只有第一个DATA参数有点猫腻，然后我们打个断点看看:\n发现这里的变量_V里面就有我们想要的图片数据:\n\n去掉双引号放在浏览器的地址栏发现就是我们要的图片数据\n然后我们来看看这个_v是怎么来的，从哪里来的\n看了一圈_v参数，我们发现第二个·_v参数前面的一个立即执行函数有点可疑，这是一个经过加密后的函数(经过eval编码加密):\n\n我们可以用这个网站进行解密:\n\n以下是解密后的代码:\nfunction Base() &#123;    _keyStr = &quot;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=&quot;;    this.decode = function(c) &#123;        var a = &quot;&quot;,        b, d, h, f, g, e = 0;        for (c = c.replace(/[^A-Za-z0-9\\+\\/\\=]/g, &quot;&quot;); e &lt; c.length;) b = _keyStr.indexOf(c.charAt(e++)),        d = _keyStr.indexOf(c.charAt(e++)),        f = _keyStr.indexOf(c.charAt(e++)),        g = _keyStr.indexOf(c.charAt(e++)),        b = b &lt;&lt; 2 | d &gt;&gt; 4,        d = (d &amp; 15) &lt;&lt; 4 | f &gt;&gt; 2,        h = (f &amp; 3) &lt;&lt; 6 | g,        a += String.fromCharCode(b),        64 != f &amp;&amp; (a += String.fromCharCode(d)),        64 != g &amp;&amp; (a += String.fromCharCode(h));        return a = _utf8_decode(a)    &#125;;    _utf8_decode = function(c) &#123;        for (var a = &quot;&quot;,        b = 0,        d = c1 = c2 = 0; b &lt; c.length;) d = c.charCodeAt(b),        128 &gt; d ? (a += String.fromCharCode(d), b++) : 191 &lt; d &amp;&amp; 224 &gt; d ? (c2 = c.charCodeAt(b + 1), a += String.fromCharCode((d &amp; 31) &lt;&lt; 6 | c2 &amp; 63), b += 2) : (c2 = c.charCodeAt(b + 1), c3 = c.charCodeAt(b + 2), a += String.fromCharCode((d &amp; 15) &lt;&lt; 12 | (c2 &amp; 63) &lt;&lt; 6 | c3 &amp; 63), b += 3);        return a    &#125;&#125;var B = new Base(),T = W[&#x27;DA&#x27; + &#x27;TA&#x27;].split(&#x27;&#x27;),N = W[&#x27;n&#x27; + &#x27;onc&#x27; + &#x27;e&#x27;],len,locate,str;N = N.match(/\\d+[a-zA-Z]+/g);len = N.length;while (len--) &#123;    locate = parseInt(N[len]) &amp; 255;    str = N[len].replace(/\\d+/g, &#x27;&#x27;);    T.splice(locate, str.length)&#125;T = T.join(&#x27;&#x27;);_v = JSON.parse(B.decode(T));\n\n从上面的代码可以看出T应该就是页面代码中的那一长串字符串，我们来验证下:\n\n然后_v就是刚刚打断点看到的包含图片url的变量\n然后我们就可以通过以上的js代码获得_v，但是我们还有一个变量N未知，同样的我们在console中看一下:\n\n但是这个N参数在哪里呢，我们在页面代码中看下，取一小部分搜索，这也是一个技巧:\n\n发现这是一句js代码生成的\n构造参数刚刚我们知道了_v这个变量的生成函数，然后目前有两个参数需要构建出来\n这里我们用正则提取，主要用到了正则的(?=、?&lt;=)，可以跳转这里查看如何使用\n下面来看看代码:\nimport requestsimport reimport execjsurl = &#x27;https://ac.qq.com/ComicView/index/id/531490/cid/1&#x27;res = requests.get(url).textdata = re.findall(&quot;(?&lt;=var DATA        = &#x27;).*?(?=&#x27;)&quot;, res)[0]   # 提取DATAnonce = re.findall(&#x27;window\\[&quot;.+?(?&lt;=;)&#x27;, res)[0]   # 提取window[&quot;no&quot;+&quot;nce&quot;]nonce = &#x27;=&#x27;.join(nonce.split(&#x27;=&#x27;)[1:])[:-1]   # 掐头去尾nonce = execjs.eval(nonce)   # 通过execjs模块计算js代码print(data)print(nonce)\n\n以上对data的提取的正则有点问题，可以用beautifsuop来获取\n获取到参数之后就可以很方便地进行获取_v变量了，可以像上面一样使用execjs来运行js代码然后获取到_v参数\n"},{"title":"Python3网络爬虫开发实战第二版第3章-网页数据的解析提取","url":"/2022/01/08/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC3%E7%AB%A0-%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A7%A3%E6%9E%90%E6%8F%90%E5%8F%96/","content":"以下并非书上内容，由个人在网上整理所得\nXpath的使用详情见: https://www.w3school.com.cn/xpath/index.asp\nBeautiful Soup的使用详情见: https://cuiqingcai.com/1319.html\npyquery的使用详情见: https://blog.csdn.net/sinat_38682860/article/details/100165446\nparsel的使用(Xpath和CSS选择器的结合)scrapy框架选择器的API和parsel的API相似，这是因为scrapy的选择器就是基于parsel的二次封装\nparsel的使用详情见: https://blog.csdn.net/wangzhuanjia/article/details/122758186\n"},{"title":"Python3网络爬虫开发实战第二版第4章-数据的存储","url":"/2022/02/08/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC4%E7%AB%A0-%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AD%98%E5%82%A8/","content":"TXT文本文件存储以txt格式存储\nr: 以只读打开\nrb: 以二进制只读方式打开\nr+: 以读写方式打开\nrb+: 以二进制读写方式打开\nw: 以写入方式打开\nwb: 以二进制写入方式打开\nw+: 以读写方式打开\nwb+: 以二进制读写方式打开\na: 以追加方式打开一个文件\nab: 以二进制追加方式打开一个文件\nab+: 以二进制追加方式打开一个文件，如果该文件不存在就新建一个文件用于读写\nJSON文件存储在js中，一切皆对象，对象在js中是指用花括号{}包围起来的内容，数据结构是{key1: value1, key2: value2}这种键值对结构，key表示对象的属性，value表示属性的值，前者可以使用整数和字符串，后者可以是任意类型\n关于Python的json文件存储以及提取可以参考这里\nCSV文件存储详情请见: https://www.cnblogs.com/gdjlc/p/11406599.html\n还可以参照书本\nMySQL数据存储详情请见: https://www.cnblogs.com/hanfanfan/p/10398244.html\nMongoDB数据存储NoSQL，全称为Not Only SQL，意为不仅仅是SQL，泛指菲关系型数据库，NoSQL是基于键值对的，而且不需要经过SQL层的解析，数据之间没有耦合性，性能非常高\n非关系型数据库又可细分如下:\n\n键值存储数据库: 代表有Redis等\n列存储数据库: 代表有Cassandra，HBase和Riak等\n文档型数据库: 代表有CouchDB和MongoDB等\n图形数据库: 代表有Neo4j，InfoGrid等\n\n我们爬虫使用非关系型数据库是比较方便的，我们来看看MongoDB:\n安装MongoDBpip install MongoDB\n\n连接MongoDB连接MongoDB，需要使用PyMongo库里面的MongoClient方法，一般而言，传入MongoDB的IP以及端口即可，MongoClient方法的第一个参数为地址host，第二个参数为端口port(如果不传入此参数默认为27017)\n示例如下:\nimport pymongoclient = pymongo.MongoClient(host=&#x27;localhost&#x27;, port=27017)\n\n上面的client就是MongoDB的连接对象了\n另外，还可以直接给MongoDB的第一个参数传入MongoDB的连接字符串，它以mongodb开头，实例如下:\nimport pymongoclient = pymongo.MongoClient(host=&#x27;mongodb://localhost:27017&#x27;)\n\n创建数据库示例如下:\nimport pymongo myclient = pymongo.MongoClient(&quot;mongodb://localhost:27017/&quot;)mydb = myclient[&quot;runoobdb&quot;]\n\n执行以上代码便创建了一个名叫runoobdb的数据库，但是要注意在MongoDB中数据库只有在内容插入后才会创建! 就是说，数据库创建后要创建集合(数据表)并插入一个文档(记录)，数据库才会真正创建\n创建集合示例如下:\nmyclient = pymongo.MongoClient(&quot;mongodb://localhost:27017/&quot;)mydb = myclient[&quot;runoobdb&quot;] mycol = mydb[&quot;sites&quot;]\n\n执行以上代码便创建了一个名叫sites的集合，但是要注意在 MongoDB 中，集合只有在内容插入后才会创建! 就是说，创建集合(数据表)后要再插入一个文档(记录)，集合才会真正创建\n指定数据库示例如下:\ndb = client.test\n\n这里调用client的test属性即可返回test数据库，当然也可以这样指定:\ndb = client[&#x27;test&#x27;]\n\n以上两种方式是等价的\n指定集合MongoDB下又包含多个集合，这些结合类似于关系型数据库的表\n示例如下:(这里指定一个集合为students)\ncollection = db.students\n\n或者:\ncollection = [&#x27;students&#x27;]\n\n插入数据我们在students这个集合中试着插入一个数据，这个数据以字典形式表示:\nimport pymongomyclient = pymongo.MongoClient(&quot;mongodb://localhost:27017/&quot;)mydb = myclient[&quot;runoobdb&quot;]mycol = mydb[&#x27;students&#x27;]studnet = &#123;\t&quot;name&quot;: &quot;jkl&quot;,\t&quot;age&quot;: &quot;45&quot;,\t&quot;gender&quot;: &quot;man&quot;&#125;rsult = mycol.insert(studnet)  # insert is deprecated(insert方法被弃用)print(rsult)  # 会返回一个ObjectId类型的_id属性，执行insert方法后会返回_id值\n\n当然我们也可以插入多条数据，用列表形式传递即可:\nimport pymongomyclient = pymongo.MongoClient(&quot;mongodb://localhost:27017/&quot;)mydb = myclient[&quot;runoobdb&quot;]mycol = mydb[&#x27;students&#x27;]studnet1 = &#123;\t&quot;name&quot;: &quot;jkl&quot;,\t&quot;age&quot;: &quot;45&quot;,\t&quot;gender&quot;: &quot;man&quot;&#125;studnet2 = &#123;\t&quot;name&quot;: &quot;jklg&quot;,\t&quot;age&quot;: &quot;453&quot;,\t&quot;gender&quot;: &quot;women&quot;&#125;rsult = mycol.insert([studnet1,studnet2])  # insert is deprecated(insert方法被弃用)print(rsult)  # 会返回一个ObjectId类型的_id属性，执行insert方法后会返回_id值# 插入多个将会返回_id的列表\n\n虽然在Python3.x中insert方法已经不被官方所推荐，但还是可以继续使用，官方推荐用insert_one插入一个，用insert_many插入多个:\n示例如下:\nimport pymongomyclient = pymongo.MongoClient(&quot;mongodb://localhost:27017/&quot;)mydb = myclient[&quot;runoobdb&quot;]mycol = mydb[&#x27;students&#x27;]studnet1 = &#123;\t&quot;name&quot;: &quot;jkvl&quot;,\t&quot;age&quot;: &quot;45&quot;,\t&quot;gender&quot;: &quot;man&quot;&#125;result = mycol.insert_one(studnet1)  # 官方推荐使用insert_oneprint(result)  # 返回这次返回的是InsertOneResult对象，我们可以调用其inserted_id属性获取_idprint(result.inserted_id)\n\nimport pymongomyclient = pymongo.MongoClient(&quot;mongodb://localhost:27017/&quot;)mydb = myclient[&quot;runoobdb&quot;]mycol = mydb[&#x27;students&#x27;]studnet1 = &#123;\t&quot;name&quot;: &quot;jokvl&quot;,\t&quot;age&quot;: &quot;45&quot;,\t&quot;gender&quot;: &quot;man&quot;&#125;studnet2 = &#123;\t&quot;name&quot;: &quot;jlkvl&quot;,\t&quot;age&quot;: &quot;445&quot;,\t&quot;gender&quot;: &quot;man&quot;&#125;result = mycol.insert_many([studnet1, studnet2])  # 官方推荐使用insert_manyprint(result)  # 返回这次返回的是InsertOneResult对象，我们可以调用其inserted_ids属性获取_idprint(result.inserted_ids)\n\n查询我们可以使用find_one或find方法进行查询，前者查询得到的是单个结果，后者则会返回一个生成器对象\n示例如下:\nimport pymongomyclient = pymongo.MongoClient(&quot;mongodb://localhost:27017/&quot;)mydb = myclient[&quot;runoobdb&quot;]mycol = mydb[&#x27;students&#x27;]result = mycol.find_one(&#123;&#x27;name&#x27;: &#x27;jokvl&#x27;&#125;)  # 字典类型print(type(result))print(result)\n\n我们还可以根据ObjectId来查询数据，需要用到bson库里的objectid:\nimport pymongofrom bson.objectid import ObjectIdmyclient = pymongo.MongoClient(&quot;mongodb://localhost:27017/&quot;)mydb = myclient[&quot;runoobdb&quot;]mycol = mydb[&#x27;students&#x27;]result = mycol.find_one(&#123;&#x27;_id&#x27;: ObjectId(&#x27;6201e6be4652abcba2496717&#x27;)&#125;)  # 字典类型print(type(result))print(result)\n\n如果查询结果不存在，就会返回None\n查询多条数据，可以使用find方法:\nresult = collection.find(&#x27;age&#x27;: 20)for r in result:   \tprint(r)\n\n如果要查询age大于20的数据，写法如下:\nresult = collection.find(&#123;&#x27;age&#x27;: &#123;&#x27;$gt&#x27;: 20&#125;&#125;)\n\n比较符号如下:\n\n\n\n符号\n含义\n实例\n\n\n\n$lt\n小于\n{‘age’: {‘$lt’: 20}}\n\n\n$gt\n大于\n{‘age’: {‘$gt’: 20}}\n\n\n$lte\n小于等于\n{‘age’: {‘$lte’: 20}}\n\n\n$gte\n大于等于\n{‘age’: {‘$gte’: 20}}\n\n\n$ne\n不等于\n{‘age’: {‘$ne’: 20}}\n\n\n$in\n在范围内\n{‘age’: {‘$in’: [20, 30]}}\n\n\n$nin\n不在范围内\n{‘age’: {‘$nin’: [20, 30]}}\n\n\n另外还可以使用正则表达式进行匹配，比如下面查询name以M为开头的学生数量:\nresult = collection.find(&#123;&#x27;name&#x27;: &#123;&#x27;$regex&#x27;: &#x27;^M.*&#x27;&#125;&#125;)\n\n计数使用count方法来计数:\ncount = collection.find().count()\n\n统计符合条件的个数:\ncount = collection.find(&#123;&#x27;age&#x27;: 20&#125;).count()\n\n运行结果都是一个数值\n排序使用sort方法，并传入排序的字段及升降序标准即可:\nresult = collection.find().sort(&#x27;name&#x27;, pymongo.ASCENDING)print([result[&#x27;name&#x27;] for result in results])\n\n以上代码中的ASCENDING表示升序排序，降序排序可传入pymongo.DESCENDING\n偏移在某些情况下，我们可能只想取某几个元素，这时候我们可以利用skip方法偏移几个位置:\nresult = collection.find().sort(&#x27;name&#x27;, pymongo.ASCENDING).skip(2)print([result[&#x27;name&#x27;] for result in results])\n\n还可以使用limit方法指定要获取的结果个数:\nresult = collection.find().sort(&#x27;name&#x27;, pymongo.ASCENDING).skip(2).limit(2)print([result[&#x27;name&#x27;] for result in results])\n\n注意: 在数据库中数量非常庞大的时候，比如千万、亿级别的，最好不要使用大偏移量来查询数据，因为这样很可能导致内存溢出，这个时候可以采用以ObjectId的方法来查询\n更新对于数据更新，我们可以使用update方法，在其中指定更新的条件和更新后的数据即可，实例如下:\ncondition = &#123;&#x27;name&#x27;: &#x27;Kevin&#x27;&#125;student = collection.find_one(condition)student[&#x27;age&#x27;] = 25result = collection.update(condition, student)print(result)\n\n执行以上语句会返回成功或者失败和影响数据的条数(nMdified)\n对比以上代码，我们还可以使用$set操作符实现数据更新，实例如下:\nresult = collection.update(condition, &#123;&#x27;$set&#x27;: student&#125;)\n\n这样可以只更新student字典内存在的字段，如果原先还有其他字段，是不会动的，不会被更新，也不会删除；而如果用update，就会把之前的数据全部用student字典替换，要是存在其他字段，会被删除\n官方推荐使用update_one和update_many方法来处理单条和多条数据更新过程，它们的用法更为严格，第二个参数都需要使用$类型操作符作为字典的键名，实例代码如下:\ncondition = &#123;&#x27;name&#x27;: &#x27;Kevin&#x27;&#125;student = collection.find_one(condition)student[&#x27;age&#x27;] = 26result = collection.update_one(condition, &#123;&#x27;$set&#x27;: student&#125;)print(result)  # UpdateResult类型print(result.matched_count, result.modified_count)  # 匹配的数据条目和影响的数据条目\n\n我们在来看一个例子:\ncondition = &#123;&#x27;age&#x27;: &#123;&#x27;$gt&#x27;: 20&#125;&#125;result = collection.update_one(condition, &#123;&#x27;$inc&#x27;: &#123;&#x27;age&#x27;: 1&#125;&#125;)  # 对age+1对第一条符合的做出改变，如果用update_many就会更新所有被选中的print(result)  # UpdateResult类型print(result.matched_count, result.modified_count)  # 匹配的数据条目和影响的数据条目\n\n删除删除操作比较简单，直接调用remove方法并指定删除条件即可，实例代码如下:\nresult = collection.remove(&#123;&#x27;name&#x27;: &#x27;kevin&#x27;&#125;)print(result)\n\n运行结果如下:\n&#123;&#x27;ok&#x27;: 1, &#x27;n&#x27;: 1&#125;\n\n这里依然有两个新方法，delete_one和delete_many，delete_one就是删除第一符合条件的数据，delete_many就是删除所有符合条件的数据:\nresult = collection.delete_one(&#123;&#x27;name&#x27;: &#x27;kevin&#x27;&#125;)print(&#x27;result&#x27;)print(result.deleted_count)  # 1result = collection.delete_many(&#123;&#x27;age&#x27;: &#123;&#x27;$lt&#x27;: 25&#125;&#125;)print(result.deleted_count)  # 4\n\n两个方法返回的结果都是DeletedResult类型，可以调用deleted_coun属性获取删除的数量\n其它操作PyMongo还提供了一些组合方法:\nfind_one_and_delete: 查找后删除\nfind_one_and_raplace: 查找后替换\nfind_one_and_update: 查找后更新\nRedi缓存存储Redis是一个基于内存的、高效的键值型非关系型数据库，存取效率极高，而且支持多种数据存储结构，使用起来也非常简单，下面我们来看看:\n安装Redispip install redis\n\n以上就是安装了redis-py库，即用来操作Redis的Python包\nRedis和StrictRedisStrictRedis类实现了绝大部分官方的Redis命令，参数也一一对应，例如set方法就对应着Redis命令的set方法，而Redis是StrictRedis的子类，其主要功能是向后兼容旧版本库里的几个方法；为了实现兼容，Redis类对方法做了改写，例如将lrem方法中的value和num参数的位置进行了互换，这和Redis命令行参数是不一样的，官方推荐使用StrictRedis！\n连接Redis首先我们需要启动redis服务，步骤如下:\n首先申明，我是在一个工作电脑上\n\n打开everything，然后搜索redis，进入到redis的安装目录:\n\n然后在此路径打开cmd，输入以下命令:\nredis-server.exe\n\n以上命令只能启动6379端口，用以下命令可以在7000端口启动redis\n  redis-server.exe redis.windows7000.conf​\t\t然后就启动了redis接下来我们进行连接并测试:```pythonfrom redis import StrictRedisredis = StrictRedis(host=&#x27;localhost&#x27;, port=6379, db=0, password=None)  # 没有设置password就None吧redis.set(&#x27;name&#x27;, &#x27;Bob&#x27;)print(redis.get(&#x27;name&#x27;))\n\n运行结果如下:\nb&#x27;Bob&#x27;\n\n以上代码我们传入了Redis的地址，运行端口，使用的数据库和密码信息，在默认不传数据的情况下这4个参数分别为localhost，6379,0和None\n以上代码同时说明我们已经成功连接redis，当然我们也可使用ConnectionPool来连接Redis，实例如下:\nfrom redis import StrictRedis, ConnectionPoolpool = ConnectionPool(host=&#x27;localhost&#x27;, port=6379, db=0, password=None)redis = StrictRedis(connection_pool=pool)redis.set(&#x27;name&#x27;, &#x27;tob&#x27;)print(redis.get(&#x27;name&#x27;))\n\n另外，ConnectionPool还支持通过URL来构建，URL支持的格式有如下3中:\nredis://[:password]@host:port/db\nrediss://[:password]@host:port/db\nunix://[password]@/path/to/socket.sock?db=db\n这三种url分别表示创建Redis TCP连接、Redis TCP+SSL连接、Redis UNIX socket连接，我们只需要构造其中一种即可，其中password部分如果没有可以省略，下面用URL连接演示下:\nurl = &#x27;redis://foobared@localhost:6379/0&#x27;pool = ConnectionPool.form_url(url)redis = StrictRedis(connection_pool=pool)\n\n键操作点击这里跳转，可配合书第152页\n字符串操作点击这里跳转，可配合书第153页\n列表操作点击这里操作，可配合书第154页\n集合操作点击这里跳转，可配合书第155页\n有序集合操作点击这里跳转，可配合书第157页\n散列操作点击这里跳转，可配合书第158页\nElasticsearch搜索引擎存储"},{"title":"Python3网络爬虫开发实战第二版第5章-Ajax数据爬取","url":"/2022/02/08/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC5%E7%AB%A0-Ajax%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/","content":"什么是Ajax以下来自百度百科:\nAjax即Asynchronous Javascript And XML（异步JavaScript和XML）在 2005年被Jesse James Garrett提出的新术语，用来描述一种使用现有技术集合的‘新’方法，包括: HTML 或 XHTML, CSS, JavaScript, DOM, XML, XSLT, 以及最重要的XMLHttpRequest。 [3] 使用Ajax技术网页应用能够快速地将增量更新呈现在用户界面上，而不需要重载（刷新）整个页面，这使得程序能够更快地回应用户的操作\n可以到豆瓣上体验几个实例: https://movie.douban.com/typerank?type_name=%E5%89%A7%E6%83%85&amp;type=11&amp;interval_id=100:90&amp;action=\n实例引入我们在浏览网页的时候，一直下滑，在数据没有展现完毕之前会一直在网页不刷新的情况下呈现数据，这个过程就是Ajax加载的过程\n基本原理从发送Ajax请求到网页更新的这个过程可以简单分为以下三步:\n\n发送请求\n我们知道Javascript可以实现页面的各种交互功能，Ajax也不例外，因为它就是由JavaScript实现的，最底层的实现代码如下:\nvar xmlhttpif (window.XMLHttpRequest) &#123;    xmlhttp=new XMLHttpRequest();&#125; else &#123; // code for IE6、IE5    xmlhttp=new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;)&#125;xmlhttp.onreadystatechange=function() &#123;    if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200) &#123;        document.getElementById(&#x27;myDiv&#x27;).innerHTML=xmlhttp.responseText;    &#125;&#125;xmlhttp.open(&quot;POST&quot;, &quot;/ajax/&quot;, true)xmlhttp.send()\n\n以上代码可以拆分为以下几步:\n\n新建一个XMLHttpRequest对象xmlhttp\n调用onreadystatechange属性设置监听\n最后调用open和send方法向某个链接(也就是服务器)发送请求\n\n前面用Python实现请求发送，由于这里是Ajax，所以实际上这里的请求发送会由JavaScript完成，由于设置了监听，当服务器返回响应时，onreadystatechange对应的方法便会被触发，然后就会在浏览器显示内容，后面的数据解析就交给Python了\n\n\n解析内容返回内容可能是HTML或者JSON，接下来只需要在方法中用JavaScript进一步处理即可，如果是JSON的话，可以进行解析和优化\n渲染网页JavaScript有改变网页内容的能力，在解析完响应内容之后，就可以调用JavaScript来进行下一步处理了，例如，通过document.getElementById().innerHTML操作可以修改源代码，这种操作也称为dom操作，即对网页文档进行操作\n再回想下豆瓣的下拉刷新，其实就是JavaScript向服务器发送了一个Ajax请求得到的，然后获取新的微博数据，对其做解析，并渲染在网页中\n因此我们知道，真实的网页数据其实就是一次次向服务器发送Ajax请求得到的，要想抓取这些数据，需要知道Ajax请求到底是怎么发送的、发往哪里，发了哪些参数，我们知道这些以后，就可以用Python模拟发送操作\nAjax分析方法这里略过\nAjax分析与实战准备工作\n安装好Python3(最低为3.6版本)\n了解Python HTTP请求库requests的基本用法\n了解Ajax基础知识和分析Ajax的基本方法\n\n爬取目标点击跳转\n我们需要完成的目标如下:\n\n分析页面数据的加载逻辑\n用request实现Ajax数据的爬取\n将每部电影的数据分别保存到MongoDB数据库\n\n我们直接上代码:\nimport requestsimport pymongoimport jsondef get_single_page_data(u):    response = requests.get(url).text    return responsedef save(r):    movies_data_list = json.loads(r)[&#x27;results&#x27;]    movie_id_page_max = movies_data_list[-1][&#x27;id&#x27;]    drama_list = list()    for d in range(movie_id_page_max - 9, movie_id_page_max + 1):        movie_drama_url = f&#x27;https://spa1.scrape.center/detail/&#123;d&#125;&#x27;        res = get_single_page_data(movie_drama_url)        drama = json.loads(res)[&#x27;drama&#x27;]        drama_list.append(drama)    for key, value in enumerate(movies_data_list):        value[&#x27;categories&#x27;] = &#x27;,&#x27;.join(i[&#x27;categories&#x27;])        value[&#x27;regions&#x27;] = &#x27;,&#x27;.join(i[&#x27;regions&#x27;])        value[&#x27;drama&#x27;] = drama_list[key]    myclient = pymongo.MongoClient(&quot;mongodb://localhost:27017/&quot;)    mydb = myclient[&quot;scrape&quot;]    mycol = mydb[&#x27;movie_data&#x27;]    result = mycol.insert_many(movies_data_list)    print(result.inserted_ids)if __name__ == &#x27;__main__&#x27;:    for i in range(0, 100, 10):        url = f&quot;https://spa1.scrape.center/api/movie/?limit=10&amp;offset=&#123;i&#125;&quot;        res = get_single_page_data(url)        save(res)\n\n结果如下:\n\n"},{"title":"Python3网络爬虫开发实战第二版第6章-异步爬虫","url":"/2022/02/09/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC6%E7%AB%A0-%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB/","content":"协程的基本原理要实现异步机制的爬虫，那自然和协程脱不了关系，下面我们就来了解下使用协程实现加速的方法，这种方法对IO密集型任务非常有效\n基础知识阻塞阻塞状态是指程序未得到所需计算资源时被挂起的状态；程序在等待某个操作完成期间，自身无法继续干别的事情，则称该程序在该操作上是阻塞的\n常见的阻塞形式有以下几种:\n\n网络IO阻塞\n磁盘IO阻塞\n用户输入阻塞\n\n阻塞是无处不在的，包括CPU在执行上下文时，所有进程都无法真正干事情，它们也会阻塞；在多核CPU的情况下，正在执行上下文切换操作的核不可被利用\n非阻塞非阻塞状态是指程序在等待某操作的时候，自身不被阻塞，可以继续干别的事情\n非阻塞因阻塞而存在，正因阻塞导致程序运行的耗时增加与效率低下，我们才要把它变成非阻塞\n同步举个栗子叭，在购物系统中更新商品库存时，需要用”行锁”，作为通行信号，强制让不同的更新请求排队并按顺序执行，这里的更新库存操作就是同步的，简而言之，同步意味着有序，不同程序单元在完成某个任务时需要靠某种通行方式保持协调一致才能完成任务\n异步举个栗子叭，我们爬虫下载网页，调度程序调用下载程序后，即可调用其他下载任务，无需与该下载任务保持通行以协调行为，简而言之，异步意味着无序，不同程序单元在完成某个任务时不需要靠某种通行方式保持协调一致也能完成任务\n多进程多进程就是利用CPU的多核优势，在同一时间并发执行多个任务，可以大大提高执行效率\n多线程线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位，而多线程就是指从软件或者硬件上实现多个线程并发执行的技术\n协程协程(coroutine)，又称微线程，是一种运行在用户态的轻量级线程，它拥有自己的寄存器上下文和栈，协程在调度切换时，将寄存器上下文和栈保存到其他地方， 等切回来的时候，再恢复先前保存的寄存器上下文和栈；因此，协程能保留上一次调用时的状态，每次进入都会进入上一次的所保留的状态\n在我们的爬虫场景下，我们发出一个请求后，需要等待一定的时间才会响应，在这个等待过程中，程序可以做很多事情，等到得到响应后再切回来继续处理，这样可以充分利用CPU和其他资源，这就是协程的优势\n协程的用法从Python3.4开始，Python中加入了协程的概念，但这个版本的协程还是以生成器对象为基础，Python3.5中增加了async、await，使得协程的实现更为方便，Python中使用协程最常用的库莫过于asyncio，下面我们来看看如何使用:\n首先我们需要了解下面几个概念:\n\nevent_loop: 事件循环，我们可以把一些函数注册到这个事件循环上\ncoroutine: 翻译过来是协程，在Python中常代指协程对象类型，我们可以将协程对象注册到事件循环中，它会被事件循环调用；我们可以使用async关键字来定义一个方法，这个方法在调用时不会立即执行，而是会返回一个协程对象\ntask: 任务，这是对协程对象的进一步封装，包含协程对象的各个状态\nfuture: 代表将来执行或没有执行的任务的结果，实际上和task没有本质区别\n\n另外，我们还需要知道，async是定义一个协程，await是用来挂起阻塞方法的执行，要使用这两个关键字要使用Python3.5以上\n定义协程我们来看一个例子:\nimport asyncioasync def execute(x):\tprint(&#x27;Number:&#x27;, x)coroutine = execute(1)print(&#x27;Coroutine:&#x27;, coroutine)print(&#x27;After calling execute&#x27;)loop = asyncio.get_event_loop()loop.run_until_complete(coroutine)print(&#x27;After calling loop&#x27;)\n\n运行结果如下:\nCoroutine: &lt;coroutine object execute at 0x0000000002D6E448&gt;After calling executeNumber: 1After calling loop\n\n首先，我们引入了asyncio包，这样才可以使用async和await关键字，然后使用async定义了一个execute方法，该方法接受一个数字参数x，执行之后会打印这个数字，随后我们直接调用了execute方法，然而这个方法并没有执行，而是返回了一个coroutine协程对象；之后我们使用get_event_loop方法创建了一个时间循环loop，并调用loop对象的run_until_complete方法将协程对象coroutine注册到了时间循环中，接着就会启动。最后我们才看到execute方法打印出了接受的数字\n前面我们提到了task，它是对协程对象的进一步封装，比协程对象多了运行状态，例如running，finished等，我们可以利用这些状态获取协程的执行情况\n在上面的例子中，当把协程对象coroutine传递给run_until_complete方法的时候，实际上它进行了一个操作，就是将coroutine封装成task对象；对此，我们也可显式地进行声明，代码如下所示:\nimport asyncioasync def execute(x):\tprint(&#x27;Number:&#x27;, x)coroutine = execute(1)print(&#x27;Coroutine:&#x27;, coroutine)print(&#x27;After calling execute&#x27;)loop = asyncio.get_event_loop()task = loop.create_task(coroutine)print(&#x27;Task:&#x27;, task)loop.run_until_complete(task)print(&#x27;Task:&#x27;, task)print(&#x27;After calling loop&#x27;)\n\n运行结果如下:\nCoroutine: &lt;coroutine object execute at 0x0000000002D6E4C8&gt;After calling executeTask: &lt;Task pending coro=&lt;execute() running at D:/Python_LHJ/test/Learn_asyncio/first_aio_demo.py:15&gt;&gt;Number: 1Task: &lt;Task finished coro=&lt;execute() done, defined at D:/Python_LHJ/test/Learn_asyncio/first_aio_demo.py:15&gt; result=None&gt;After calling loop\n\n这里我们定义了loop对象之后，紧接着调用了它的create_task方法，将协程对象转化为task对象，随后打印发现它处于pending状态，随后把它放在run_until_complete方法中去执行，并再次打印task对象，发现它的状态变成了finished\n定义task对象还有另外一种方式，就是直接调用asyncio包的ensure_future方法，返回结果也是task对象，这样的话我们就可以不借助loop对象，即使还没有声明loop，也可以提前定义好task对象，这种方式的写法如下:\nimport asyncioasync def execute(x):\tprint(&#x27;Number:&#x27;, x)coroutine = execute(1)print(&#x27;Coroutine:&#x27;, coroutine)print(&#x27;After calling execute&#x27;)task = asyncio.ensure_future(coroutine)print(&#x27;Task:&#x27;, task)loop = asyncio.get_event_loop()loop.run_until_complete(task)print(&#x27;Task:&#x27;, task)print(&#x27;After calling loop&#x27;)\n\n运行效果是一样的\n绑定回调我们也可以为某个task对象绑定一个回调方法，实例如下:\nimport asyncioimport requestsasync def request():\turl = &#x27;https://www.baidu.com&#x27;\tstatus = requests.get(url).status_code\treturn statusdef callback(task):\tprint(&#x27;Status:&#x27;, task.result())coroutine = request()task = asyncio.ensure_future(coroutine)task.add_done_callback(callback)print(&#x27;Task:&#x27;, task)loop = asyncio.get_event_loop()loop.run_until_complete(task)print(&#x27;Task:&#x27;, task)\n\n我们希望达到的效果是，当协程对象执行完毕之后，就去执行声明的callback方法，以上方法就为我们实现了\n实际上，即使不使用回调方法，在task运行完毕之后，也可以直接调用result方法获取结果，代码如下:\nimport asyncioimport requestsasync def request():\turl = &#x27;https://www.baidu.com&#x27;\tstatus = requests.get(url).status_code\treturn statuscoroutine = request()task = asyncio.ensure_future(coroutine)print(&#x27;Task:&#x27;, task)loop = asyncio.get_event_loop()loop.run_until_complete(task)print(&#x27;Task:&#x27;, task)print(&#x27;Task Ruesult:&#x27;, task.result())\n\n运行结果是一样的:\nTask: &lt;Task pending coro=&lt;request() running at D:/Python_LHJ/test/Learn_asyncio/bind_callback.py:17&gt;&gt;Task: &lt;Task finished coro=&lt;request() done, defined at D:/Python_LHJ/test/Learn_asyncio/bind_callback.py:17&gt; result=200&gt;Task Ruesult: 200\n\n多任务协程在上面的例子中，我们都只进行了一次请求，如果想执行多次请求，我们可以定义一个task列表，然后使用asyncio包中的wait方法执行，如下实例所示:\nimport asyncioimport requestsasync def request():\turl = &#x27;https://www.baidu.com&#x27;\tstatus = requests.get(url).status_code\treturn statustasks = [asyncio.ensure_future(request()) for _ in range(5)]print(&#x27;Tasks:&#x27;, tasks)loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks))for task in tasks:\tprint(&#x27;Task Result:&#x27;, task.result())\n\n可以看到，这五个协程都被顺利执行\n协程实现上述案例只是为后面的使用做铺垫，现在我们来看看协程在解决IO密集型任务方面到底有怎样的优势\n在前面的代码中，我们用一个网络请求作为例子，这本身就是一个耗时等待的操作，因为在请求网页之后需要等待页面响应并返回结果；耗时等待操作一般都是IO操作，例如文件读取，网络请求等；协程在处理这种操作时是有很大优势的，当遇到需要等待的情况时，程序可以暂时挂起，转而执行其他操作，避免一直等待下去\n我们先来看几个错误的实现:\n我们还是以之前的案例为例:\nimport asyncioimport timeimport requestsstart = time.time()async def request():\turl = &#x27;https://www.httpbin.org/delay/5&#x27;\tprint(&#x27;Waiting for&#x27;, url)\tresponse = requests.get(url)\tprint(&#x27;get response from:&#x27;, url, &#x27;response:&#x27;, response)tasks = [asyncio.ensure_future(request()) for _ in range(10)]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks))end = time.time()print(&#x27;Cost time:&#x27;, end-start)\n\n这里我们还是创建了10个task，然后将task列表传给wait方法并注册到时间循环中执行\n运行结果如下:\nWaiting for https://www.httpbin.org/delay/5get response from: https://www.httpbin.org/delay/5 response: &lt;Response [200]&gt;Waiting for https://www.httpbin.org/delay/5get response from: https://www.httpbin.org/delay/5 response: &lt;Response [200]&gt;Waiting for https://www.httpbin.org/delay/5get response from: https://www.httpbin.org/delay/5 response: &lt;Response [200]&gt;Waiting for https://www.httpbin.org/delay/5get response from: https://www.httpbin.org/delay/5 response: &lt;Response [200]&gt;Waiting for https://www.httpbin.org/delay/5get response from: https://www.httpbin.org/delay/5 response: &lt;Response [200]&gt;Waiting for https://www.httpbin.org/delay/5get response from: https://www.httpbin.org/delay/5 response: &lt;Response [200]&gt;Waiting for https://www.httpbin.org/delay/5get response from: https://www.httpbin.org/delay/5 response: &lt;Response [200]&gt;Waiting for https://www.httpbin.org/delay/5get response from: https://www.httpbin.org/delay/5 response: &lt;Response [200]&gt;Waiting for https://www.httpbin.org/delay/5get response from: https://www.httpbin.org/delay/5 response: &lt;Response [200]&gt;Waiting for https://www.httpbin.org/delay/5get response from: https://www.httpbin.org/delay/5 response: &lt;Response [200]&gt;Cost time: 65.49599981307983\n\n我们发现耗时差不读66秒，这好像不是异步啊，其实，要实现异步，先得有挂起操作，当一个任务需要等待IO结果的时候，可以挂起当前任务，转而执行其他任务，而上面的方法都是一本正经地串行执行下来，连个挂起都没有，怎么可能实现异步\n下面我们试试在请求的时候await一下是否有效果:\nimport asyncioimport timeimport requestsstart = time.time()async def request():\turl = &#x27;https://www.httpbin.org/delay/5&#x27;\tprint(&#x27;Waiting for&#x27;, url)\tresponse = await requests.get(url)\tprint(&#x27;get response from:&#x27;, url, &#x27;response:&#x27;, response)tasks = [asyncio.ensure_future(request()) for _ in range(10)]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks))end = time.time()print(&#x27;Cost time:&#x27;, end-start)\n\n运行下发现会报错:\nTask exception was never retrievedfuture: &lt;Task finished coro=&lt;request() done, defined at D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py:22&gt; exception=TypeError(&quot;object Response can&#x27;t be used in &#x27;await&#x27; expression&quot;)&gt;Traceback (most recent call last):  File &quot;D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py&quot;, line 25, in request    response = await requests.get(url)TypeError: object Response can&#x27;t be used in &#x27;await&#x27; expressionTask exception was never retrievedfuture: &lt;Task finished coro=&lt;request() done, defined at D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py:22&gt; exception=TypeError(&quot;object Response can&#x27;t be used in &#x27;await&#x27; expression&quot;)&gt;Traceback (most recent call last):  File &quot;D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py&quot;, line 25, in request    response = await requests.get(url)TypeError: object Response can&#x27;t be used in &#x27;await&#x27; expressionTask exception was never retrievedfuture: &lt;Task finished coro=&lt;request() done, defined at D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py:22&gt; exception=TypeError(&quot;object Response can&#x27;t be used in &#x27;await&#x27; expression&quot;)&gt;Traceback (most recent call last):  File &quot;D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py&quot;, line 25, in request    response = await requests.get(url)TypeError: object Response can&#x27;t be used in &#x27;await&#x27; expressionTask exception was never retrievedfuture: &lt;Task finished coro=&lt;request() done, defined at D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py:22&gt; exception=TypeError(&quot;object Response can&#x27;t be used in &#x27;await&#x27; expression&quot;)&gt;Traceback (most recent call last):  File &quot;D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py&quot;, line 25, in request    response = await requests.get(url)TypeError: object Response can&#x27;t be used in &#x27;await&#x27; expressionTask exception was never retrievedfuture: &lt;Task finished coro=&lt;request() done, defined at D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py:22&gt; exception=TypeError(&quot;object Response can&#x27;t be used in &#x27;await&#x27; expression&quot;)&gt;Traceback (most recent call last):  File &quot;D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py&quot;, line 25, in request    response = await requests.get(url)TypeError: object Response can&#x27;t be used in &#x27;await&#x27; expressionTask exception was never retrievedfuture: &lt;Task finished coro=&lt;request() done, defined at D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py:22&gt; exception=TypeError(&quot;object Response can&#x27;t be used in &#x27;await&#x27; expression&quot;)&gt;Traceback (most recent call last):  File &quot;D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py&quot;, line 25, in request    response = await requests.get(url)TypeError: object Response can&#x27;t be used in &#x27;await&#x27; expressionTask exception was never retrievedfuture: &lt;Task finished coro=&lt;request() done, defined at D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py:22&gt; exception=TypeError(&quot;object Response can&#x27;t be used in &#x27;await&#x27; expression&quot;)&gt;Traceback (most recent call last):  File &quot;D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py&quot;, line 25, in request    response = await requests.get(url)TypeError: object Response can&#x27;t be used in &#x27;await&#x27; expressionTask exception was never retrievedfuture: &lt;Task finished coro=&lt;request() done, defined at D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py:22&gt; exception=TypeError(&quot;object Response can&#x27;t be used in &#x27;await&#x27; expression&quot;)&gt;Traceback (most recent call last):  File &quot;D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py&quot;, line 25, in request    response = await requests.get(url)TypeError: object Response can&#x27;t be used in &#x27;await&#x27; expressionTask exception was never retrievedfuture: &lt;Task finished coro=&lt;request() done, defined at D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py:22&gt; exception=TypeError(&quot;object Response can&#x27;t be used in &#x27;await&#x27; expression&quot;)&gt;Traceback (most recent call last):  File &quot;D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py&quot;, line 25, in request    response = await requests.get(url)TypeError: object Response can&#x27;t be used in &#x27;await&#x27; expressionTask exception was never retrievedfuture: &lt;Task finished coro=&lt;request() done, defined at D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py:22&gt; exception=TypeError(&quot;object Response can&#x27;t be used in &#x27;await&#x27; expression&quot;)&gt;Traceback (most recent call last):  File &quot;D:/Python_LHJ/test/Learn_asyncio/Learn_aiohttp/first_aiohttp_demo.py&quot;, line 25, in request    response = await requests.get(url)TypeError: object Response can&#x27;t be used in &#x27;await&#x27; expression\n\n为什么会报错呢，这是因为requests返回的Response对象不能和await一起使用，官方文档说明，await后面的对象必须是如下格式之一:\n\n一个原生协程对象\n一个由types.coroutine修饰过的生成器，这个生成器可以返回协程对象\n由一个包含__await__方法的对象返回的一个迭代器\n\n既然await后面可以跟一个协程对象，那么async把请求的方法改成协程对象不就行了，于是代码就被改成了如下:\nimport asyncioimport timeimport requestsstart = time.time()async def get(url):\tres = requests.get(url)\treturn resasync def request():\turl = &#x27;https://www.httpbin.org/delay/5&#x27;\tprint(&#x27;Waiting for&#x27;, url)\tresponse = await get(url)\tprint(&#x27;get response from:&#x27;, url, &#x27;response:&#x27;, response)tasks = [asyncio.ensure_future(request()) for _ in range(10)]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks))end = time.time()print(&#x27;Cost time:&#x27;, end-start)\n\n以上代码把请求的页面独立出来了，并用async修饰，就得到了一个协程对象，运行发现还是60多秒，这是为啥呢\n这告诉我们仅仅将涉及IO操作的代码封装到async修饰的方法里是不可行的，只有使用支持异步操作的请求方式才可以实现真正的异步，这里就要使用aiohttp了\n使用aiohttpaiohttp是一个支持异步请求的库，它和asyncio配合使用，可以非常方便地实现异步请求\n安装aiohttp\npip install aiohttp\n\n下面我们将aiohttp投入使用，将代码改写成如下:\nimport aiohttpimport asyncioimport timestart = time.time()async def get(url):\tsession = aiohttp.ClientSession()\tresponse = await session.get(url)\tawait response.text()\tawait session.close()\treturn responseasync def request():\turl = &#x27;https://www.httpbin.org/delay/5&#x27;\tprint(&#x27;Waiting for&#x27;, url)\tresponse = await get(url)\tprint(&#x27;get response from:&#x27;, url, &#x27;response:&#x27;, response)tasks = [asyncio.ensure_future(request()) for _ in range(10)]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks))end = time.time()print(&#x27;Cost time:&#x27;, end-start)\n\n这里我们就成功了，可见异步爬虫的速度是十分可观的\naiohttp的使用基本介绍前面介绍的asyncio模块，其内部实现了对TCP，UDP，SSL协议的异步操作，但是对于HTTP请求来说，就需要用aiohttp来实现了\n aiohttp是一个基于asyncio的异步HTTP网络模块，它既提供了服务端，又提供了客户端，其中，我们可以使用服务端搭建一个支持异步处理的服务器，用来处理请求并提供响应的，类似于Django、flask、Tornado等一些Web服务器；而客户端可以用来发起请求，类似于requests发起一个HTTP请求然后获得响应，但是request发起的是一个同步的网络请求，aiohttp则是异步的\n基本实例import aiohttpimport asyncioasync def fetch(session, url):\tasync with session.get(url) as response:\t\treturn await response.text(), response.statusasync def main():\tasync with aiohttp.ClientSession() as session:\t\thtml, status = await fetch(session, &#x27;https://cuiqingcai.com&#x27;)\t\tprint(html)\t\tprint(status)if __name__ == &#x27;__main__&#x27;:\tloop = asyncio.get_event_loop()\ttask = loop.create_task(main())\tloop.run_until_complete(task)\n\n能够发现，aiohttp的请求方法的定义和之前有明显区别，主要包括如下几点:\n\n首先在导入库的时候，除了必须导入aiohttp这个库，还必须导入asyncio这个库，因为要实现异步爬取，需要启动协程，而协程需要借助于asyncio里面的事件循环才能执行\n异步爬取方法的定义和之前有所不同吗，在每个异步方法的前面都要统一加async来修饰\nwith as语句前面同样需要加async来修饰，在Python中，with as语句用于声明一个上下文管理器，能够帮助我们自动分配和释放资源， 而在异步方法中，with as前面加上async代表声明一个支持异步的上下文管理器\n对于一些返回协程对象的操作，前面需要加上await，如果是协程对象或者前面提到的三种中的一种那就要加上，如果只是返回数字那就不需要，比如返回状态码\n\nURL参数设置对于URL参数的设置，我们可以借助params参数，传入一个字典即可，实例如下:\nimport aiohttpimport asyncioasync def main():\tparams = &#123;&#x27;name&#x27;: &#x27;germey&#x27;, &#x27;age&#x27;: &#x27;25&#x27;&#125;\tasync with aiohttp.ClientSession() as session:\t\tasync with session.get(&#x27;https://www.httpbin.org/get&#x27;, params=params) as response:\t\t\tprint(await response.text())if __name__ == &#x27;__main__&#x27;:\tasyncio.get_event_loop().run_until_complete(main())\n\n其他请求类型aiohttp还支持其他请求类型，比如POST、PUT、DELETE等，这些和requests的使用方法相似，实例如下:\nsession.post(&#x27;http://www.httpbin.org/post&#x27;, data=b&#x27;data&#x27;)session.put(&#x27;http://www.httpbin.org/post&#x27;, data=b&#x27;data&#x27;)session.delete(&#x27;http://www.httpbin.org/delete&#x27;)session.head(&#x27;http://www.httpbin.org/get&#x27;)session.options(&#x27;http://www.httpbin.org/get&#x27;)session.patch(&#x27;http://www.httpbin.org/patch&#x27;, data=b&#x27;data&#x27;)\n\nPOST请求对于POST请求，其对应的请求头中的Content-Type为application/x-www-form-urlencoded我们可以用如下方式来提交:\nimport aiohttpimport asyncioasync def main():\tdata = &#123;&#x27;name&#x27;: &#x27;germey&#x27;, &#x27;age&#x27;: &#x27;25&#x27;&#125;\tasync with aiohttp.ClientSession() as session:\t\tasync with session.post(&#x27;https://www.httpbin.org/post&#x27;, data=data) as response:\t\t\tprint(await response.text())if __name__ == &#x27;__main__&#x27;:\tasyncio.get_event_loop().run_until_complete(main())\n\n运行结果如下:\n&#123;  &quot;args&quot;: &#123;&#125;,   &quot;data&quot;: &quot;&quot;,   &quot;files&quot;: &#123;&#125;,   &quot;form&quot;: &#123;    &quot;age&quot;: &quot;25&quot;,     &quot;name&quot;: &quot;germey&quot;  &#125;,   &quot;headers&quot;: &#123;    &quot;Accept&quot;: &quot;*/*&quot;,     &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;,     &quot;Content-Length&quot;: &quot;18&quot;,     &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;,     &quot;Host&quot;: &quot;www.httpbin.org&quot;,     &quot;User-Agent&quot;: &quot;Python/3.7 aiohttp/3.8.1&quot;,     &quot;X-Amzn-Trace-Id&quot;: &quot;Root=1-6203958d-60f5aa1f65cba41349a09e45&quot;  &#125;,   &quot;json&quot;: null,   &quot;origin&quot;: &quot;113.66.217.106&quot;,   &quot;url&quot;: &quot;https://www.httpbin.org/post&quot;&#125;\n\n对于POST JSON数据提交，其对应的请求头中的Content-Type为application/json，我们只需要将post方法中的data参数改成json即可，实例代码如下:\nimport aiohttpimport asyncioasync def main():\tdata = &#123;&#x27;name&#x27;: &#x27;germey&#x27;, &#x27;age&#x27;: &#x27;25&#x27;&#125;\tasync with aiohttp.ClientSession() as session:\t\tasync with session.post(&#x27;https://www.httpbin.org/post&#x27;, json=data) as response:\t\t\tprint(await response.text())if __name__ == &#x27;__main__&#x27;:\tasyncio.get_event_loop().run_until_complete(main())\n\n响应对于响应来说，我们可以用如下方法分别获取其中的状态码、响应头、响应体、响应体二进制内容、响应体JSON结果，实例如下:\nimport aiohttpimport asyncioasync def main():\tdata = &#123;&#x27;name&#x27;: &#x27;germey&#x27;, &#x27;age&#x27;: &#x27;25&#x27;&#125;\tasync with aiohttp.ClientSession() as session:\t\tasync with session.post(&#x27;https://www.httpbin.org/post&#x27;, json=data) as response:\t\t\tprint(response.status)\t\t\tprint(response.headers)\t\t\tprint(await response.text())\t\t\tprint(await response.read())\t\t\tprint(await response.json())if __name__ == &#x27;__main__&#x27;:\tasyncio.get_event_loop().run_until_complete(main())\n\n设置超时我们可以借助ClientTimeout对象设置超时，比如设置1秒的超时时间，可以这么实现:\nimport aiohttpimport asyncioasync def main():\ttimeout = aiohttp.ClientTimeout(total=1)\tdata = &#123;&#x27;name&#x27;: &#x27;germey&#x27;, &#x27;age&#x27;: &#x27;25&#x27;&#125;\tasync with aiohttp.ClientSession(timeout=timeout) as session:\t\tasync with session.post(&#x27;https://www.httpbin.org/post&#x27;, json=data) as response:\t\t\tprint(response.status)if __name__ == &#x27;__main__&#x27;:\tasyncio.get_event_loop().run_until_complete(main())\n\n如果超时，则会抛出TimeoutError，其类型为asynico.TimeoutError，我们进行异常捕获即可，另外，ClientTimeout对象还有其他参数，比如connect、socket_connect等，详细可见官网\n并发限制由于aiohttp可以支持很高的并发量，可能高达上百万，面对如此高的并发量，目标网站可能会处理不过来而有挂掉的危险，这就警示我们需要控制一下爬取的并发量\n一般情况下，可以借助asyncio的Semaphore来控制并发量，实例代码如下:\n代码见: https://github.com/Python3WebSpider/AsyncTest\naiohttp异步爬取实战案例介绍点击跳转到目标网站，这是个图书网站，我们要使用aiohttp把该网站上的所有数据爬取下来，将数据用异步的方式保存到MongoDB中\n准备工作\n安装好了Python(最好为3.7或者以上)\n了解了Ajax爬取的一些基本原理和模拟方法\n了解了异步爬虫的基本原理和asyncio基本库的使用\n了解了aiohttp基本库的使用\n安装并成功运行了MongoDB数据库，而且安装了异步爬虫库motor\n\n要实现MongoDB异步存储，离不开异步实现的MongoDB存储库motor，其安装命令如下:\npip install motor\n\n由于这里有新的库motor，这里我就跟着书上的内容走一遍:\n页面分析\n列表页的Ajax请求接口格式为https://spa5.scrape.center/api/book/?limit=18&amp;offset=&#123;offset&#125;，其中limit的值为每一页包含多少本书，offset的值为每一页的偏移量，计算公式为limit * (page - 1)\n\n我们随便点开一本图书，然后对比刚刚列表页请求接口返回的数据，我们会发现每本书的id字段就是图书本身的id:\n\n\n这样我们就可以用来进一步请求详情页\n\n\n实现思路\n第一阶段是异步爬取所有列表页，将所有列表页的爬取任务集合在一起，并将其声明为由task组成的列表，进行异步爬取\n第二阶段则是拿到上一步列表页的所有内容并解析，将所有图书的id信息组合为所有详情页的爬取任务列表，并将其声明为task组成的列表，进行异步爬取，同时爬取结果也以异步方式存储到MongoDB中\n\n基本配置首先我们先配置一些基本的变量并引入一些必须的库，代码如下:\nimport asyncioimport aiohttpimport logginglogging.basicConfig(level=logging.INFO,                    format=&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;)INDEX_URL = &#x27;https://spa5.scrape.center/api/book/?limit=18&amp;offset=&#123;offset&#125;&#x27;DETAIL_URL = &#x27;https://spa5.scrape.center/api/book/&#123;id&#125;&#x27;PAGE_SIZE = 18PAGE_NUMBER = 100CONCURRENCY = 5\n\n这里我们导入了基本的库，然后定义了loggin的基本配置，接着定义了爬取的页数，并发量，每一页的书本数，列表页的URL以及详情页的URL\n直接看代码叭&quot;&quot;&quot;@Description : @File        : get_all_books@Project     : test@Time        : 2022/2/11 9:28@Author      : LiHouJian@Software    : PyCharm@issue       : @change      : @reason      : &quot;&quot;&quot;import asyncioimport aiohttpimport logginglogging.basicConfig(level=logging.INFO,                    format=&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;)  # loggin的基本配置INDEX_URL = &#x27;https://spa5.scrape.center/api/book/?limit=18&amp;offset=&#123;offset&#125;&#x27;  # 列表页的baseURLDETAIL_URL = &#x27;https://spa5.scrape.center/api/book/&#123;id&#125;&#x27;  # 详情页的baseURLPAGE_SIZE = 18PAGE_NUMBER = 100CONCURRENCY = 5  # 并发量session = NoneMONGO_CONNECTION_STRING = &#x27;mongodb://localhost:27017&#x27;MONGO_DB_NAME = &#x27;books&#x27;MONGO_COLLECTION_NAME = &#x27;books&#x27;from motor.motor_asyncio import AsyncIOMotorClient  # 异步的插入数据库，需提前安装motor包client = AsyncIOMotorClient(MONGO_CONNECTION_STRING)db = client[MONGO_DB_NAME]collection = db[MONGO_COLLECTION_NAME]semaphore = asyncio.Semaphore(CONCURRENCY)  # 声明信号量，用来控制最大并发数量async def scrape_api(url):    async with semaphore:  # 引入信号量作为上下文        try:            logging.info(&#x27;scraping %s&#x27;, url)            async with session.get(url) as response:                return await response.json()  # 返回json格式的结果        except aiohttp.ClientError:  # 捕获错误，类型为aiohttp.ClientError            logging.error(&#x27;error occurred while scraping %s&#x27;, url, exc_info=True)async def scrape_index(page):  # 爬取列表页    url = INDEX_URL.format(offset=PAGE_SIZE * (page - 1))  # 构造列表页URL    return await scrape_api(url)async def scrape_detail(id):  # 爬取详情页并保存数据    url = DETAIL_URL.format(id=id)  # 构造真实详情页    data = await scrape_api(url)    await save_data(data)  # 保存数据async def save_data(data):    logging.info(&#x27;saving data %s&#x27;, data)    if data:        return await collection.update_one(&#123;  # 这里使用update_one方法，其第二个参数都要使用类似&#x27;$set&#x27;: data的格式            &#x27;id&#x27;: data.get(&#x27;id&#x27;)        &#125;, &#123;            &#x27;$set&#x27;: data        &#125;, upsert=True)async def main():    # index tasks    global session  # 声明session为全局变量，这样的话就不用在各个方法中都传递session了    session = aiohttp.ClientSession()    scrape_index_tasks = [asyncio.ensure_future(scrape_index(page)) for page in range(1, PAGE_NUMBER + 1)]    results = await asyncio.gather(*scrape_index_tasks)  # 执行asyncio.gather(*tasks)即可爬取列表页    # detail tasks    print(&#x27;results&#x27;, results)    ids = []    for index_data in results:        if not index_data: continue        for item in index_data.get(&#x27;results&#x27;):            ids.append(item.get(&#x27;id&#x27;))    scrape_detail_tasks = [asyncio.ensure_future(scrape_detail(id)) for id in ids]  # 所有爬取详情页的task组成的列表    await asyncio.wait(scrape_detail_tasks)  # 执行asynico.wait(tasks)即可爬取详情页，这里使用asyncio.gather()效果是一样的，只不过返回的结果略有差异    await session.close()  # 调用session.close()关闭sessionif __name__ == &#x27;__main__&#x27;:    loop = asyncio.get_event_loop()  # 使用事件循环启动main()对应的协程，main()是最外层的协程，需要放在事件循环中去执行    loop.run_until_complete(main())\n\n\n\n\n\n\n\n"},{"title":"Python3网络爬虫开发实战第二版第2章-基本库的使用","url":"/2022/02/07/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC2%E7%AB%A0-%E5%9F%BA%E6%9C%AC%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"Python提供了功能齐全的类库来帮助我们实现需求，最基础的有HTTP库有urllib、requests、httpx等\nurllib的使用注意: 在Python2中，有urllib和urllib2两个库来实现HTTP请求的发送，而在Python3中，urllib2库已经不存在了，统一为了urllib\nurllib是Python内置的HTTP请求库，也就是说不需要额外安装，可直接使用；urllib库包括如下4个模块:\n\nrequest: 这是最基本的HTTP请求模块，可以模拟请求的发送，就像在浏览器中输入网址然后按下了回车一样，只需要给库方法传入URL以及额外的参数，就可以模拟实现发送请求的过程了\nerror: 异常处理模块，如果出现请求异常，那么我们可以捕获这些异常，然后进行重试或其他操作以保证程序运行不会意外终止\nparse: 一个工具模块，提供了许多URL的处理方法，例如拆分、解析、合并等\nrobotparser: 主要用来识别网站的robots.txt文件，然后判断哪些网站可以爬，哪些网站不可以爬，它其实用的比较少\n\n发送请求urlopenurllib.request模块提供了最基本的构造HTTP请求的方法，利用这个模块可以模拟浏览器的请求发起过程，同时它还具有处理授权验证，重定向，浏览器Cookie以及其他一些功能\n下面以Python官网为例体验下这个模块:\nimport urllib.requestresponse = urllib.request.urlopen(&#x27;https://www.python.org&#x27;)print(response.read().decode(&#x27;utf-8&#x27;))\n\n运行结果如下图所示:\n我们来看看返回的是个什么类型:\nimport urllib.requestresponse = urllib.request.urlopen(&#x27;https://www.python.org&#x27;)print(type(response))\n\n输出结果如下:\n&lt;class &#x27;http.client.HTTPResponse&#x27;&gt;\n\n这是一个HTTPResponse类型的对象，主要包含read、readinto、getheader、getheaders、fileno等方法，以及msg、version、status、reason、debuglevel、closed等属性\n我们来看看实例:\nimport urllib.requestresponse = urllib.request.urlopen(&#x27;https://www.python.org&#x27;)print(response.status)print(response.getheaders())print(response.getheader(&#x27;Server&#x27;))\n\n运行结果如下:\n200[(&#x27;Connection&#x27;, &#x27;close&#x27;), (&#x27;Content-Length&#x27;, &#x27;49476&#x27;), (&#x27;Server&#x27;, &#x27;nginx&#x27;), (&#x27;Content-Type&#x27;, &#x27;text/html; charset=utf-8&#x27;), (&#x27;X-Frame-Options&#x27;, &#x27;DENY&#x27;), (&#x27;Via&#x27;, &#x27;1.1 vegur, 1.1 varnish, 1.1 varnish&#x27;), (&#x27;Accept-Ranges&#x27;, &#x27;bytes&#x27;), (&#x27;Date&#x27;, &#x27;Sun, 06 Feb 2022 14:10:46 GMT&#x27;), (&#x27;Age&#x27;, &#x27;283&#x27;), (&#x27;X-Served-By&#x27;, &#x27;cache-iad-kcgs7200085-IAD, cache-nrt18330-NRT&#x27;), (&#x27;X-Cache&#x27;, &#x27;HIT, HIT&#x27;), (&#x27;X-Cache-Hits&#x27;, &#x27;3, 353&#x27;), (&#x27;X-Timer&#x27;, &#x27;S1644156646.362936,VS0,VE0&#x27;), (&#x27;Vary&#x27;, &#x27;Cookie&#x27;), (&#x27;Strict-Transport-Security&#x27;, &#x27;max-age=63072000; includeSubDomains&#x27;)]nginx\n\n下面是urlopen方法的API:\nurllib.request.urlopen(url, data=None, [timeout,]*, cafile=None, capath=None, cadefault=False, context=None)\n\n接下来详细说明下urlopen方法中几个参数的用法:\n\ndata参数\ndata参数为可选，使用该参数需要使用bytes方法将参数转化为字节流编码格式的内容即bytes类型，如果传递了这个参数，那么它的请求方式就不再是GET了，而是POST了\n以下是实例:\nimport urllib.parseimport urllib.requestdata = bytes(urllib.parse.urlencode(&#123;&#x27;name&#x27;: &#x27;germey&#x27;&#125;), encoding=&#x27;utf-8&#x27;)response = urllib.request.urlopen(&#x27;https://www.httpbin.org/post&#x27;, data=data)print(response.read().decode(&#x27;utf-8&#x27;))\n\n上面代码中转码时使用了bytes方法，该方法的第一个参数得是str类型，因此用urllib.parse模块里的urlencode方法将字典参数转化为字符串，第二个参数指定编码格式\n此处我们请求的站点是www.httpbin.org，它可以提供HTTP请求测试，上面实例的运行结果如下:\n&#123;  &quot;args&quot;: &#123;&#125;,   &quot;data&quot;: &quot;&quot;,   &quot;files&quot;: &#123;&#125;,   &quot;form&quot;: &#123;    &quot;name&quot;: &quot;germey&quot;  &#125;,   &quot;headers&quot;: &#123;    &quot;Accept-Encoding&quot;: &quot;identity&quot;,     &quot;Content-Length&quot;: &quot;11&quot;,     &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;,     &quot;Host&quot;: &quot;www.httpbin.org&quot;,     &quot;User-Agent&quot;: &quot;Python-urllib/3.7&quot;,     &quot;X-Amzn-Trace-Id&quot;: &quot;Root=1-61ffda7a-05a2c9b60ba676290898d9d9&quot;  &#125;,   &quot;json&quot;: null,   &quot;origin&quot;: &quot;182.101.213.95&quot;,   &quot;url&quot;: &quot;https://www.httpbin.org/post&quot;&#125;\ntimeout参数\n直接上实例:\nimport urllib.requestresponse = urllib.request.urlopen(&#x27;https://www.httpbin.org/get&#x27;, timeout=0.1)print(response.read())\n\n运行结果如下:\n  File &quot;C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py&quot;, line 1360, in https_open    context=self._context, check_hostname=self._check_hostname)  File &quot;C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py&quot;, line 1319, in do_open    raise URLError(err)urllib.error.URLError: &lt;urlopen error timed out&gt;\n\n利用try except语句也可实现:\nimport socketimport urllib.requestimport urllib.errortry:    response = urllib.request.urlopen(&#x27;https://www.httpbin.org/get&#x27;, timeout=0.1)except urllib.error.URLError as e:    if isinstance(e.reason, socket.timeout):        print(&#x27;time out&#x27;)\n\n运行结果如下:\ntime out\n其他参数\n除了以上两个参数，urlopen还有context参数，该参数必须是ssl.SSLContext类型，用来指定SSL的设置，此外，cafile和capath这连个参数分别用来指定CA证书和其路径，这两个在请求HTTPS链接时会有用，cadefault参数现在已经弃用了，其默认值为Flase，到这里我们就讲完了urlopen方法的用法\n\n\nRequesturlopen可以发起最基本的请求，但它那几个简单的参数并不足以构建一个完整的请求，如果需要往请求中加入Headers等信息，就需要使用更强大的Request来构建请求了\n来看看最基本的实例:\nimport urllib.requestrequest = urllib.request.Request(&#x27;http://www.baidu.com&#x27;)response = urllib.request.urlopen(request)print(response.read().decode(&#x27;utf-8&#x27;))\n\n我们来看下可以通过怎样的参数来构造Request类，构造方法如下:\nurllib.request.Request(url, data=None, headers=&#123;&#125;, origin_req_host=None, unverifiable=False, method=None)\n\n\nurl为请求的URL，这是必传参数，其他都是可选参数\ndata如果要传数据，必须传bytes类型的，如果数据是字典，可以先用urllib.parse模块里的urlencode方法进行编码\n第三个参数是一个字典，这是请求头，可以用headers参数直接构造，也可以调用请求实例的add_heade方法添加\norigin_req_host指的是请求方的host名称或者IP地址\nunverifiable表示请求是否是无法验证的，默认取值是False，意思是用户没有足够的权限来接收这个请求的结果\nmethod是一个字符串，指示请求使用的方法\n\n由于urllib使用不是太频繁，详情见书本\nrequests的使用我们感觉使用urllib不太方便，接下来我们来看看requests库的强大之处叭\n首先我们需要安装requests:\npip3 install r\n\n"},{"title":"Python3网络爬虫开发实战第二版第1章-爬虫基础","url":"/2022/01/28/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC1%E7%AB%A0-%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/","content":"本章我们将了解到HTTP原理、网页的基础知识、爬虫的基本原理、Cookie的基本原理、多进程和多线程的基本原理等，了解这些内容有助于我们更好地理解和编写网络爬虫相关的程序\nHTTP基本原理URI和URLURL: Uniform Resource Location(统一资源定位符)\nURI: Uniform Resource Identifier(统一资源标识符)\nURL是大家所熟知的，它指向网络服务器上的某个资源，而其实URI有两个子类，一个是上面提到的URL，还有一个叫做URN(Uniform Resource Name)，URN只为资源命名而不指定如何定位资源，也就是说URI包括了URL和URN；\nURL的基本组成格式scheme://[username:password@]hostname[:port][path][;parameters][?query][#fragment]\n\nscheme: 协议，常用的协议有http、https、ftp等，另外，scheme也常被称作protocol，二者都代表协议的意思\nusername、password: 用户名和密码，在某些情况下URL需要提供用户名和密码才能访问\nhostname: 主机地址，或IP地址\nport: 端口，这是服务器设定的服务端口，但是有些URL中没有端口信息，这是使用了默认的端口，http协议的默认端口是80，https协议的默认端口是443\npath: 路径，指的是网络资源在服务器中的指定位置\nparameters: 参数，用来指定访问某个资源时的附加信息，这个用的比较少\nquery: 查询，用来查询某类资源，如果有多个查询，则用&amp;隔开\nfragment: 片段，它是对资源描述的部分补充，可以理解为资源内部的书签\nHTTP和HTTPS在爬虫中，我们主要接触到的协议通常是基于http或https协议的，因此这里首先了解下这两个协议:\nHTTP的全称是Hypertext Transfer Protocol，中文名为超文本传输协议，其作用是把超文本数据从网络传输到本地浏览器，能够保证高效而准确地传输超文本文档，目前被人们广泛使用的是HTTP1.1版本，当然，现在也有不少网站支持HTTP2.0\nHTTPS的全称是Hyper Text Transfer Protocol over SecureSocket Layer，是以安全为目标的HTTP通道，简单讲就是HTTP的安全版，即在HTTP下加入SSL层，简称HTTPS\nHTTPS的安全基础是SSL，因此通过该协议传输的内容都是经过SSL加密的，SSL的主要作用有以下两种:\n\n建立一个信息安全通道，保证数据传输的安全性\n确认网站的真实性，凡是使用了HTTPS协议的网站，都可以通过单击浏览器地址栏的锁头编制来查看网站认证之后的真实信息，此外还可以通过CA机构颁发的安全签章来查询\n\nHTTP和HTTPS协议都属于计算机网络中的应用层协议，其下层是基于TCP协议实现的，TCP协议属于计算机网络中的传输层协议，包括建立连接时的三次握手和断开时的四次挥手等过程\nHTTP请求过程在浏览器地址栏输入一个URL，按下回车之后便可观察到对应的页面内容，实际上，这个过程是浏览器先向网站所在的服务器发送一个请求，网站服务器接收到请求后对其处理和解析，然后返回对应的响应，接着传回浏览器；由于响应里包含页面的源代码等响应内容，所以浏览器再对其进行解析，便将网页呈现出来\n关于浏览器开发者工具的使用点此跳转\n请求请求，英文为Request，由客户端发往服务器，分为四部分内容: 请求方法(Request Method)、请求的网址(Request URL)，请求头(Request head)、请求体(Request body)\n请求方法请求方法，用于标识客户端请求服务端的方式，常见的请求方法，有两种: GET和POST，在浏览器中直接输入URL并回车，便发起了一个GET请求，请求参数会直接包含到URL里；POST请求大多会在提交表单时发起，例如，对于一个登录表单，输入用户名和密码后，单击登录按钮，这时通常会发起一个POST请求，其数据通常会以表单的形式传输，而不会体现在URL中\nGET和POST的区别\nGET请求中的参数包含在URL里面，数据可以在URL中看到；而POST请求的URL不会包含这些数据，数据都是通过表单形式传输，会包含在请求体中\nGET请求提交的数据最多只有1024字节，POST方式则没有限制\n\n响应响应，即Response，由服务器返回给客户端，可以分为三部分: 响应状态码(HTTP Status Code)，响应头(Response head)，响应体(Response body)\n响应状态码详情点击这里\nWeb网页基础网页的组成网页可以分为三大部分: HTML、CSS和JS\n\nHTML: HTML的全称为超文本标记语言，是一种标记语言。它包括一系列标签．通过这些标签可以将网络上的文档格式统一，使分散的Internet资源连接为一个逻辑整体。HTML文本是由HTML命令组成的描述性文本，HTML命令可以说明文字，图形、动画、声音、表格、链接等\nCSS: 层叠样式表(英文全称：Cascading Style Sheets)是一种用来表现HTML（标准通用标记语言的一个应用）或XML（标准通用标记语言的一个子集）等文件样式的计算机语言。CSS不仅可以静态地修饰网页，还可以配合各种脚本语言动态地对网页各元素进行格式化\nJavaScript: （简称“JS”） 是一种具有函数优先的轻量级，解释型或即时编译型的编程语言。虽然它是作为开发Web页面的脚本语言而出名，但是它也被用到了很多非浏览器环境中，JavaScript 基于原型编程、多范式的动态脚本语言，并且支持面向对象、命令式、声明式、函数式编程范式\n\n网页的结构看示例代码:\n&lt;!DOCTYPE html&gt;        &lt;!-- 声明文档。定义html --&gt;&lt;html lang=&quot;en&quot;&gt;         &lt;!-- 元素是页面的根元素 --&gt;&lt;head&gt;                     &lt;!-- 元素包含文档的元数据 --&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;   &lt;!-- 定义网页编码格式 --&gt;    &lt;title&gt;第一个项目&lt;/title&gt;  &lt;!-- 元素描述了文档的标题--&gt;&lt;/head&gt;&lt;body&gt;&lt;!--元素包含了页面可以看见的内容。定义文档主体。--&gt;    &lt;p&gt;这个p是段落。可以把很多文字放到里面去。比如这是一段文字。&lt;/p&gt;    &lt;p&gt;这是另一个段落。&lt;/p&gt;    &lt;h1&gt;这是h1标题&lt;/h1&gt;&lt;!-- 通过&lt;h1&gt;-&lt;h6&gt;标签来定义 --&gt;    &lt;h2&gt;这是h2标题&lt;/h2&gt;    &lt;h3&gt;这是h3标题&lt;/h3&gt;    &lt;h4&gt;这是h4标题&lt;/h4&gt;    &lt;h5&gt;这是h5标题&lt;/h5&gt;    &lt;h6&gt;这是h6标题&lt;/h6&gt;    &lt;hr&gt;&lt;!--定义水平线--&gt;    &lt;p&gt;这是一个段落。插入图片&lt;/p&gt;    &lt;a href=&quot;www.baidu.com&quot;&gt;这是跳转到的百度链接&lt;/a&gt;  &lt;!--&lt;a&gt;标签来定义。在 href 属性中指定链接的地址。--&gt;    &lt;br&gt;&lt;!--换行--&gt;    &lt;img src=&quot;images/one.jpg&quot; alt=&quot;&quot; width=&quot;500&quot; height=&quot;500&quot;&gt;   &lt;!--图像是通过标签 &lt;img&gt; 来定义的。 --&gt;    &lt;img src=&quot;images/two.jpg&quot; alt=&quot;&quot; width=&quot;500&quot; height=&quot;500&quot;&gt;    &lt;hr&gt;&lt;!--文本格式化的标签--&gt;    &lt;b&gt;这是一句话。定义粗体&lt;/b&gt;    &lt;em&gt;这是一句话。定义着重文字&lt;/em&gt;    &lt;i&gt;这是一句话。定义斜体&lt;/i&gt;    &lt;small&gt;这是一句话。定义小字号&lt;/small&gt;    &lt;strong&gt;这是一句话。定义加重语气&lt;/strong&gt;    &lt;p&gt;插入&lt;sub&gt;这是一句话&lt;/sub&gt;定义下标字&lt;/p&gt;    &lt;p&gt;插入&lt;sup&gt;这是一句话&lt;/sup&gt;定义上标字&lt;/p&gt;    &lt;ins&gt;这是一句话。定义插入字&lt;/ins&gt;    &lt;del&gt;这是一句话。定义删除字&lt;/del&gt;&lt;!-- 计算机输出标签 --&gt;    &lt;hr&gt;    &lt;p&gt;这是计算机输出标签&lt;/p&gt;    &lt;code &gt;#定义计算机代码print(&quot;hello world!&quot;)    &lt;/code&gt;    &lt;br&gt;    &lt;kbd&gt;定义键盘码&lt;/kbd&gt;    &lt;br&gt;    &lt;samp&gt;定义计算机代码样本&lt;/samp&gt;    &lt;br&gt;    &lt;var&gt;定义变量&lt;/var&gt;    &lt;pre&gt;定义预格式文本&lt;/pre&gt;    &lt;p&gt;&lt;b&gt;注释：&lt;/b&gt;这些标签常用于显示计算机/编程代码。&lt;/p&gt;&lt;!-- HTML 引文 引用 标签定义 --&gt;    &lt;hr&gt;    &lt;abbr title=&quot;&quot;&gt;定义缩写&lt;/abbr&gt;    &lt;address&gt;定义地址&lt;/address&gt;    &lt;p&gt;&lt;bdo dir=&quot;rtl&quot;&gt;该段落文字从右到左显示。&lt;/bdo&gt;&lt;/p&gt;    &lt;blockquote&gt;定义长的引用&lt;/blockquote&gt;    &lt;q&gt;定义短的引用&lt;/q&gt;    &lt;br&gt;    &lt;cite&gt;定义引用、引证&lt;/cite&gt;    &lt;br&gt;    &lt;dfn&gt;定义一个定义项目&lt;/dfn&gt;&lt;/body&gt;&lt;/html&gt;\n\n节点树及节点间的关系在HTML中，所有标签定义的内容都是节点，这些节点构成一个HTML节点树，也叫HTML DOM树；先来看下什么是DOM，DOM是W3C(万维网联盟)的标准，英文全称是Document Object Model，即文档对象模型，它定义了访问HTML和XML文档的标准，根据W3C的HTML DOM标准，HTML文档中的所有内容都是节点\n\n整个网站文档是一个文档节点\n每个html标签对应一个根节点，即上例中的html标签，它属于一个根节点\n节点内的文本是文本节点，比如a节点代表一个超链接，它内部的文本也被认为是一个文本节点\n每个节点的属性是属性节点，比如a节点有一个href属性，它就是一个属性节点\n注释是注释节点，在HTML中有特殊的语法会被解析为注释，它也会对应一个节点\n\n选择器CSS选择器详情请见: https://www.w3school.com.cn/cssref/css_selectors.asp\nXpath详情请见: https://www.w3school.com.cn/xpath/index.asp\n爬虫的基本原理爬虫概述简单点讲，爬虫就是获取网页并提取和保存信息的自动化程序\n获取网页爬虫的工作首先是获取网页的源代码，源代码里包含网页的部分有用信息，所以只要获取源代码，就可以从中提取想要的信息了，Python提供了许多库，可以帮助我们获取源代码，比如urllib，requests等，我们可以用这些库完成HTTP请求操作，除此之外，请求和响应都可以用类库提供的数据结构来表示，因此得到相应之后只需要解析数据结构中的body部分，即可得到网页的源代码\n提取信息提取网页的源代码之后，接下来的就是分析源代码，从中提取我们想要的数据，首先，最通用的提取方式是采用正则表达式，这是一个万能的方法，但是构造正则表达式的过程比较复杂且容易出错；另外，由于网页结构具有一定的规则，所以还有一些库是根据网页节点属性、CSS选择器或Xpath来提取网页信息的，如BeautifulSoup、pyquery，lxml等，使用这些库，可以高效地从源代码中提取网页信息，如节点地属性，文本值等\n保存数据提取数据之后，我们一般会将提取到的数据保存到某处以便后续使用，保存数据的形式多种多样，可以简单保存为TXT文本或者JSON文本，也可以保存到数据库，如MySQL和MongoDB等，还可保存到远程服务器如借助SFTP进行操作等\n自动化程序自动化程序的意思是爬虫可以代替人来完成上述操作，我们当然可以手动提取网页中的信息，但是当量特别大或者想快速大量获取数据的时候，肯定还是借助程序快，爬虫就是代替我们完成爬取工作的自动化程序，它可以在爬取过程中进行各种异常处理、错误重试等操作，确保爬取持续高效地运行\n能爬怎样的数据网页中存在各种各样的信息，最常见的便是常规网页，这些网页对应着HTML代码，而最常抓取的便是HTML源代码\n另外，可能有些网页返回的不是HTML代码，而是一个JSON字符串(其中API接口大多采用这种方式)，这种格式的数据方便传输和解析，爬虫同样可以抓取这些数据，而且数据提取会更加方便；\n网页中还包含着各种二进制数据，如图片、视频音频文件，利用爬虫，我们可以将这些二进制数据抓取下来，然后保存成对应的文件名\n除了上述数据，网页中还有各种扩展名文件，如CSS、Javascript和配置文件等\nJavascript渲染的页面对于Javascript渲染的网页，我们可以分析源代码后台Ajax接口，也可使用Selenium、Splash、Pyppeteer、Playwright这样的库来模拟Javascript渲染\nSession和Cookie神秘的凭证很多页面是需要登录之后才可以查看的，按照一般的逻辑，输入用户名和密码登陆网站，肯定是拿到了一种类似凭证的东西，有了这个凭证，才能保持登录的状态，访问那些登录之后才能看到的页面\n那么这种神秘的凭证到底是什么呢，其实它就是Session和Cookie共同产生的结果\n无状态HTTP我们需要知道HTTP的一个特点: 无状态\n什么叫无状态呢，也就是说HTTP协议对事物处理是没有记忆能力的，或者说服务并不知道客户端处于什么状态，这时，两种用于保持HTTP连接状态的技术出现了，分别是Session和Cookie；Session在服务端，也就是网站的服务器，用来保存用户的Session信息，Cookie在客户端，也可以理解为在浏览器端，有了Cookie，浏览器在下次访问相同网页时就会自动附带上它，并发送给服务器，服务器通过识别Cookie鉴定出是哪个用户在访问，然后判断此用户是否处于登录状态，并返回对应的响应\nSessionSession译为会话，其本意是指有始有终的一系列动作、消息，例如打电话时，从拿起电话拨号到挂断电话之间的一系列过程就可以称为一个Session\n而在Web中，Session对象用来存储特定用户Session所需的属性及配置信息，这样，当用户在应用程序的页面之间跳转时，存储在Session对象中的变量将不会丢失，会在整个Session中一直保存下去；当用户请求来自应用程序的页面时，如果该用户还没有Session，那么Web服务器将自动创建一个Session对象，当Session过期或被放弃后，服务器将终止该Session\nCookie值某些网站为了鉴别用户身份、进行Session跟踪而存储在用户本地终端上的数据\nSession维持如何利用Cookie保持状态呢，在客户端第一次请求服务器时，服务器会返回一个响应头中带有Set-Cookie字段的响应给客户端，这个字段用来标记用户；客户端浏览器会把Cookie保存起来，当下一次请求相同的网站时，把保存的Cookie放到请求头中一起交给服务器；Cookie中携带着Session ID相关信息，服务器通过检查Cookie即可找到对应的Session，继而通过判断Session辨认用户状态；如果Session当前是有效的，就证明用户处于登录状态，此时服务器返回登录之后才可以查看的网页内容，浏览器再进行解析即可\n反之，如果传给服务器的Cookie是无效的，或者Session已经过期了，客户端将不能继续访问页面\nCookie和Session需要配合，一个在客户端，一个在服务端，二者共同协作，就实现了登录控制\n属性结构接下来，我们看看Cookie都包含哪些内容:\nName: Cookie的名称，Cookie一旦创建，名称便不可更改\nValue: Cookie的值，如果值为Unicode字符，则需要为字符编码；如果值为二进制数据，则需要使用base64编码\nDomain: 指定可以访问该Cookie的域名，例如设置Domain为.zhihu.com，表示所有以.zhihu.com结尾的域名都可以访问该Cookie\nPath: Cookie的使用路径，如果设置为/path/，则只有该路径为/path/的页面才可以访问该Cookie，如果设置为/，则本域名下的所有页面都可以访问该Cookie\nMax-Age: Cookie失效的时间，单位为秒，常和Expires一起使用，通过此属性可以计算出Cookie的有效时间，Max-Age如果为正数，则表示Cookie在Max-Age秒之后失效，如果为负数，则Cookie在关闭浏览器时失效，而且浏览器不会以任何形式保存该Cookie\nSize: Cookie的大小\nHTTP: Cookie的httponly属性，若此属性为true，则只有在HTTP Headers中才会带有此Cookie的信息，而不能通过document.cookie来访为此Cookie\nSecure: 是否允许使用安全协议传输Cookie，安全协议有HTTPS和SSL等，使用这些协议在网络上传输数据之前会先将数据加密，其默认值为false\n会话Cookie和持久Cookie会话Cookie就是把Cookie放在浏览器内存里，关闭浏览器之后，Cookie即失效，持久Cookie则会把Cookie保存在客户端的硬盘中，下次还可以继续使用，用于长久保持用户的登录状态\n其实没有会话Cookie和持久Cookie之说，只是Maxage或者Expires字段决定了Cookie失效的时间\n因此，一些持久化登录的网站实际上就是把Cookie的有效时间和Session有效期设置得比较长\n常见误区关闭浏览器不会删除Session，关闭浏览器可能会删除会话Cookie，所以就找不到Session ID，如果是持久Cooike就能找到Session ID\n代理的基本原理基本原理代理实际上就是指代理服务器，形象点说代理就是网络信息的中转站\n代理的作用\n突破自身IP的限制，访问一些平时不能访问的站点\n访问一些单位或团体的内部资源\n提高访问速度，通常代理服务器会设置一个较大的硬盘缓冲区，当有外界信息通过时，会同时将其保存到自己的缓冲区中，当其他用户访问相同的信息时，直接从缓冲区中取出信息，所以提高了访问速度\n隐藏真实的IP\n\n爬虫代理爬虫中使用代理，可以隐藏我们真实的IP，让服务器误以为是代理服务器在请求自己，这样在爬取过程中不断更换代理，就可以实现避免IP被封锁，达到很好的爬取效果\n代理分类根据协议区分\nFTP代理服务器: 主要用于访问FTP服务器，一般有上传下载以及缓存功能，端口一般我为21、2121等\nHTTP代理服务器: 主要用于访问网页，一般有内容过滤和缓存功能，端口一般为80，8080\nSSL/TLS代理: 主要用于访问加密网站，一般有SSL或TLS加密功能(最高支持128位加密强度)，端口一般为443\nRTSP代理: 主要用于Realplyer访问流媒体服务器，一般有缓存功能，端口一般为554\nTelnet代理: 主要用于Telnet远程控制(黑客入侵计算机时常用于隐藏身份)，端口一般为23\nPOP3/SMTP代理: 主要用于以POP3/SMTP方式收发邮件，一般有缓存功能，端口一般为110/25\nSOCKS代理: 只是单纯传递数据包，不关心具体协议和用法，所以速度快很多，一般有缓存功能，端口一般为1080\n\n根据匿名程度区分\n高度匿名代理: 数据包会原封不动地转发\n普通匿名代理: 数据包会做一些处理\n透明代理: 会告诉服务器客户端真实的IP\n间谍代理: 由组织或个人创建的代理服务器\n\n常见代理设置\n对于网上的免费代理，最好使用高度代理，可以在使用前把所有代理都抓取下来筛选一遍拿到可用代理，也可以进一步维护一个代理池\n使用付费代理服务，使用付费的代理会好用很多\nADSL拨号，拨一次号换一次IP，稳定性高，也是一种比较有效的方法\n蜂窝代理，使用4G或5G网卡等制作的代理，由于使用蜂窝网络作为代理的情形比较少，因此整体被封锁的概率会比较低，但搭建蜂窝代理的成本是比较高的\n\n多线程和多进程的基本原理多线程的含义先说说什么是进程:\n进程可以理解为一个可以独立运行的程序单位，例如打开一个浏览器，这就是开启了一个浏览器进程；在一个进程中可以同时处理很多事情，比如浏览器可以打开很多个选项卡，这一个个选项卡其实就是一个个线程，进程就是线程的集合，进程是由一个或多个线程构成的，线程是操作系统进行运算调度的最小单位，是进程中的最小运行单位\n有了上面的铺垫，我们可以了解到，多线程就是一个进程中同时执行多个线程，上面的浏览器进程就是典型的多线程\n并发和并行我们知道，在计算机中运行一个程序，底层是通过处理器运行一条条指令来实现的\n并发是指多个线程对应的多条指令被快速轮换地执行\n并行是指同一时刻有多条指令在多个处理器上同时执行\n例如，系统处理器需要同时运行多个线程，如果系统处理器只有一个核，那它只能通过并发地方式来运行这些线程，然而如果系统处理器有多个核，那么在一个核执行一个线程地同时，另一个核可以执行另一个线程，这样两个线程就实现了并行执行\n多线程适用场景如果任务不全是计算密集型任务，就可以使用多线程来提高程序的整体执行效率，尤其对于网络爬虫这种IO密集型任务，使用多线程能够大大提高程序整体的爬取效率\n多进程的含义顾名思义，多进程就是同时运行多个进程，由于进程就是线程的集合，而且进程是由一个或多个线程构成的，所以多进程就意味着有大于等于进程数量的线程在同时运行\nPython中的多线程和多进程Python中GIL(全局解释器锁，其设计之初是出于对数据安全的考虑)的限制导致不论是在单核还是多核条件下，同一时刻都只能运行一个线程，这使得Python多线程无法发挥多核并行的优势\n在Python的多线程下，每个线程的执行方式分如下三步:\n\n获取GIL\n执行对应线程的代码\n释放GIL\n\n而对于多进程来说，每个进程都有属于自己的GIL，所以在多核处理器下，多进程的运行是不会受GIL影响的，也就是说，多进程能够更好地发挥多核优势\n不过，对于爬虫这种IO密集型任务来说，多线程和多进程产生的影响差别并不大；但对于计算密集型任务来说，由于GIL的存在，Python多线程的整体运行效率在多核情况下可能反而比单核更低，而Python的多进程相比多线程，运行效率在多核的情况下比单核会有成倍提升\n从整体来说，Python的多进程比多线程更有优势，所以，如果条件允许的话，尽量使用多进程\n"},{"title":"Python3网络爬虫开发实战第二版第9章-代理的使用","url":"/2022/02/15/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC9%E7%AB%A0-%E4%BB%A3%E7%90%86%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"在使用爬虫的过程中经常会遇到这样的情况，爬虫最初还可以正常运行，正常爬取数据，一切看起来都是那么美好，然而一杯茶的功夫，就可能出现了错误，比如返回403或者啥的，出现这些现象的原因是网站采取了一些反爬措施，例如服务器会检测某个IP在单位时间内的请求次数，如果这个次数超过了指定的阈值，就直接拒绝服务，并返回一些错误信息，这种情况就称为封IP，既然服务器检测的是单位时间内某个IP在单位时间的请求次数，那么借助某种方式把IP伪装起来，让服务器识别不出是由我们本机发起的请求不就可以了\n代理的设置准备工作代理的基本原理可移步第一章，这样有助于更好地理解和学习以下内容；另外，需要先获取一个可用代理，代理就是IP地址和端口的组合，格式是&lt;ip&gt;:&lt;port&gt;；如果代理需要访问认证，则还需要额外的用户名和密码两个信息\n那么如何获取一个可用代理呢，使用搜索引擎搜索代理两字，会返回许多代理服务网站，网站上提供了很多免费或付费代理，例如快代理的免费HTTP代理: https:www.kuaidaili.com/free/就提供了很多免费代理，但在大多数情况下这些免费代理并一定稳定，所以比较靠谱的还是购买付费代理\n除了购买付费代理，也可以在本机配置一些代理软件，具体的配制方法可以参考https://setup.scrape.center/proxy-client\n以下示例都是基于本机代理软件\nurllib的代理设置from urllib.error import URLErrorfrom urllib.request import ProxyHandler, build_openerproxy = &#x27;127.0.0.1:7890&#x27;proxy_handler = ProxyHandler(&#123;    &#x27;http&#x27;: &#x27;http://&#x27; + proxy,    &#x27;https&#x27;: &#x27;http://&#x27; + proxy&#125;)opener = build_opener(proxy_handler)try:    response = opener.open(&#x27;https://httpbin.org/get&#x27;)    print(response.read().decode(&#x27;utf-8&#x27;))except URLError as e:    print(e.reason)\n\n这里需要借助ProxyHandler对象设置代理，参数是字典类型的数据，键名是协议类型，键值是代理地址(注意，此处的代理地址前面需要加上协议，即http://或者https://)，当请求链接使用的是HTTP协议时，使用http键名对应的代理地址， 反之就使用https\n如果遇到需要认证的代理，可以使用如下方式设置:\nfrom urllib.error import URLErrorfrom urllib.request import ProxyHandler, build_openerproxy = &#x27;username:password@127.0.0.1:7890&#x27;proxy_handler = ProxyHandler(&#123;    &#x27;http&#x27;: &#x27;http://&#x27; + proxy,    &#x27;https&#x27;: &#x27;http://&#x27; + proxy&#125;)opener = build_opener(proxy_handler)try:    response = opener.open(&#x27;https://httpbin.org/get&#x27;)    print(response.read().decode(&#x27;utf-8&#x27;))except URLError as e:    print(e.reason)\n\n如果代理是SOCKS代理，那么可以使用如下方式设置代理，需要注意要在本机7891端口运行一个SOCKS代理\n&quot;&quot;&quot;@Description : @File        : urllib_socks@Project     : test@Time        : 2022/2/15 17:25@Author      : LiHouJian@Software    : PyCharm@issue       : @change      : @reason      : &quot;&quot;&quot;import socksimport socketfrom urllib import requestfrom urllib.error import URLErrorsocks.set_default_proxy(socks.SOCKS5, &#x27;127.0.0.1&#x27;, 7891)socket.socket = socks.socksockettry:\tresponse = request.urlopen(&#x27;https://www.httpbin.org/get&#x27;)\tprint(response.read().decode(&#x27;utf-8&#x27;))except URLError as e:\tprint(e.reason)\n\nrequests的代理设置对于requests来说，代理设置非常简单，只需要传入prosies参数即可，这里以我本机的代理为例，看一下requests的HTTP代理配置，代码如下:\nimport requestsproxy = &#x27;127.0.0.1:7890&#x27;proxies = &#123;    &#x27;http&#x27;: &#x27;http://&#x27; + proxy,    &#x27;https&#x27;: &#x27;http://&#x27; + proxy,&#125;try:    response = requests.get(&#x27;https://httpbin.org/get&#x27;, proxies=proxies)    print(response.text)except requests.exceptions.ConnectionError as e:    print(&#x27;Error&#x27;, e.args)\n\n这里同样使用httpbin这个测试站点，这个返回的是一个json格式的数据，如果运行结果中的origin字段如果是代理服务器的IP，则证明代理已经设置成功\n如果代理类型是SOCKS，可以使用如下方式设置代理:\nimport requestsproxy = &#x27;127.0.0.1:7891&#x27;proxies = &#123;    &#x27;http&#x27;: &#x27;socks5://&#x27; + proxy,    &#x27;https&#x27;: &#x27;socks5://&#x27; + proxy&#125;try:    response = requests.get(&#x27;https://httpbin.org/get&#x27;, proxies=proxies)    print(response.text)except requests.exceptions.ConnectionError as e:    print(&#x27;Error&#x27;, e.args)\n\n要运行以上代码我们要额外安装一个包requests[socks]，相关命令如下:\npip install &quot;requests[socks]&quot;\n\n另外还有一种设置SOCKS代理的方法，即使用socks模块，需要安装socks库，这种设置方式如下:\nimport requestsimport socksimport socketsocks.set_default_proxy(socks.SOCKS5, &#x27;127.0.0.1&#x27;, 7891)socket.socket = socks.socksockettry:    response = requests.get(&#x27;https://httpbin.org/get&#x27;)    print(response.text)except requests.exceptions.ConnectionError as e:    print(&#x27;Error&#x27;, e.args)\n\nhttpx代理设置httpx的用法本身就和requests的非常相似，所以也是通过proxies参数设置代理，不过也有不同，就是proxies参数的键名不能再是http或https，而需要改为http://或者https://\n设置HTTP代理的方式如下:\nimport httpxproxy = &#x27;127.0.0.1:7890&#x27;proxies = &#123;    &#x27;http://&#x27;: &#x27;http://&#x27; + proxy,    &#x27;https://&#x27;: &#x27;http://&#x27; + proxy,&#125;with httpx.Client(proxies=proxies) as client:    response = client.get(&#x27;https://httpbin.org/get&#x27;)    print(response.text)\n\n对于需要认证的代理，也是在代理地址前加上用户名和密码，在使用的时候替换username和password字段:\nproxy = &#x27;username:password@127.0.0.1:7890&#x27;\n\n对于SOCKS代理，需要安装httpx-socks[asyncio]库，安装方式如下:\npip install &#x27;httpx-socks[asyncio]&#x27;\n\n与此同时需要设置同步模式或异步模式，同步模式的设置方式如下:\nimport httpxfrom httpx_socks import SyncProxyTransporttransport = SyncProxyTransport.from_url(    &#x27;socks5://127.0.0.1:7891&#x27;)with httpx.Client(transport=transport) as client:    response = client.get(&#x27;https://httpbin.org/get&#x27;)    print(response.text)\n\n异步模式的设置方式如下:\nimport httpximport asynciofrom httpx_socks import AsyncProxyTransporttransport = AsyncProxyTransport.from_url(    &#x27;socks5://127.0.0.1:7891&#x27;)async def main():    async with httpx.AsyncClient(transport=transport) as client:        response = await client.get(&#x27;https://httpbin.org/get&#x27;)        print(response.text)if __name__ == &#x27;__main__&#x27;:    asyncio.get_event_loop().run_until_complete(main())\n\nSelenium的代理设置对于无认证的代理设置如下:\nfrom selenium import webdriverproxy = &#x27;127.0.0.1:7890&#x27;options = webdriver.ChromeOptions()options.add_argument(&#x27;--proxy-server=http://&#x27; + proxy)browser = webdriver.Chrome(options=options)browser.get(&#x27;https://httpbin.org/get&#x27;)print(browser.page_source)browser.close()\n\n如果代理需要认证，则设置方式相对繁琐点:\nfrom selenium import webdriverfrom selenium.webdriver.chrome.options import Optionsimport zipfileip = &#x27;127.0.0.1&#x27;port = 7890username = &#x27;foo&#x27;password = &#x27;bar&#x27;manifest_json = &quot;&quot;&quot;&#123;&quot;version&quot;:&quot;1.0.0&quot;,&quot;manifest_version&quot;: 2,&quot;name&quot;:&quot;Chrome Proxy&quot;,&quot;permissions&quot;: [&quot;proxy&quot;,&quot;tabs&quot;,&quot;unlimitedStorage&quot;,&quot;storage&quot;,&quot;&lt;all_urls&gt;&quot;,&quot;webRequest&quot;,&quot;webRequestBlocking&quot;],&quot;background&quot;: &#123;&quot;scripts&quot;: [&quot;background.js&quot;]    &#125;&#125;&quot;&quot;&quot;background_js = &quot;&quot;&quot;var config = &#123;        mode: &quot;fixed_servers&quot;,        rules: &#123;          singleProxy: &#123;            scheme: &quot;http&quot;,            host: &quot;%(ip) s&quot;,            port: %(port) s          &#125;        &#125;      &#125;chrome.proxy.settings.set(&#123;value: config, scope: &quot;regular&quot;&#125;, function() &#123;&#125;);function callbackFn(details) &#123;    return &#123;        authCredentials: &#123;username: &quot;%(username) s&quot;,            password: &quot;%(password) s&quot;        &#125;    &#125;&#125;chrome.webRequest.onAuthRequired.addListener(            callbackFn,            &#123;urls: [&quot;&lt;all_urls&gt;&quot;]&#125;,            [&#x27;blocking&#x27;])&quot;&quot;&quot; % &#123;&#x27;ip&#x27;: ip, &#x27;port&#x27;: port, &#x27;username&#x27;: username, &#x27;password&#x27;: password&#125;plugin_file = &#x27;proxy_auth_plugin.zip&#x27;with zipfile.ZipFile(plugin_file, &#x27;w&#x27;) as zp:    zp.writestr(&quot;manifest.json&quot;, manifest_json)    zp.writestr(&quot;background.js&quot;, background_js)options = Options()options.add_argument(&quot;--start-maximized&quot;)options.add_extension(plugin_file)browser = webdriver.Chrome(options=options)browser.get(&#x27;https://httpbin.org/get&#x27;)print(browser.page_source)browser.close()\n\n这里在本地创建了一个manifest.json配置文件和background.js脚本来设置认证代理，运行代码后本地会生成一个proxy_auth_plugin.zip文件来保存当前的配置，SOCKS代理的配置方式也比较简单，如下所示:\nfrom selenium import webdriverproxy = &#x27;127.0.0.1:7891&#x27;options = webdriver.ChromeOptions()options.add_argument(&#x27;--proxy-server=socks5://&#x27; + proxy)browser = webdriver.Chrome(options=options)browser.get(&#x27;https://httpbin.org/get&#x27;)print(browser.page_source)browser.close()\n\naiohttp代理设置对于aiohttp，可以通过proxy参数直接设置代理，HTTP设置方式如下:\nimport asyncioimport aiohttpproxy = &#x27;http://127.0.0.1:7890&#x27;async def main():    async with aiohttp.ClientSession() as session:        async with session.get(&#x27;https://httpbin.org/get&#x27;, proxy=proxy) as response:            print(await response.text())if __name__ == &#x27;__main__&#x27;:    asyncio.get_event_loop().run_until_complete(main())\n\n如果代理需要认证，就把代理地址修改下:\nproxy = &#x27;http://username:password@127.0.0.1:7890&#x27;\n\n对于SOCKS代理，需要安装一个aiohttp-socks库，安装方式如下:\npip install aiohttp-socks\n\n可以借助这个库的ProxyConnector方法来设置SOCKS代理:\nimport asyncioimport aiohttpfrom aiohttp_socks import ProxyConnector, ProxyType# connector = ProxyConnector.from_url(&#x27;socks5://127.0.0.1:7891&#x27;)connector = ProxyConnector(    proxy_type=ProxyType.HTTP,    host=&#x27;127.0.0.1&#x27;,    port=7890,    # username=&#x27;user&#x27;,    # password=&#x27;password&#x27;,    # rdns=True)async def main():    async with aiohttp.ClientSession(connector=connector) as session:        async with session.get(&#x27;https://httpbin.org/get&#x27;) as response:            print(await response.text())if __name__ == &#x27;__main__&#x27;:    asyncio.get_event_loop().run_until_complete(main())\n\n另外，aiohttp-socks库还支持SOCKS4代理、HTTP代理以及需要认证的代理，详情可以参见官方介绍\nPyppeteer的代理设置对于Pyppeteer，由于其默认使用的是类似Chrome的Chromium浏览器，因此代理的设置方式和使用Chrome的Selenium一样，都是通过args参数设置HTTP代理的，代码如下:\nimport asynciofrom pyppeteer import launchproxy = &#x27;127.0.0.1:7890&#x27;async def main():    browser = await launch(&#123;&#x27;args&#x27;: [&#x27;--proxy-server=http://&#x27; + proxy], &#x27;headless&#x27;: False&#125;)    page = await browser.newPage()    await page.goto(&#x27;https://httpbin.org/get&#x27;)    print(await page.content())    await browser.close()if __name__ == &#x27;__main__&#x27;:    asyncio.get_event_loop().run_until_complete(main())\n\nSOCKS代理也一样，只需要将协议修改为socks5即可:\nimport asynciofrom pyppeteer import launchproxy = &#x27;127.0.0.1:7891&#x27;async def main():    browser = await launch(&#123;&#x27;args&#x27;: [&#x27;--proxy-server=socks5://&#x27; + proxy], &#x27;headless&#x27;: False&#125;)    page = await browser.newPage()    await page.goto(&#x27;https://httpbin.org/get&#x27;)    print(await page.content())    await browser.close()if __name__ == &#x27;__main__&#x27;:    asyncio.get_event_loop().run_until_complete(main())\n\nPlaywright的代理设置HTTP代理设置:\nfrom playwright.sync_api import sync_playwrightwith sync_playwright() as p:    browser = p.chromium.launch(headless=False, proxy=&#123;        &#x27;server&#x27;: &#x27;http://127.0.0.1:7890&#x27;  # 填入代理地址    &#125;)    page = browser.new_page()    page.goto(&#x27;https://httpbin.org/get&#x27;)    print(page.content())    browser.close()\n\nSOCKS代理设置:\nfrom playwright.sync_api import sync_playwrightwith sync_playwright() as p:    browser = p.chromium.launch(proxy=&#123;        &#x27;server&#x27;: &#x27;socks5://127.0.0.1:7891&#x27;    &#125;)    page = browser.new_page()    page.goto(&#x27;https://httpbin.org/get&#x27;)    print(page.content())    browser.close()\n\n需要认证的代理:\nfrom playwright.sync_api import sync_playwrightwith sync_playwright() as p:    browser = p.chromium.launch(proxy=&#123;        &#x27;server&#x27;: &#x27;http://127.0.0.1:7890&#x27;,        &#x27;username&#x27;: &#x27;foo&#x27;,        &#x27;password&#x27;: &#x27;bar&#x27;    &#125;)    page = browser.new_page()    page.goto(&#x27;https://httpbin.org/get&#x27;)    print(page.content())    browser.close()\n\n代理池的维护前面在代理的设置中了解了给各个请求库设置代理的方法，如何实时高效地获取大量可用代理变成了新的问题\n首先，互联网上有大量公开免费的代理，当然我们也可以购买付费代理，但无论是免费代理还是付费代理，都不能保证是可用的，因为自己选用的IP，可能别人也在使用，爬取的还是同样的目标网站，从而被封禁，或者代理服务器突然发生故障、网络繁忙；一旦选用的是一个不可用的代理，势必就会影响爬虫的工作效率，所以我们要提前做筛选，删除掉不可用的代理，只保留可用的代理，那么怎么实现呢？这就需要借助一个叫代理池的东西了，下面我们就来看看如何搭建一个高效易用的代理池:\n准备工作存储代理池需要借助Redis数据库，因此需要额外安装Redis数据库；整体来讲，需要的环境如下:\n\n安装并成功运行和连接一个Redis数据库，它运行在本地或者远端服务器都行，只要能正常连接就行，安装的方式可以参考: https://setup.scrape.center/redis\n\n安装好一些必要的库，包括aiohttp、requests、redis-py、pyquery、Flask、loguru等，安装命令如下:\npip install aiohttp requests redis pyquery flask loguru\n\n代理池四大基本模块代理池分为4个基本模块: 存储模块、获取模块、检测模块和接口模块；各模块的功能如下:\n\n存储模块: 负责存储爬取下来的代理，首先要保证代理不重复，标识代理的可用情况，其次要动态实时地处理每个代理，一种比较高效和方便的存储方式就是Redis的Sorted Set，即有序集合\n获取模块: 负责定时在各大代理网站爬取代理，代理既可以是免费公开的，也可以是付费的，形式都是IP加端口，此模块尽量从不同来源爬取，并且尽量爬取高匿代理，爬取成功后存储到存储模块中\n检测模块: 用负责定时检测存储模块中的代理是否可用，这里需要设置一个检测链接，最好是设置为要爬取的那个网站，这样更具有针对性；对于一个通用型的代理，可以设置为百度等链接；另外，需要标识每一个代理的状态，例如设置分数表示，100分代表可用，分数越少代表越不可用；经检测，如果代理可用，可以将立即设置为满分100，也可以在原分数基础上加1；如果代理不可用，就将分数标识减1，当分数减到一定阈值后，直接从存储模块中删除此代理，这样就可以标识代理的可用情况，在选用的时候也会更加有针对性\n接口模式: 用API提供对外服务的接口。其实我们可以直接连接数据库来获取对应的数据，但这样需要知道数据库的连接信息，并且要配置连接；比较安全和方便的方式是提供一个Web API接口，访问这个接口即可拿到可用代理；另外，由于可用代理可能有多个，所以可以设置一个随机返回某个可用代理的接口，这样就能保证每个可用代理都有机会被获取，实现负载均衡\n\n代理池的整体架构根据上面的描述，代理池的架构可以是是这样的:\n以上代理池架构分为四个部分，获取模块、存储模块、检测模块、接口模块\n\n存储模块使用 Redis 的有序集合，用以代理的去重和状态标识，同时它也是中心模块和基础模块，将其他模块串联起来\n获取模块定时从代理网站获取代理，将获取的代理传递给存储模块，保存到数据库\n检测模块定时通过存储模块获取所有代理，并对其进行检测，根据不同的检测结果对代理设置不同的标识\n接口模块通过 Web API 提供服务接口，其内部还是连接存储模块，获取可用的代理\n\n代理池的实现代码量大，源码地址为: https://github.com/Python3WebSpider/ProxyPool对代码的解释可详见: https://cuiqingcai.com/7048.html\n付费代理的使用付费代理的分类以及代理商推荐\n一类是代理商提供代理提取接口的付费代理，我们可以通过接口获取这类代理组成的列表，这类代理地址的IP和端口都是可见的，想用哪个就用哪个，灵活操作即可，这类代理一般会按照时间或者量来收费，比较有代表性的的有快代理(https://www.kuaidaili.com/)、芝麻代理(https://www.zhimaruanjian.com/)和多贝代理(http://www.dobel.cn)等\n另一类是代理商搭建了隧道代理的付费代理，我们可以直接把此类代理设置为固定的IP和端口，无需进一步通过请求接口获取随机代理并设置；在这种情况下，我们只需要知道一个固定的代理服务器地址即可，代理商会在背后进一步将我们发出的请求分发给不同的代理服务器并做负载均衡，同时代理商会负责维护背后的整个代理池，因此开发者使用起来更加方便，但这样就无法自由控制设置哪个IP了；比较有代表性的这类代理有阿布云代理(https://www.abuyun.com/)、快代理(https://www.kuaidaili.com/)和多贝代理(http://www.dobel.cn)等\n\n如何使用至于如何使用，在对应服务商购买之后应该会有相应的教程\nhttps://cuiqingcai.com/7051.html\nADSL拨号代理的搭建方法这个详情见: https://cuiqingcai.com/3443.html\n代理反爬案例爬取实战实战目标以一个IP反爬网站为例进行一次实战演练，该网站限制单个IP\n每五分钟最多访问10次，访问次数超过10，该网站便会封锁该IP，并返回403状态码，10分钟后才解除封锁\n准备工作首先需要准备并正常运行代理池，还需要安装好一些Python库—requests、redis-py、environs、pyquery和loguru，安装命令如下:\npip install requests redis-py environs pyquery loguru\n\n爬取分析目标网站: https://antispider5.scrape.center/，这个网页打开后看上去和之前没有啥不同，但这里网站增加了IP反爬机制，限制单个IP的访问次数，在5分钟内超过十次访问就会封IP，但如果此时切换一个网络环境，例如使用手机热点，总之让访问目标网站所用的IP地址发生改变，就又可以看到页面正常显示了，也是就说，要想在短时间内爬取这个网站的所有数据，得更换多个IP进行爬取，这就得使用代理了\n由于我们无法预知某个代理是否能完成一个正常的爬取，因此可能请求成功也可能请求失败，失败原因可能是网站封锁了该代理，或者代理本身失效了；为了保证正常爬取，我们需要添加重试机制，以确保请求失败的时候可以再次爬取，直到成功\n那怎么实现失败后的重试呢，我们可以使用队列，当请求失败时，把对应的请求加入队列里，等待下次被调用，队列的实现方式有很多，本节我们选用Redis实现，简单高效\n本案例的实现步骤如下:\n\n 构造Redis爬取队列，用队列存取请求\n实现异常处理，把失败的请求重新加入队列\n解析列表页的数据，将爬取详情页和下一页的请求加入队列\n提取详情页的信息\n\n构造请求对象既然要用队列存储请求，就肯定要实现一个请求的数据结构，这个请求需要包含一些必要信息，例如请求链接、请求头、请求方式和超时时间；另外，对于一个请求，需要实现对应的方法来处理它的响应，那么就需要加一个回调函数callback；如果一个请求的失败次数太多，就不会再重新请求了，所以还需要增加失败次数的记录；用这些内容组成一个完整的请求对象并放入队列等待被调度，从队列获取出这个对象后直接执行就行了\n我们可以采用继承requests库中的Request对象的方式实现这个数据结构；requests库中已经存在Request对象，它将请求作为一个整体对象去执行，得到响应后再返回；其实requests库里的get、post等方法都是通过Request对象实现的，我们先来看看Request对象的部分源代码:\nclass Request(RequestHooksMixin):    def __init__(self,            method=None, url=None, headers=None, files=None, data=None,            params=None, auth=None, cookies=None, hooks=None, json=None):        # Default empty dicts for dict params.        data = [] if data is None else data        files = [] if files is None else files        headers = &#123;&#125; if headers is None else headers        params = &#123;&#125; if params is None else params        hooks = &#123;&#125; if hooks is None else hooks        self.hooks = default_hooks()        for (k, v) in list(hooks.items()):            self.register_hook(event=k, hook=v)        self.method = method        self.url = url        self.headers = headers        self.files = files        self.data = data        self.json = json        self.params = params        self.auth = auth        self.cookies = cookies\n\n这是 requests 库中 Request 对象的构造方法。这个 Request 已经包含了请求方式、请求链接、请求头这几个属性，但是相比我们需要的还差了几个。我们需要实现一个特定的数据结构，在原先基础上加入上文所提到的额外几个属性。这里我们需要继承 Request 对象重新实现一个请求，将它定义为 MovieRequest，实现如下:\nTIMEOUT = 10from requests import Requestclass MovieRequest(Request):    def __init__(self, url, callback, method=&#x27;GET&#x27;, headers=None, need_proxy=False, fail_time=0, timeout=TIMEOUT):        Request.__init__(self, method, url, headers)        self.callback = callback        self.fail_time = fail_time        self.timeout = timeout\n\n这里我们实现了MovieRequest类，代码保存为request.py，在构造方法中先调用了Request类的构造方法，然后加入了几个额外的参数，分别定义为callback、fail_time和timeout，代表回调函数、失败次数和超时时间\n之后就可以将MovieRequest作为一个整体来执行，各个MovieRequest对象都是独立的，每个请求都有自己的属性；例如，调用请求的callback属性就可以知道应该用什么方法处理这个请求的响应，调用fail_time就可以知道这个请求失败了多少次，继而判断失败次数是否达到阈值，该不该丢弃这个请求\n实现请求队列接下来我们就需要构造请求队列，实现请求的存取。存取无非就是两个操作，一个是放，一个是取，所以这里利用 Redis 的 rpush () 和 lpop () 方法即可。 另外还需要注意，存取不能直接存 Request 对象，Redis 里面存的是字符串。所以在存 Request 对象之前我们先把它序列化，取出来的时候再将其反序列化，这个过程可以利用 pickle 模块实现\nfrom pickle import dumps, loadsfrom request import MovieRequestclass RedisQueue():    def __init__(self):        &quot;&quot;&quot;初始化 Redis&quot;&quot;&quot;        self.db = StrictRedis(host=REDIS_HOST, port=REDIS_PORT, password=REDIS_PASSWORD)    def add(self, request):        &quot;&quot;&quot;        向队列添加序列化后的 Request        :param request: 请求对象        :param fail_time: 失败次数        :return: 添加结果        &quot;&quot;&quot;        if isinstance(request, MovieRequest):            return self.db.rpush(REDIS_KEY, dumps(request))        return False    def pop(self):        &quot;&quot;&quot;        取出下一个 Request 并反序列化        :return: Request or None        &quot;&quot;&quot;        if self.db.llen(REDIS_KEY):            return loads(self.db.lpop(REDIS_KEY))        else:            return False    def empty(self):        return self.db.llen(REDIS_KEY) == 0\n\n这里实现了一个 RedisQueue类，代码文件保存为db.py，它的 init() 构造方法里面初始化了一个 StrictRedis 对象。随后实现了 add () 方法，首先判断 Request 的类型，如果是 MovieRequest，那么就把程序就会用 pickle 的 dumps () 方法序列化，然后再调用 rpush () 方法加入队列。pop () 方法则相反，调用 lpop () 方法将请求从队列取出，然后再用 pickle 的 loads () 方法将其转为 MovieRequest 对象。另外，empty () 方法返回队列是否为空，只需要判断队列长度是否为 0 即可。 在调度的时候，我们只需要新建一个 RedisQueue 对象，然后调用 add () 方法，传入 MovieRequest 对象，即可将 MovieRequest 加入队列，调用 pop () 方法，即可取出下一个 MovieRequest对象，非常简单易用\n修改代理池现在我们要找一些可用代理，这里直接使用崔庆才先生所构建的代理池，我已根据此链接在云服务器上构建好5555端口的接口，接口地址为: http://175.24.172.64:5555/random，我们再定义一个用来获取可用代理的方法:\nPROXY_ROOT_RUL = &#x27;http://175.24.172.64:5555/random&#x27;from loguru import logger@logger.catch    def get_proxy(self):        &quot;&quot;&quot;        get proxy from proxypool        :return: proxy        &quot;&quot;&quot;        response = requests.get(PROXY_POOL_URL)        if response.status_code == 200:            logger.debug(f&#x27;get proxy &#123;response.text&#125;&#x27;)            return response.text\n\n这里有个小技巧，我们使用loguru日志库里的catch方法作为get_proxy方法的装饰器，这样可以在请求代理池失败的时候输出具体的报错信息，同时又不会中断程序运行，也避免了编写try/catch语句的麻烦，使得代码看起来更简洁\n第一个请求一切工作都做好了，现在我们就可以构造第一个请求请求并放在队列里以供调度了，代码如下:\nfrom requests import Sessionfrom core.db import RedisQueuefrom core.request import MovieRequestBASE_URL = &#x27;https://antispider5.scrape.center/&#x27;HEADERS = &#123;    &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&#x27;&#125;class Spider():    session = Session()  # Session对象    queue = RedisQueue()  # RedisQueue对象        def start(self):        &quot;&quot;&quot;        start request        &quot;&quot;&quot;        self.session.headers.update(HEADERS)  # 全局更新了HEADERS        start_url = BASE_URL        request = MovieRequest(            url=start_url, callback=self.parse_index)        # schedule first request        self.queue.add(request)  # 请求入队\n\n这里先定义了两个全局变量，BASE_URL代表目标网站的URL，HEADERS代表请求头，然后定义了Spider类，代码保存为spider.py\n调度请求把第一个请求加入队列之后，就可以开始调度执行了；首先从队列中取出这个请求，将它的结果解析出来，生成新的请求加入队列，然后拿出新的请求，将结果解析，再将新生成的请求加入队列，这样循环执行，直到队列中没有请求，代表爬虫结束\n我们在Spider类中添加scheduler方法，实现如下:\ndef schedule(self):        &quot;&quot;&quot;        schedule request        :return:        &quot;&quot;&quot;        while not self.queue.empty():            request = self.queue.pop()            callback = request.callback            logger.debug(f&#x27;executing request &#123;request.url&#125;&#x27;)            response = self.request(request)            logger.debug(f&#x27;response status &#123;response&#125; of &#123;request.url&#125;&#x27;)            if not response or not response.status_code in VALID_STATUSES:                self.error(request)                continue            results = list(callback(response))            if not results:                self.error(request)                continue            for result in results:                if isinstance(result, MovieRequest):                    logger.debug(f&#x27;generated new request &#123;result.url&#125;&#x27;)                    self.queue.add(result)                if isinstance(result, dict):                    logger.debug(f&#x27;scraped new data &#123;result&#125;&#x27;)\n\nscheduler方法的内部是一个wihle循环，该循环内部的判断条件是队列不为空；当队列不为空时，调用pop方法取出下一个请求，然后调用request方法执行这个请求，request方法的实现如下:\ndef request(self, request):        &quot;&quot;&quot;        execute request        :param request: weixin request        :return: response        &quot;&quot;&quot;        try:            proxy = self.get_proxy()            logger.debug(f&#x27;get proxy &#123;proxy&#125;&#x27;)            proxies = &#123;                &#x27;http&#x27;: &#x27;http://&#x27; + proxy,                &#x27;https&#x27;: &#x27;https://&#x27; + proxy            &#125; if proxy else None            return self.session.send(request.prepare(),                                     timeout=request.timeout,                                     proxies=proxies)        except RequestException:            logger.exception(f&#x27;requesting &#123;request.url&#125; failed&#x27;)\n\n以上request方法也可以不用try/catch方法采用logger中的catch装饰器，在这个方法中，首先调用get_proxy()获取代理，然后将代理赋值给proxies字典，接着调用session变量的send方法执行这个请求，这里调用prepare方法将请求转化为了Prepared Request对象(具体可看2.2节)，timeout属性是该请求的超时时间，proxies属性就是刚才声明的代理，最后返回send方法的执行结果\n执行request方法之后会得到两种结果，一种是False，即请求失败，连接错误；另一种是Response对象，即请求成功后返回的结果，需要判断其中的状态码，如果状态码合法，就对返回结果进行解析，否则将请求重新放入队列\n之后的就自己看代码了: https://github.com/Python3WebSpider/ScrapeAntispider5\n"},{"title":"Python3网络爬虫开发实战第二版第10章-模拟登陆","url":"/2022/02/16/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC10%E7%AB%A0-%E6%A8%A1%E6%8B%9F%E7%99%BB%E9%99%86/","content":"很多情况下，网站的一些数据需要登录后才能查看，如果想要爬取这部分数据的话，就需要实现模拟登录的一些机制\n模拟登录现在主要分为两种模式，一种是基于Session和Cookie的模拟登录，一种是基于JWT(JSON Web Token)的模拟登录\n对于第一种模式，我们已经学习过Session和Cookie，简单来说，打开网页后模拟登录，服务器会返回带有Set-Cookie字段的响应头，客户端会生成相应的Cookie，其中保存着SessionID相关的信息，之后发送给服务器的请求都会携带这个生成的Cookie；服务器接收到请求后，会根据Cookie中保存的SessionID找到对应的Session，同时校验Cookie中的其他信息，如果当前Session是有效的并且校验成功，服务器就判断当前用户已经登录，返回所请求的页面信息；所以这种模式的核心是获取客户端登录后生成的Cookie\n对于第二种模式也是如此，我们可以手动在浏览器中输入用户名和密码，再把Cookie或者JWT复制到代码中来进行请求数据，但这样做明显会增加人工工作量；实现爬虫的目的不就是自动化嘛，所以我们要做的就是用程序来完成这个过程，或者说用程序模拟登录\n模拟登录的基本原理很多时候，一些网站的页面或资源需要先登录才能看到，例如GitHub的个人设置页面，如果不登录就无法查看，12306网站的提交订单页面，如果不登录也是无法提交订单，在微博上写了个新内容不登录也是无法发表\n网站登录验证的实现要实现模拟登录，首先就得了解网站如何验证登录内容\n登录一般需要两个内容，用户名和密码，也有的网站是填写手机号获取验证码，或者微信扫码从根本上看，这些方式都是把一些可供认证的信息提交给服务器\n就拿用户名和密码来说，用户在一个网页表单里面输入这两个内容，然后点击登录按钮的一瞬间，浏览器客户端会向服务器发送一个登录请求，这个请求里肯定包含刚输入的用户名和密码，这时服务器需要处理这些内容，然后返回给客户端一个类似凭证的东西，有了这个凭证，客户端再去访问某些需要登录才能看的页面时，服务器自然会放行，并返回对应的内容或执行对应的操作\n那么问题来了，这个凭证是怎么生成的，服务器又是怎么校验的呢，答案其实刚刚已经介绍过了，一种是基于Session和Cookie，一种是基于JWT\n基于Session和Cookie不同网站对于用户登录状态的实现可能是不同的，但Sesson和Cookie一定是相互配合工作的，下面梳理下:\n\nCookie里面可能只保存了SessionID相关的信息，服务器能根据这个信息找到对应的Session；当用户登录后，服务器会在相应的Session里标记一个字段，代表用户已处于登录状态或者其他(如角色或登录时间)，这样一来，用户每次访问网站的时候都带着Cookie，服务器每次都找到对应的Session，然后看一下用户的状态是否为登录状态，在决定返回什么结果或执行什么操作；\nCookie里直接保存了某些凭证信息；例如用户发起登陆请求，服务器校验通过后，返回给客户端的响应头里面可能带有Set-Cookie字段，里面就包含着类似的凭证的信息，这样客户端会执行设置Cookie的操作，将那些类似凭证的信息保存到Cookie里，以后再访问网站时都携带这Cookie，服务器拿着其中的信息进行检验，自然也能检测登录状态\n\n以上两种情况几乎能涵盖大部分这种模式的实现，具体的实现逻辑因服务器而异，但Session和Cookie是一定要配合使用的\n基于JWTweb的开发技术一直在发展，近几年前后端分离的开发模式也越来越火，传统的基于Sesson和Cookie的校验又存在一定的问题，例如服务器需要维护登录用户的Session信息，而且分布式部署也不太方便，不太适合前后端分离的项目，所以JWT技术应运而生\n有了JWT，一些认证就不需要借助Session和Cookie了，服务器也无需维护Session信息，从而减少了开销，只需要有一个校验JWT的功能即可，同时还支持分布式部署和跨语言\nJWT一般是一个经过Base64编码技术加密的字符串，有自己的标准，可以把JWT看成一个三段加密字符串，这三部分分别是Header、Payload、Sinnature\n\nHeader: 申明了JWT的签名算法(如RSA，SHA256等)，还可能包含JWT编号或类型等数据\nPayload: 通常是一些业务需要但是不敏感的信息(如UserID)，另外还有很多默认字段，如JWT签发者、JWT接受者、JWT过期时间等\nSignature: 这就是一个签名，是利用秘钥secret对Hader、Payload的信息进行加密后形成的，这个秘钥保存在服务端，不会轻易泄露；如此以来，如果Payload的信息被串改，服务器就能通过Signature判断出这是非法请求，拒绝提供服务\n\n登录认证流程也很简单了，用户通过用户名和密码登录，然后服务器生成JWT字段返回给客户端，之后客户每次请求都带着这个JWT，服务器会自动判断其有效情况，如果有效就返回对应的数据；JWT的传递方式有很多种，可以放在请求头中，可以放在URL中，甚至有些网站把它放在Cookie中\n模拟登录基于Session和Cookie模拟登录如果要用爬虫实现基于Cookie和Session的模拟登录，最主要的是要维护好Cookie的信息\n\n第一，如果已经在浏览器中登录了自己的账号，那么可以直接把Cookie赋值给爬虫，详细点说就是放在请求头中\n第二，如果想让爬虫完全自动化工作，那么可以直接使用爬虫模拟登录过程，大多数时候，登录过程其实就是Post请求，用爬虫把用户名、密码等信息提交给服务器，服务器返回的响应头里面可能会有Set-Cookie字段，我们只需要把这个字段的内容保存下来即可，所以最主要的是把这个过程中的Cookie维持好，当然，我们可能会遭遇到一些困难，例如登录过程中伴随着各种校验参数，不好直接模拟请求；客户端设置Cookie的过程中是通过JavaScript实现的，所以可能还得仔细分析其中的逻辑，尤其是用requests这样的请求的库进行模拟登录遇到的问题总会是比较多\n可以用一些简单的方式，那就是自动化处理工具了\n\n基于JWT模拟登录基于JWT的模拟登录思路也比较清晰，由于JWT的字符串就是用户访问的凭证，所以模拟登录只需要做到下面几步:\n\n模拟登录操作，例如拿着用户名和密码信息请求登录接口，获取服务器返回的结果，这个结果中通常包含着JWT信息，将其保存下来即可\n之后发送个给服务器的请求都携带JWT，在JWT不过期的情况下，通常能正常访问和执行操作，携带方式多种多样，因网站而异\n如果JWT过期了，可能需要再次做第一步，重新获取JWT\n\n当然，模拟登录的过程中肯定会带有一些其他加密参数，需要根据情况而定\n账号池如果爬虫要求爬取的数据量比较大或爬取速度比较快，网站又有单账号并发限制或者访问状态检测等反爬虫手段，我们的账号可能就无法访问网站或者面临封号的风险\n这时一般怎么处理呢，可以分流，建立一个账号池，用多个账号随机访问网站或爬取数据，这样能大幅提高爬虫的并发量，降低被封号的风险；例如准备100个账号，然后这100个账号都模拟登录，并保存对应的Cookie或JWT，每次都随机从中选取一个来访问，账号多，所以每个账号被选中的概率就小，也就避免了单账号并发量过大的问题\n基于Session和Cookie的模拟登录爬取实战目标网站: https://login2.scrape.center/，用户名和密码都是admin\n下面开始分析过程\n分析首先我们打开上面提供的目标网站然后F12，我么输入用户名和密码，我们可以看到:\n\n这里就携带了一个Cookie，这个Cookie一般是有一定有效期的，我们可以直接把它放在Haders中去请求\nreqeust爬取&quot;&quot;&quot;@Description :@File        : Login-scrape@Project     : test@Time        : 2022/2/16 18:09@Author      : LiHouJian@Software    : PyCharm@issue       :@change      :@reason      :&quot;&quot;&quot;import requestsimport jsonheaders = &#123;    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36&quot;,&#125;login_url = &quot;https://login2.scrape.center/login&quot;index_url = &quot;https://login2.scrape.center/page/2&quot;data = &#123;    &quot;username&quot;: &quot;admin&quot;,    &quot;password&quot;: &quot;admin&quot;&#125;# 由于requests模块有自动处理重定向的能力，所以要加上allow_redirects=Falseres = requests.post(    login_url,    headers=headers,    data=data,    allow_redirects=False)cookies = res.cookiesresp = requests.get(index_url, headers=headers, cookies=cookies)print(resp.url)\n\n最后打印的url如果和index_url一致这说明成功登录了，但是这样我们发现比较繁琐，每次请求都需要处理并传递一次Cookie，其实我们可以直接借助requests内置的Session对象帮我们自动处理Cookie，使用Session对像之后，requests会自动保存每次请求后设置的Cookie，并在下次请求的时候携带上它，这样就方便了，把上面的代码简化下:\n&quot;&quot;&quot;@Description :@File        : Login-scrape@Project     : test@Time        : 2022/2/16 18:09@Author      : LiHouJian@Software    : PyCharm@issue       :@change      :@reason      :&quot;&quot;&quot;import requestsimport jsonheaders = &#123;    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36&quot;,&#125;session = requests.Session()login_url = &quot;https://login2.scrape.center/login&quot;index_url = &quot;https://login2.scrape.center/page/2&quot;data = &#123;    &quot;username&quot;: &quot;admin&quot;,    &quot;password&quot;: &quot;admin&quot;&#125;# 由于requests模块有自动处理重定向的能力，所以要加上allow_redirects=Falseres = session.post(    login_url,    headers=headers,    data=data)# cookies = res.cookiesresp = session.get(index_url, headers=headers)print(resp.url)\n\nSelenium爬取from urllib.parse import urljoinfrom selenium import webdriverimport requestsimport timeBASE_URL = &#x27;https://login2.scrape.cuiqingcai.com/&#x27;LOGIN_URL = urljoin(BASE_URL, &#x27;/login&#x27;)INDEX_URL = urljoin(BASE_URL, &#x27;/page/1&#x27;)USERNAME = &#x27;admin&#x27;PASSWORD = &#x27;admin&#x27;browser = webdriver.Chrome()browser.get(BASE_URL)browser.find_element_by_css_selector(&#x27;input[name=&quot;username&quot;]&#x27;).send_keys(USERNAME)browser.find_element_by_css_selector(&#x27;input[name=&quot;password&quot;]&#x27;).send_keys(PASSWORD)browser.find_element_by_css_selector(&#x27;input[type=&quot;submit&quot;]&#x27;).click()time.sleep(10)# get cookies from seleniumcookies = browser.get_cookies()print(&#x27;Cookies&#x27;, cookies)browser.close()# set cookies to requestssession = requests.Session()for cookie in cookies:    session.cookies.set(cookie[&#x27;name&#x27;], cookie[&#x27;value&#x27;])response_index = session.get(INDEX_URL)print(&#x27;Response Status&#x27;, response_index.status_code)print(&#x27;Response URL&#x27;, response_index.url)\n\n基于JWT的模拟登录爬取实战分析目标网站: https://login3.scrape.center/\n用户名和密码同样是admin\n我们打开这个网站然后看下后台向它发送了什么数据:\n\n我们可以看到服务器向客户端响应了一段字符串\n然后我们再往后点击几页，我们会发现在请求头中正好有个Authorization字段包含了前面服务器向客户端响应的字符串，这就说明那就是我们在发送请求的时候需要夹带的数据\n那么整个思路就变得简单了:\n\n模拟登录请求，带上必要的登录信息，获取返回的JWT\n之后发送请求在请求头里面加上Authorization字段，值就是JWT对应的内容\n\n代码实现如下:\nimport requestsfrom urllib.parse import urljoinBASE_URL = &#x27;https://login3.scrape.cuiqingcai.com/&#x27;LOGIN_URL = urljoin(BASE_URL, &#x27;/api/login&#x27;)INDEX_URL = urljoin(BASE_URL, &#x27;/api/book&#x27;)USERNAME = &#x27;admin&#x27;PASSWORD = &#x27;admin&#x27;response_login = requests.post(LOGIN_URL, json=&#123;    &#x27;username&#x27;: USERNAME,    &#x27;password&#x27;: PASSWORD&#125;)data = response_login.json()print(&#x27;Response JSON&#x27;, data)jwt = data.get(&#x27;token&#x27;)print(&#x27;JWT&#x27;, jwt)headers = &#123;    &#x27;Authorization&#x27;: f&#x27;jwt &#123;jwt&#125;&#x27;&#125;response_index = requests.get(INDEX_URL, params=&#123;    &#x27;limit&#x27;: 18,    &#x27;offset&#x27;: 0&#125;, headers=headers)print(&#x27;Response Status&#x27;, response_index.status_code)print(&#x27;Response URL&#x27;, response_index.url)print(&#x27;Response Data&#x27;, response_index.json())\n\n大规模账号池的搭建见P385\n"},{"title":"Python中的pip工具丢失的解决方法","url":"/2022/02/19/Python%E4%B8%AD%E7%9A%84pip%E5%B7%A5%E5%85%B7%E4%B8%A2%E5%A4%B1%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","content":"昨天在使用更新pip的命令后，莫名其妙我的pip就被删除了:\n\n我当时就傻眼了，这怎么搞呢，我还要用pip工具安装包呢，然后我是用以下命令解决的:\npython -m ensurepip\n\nensurepip默认会安装标准库提供的一个pip副本，这个副本一般不是最新的，然后可以用这个版本安装pip的任意一个更新版本，当然如果你想直接安装pip的一个最新版本，可以在ensurepip命令中添加-uupgrade选项\n\n"},{"title":"2022-2-24使用到的Linux命令","url":"/2022/02/24/2022-2-24%E4%BD%BF%E7%94%A8%E5%88%B0%E7%9A%84Linux%E5%91%BD%E4%BB%A4/","content":"\nubuntu删除用户:\nsudo userdel test cd /home/sudo rm -r test\n\n如果提示tese is a directory，那就使用以下命令递归删除此文件夹:\nsudo rm -rf test\n\n​        删除单个文件可以使用sudo rm -r test，如果是文件夹那就需要递归删除了\n​        这里做个解释:\n​        -r 就是向下递归，不管有多少级目录，一并删除\n​        -f 就是直接强行删除，不作任何提示的意思\n\nubuntu添加用户\nsudo adduser test\n\n然后后面会要求输入密码和确认密码，在接着什么work/home phone都可以直接enter\n\nubuntu修改主机名\n\n修改hostname文件，这里修改为robot-home:\nsudo gedit /etc/hostname\n修改hosts文件\nsudo gedit /etc/hosts\n\n\n查看某进程，这里以gitlab为例:\nps aux | grep gitlab\n\n或者:\nps -ef | grep gitlab\n杀掉某个进程:\nsudo kill -9 9527    ##(-9为强制终止，9527为进程id)\n删除所有包含xxx的文件，这里以gitlab为例:\nsudo find / -name *gitlab* | xargs rm -rf\n\n或者:\ncd /\n\n然后:\nfind / -name *gitlab* | xargs rm -rf\n在没有运行image之前，删除docker中的image:\ndocker rmi tagid\n如果是已经运行了image的，那就意味着已经生成了container，那我们可以这么操作:\n首先我们要找到对应的containerid，用如下命令查看:\ndocker ps是查看目前在运行的container，docker ps -a是查看所有的，包括了停止的container也会展示出来\ndocker ps -a\n\n我们要操作的container必须先将它关闭再删除，所以我们先使用下面的命令关闭:\ndocker stop 117843ade696\n\n然后用rm命令删除container:\ndocker rm containerid\n\n我们可以确认下，用docker images来查看对应image是否已被删除\n\n\n"},{"title":"ubuntu16安装Jenkins","url":"/2022/02/23/ubuntu16%E5%AE%89%E8%A3%85Jenkins/","content":"下面我们将在云服务器上安装Jenkins\n首先我们看看什么是Jenkins以及他能做什么\n什么是JenkinsJenkins是一个开源的、提供友好操作界面的持续集成(CI)工具，起源于Hudson（Hudson是商用的），主要用于持续、自动的构建/测试软件项目、监控外部任务的运行（这个比较抽象，暂且写上，不做解释）。Jenkins用Java语言编写，可在Tomcat等流行的servlet容器中运行，也可独立运行。通常与版本管理工具(SCM)、构建工具结合使用。常用的版本控制工具有SVN、GIT，构建工具有Maven、Ant、Gradle\nJenkins能做什么首先，Jenkins可以很方便的在我们的项目中帮助我们去部署、打包项目，在开发过程中避免了繁琐的手动打包步骤，只要我们把项目部署到Jenkins中，然后添加上一些列的脚本，就能帮助我们很快的完成打包工作，并且它与版本管理工具Svn、Git等兼容\n先决条件\n 一个安装有ubuntu16.04或者ubuntu18.04系统的服务器\n\n最小推荐配置\n\nJava8(JRE或JDK)\n256MB可用内存\n1GB+可用磁盘空间\n\n\n推荐配置小团队\n\njava8\n1GB+内存\n50GB+可用磁盘空间\n\n\n安装Java SDK，也就是Java软件开发工具包\nsudo apt-get install openjdk-8-jdk\n\n安装Jenkins包含在默认Ubuntu软件包中的Jenkins版本往往落后于项目本身的最新版本。 为了利用最新的修复和功能，我们将使用项目维护的软件包来安装Jenkins\n首先，我们将存储库密钥添加到系统:\nwget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add -\n\n添加密钥后，系统将返回OK 。 接下来，我们将Debian包存储库地址附加到服务器的sources.list :\nsudo sh -c &#x27;echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list&#x27;\n\n当这两个都到位时，我们将运行update ，以便apt-get将使用新的存储库:\nsudo apt-get update\n\n最后，我们将安装Jenkins及其依赖项，包括Java:\nsudo apt-get install jenkins\n\n现在Jenkins及其依赖项已经到位，我们将启动Jenkins服务器\n开始Jenkins使用systemctl我们将启动Jenkins:\nsudo systemctl start jenkins\n\n由于systemctl不显示输出，我们将使用其status命令来验证它是否成功启动:\nsudo systemctl status jenkins\n\n如果一切顺利，输出的开始应显示服务处于活动状态，并配置为启动时启动:\n● jenkins.service - LSB: Start Jenkins at boot time  Loaded: loaded (/etc/init.d/jenkins; bad; vendor preset: enabled)  Active:active (exited) since Thu 2017-04-20 16:51:13 UTC; 2min 7s ago    Docs: man:systemd-sysv-generator(8)\n\n现在Jenkins正在运行，我们将调整防火墙规则，以便我们可以从网络浏览器到达Jenkins以完成初始设置\n打开防火墙默认情况下，Jenkins在端口8080上运行，因此我们将在云服务器的防火墙中添加规则，打开8080端口，如果8080端口已被占用，我们可以修改Jenkins的端口，点击此处跳转查看\n\n现在，Jenkins已安装，防火墙允许我们访问它，我们可以完成初始设置\n设置Jenkins通过以上设置，我们可以使用服务器域名或IP地址访问Jenkins，比如: http://192.168.2.3:8080\n访问网址之后，我们应该看到”Unlock Jenkins”屏幕:\n\n复制以上文件路径，我们将在终端中使用cat命令查看密码:\nsudo cat /var/lib/jenkins/secrets/initialAdminPassword\n\n我们将从终端复制32个字符的字母数字密码，并将其粘贴到“管理员密码”字段中，然后单击“继续”。 下一个屏幕提供安装建议的插件或选择特定插件的选项:\n\n我们将点击“安装建议的插件”选项，这将立即开始下载以及安装:\n\n安装完成后，系统将提示您设置第一个管理用户；可以跳过此步骤，并点击右下方的Continue as admin继续，但是我们将花一点时间创建用户:\n需要注意的是，此时Jenkins默认未加密，因此使用此表单提交的数据不受保护；这个时候我们可以按照指南如何使用Nginx反向代理将SSL配置为Jenkins，这将保护用户凭据和通过Web界面发送的构建的信息(我第一次使用这个我就不配置反向代理了)\n\n一旦第一个管理员用户到位，你应该看到一个“Jenkin is ready!” 确认屏幕:\n\n点击“开始使用Jenkins”来访问主要的Jenkins仪表板:\n\n"},{"title":"关于pip挂了的补充","url":"/2022/02/22/%E5%85%B3%E4%BA%8Epip%E6%8C%82%E4%BA%86%E7%9A%84%E8%A1%A5%E5%85%85/","content":"上一篇笔记提到使用python -m ensurepip将pip.exe文件下载下来，然后我们在Python主目录下中的Scripts文件夹内可以看到pip3.exe，然后我们要将这个.exe文件的路径添加进环境变量即可在小黑窗口使用\n"},{"title":"爬虫的管理与部署之云服务器环境搭建","url":"/2022/02/22/%E7%88%AC%E8%99%AB%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E9%83%A8%E7%BD%B2%E4%B9%8B%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","content":"首先我们要跟随以下链接的步骤(当然里面还介绍了如何配置访问认证)在云服务器上安装好Scrapyd:\n点击跳转\n然后我们要做的就是安装一个高度集成话的图形界面工具—gerapy:\n我在操作的时候遇到一个小小的问题，报错如下:\nCommand &quot;python setup.py egg_info&quot; failed with error code 1 in /tmp/pip-build-*\n\n这个问题的解决我采集自: https://www.cnblogs.com/xiao987334176/p/12600835.html\n答案就是更新下pip工具，使用以下命令:\npip3 install --upgrade pip\n\n然后我们就可以使用使用以下步骤逐步运行起图形界面:\n安装完Gerapy后，我们就可以使用gerapy命令了，首先，可以利用gerapy命令创建一个工作目录，如下:\ngerapy init\n\n这样会在当前目录下生成一个gerapy文件夹，然后进入该文件夹(进入该文件夹后再执行以下命令)，会发现一个空的projects文件夹，这会在后面提到\n这时先对数据库进行初始化:\ngerapy migrate\n\n这样即会生成一个SQLite数据库，该数据库中会保存各个主机配置信息、部署版本等\n接下来，我们可以生成一个管理账号:\ngerapy initadmin\n\n这时候可以生成一个用户名和密码都为admin的管理员账号，用于后续系统的登录\n当然，如果不想使用默认的admin账号，也可以利用如下命令来创建单独的账号:\ngerapy createsuperuser\n\n输入用户名和密码之后，就可以创建一个管理员帐号了\n接下来，启动Gerapy服务，命令如下:\ngerapy runserver\n\n这样即可在默认的8000端口上开启Gerapy服务，用浏览器打开http://localhost:8000即可进入\ngerapy runserver这个命令一运行，那只能在云服务器本机上运行，我们在本地是无法通过http://192.168.2.3:8000来访问到这个面板的，如果要想在本地访问到，我们就要使用这个命令gerapy runserver 0.0.0.0 8000，这表示在任何主机的8000端口都可访问，前提是你云服务器主机的8000端口是否打开，也可以自定义其他端口，不一定非要8000端口\n"},{"title":"腾讯云ubuntu主机安装mongodb并设置远程访问","url":"/2022/02/22/%E8%85%BE%E8%AE%AF%E4%BA%91ubuntu%E4%B8%BB%E6%9C%BA%E5%AE%89%E8%A3%85mongodb%E5%B9%B6%E8%AE%BE%E7%BD%AE%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/","content":"首先我们连接上云服务器，然后我们要使用以下命令更新下软件包:\nsudo apt update &amp;&amp; sudo apt upgrade -y\n\n然后我们就可以继续使用以下命令进行安装MongoDB:\nsudo apt install mongodb\n\n稍等一会儿之后，MongoDB就安装到云服务器上了\n在安装完成之后，MongoDB是启动了的，但后期我们可以使用以下命令查看服务是否启动:\nsudo systemctl status mongodb\n\n如果看到active那服务就是启动了的，其他的都是没有启动\n然后下面我们就来看看如何设置，然后在本地也能访问到远程云服务器上的MongoDB数据库:\n首先，我们要使用使用以下命令修改配置文件:\nvim /etc/mongodb.conf\n\n进入配置文件后，我们进行编辑，把bind_ip=127.0.0.1这一行修改成bind_ip=0.0.0.0，这里要注意，设置远程访问之后，启动auth授权访问，不然非常不安全，数据库容易被攻击，在配置文件中修改如下:\n# Turn on/off security.  Off is currently the default#noauth = trueauth = true\n\n然后我们需要在mongodb数据库中新建用户名和密码，也就是上面的noauth = true要打开，然后，我们使用以下命令切换数据库到admin:\nuse admin\n\n然后我们使用以下命令添加admin数据库的用户:\ndb.createUser(&#123;user:&quot;kimkat&quot;,pwd:&quot;123456&quot;,roles:[&#123; role: &quot;readWriteAnyDatabase&quot;, db: &quot;admin&quot; &#125;]&#125;)\n\n这里附上mongodb添加用户的方法: https://docs.mongodb.com/manual/reference/method/db.createUser/index.html\n以及mongod内置的用户角色: https://docs.mongodb.com/manual/core/security-built-in-roles/index.html\n然后我们需要使用以下命令再次修改配置文件:\nvim /etc/mongodb.conf\n\n然后修改成如下即可:\n# mongodb.conf  # Where to store the data.dbpath=/var/lib/mongodb#where to loglogpath=/var/log/mongodb/mongodb.loglogappend=truebind_ip = 0.0.0.0port = 27017# Enable journaling, http://www.mongodb.org/display/DOCS/Journalingjournal=true# Enables periodic logging of CPU utilization and I/O wait#cpu = true# Turn on/off security.  Off is currently the default#noauth = trueauth = true# Verbose logging output.#verbose = true# Inspect all client data for validity on receipt (useful for# developing drivers)#objcheck = true# Enable db quota management#quota = true# Set diagnostic logging level where n is#   0=off (default)#   1=W#   2=R#   3=both#   7=W+some reads#diaglog = 0# Diagnostic/debugging option#nocursors = true# Ignore query hints#nohints = true\n\n然后我们使用以下命令重启mongodb数据库:\n/etc/init.d/mongodb restart\n\n然后我们就要打开云服务器的端口了，这个在云服务器中的控制面板中可以自由设置\n下面我们来看看远程连接测试:\n进行到这一步的时候我遇到点问题，前面在查阅资料的时候，说mongodb.conf文件中的bind_ip可以被注释掉，这个我一注释后面就遇到怎么也无法连接的问题，所以这个千万不能注释掉，我们要把它修改为0.0.0.0，然后按照上面的步骤，在默认的admin数据库指定一个username和password然后开启auth即可开启用户名密码连接\n这样我们就完成了远程访问\n"},{"title":"Python3网络爬虫开发实战第二版第7章-JavaScript动态渲染页面抓取","url":"/2022/02/11/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%AC7%E7%AB%A0-JavaScript%E5%8A%A8%E6%80%81%E6%B8%B2%E6%9F%93%E9%A1%B5%E9%9D%A2%E6%8A%93%E5%8F%96/","content":"在第5章中，我们了解了Ajax数据的分析和爬取方式，其实这也是JavaScript动态渲染页面的一种情形，通过直接分析Ajax，使我们仍然可以借助request或urllib实现数据爬取，不过JavaScript动态渲染不止Ajax一种，有些页面的分页部分由JavaScript生成，而非原始HTML代码，这其中并不包含Ajax请求；如Echarts的官方实例，其图形都是经过JavaScript计算之后生成的，还有类似淘宝这种页面，即使是Ajax获取的数据，其Ajax接口中也含有很多加密参数，使我们很难直接找出规律\n为了解决这些问题，我们可以直接模拟浏览器运行，然后爬取数据，这样就能做到在浏览器中看到的内容是什么样，爬取的源码就是什么样—所见即所爬；此时我们无需去管网页内部的JavaScript使用什么算法渲染页面，也不用管网页后台的Ajax接口到底还有哪些参数\nPython提供了很多模拟浏览器运行的库，例如Selenium、Splash、Pyppeter、Playwright等，我们可以借助这些库来完成爬取动态渲染的页面\nSelenium的使用很多情况下，Ajax的请求接口会含有加密参数，例如token、sing等，由于请求Ajax接口时必须加上token等参数，因此如果深入分析并找到token等参数的构造逻辑，是很难模拟Ajax请求的\n方法通常有两种:\n\n深挖其中的逻辑，把token参数的构造逻辑完全找出来，再用Python代码实现\n模拟浏览器的运行，爬取数据\n\nSelenium是一个自动化测试工具，利用它可以驱动浏览器完成特定的操作，例如点击，下拉等，还可以获取浏览器当前呈现的页面的源代码，做到所见即所爬，对于一些JavaScript动态渲染的页面，这种爬取方式非常有效\n准备工作\n安装Chrome浏览器\n安装Selenium这个包\n安装并配置好ChormDriver这个驱动\n\n具体准备工作各个模块的安装步骤，可参见: https://setup.scrape.center/selenium\n基本用法我们首先大体来看看Selenium的功能:\nfrom selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.common.keys import Keysfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.support.wait import WebDriverWaitbrowser = webdriver.Chrome()try:    browser.get(&#x27;https://www.baidu.com&#x27;)    input = browser.find_element_by_id(&#x27;kw&#x27;)  # 找到这个元素    input.send_keys(&#x27;Python&#x27;)  # 相当于在搜索框中键入Python    input.send_keys(Keys.ENTER)  # 相当于点击搜索键    wait = WebDriverWait(browser, 10)  # 给浏览器一定的加载时间，不然会出错    wait.until(EC.presence_of_element_located((By.ID, &#x27;content_left&#x27;)))    print(browser.current_url)  # 输出浏览器当前所处理的url    print(browser.get_cookies())  # 输出当前的Cookie    print(browser.page_source)  # 输出网页源代码finally:    browser.close()  # 关闭浏览器\n\n运行以上代码之后会打开一个Chrome浏览器，浏览器会跳转到百度页面，然后在搜索框中输入Python，就会跳转到搜索结果页面:\n下面详细了解下Selenium的用法:\n初始化浏览器对象我们可以用如下方式初始化浏览器对象:\nfrom selenium import Webdriverbrowser = webdriver.Chrome()browser = webdriver.Firefox()browser = webdriver.Edge()browser = webdriver.Safari()\n\n访问页面from selenium import Webdriverbrowser = webdriver.Chrome()browser.get(&#x27;https://www.taobao.com&#x27;)print(browser.page_source)browser.close()\n\n以上代码弹出浏览器并且自动访问了淘宝，打印了页面代码之后关闭浏览器\n查找节点单个节点我们要想从淘宝页面中提取搜索框这个节点，首先就要观察这个页面的源代码，我们发现淘宝页面输入框的id属性值是q，name属性值也是q，此外，还有许多其他属性，我们可以用多种方式获取它们，例如find_element_by_name是根据name属性获取，find_element_by_id是根据id属性获取，此外还有更新Xpth、CSS选择器等的获取方式\nfrom selenium import webdriverbrowser = webdriver.Chrome()browser.get(&#x27;https://www.taobao.com&#x27;)input_first = browser.find_element_by_id(&#x27;q&#x27;)  # 根据name属性获取input_second = browser.find_element_by_css_selector(&#x27;#q&#x27;)  # 用CSS选择器方式input_third = browser.find_element_by_xpath(&#x27;//*[@id=&quot;q&quot;]&#x27;)  # 用Xpth方式print(input_first, input_second, input_third)browser.close()\n\n获取单个节点可以使用如下方式:\n\nfind_element_by_id()\nfind_element_by_name()\nfind_element_by_xpath()\nfind_element_by_link_text()\nfind_element_by_partial_link_text()\nfind_element_by_tag_name()\nfind_element_by_class_name()\nfind_element_by_css_selector\n\n除了上述方法，Selenium还提供了通用方法find_element()，比如find_element_by_id(id)就等价于find_element(By.ID, id)，我们来看下实例代码:\nfrom selenium import webdriverfrom selenium.webdriver.common.by import Bybrowser = webdriver.Chrome()browser.get(&#x27;https://www.taobao.com&#x27;)input_first = browser.find_element(By.ID, &#x27;q&#x27;)print(input_first)browser.close()\n\n多个节点单个节点使用find_element()，如果目标节点是多个，那就使用find_elements()，首先我们同样来看看单个方法的方式:\nfrom selenium import webdriverbrowser = webdriver.Chrome()browser.get(&#x27;https://www.taobao.com&#x27;)lis = browser.find_elements_by_css_selector(&#x27;.service-bd li&#x27;)print(lis)browser.close()\n\n以上返回的节点都是WebElement类型，使用find_elements_by…就可返回多个节点，获取多个节点可以使用方式:\n\nfind_elements_by_id()\nfind_elements_by_name()\nfind_elements_by_xpath()\nfind_elements_by_link_text()\nfind_elements_by_partial_link_text()\nfind_elements_by_tag_name()\nfind_elements_by_class_name()\nfind_elements_by_css_selector\n\n同样的，我们也可直接使用find_elements()，以上代码可以改写为:\nlis = browser.find_elements(By.CSS_SELECTOR&#x27;.service-bd li&#x27;)\n\n节点交互Selenium可以驱动浏览器执行一些操作，比较常见的用法有:用send_keys()输入文字，用clear()清空文字，用click()点击按钮，实例如下:\nfrom selenium import webdriverimport timebrowser = webdriver.Chrome()browser.get(&#x27;https://www.taobao.com&#x27;)input = browser.find_element_by_id(&#x27;q&#x27;)input.send_keys(&#x27;iPhone&#x27;)time.sleep(1)input.clear()input.send_keys(&#x27;iPad&#x27;)button = browser.find_element_by_class_name(&#x27;btn-search&#x27;)button.click()\n\n动作链上面提到的都是单个动作，但是我们如果要完成比如鼠标拖拽、键盘按键这些操作时，那就需要用另一种方式执行，那就是动作链\n例如，可以这样实现拖拽的动作:\nfrom selenium import webdriverfrom selenium.webdriver import ActionChainsbrowser = webdriver.Chrome()url = &#x27;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#x27;browser.get(url)browser.switch_to.frame(&#x27;iframeResult&#x27;)  # 切换frame，因为节点在子页面source = browser.find_element_by_css_selector(&#x27;#draggable&#x27;)target = browser.find_element_by_css_selector(&#x27;#droppable&#x27;)actions = ActionChains(browser)actions.drag_and_drop(source, target)actions.perform()  # 执行\n\n由于我的chrome的安装问题这里就不贴案例图片了\n运行JavaScript还有一些操作，Selenium并没有提供API，例如下拉进度条，这种情况我们就可以模拟运行JavaScript，使用execute_script()可以实现，如下实例所示:\nfrom selenium import webdriverbrowser = webdriver.Chrome()browser.get(&#x27;https://www.zhihu.com/explore&#x27;)browser.execute_script(&#x27;window.scrollTo(0, document.body.scrollHeight)&#x27;)browser.execute_script(&#x27;alert(&quot;To Bottom&quot;)&#x27;)\n\n获取节点信息前面我们已经通过page_source获取了网页的源代码，下面就可以使用解析库(正则、Beautiful Soup、pyquery等)从中提取信息了，不过，既然Selenium已经提供了选择节点的方法，返回结果是WebElemet类型，那么它肯定也有相关的方法和属性用来直接获取节点信息，我们来看看:\n\n获取属性\n可以使用get_attribute方法获取节点的属性，但前提是得先选中这个节点:\nfrom selenium import webdriverbrowser = webdriver.Chrome()url = &#x27;https://dynamic2.scrape.cuiqingcai.com/&#x27;browser.get(url)logo = browser.find_element_by_class_name(&#x27;logo-image&#x27;)print(logo)print(logo.get_attribute(&#x27;src&#x27;))\n获取文本值\n可以使用text属性获取文本值:\nfrom selenium import webdriverbrowser = webdriver.Chrome()url = &#x27;https://dynamic2.scrape.cuiqingcai.com/&#x27;browser.get(url)input = browser.find_element_by_class_name(&#x27;logo-title&#x27;)print(input.text)\n获取ID、位置、标签名和大小\n除了属性和文本值，WebElemet节点还有一些其他属性，例如id属性用于获取节点ID，location属性用于获取节点在页面中的相对位置，tag_name属性用于获取标签的名称，size属性用于获取节点的大小，也就是宽高，有些时候这些属性还是挺重要的，示例如下:\nfrom selenium import webdriverbrowser = webdriver.Chrome()url = &#x27;https://dynamic2.scrape.cuiqingcai.com/&#x27;browser.get(url)input = browser.find_element_by_class_name(&#x27;logo-title&#x27;)print(input.id)print(input.location)print(input.tag_name)print(input.size)\n\n切换Frame我们知道网页中有一种节点叫做iframe，也就是子Frame，相当于页面的子页面，它的结构和外部网页的结构完全一致，Selenimu打开一个页面后，默认是在父页面里操作，此时这个页面中如果还有子Frame，它是不能获取子Frame里的节点的，这时就需要使用switch_to.frame方法切换Frame，示例如下:\nimport timefrom selenium import webdriverfrom selenium.common.exceptions import NoSuchElementExceptionbrowser = webdriver.Chrome()url = &#x27;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#x27;browser.get(url)browser.switch_to.frame(&#x27;iframeResult&#x27;)  # 切换到子Frame中try:    logo = browser.find_element_by_class_name(&#x27;logo&#x27;)  #尝试获取其中的logo节点except NoSuchElementException:  # 如果没找到logo节点就会抛出异常(这边实际上是没有的)    print(&#x27;NO LOGO&#x27;)browser.switch_to.parent_frame()  # 切换回父Framelogo = browser.find_element_by_class_name(&#x27;logo&#x27;)  # 重新获取logoprint(logo)print(logo.text)\n\n延时等待在Selenium中，get方法在网页框架加载完毕之后才会结束执行，如果我们在get方法执行完毕时获取网页源代码，其结果可能并不是浏览器完全加载完成的页面，因为某些页面有额外的Ajax请求，页面还会经由JavaScript渲染，所以，在必要的时候，我们需要设置浏览器延时等待一段时间，确保节点已经加载出来\n这里方式有两种，一种是隐式等待，一种是显式等待\n\n隐式等待\n使用隐式等待执行测试时，如果Selenium没有在DOM中找到节点，将继续等待，在超出设定时间后，将抛出找不到节点的异常，默认的等待时间是0\nfrom selenium import webdriverbrowser = webdriver.Chrome()browser.implicitly_wait(10)browser.get(&#x27;https://dynamic2.scrape.cuiqingcai.com/&#x27;)input = browser.find_element_by_class_name(&#x27;logo-image&#x27;)print(input)\n显式等待\n\n\n隐式等待的效果其实不太好，因为我们只规定了一个固定的时间，而页面的加载时间会受网络条件影响，还有一种方式就是显式等待，这种方式会指定要查找的节点和最长等待时间，如果在规定的时间内加载出了要查找的节点，就返回这个节点，如果到了规定的时间依然没有加载出节点，就抛出超时异常\nfrom selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECbrowser = webdriver.Chrome()browser.get(&#x27;https://www.taobao.com/&#x27;)wait = WebDriverWait(browser, 10)input = wait.until(EC.presence_of_element_located((By.ID, &#x27;q&#x27;)))button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, &#x27;.btn-search&#x27;)))print(input, button)\n\n这里首先引入WebDriver对象，指定最长等待时间为10，并赋值给wait变量，然后调用wait的until方法，传入等待条件；这里先传入了presence_of_element_located这个条件，代表节点出现，其参数是节点的定位元组(By.ID, ‘q’)；然后传入的等待条件是element_to_be_clickable，代表按钮可点击，其参数是利用css查找的定位元组(By.CSS_SELECTOR, ‘.btn-search’)\n更多的等待条件可以见书本\n前进和后退使用froword方法前进，使用back方法后退，示例如下:\nimport timefrom selenium import webdriverbrowser = webdriver.Chrome()browser.get(&#x27;https://www.baidu.com/&#x27;)browser.get(&#x27;https://www.taobao.com/&#x27;)browser.get(&#x27;https://www.python.org/&#x27;)browser.back()time.sleep(1)browser.forward()browser.close()\n\n这里我们打开了3个页面，然后调用back方法回到第2个页面，接着调用forword方法又前进到第3个页面\nCookie使用Selenium，还可以方便地对Cookie进行操作，例如获取、添加、删除等，示例如下:\nfrom selenium import webdriverbrowser = webdriver.Chrome()browser.get(&#x27;https://www.zhihu.com/explore&#x27;)print(browser.get_cookies())  # 获取browser.add_cookie(&#123;&#x27;name&#x27;: &#x27;name&#x27;, &#x27;domain&#x27;: &#x27;www.zhihu.com&#x27;, &#x27;value&#x27;: &#x27;germey&#x27;&#125;)  # 添加print(browser.get_cookies())browser.delete_all_cookies()  # 删除print(browser.get_cookies())\n\n选项卡管理在访问网页的时候，会开启一个个选项卡，在selenium中，我们也可以对选项卡做操作，示例如下:\nimport timefrom selenium import webdriverbrowser = webdriver.Chrome()browser.get(&#x27;https://www.baidu.com&#x27;)browser.execute_script(&#x27;window.open()&#x27;)  # 开启一个新的选项卡print(browser.window_handles)browser.switch_to.window(browser.window_handles[1])  # 切换到新开的选项卡browser.get(&#x27;https://www.taobao.com&#x27;)time.sleep(1)browser.switch_to.window(browser.window_handles[0])  # 回到原来的选项卡browser.get(&#x27;https://python.org&#x27;)\n\n异常处理在使用Selenium的过程中，难免会遇到一些异常，例如超时、节点未找到等，一旦出现此类异常，程序便不会再继续运行了，此时我们可以使用try…except语句捕获各种异常，NoSuchElementException表示节点未找到\n反屏蔽现在有很多网站增加了对Selenium的检测，防止一些爬虫的恶意爬取，如果检测到有人使用Selenium打开浏览器，就直接屏蔽，在大多数情况下，检测的基本原理是检测当前浏览器窗口下的window.navigator对象中是否包含webdriver属性，因为在正常使用浏览器时，这个属性应该是undefined，一旦使用了Selenium，它就会给window.navigator对象设置webdriver属性，很多网站就是通过这个JavaScript语句判断是否存在webdriver属性，如果存在就直接屏蔽\n一个典型的案例网站https://antispider.scrape.center/就是使用上述原理，检测是否存在webdriver属性，如果我们使用Selenium直接爬取该网站的数据，网站就会返回`Webdriver Rrobidden`\n这时可能有人会直接使用JavaScript语句把webdriver属性置空不就行了，例如调用execuet_script方法执行这行代码:\nObject.defineProperty(navigator, &quot;webdriver&quot;, &#123;get: () =&gt; undefined)\n\n这行代码确实可以把webdriver属性置空，但execute_script方法是在页面加载完毕之后才调用的，这个时候调用就太晚了，网页早就检测到webdriver属性了，所以这个方法行不通\n在Selenium中，可以用CDP(即Chrome Devtools Protocol)，解决这个问题，利用它可以实现在每个页面刚加载的时候就执行JavaScript语句，将webdriver属性置空，另外还可以加入几个选项来隐藏Webdriver提示条和自动化扩展信息，代码实现如下:\nfrom selenium import webdriverfrom selenium.webdriver import ChromeOptionsoption = ChromeOptions()option.add_experimental_option(&#x27;excludeSwitches&#x27;, [&#x27;enable-automation&#x27;])option.add_experimental_option(&#x27;useAutomationExtension&#x27;, False)browser = webdriver.Chrome(options=option)browser.execute_cdp_cmd(&#x27;Page.addScriptToEvaluateOnNewDocument&#x27;, &#123;    &#x27;source&#x27;: &#x27;Object.defineProperty(navigator, &quot;webdriver&quot;, &#123;get: () =&gt; undefined&#125;)&#x27;&#125;)browser.get(&#x27;https://antispider1.scrape.cuiqingcai.com/&#x27;)\n\n在大多数时候，以上方式可以实现Selenium的反屏蔽，但也存在一些特殊网站会对Wdbdriver属性设置更多的特征检测，这种情况下就要具体排查了\n无头模式在上面的案例中，都会弹出一个浏览器窗口，虽然有助于观察页面的爬取状况，但窗口弹来弹去有时也会造成一些干扰\nChrome浏览器从60版本开始，已经开启了对无头浏览器的支持，即Headless，我们可以借助ChromeOptions对象开启Chrome浏览器的无头模式，代码实现如下:\nfrom selenium import webdriverfrom selenium.webdriver import ChromeOptionsoption = ChromeOptions()option.add_argument(&#x27;--headless&#x27;)browser = webdriver.Chrome(options=option)browser.set_window_size(1366, 768)browser.get(&#x27;https://www.baidu.com&#x27;)browser.get_screenshot_as_file(&#x27;preview.png&#x27;)  # 页面截图\n\nSplash的使用Splash是一个JavaScript渲染服务，是一个含有HTTP API的轻量级浏览器，它还对接了Python中的Twisted库和QT库，利用它，同样可以爬取动态渲染的页面\n功能介绍\n异步处理多个网页的渲染过程\n获取渲染后页面的源代码或截图\n通过关闭图片渲染或者使用Adblock规则的方式加快页面渲染的速度\n执行特定的JavaScript脚本\n通过Lua脚本控制页面的渲染过程\n获取页面渲染的详细过程并以HAR(HTTP Archive)的格式呈现出来\n\n准备工作请确保Splash已经正确安装并可以在本地8050端口上正常运行，安装方法见: https://setup.scrape.center/splash\n由于我这工作电脑是win7的，安装docker-desktop比较麻烦，所以这部分还是见书本叭\nPyppeteer的使用在前面，我们使用了Selenium，其功能的确非常强大，但很多时候会发现它也有一些不太方便的地方，例如配置环境时，需要先安装好相关浏览器，例如Chrome、Firefox等，然后到官方网站下载对应的驱动，最重要的是得看版本是否对应，另外，如果大规模部署Selenium，一些环境配置问题也是很头疼的，这里我们介绍Selenium的一个替代品: Pyppeteer\nPyppeteer介绍PupeteerGoogle基于node.js开发的一个工具，有了它，我们可以利用JavaScript控制Chrome浏览器的一些操作；当然，Puppeteer也可以应用于网络爬虫上，其API极其完善，功能非常强大\nPyppeteer又是什么呢，它其实是Puppeteer的Python版实现，但不是Google开发的，是由一位来自日本的工程师依据Puppeteer的一些功能开发出来的非官方版本\nPyppeteer的背后实际上有一个类似于Chrome的浏览器—-Chromium，它执行一些动作，从而进行网页渲染，总的来说，两款浏览器的内核一样，实现方式也一样，可以看作开发版和正式版，功能上没有太大区别\nPyppeteer就是依赖Chromium浏览器运行的，第一次运行Pyppeteer的时候，没有安装Chroimium浏览器，程序会自动帮我们安装和配置好，免去了琐碎的环境配置等工作，另外，Pyppeteer是基于Python的新特性async实现的，所以它的一些操作执行也支持异步方式，和Selenium相比效率也提高了\n安装由于Pyppeteer采用了Python的async机制，所以要求Python版本为3.5以上\n安装命令如下:\npip install pyppeteer\n\n快速上手测试网址: https://spa2.scrape.center/，这个网站在前面已经分析过了整个页面是用JavaScript渲染出来的，一些Ajax接口还带有加密参数，所以没法直接用requests爬取看到数据，同时也不太好直接模拟，Ajax来获取数据；在前面我们使用的是Selenium，这里我们试试Pyppeteer:\nimport asynciofrom pyppeteer import launchfrom pyquery import PyQuery as pqasync def main():    browser = await launch()  # 调用launch方法新建了一个Browser对象，相当于启动了了浏览器    page = await browser.newPage()  # 相当于在浏览器中新建一个选项卡    await page.goto(&#x27;https://dynamic2.scrape.cuiqingcai.com/&#x27;)  # 相当于在浏览器中输入goto方法的参数中的URL，之后浏览器加载对应的页面    await page.waitForSelector(&#x27;.item .name&#x27;)  # 传入选择器，页面会等待选择器对应的节点信息加载出来后就立即返回，否则持续等待直到超时    doc = pq(await page.content())  # 获取当前浏览器页面的源代码，这就是JavaScript渲染后的结果    names = [item.text() for item in doc(&#x27;.item .name&#x27;).items()]    print(&#x27;Names:&#x27;, names)    await browser.close()asyncio.get_event_loop().run_until_complete(main())\n\n相比来说是比Selenium简单点，接下来我们来看看另一个例子:\nimport asynciofrom pyppeteer import launchwidth, height = 1366, 768async def main():    browser = await launch()    page = await browser.newPage()    await page.setViewport(&#123;&#x27;width&#x27;: width, &#x27;height&#x27;: height&#125;)  # 设置页面窗口大小    await page.goto(&#x27;https://dynamic2.scrape.cuiqingcai.com/&#x27;)    await page.waitForSelector(&#x27;.item .name&#x27;)    await asyncio.sleep(2)    await page.screenshot(path=&#x27;example.png&#x27;)  # 保存页面截图    dimensions = await page.evaluate(&#x27;&#x27;&#x27;() =&gt; &#123;        return &#123;            width: document.documentElement.clientWidth,            height: document.documentElement.clientHeight,            deviceScaleFactor: window.devicePixelRatio,        &#125;    &#125;&#x27;&#x27;&#x27;)  # 调用evaluate执行JavaScript语句并返回了对应的数据，是一个json格式的对象        print(dimensions)    await browser.close()asyncio.get_event_loop().run_until_complete(main())\n\n在screenshot方法中，我们通过path参数用于传入页面截图的保存路径，另外还可以指定截图的保存格式type、清晰度quality、是否全屏fullpage和裁切clip等参数\nPyppeteer所有的用法都在其官方文档中，我们不用死记硬背，即查即用即可: https://pyppeteer.github.io/pyppeteer/reference.html\nlaunch方法launch方法相当于双击桌面上的浏览器图标，用于启动浏览器\nlaunch方法的API链接为: https://pyppeteer.github.io/pyppeteer/reference.html#launcher，具体可查看这个链接，也可结合书本246页\n无头模式无头模式，launch方法中使用参数headless，将它设置为False就是在启动的时候可以看到界面，反之则看不到，示例代码如下:\nimport asynciofrom pyppeteer import launchasync def main():    await launch(headless=False)  # 显示浏览器界面    await asyncio.sleep(100)asyncio.get_event_loop().run_until_complete(main())\n\n调试模式调试模式，launch方法中使用参数devtools，将它设置为True就会在开启页面的时候会弹出一个调试窗口，示例如下:\nimport asynciofrom pyppeteer import launchasync def main():    browser = await launch(devtools=True)    page = await browser.newPage()    await page.goto(&#x27;https://www.baidu.com&#x27;)    await asyncio.sleep(100)asyncio.get_event_loop().run_until_complete(main())\n\n\n禁用提示条如上图片所示，有一个提示，’Chrome正受到自动测试软件的控制’，这个提示有点烦人，我们可以使用args参数关闭:\nbrowser = await launch(devtools=True, args=[&#x27;--disable-infobars&#x27;])\n\n防止检测刚刚只是把提示关闭了，有些网站还是能检测到Webdriver属性，不妨拿之前的案例网站https://antispider1.scrape.center/验证下:\nimport asynciofrom pyppeteer import launchasync def main():    browser = await launch(devtools=True, args=[&#x27;--disable-infobars&#x27;])    page = await browser.newPage()    await page.goto(&#x27;https://antispider1.scrape.center/&#x27;)    await asyncio.sleep(100)asyncio.get_event_loop().run_until_complete(main())\n\n\n果然就被检测出来了，这说明Pyppeteer开启Chromium后，照样能被检测到Webdriver属性的存在\n那么如何规避此问题呢，Pyppeteer的page对象有一个叫做evaluateOneNewDocument的方法，意思是在每次加载网页的时候执行某条语句，这里可以利用它执行隐藏Webdriver属性的命令，代码改写如下:\nimport asynciofrom pyppeteer import launchasync def main():    browser = await launch(devtools=True, args=[&#x27;--disable-infobars&#x27;])    page = await browser.newPage()    await page.evaluateOnNewDocument(&#x27;Object.defineProperty(navigator, &quot;webdriver&quot;, &#123;get: () =&gt; undefined&#125;)&#x27;)    await page.goto(&#x27;https://antispider1.scrape.center/&#x27;)    await asyncio.sleep(100)asyncio.get_event_loop().run_until_complete(main())\n\n这样就加载出来了:\n\n页面大小设置这时我们可以设置窗口大小，调用Page对象的setViewport方法即可，代码如下:\nimport asynciofrom pyppeteer import launchwidth, height = 1366, 768async def main():    browser = await launch(headless=False, args=[&#x27;--disable-infobars&#x27;, f&#x27;--window-size=&#123;width&#125;,&#123;height&#125;&#x27;])  # 这里设置了浏览器的宽高    page = await browser.newPage()    await page.setViewport(&#123;&#x27;width&#x27;: width, &#x27;height&#x27;: height&#125;)  # 这里设置了显示区域的宽高    await page.evaluateOnNewDocument(&#x27;Object.defineProperty(navigator, &quot;webdriver&quot;, &#123;get: () =&gt; undefined&#125;)&#x27;)    await page.goto(&#x27;https://antispider1.scrape.cuiqingcai.com/&#x27;)    await asyncio.sleep(100)asyncio.get_event_loop().run_until_complete(main())\n\n这里我们同时设置了浏览器窗口的宽高以及显示区域的宽高，让二者保持一致\n用户数据持久化我们发现，每次打开Pyppeteer都是一个新的空白的浏览器，如果网页需要登录，那么下次打开同样需要登录，这是因为它默认没保存cookie，既然要下次还处于登录状态，那么就是需要存储一些数据，那么这些数据保存到哪里呢？答案是用户目录下，其中不仅包括浏览器的基本配置信息，还包括一些Cache、cookie等信息，如果我们能在浏览器启动的时候读取这些信息，就可恢复一些历史记录甚至登录状态信息了，那么如何设置用户目录呢？很简单，在启动浏览器的时候设置userDataDir属性就好了，示例如下:\nimport asynciofrom pyppeteer import launchwidth, height = 1366, 768async def main():    browser = await launch(headless=False, userDataDir=&#x27;./userdata&#x27;,                           args=[&#x27;--disable-infobars&#x27;, f&#x27;--window-size=&#123;width&#125;,&#123;height&#125;&#x27;])    page = await browser.newPage()    await page.setViewport(&#123;&#x27;width&#x27;: width, &#x27;height&#x27;: height&#125;)    await page.goto(&#x27;https://www.taobao.com&#x27;)    await asyncio.sleep(100)asyncio.get_event_loop().run_until_complete(main())\n\nBrowser我们了解了launch方法，它的返回值是一个Browser对象，也就是浏览器对象，我们通常会将其赋值给browser变量，它就是Browser的一个实例，browser作为Browser的实例，自然有很多用于操作浏览器的方法，下面我们选取一些比较有用的方法介绍下:\n开启无痕模式我们知道Chrome浏览器有无痕模式，其好处就是环境比较干净，不与其他浏览器示例共享Cache、cookie等内容，可以通过createIncognitoBrowserContext方法开启无痕模式，示例如下:\nimport asynciofrom pyppeteer import launchwidth, height = 1200, 768async def main():    browser = await launch(headless=False,                           args=[&#x27;--disable-infobars&#x27;, f&#x27;--window-size=&#123;width&#125;,&#123;height&#125;&#x27;])    context = await browser.createIncognitoBrowserContext()    page = await context.newPage()    await page.setViewport(&#123;&#x27;width&#x27;: width, &#x27;height&#x27;: height&#125;)    await page.goto(&#x27;https://www.baidu.com&#x27;)    await asyncio.sleep(100)asyncio.get_event_loop().run_until_complete(main())\n\n关闭使用close方法关闭浏览器，很多时候会因为忘记关闭浏览器而产生额外的开销\nPagepage即页面，对应一个网页，一个选项卡，下面来看看它的一些常见用法\n\n选择器\npage对象内置了很多用于选取节点的选择器方法，例如J方法，给它传入一个选择器，就能返回匹配到的第一个节点，等价于querySelector方法；又如JJ方法，给它传入选择器，会返回符合选择器的所有节点组成的列表，等价于querySectorAll方法，下面我们分别调用了J方法、querySelector方法、JJ方法、和querySelectorAll方法\nimport asynciofrom pyppeteer import launchfrom pyquery import PyQuery as pqasync def main():    browser = await launch()    page = await browser.newPage()    await page.goto(&#x27;https://dynamic2.scrape.cuiqingcai.com/&#x27;)    await page.waitForSelector(&#x27;.item .name&#x27;)    j_result1 = await page.J(&#x27;.item .name&#x27;)    j_result2 = await page.querySelector(&#x27;.item .name&#x27;)    jj_result1 = await page.JJ(&#x27;.item .name&#x27;)    jj_result2 = await page.querySelectorAll(&#x27;.item .name&#x27;)    print(&#x27;J Result1:&#x27;, j_result1)    print(&#x27;J Result2:&#x27;, j_result2)    print(&#x27;JJ Result1:&#x27;, jj_result1)    print(&#x27;JJ Result2:&#x27;, jj_result2)    await browser.close()asyncio.get_event_loop().run_until_complete(main())\n\n运行结果如下:\nJ Result1: &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E565C8&gt;J Result2: &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E5BC48&gt;JJ Result1: [&lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E63888&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E63BC8&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E63A08&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E63C88&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E63808&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E61E88&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E61E08&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E61DC8&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E61E48&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E61D88&gt;]JJ Result2: [&lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E63F48&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E63948&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E631C8&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E63388&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E638C8&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E5BCC8&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E5B388&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E5B348&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E5BC88&gt;, &lt;pyppeteer.element_handle.ElementHandle object at 0x0000000003E5B308&gt;]\n\n可以看到J方法和querySelector方法的返回结果都是传入的选择器相匹配的单个节点，返回值为ElementHandle对象；JJ方法和querySectorAll方法则都是返回了和选择器相匹配的节点组成的列表，列表中的内容是ElementHandle对象\n\n选项卡操作\n前面使用的newPage方法用于新建选项卡的操作，那么新建选项卡之后怎么获取和切换呢？我们可以先调用pages方法获取所有打开的页面，然后选择一个页面调用其bringToFront方法即可，来看看例子:\nimport asynciofrom pyppeteer import launchasync def main():    browser = await launch(headless=False)    page = await browser.newPage()    await page.goto(&#x27;https://www.baidu.com&#x27;)    page = await browser.newPage()    await page.goto(&#x27;https://www.bing.com&#x27;)    pages = await browser.pages()    print(&#x27;Pages:&#x27;, pages)    page1 = pages[1]    await page1.bringToFront()    await asyncio.sleep(100)asyncio.get_event_loop().run_until_complete(main())\n\n效果如下:\n\n\n页面操作\n一定要有对应的方法来控制一个页面的加载、前进、后退、关闭和保存等行为，示例如下:\nimport asynciofrom pyppeteer import launchfrom pyquery import PyQuery as pqasync def main():    browser = await launch(headless=False)    page = await browser.newPage()    await page.goto(&#x27;https://cuiqingcai.com/31099.html/&#x27;)    await page.goto(&#x27;https://www.cnblogs.com/youyouxiaosheng-lh/p/11212340.html&#x27;)    # 后退    await page.goBack()    # 前进    await page.goForward()    # 刷新    await page.reload()    # 保存 PDF    await page.pdf()  # 运行显示还未实现    # 截图    await page.screenshot()    # 设置页面 HTML    await page.setContent(&#x27;&lt;h2&gt;Hello World&lt;/h2&gt;&#x27;)    # 设置 User-Agent    await page.setUserAgent(&#x27;Python&#x27;)    # 设置 Headers    await page.setExtraHTTPHeaders(headers=&#123;&#125;)    # 关闭    await page.close()    await browser.close()asyncio.get_event_loop().run_until_complete(main())\n点击\nPyppeteer同样可以模拟点击，调用其click方法即可；以https://spa2.scrape.center/为例，等其所有节点都加载出来之后，模拟邮件点击:\nimport asynciofrom pyppeteer import launchfrom pyquery import PyQuery as pqasync def main():    browser = await launch(headless=False)    page = await browser.newPage()    await page.goto(&#x27;https://spa2.scrape.center/&#x27;)    await page.waitForSelector(&#x27;.item .name&#x27;)    await page.click(&#x27;.item .name&#x27;, options=&#123;        &#x27;button&#x27;: &#x27;right&#x27;,        &#x27;clickCount&#x27;: 1,  # 1 or 2        &#x27;delay&#x27;: 3000,  # 毫秒    &#125;)    await asyncio.sleep(100)    await browser.close()asyncio.get_event_loop().run_until_complete(main())\n\n\n这里click方法中的第一个参数就是选择器，即在哪里操作；第二个参数是几项配置，具体有以下内容:\n\nbutton: 鼠标按钮，取值有left、middle、right\nclickCount: 点击次数，取值有1和2，表示单击和双击\ndelay: 延迟点击\n\n\nPyppeteer也可以输入文本，使用type方法即可，示例如下:\nimport asynciofrom pyppeteer import launchfrom pyquery import PyQuery as pqasync def main():    browser = await launch(headless=False)    page = await browser.newPage()    await page.goto(&#x27;https://www.taobao.com&#x27;)    # 后退    await page.type(&#x27;#q&#x27;, &#x27;iPad&#x27;)    # 关闭    await asyncio.sleep(10)    await browser.close()asyncio.get_event_loop().run_until_complete(main())\n\n效果如下:\n\n这里我们打开了淘宝，给type方法的第一个参数传入选择器，第二个参数传入要输入的内容\n\n获取信息\nPage对象需要调用content方法获取源码，Cookie对象调用cookies方法获取，示例如下:\nimport asynciofrom pyppeteer import launchfrom pyquery import PyQuery as pqasync def main():    browser = await launch(headless=False)    page = await browser.newPage()    await page.goto(&#x27;http://www.baidu.com&#x27;)    print(&#x27;HTML:&#x27;, await page.content())    print(&#x27;Cookies:&#x27;, await page.cookies())    await browser.close()asyncio.get_event_loop().run_until_complete(main())\n执行\nPyppeteer可以支持执行JavaScript语句，使用evaluate方法即可，我们来看一个例子:\nimport asynciofrom pyppeteer import launchasync def main():    browser = await launch()    page = await browser.newPage()    await page.goto(&#x27;http://quotes.toscrape.com/js/&#x27;)    await page.screenshot(path=&#x27;example.png&#x27;)    await page.pdf(path=&#x27;example.pdf&#x27;)    dimensions = await page.evaluate(&#x27;&#x27;&#x27;() =&gt; &#123;        return &#123;            width: document.documentElement.clientWidth,            height: document.documentElement.clientHeight,            deviceScaleFactor: window.devicePixelRatio,        &#125;    &#125;&#x27;&#x27;&#x27;)    print(dimensions)    # &gt;&gt;&gt; &#123;&#x27;width&#x27;: 800, &#x27;height&#x27;: 600, &#x27;deviceScaleFactor&#x27;: 1&#125;    await browser.close()asyncio.get_event_loop().run_until_complete(main())\n延时等待\n在本文章最开头的地方，我们演示了waitForSelector的用法，它可以让页面等待某些符合条件的节点加载出来再返回结果；例如这里我们给waitForSelector传入一个css选择器，如果找到符合条件的节点，就立马返回结果，否则等待直到超时，下面我们来看看其他的:\n\nwaitForFunction: 等待某个Java方法执行完毕或返回结果\nwaitForNavigation: 等待页面跳转，如果没加载出来，就报错\nwaitForRequest: 等待某个特定的请求发出\nwaitFOrResponse: 等待某个特定的请求对应的响应\nwaitFor: 通用的等待方法\nwaitForXpth: 等待符合xpath的节点加载出来\n\n\n\n总结Pyppeteer还有其他很多功能，例如键盘事件、鼠标事件、对话框事件等，这里就不再一一赘述了，更多内容可以查看官方文档: https://miyakogi.github.io/pyppeteer/reference.html\nPlaywright的使用Playwright的特点\n支持当前所有主流浏览器，包括Chrome和Edge(基于Chromium)、Filefox、Safari(基于WebKit)，提供完善的自动化控制的API\n支持移动端页面测试，使用设备模拟技术，可以让我们在移动Web浏览器中测试响应式的Web应用程序\n支持所有浏览器的无头和非无头模式的测试\n安装和配置过程非常简单，安装过程中会自动安装对应的浏览器和驱动，不需要额外配置WebDriver\n提供自动等待相关的API，在页面加载时会自动等待对应的节点加载，大大减小了API编写的复杂度\n\n安装首先请确保Python的版本大于或等于3.7，直接使用pip工具安装，命令如下:\npip3 install playwright\n\n具体的安装说明可以参考: https://setup.scrape.center/playwright\n基本使用playwright支持两种编写模式，一种是和Pyppeteer一样的异步模式，另一种是和Selenium一样的同步模式，可以根据实际需要选择不同的模式，下面先来看一个同步模式的例子:\nfrom playwright.sync_api import sync_playwrightwith sync_playwright() as p:    for browser_type in [p.chromium, p.firefox, p.webkit]:        browser = browser_type.launch(headless=False)        page = browser.new_page()        page.goto(&#x27;https://www.baidu.com&#x27;)        page.screenshot(path=f&#x27;screenshot-&#123;browser_type.name&#125;.png&#x27;)        print(page.title())        browser.close()\n\n这里我们首先导入了并直接调用了sync_playwright方法，该方法的返回值是一个PlaywrightContextManger对象，可以理解为一个浏览器上下文管理器，我们将其赋值为P变量；然后依次调用p的chromium、firefox和webkit属性创建了Chromium、Firefox以及WebKit浏览器实例，接着用一个for循环依次执行了这3个浏览器的launch方法，同时设置headless的参数为false，如果不设置为false，这里我们将看不到任何效果，然后分别打印网页标题然后保存了浏览器截图\n这里由于我的playwright安装出了点问题，不知道是不是工作电脑的问题，现在报这个错:\n\n来看看异步模式:\nimport asynciofrom playwright.async_api import async_playwrightasync def main():    async with async_playwright() as p:        for browser_type in [p.chromium, p.firefox, p.webkit]:            browser = await browser_type.launch(headless=False)            page = await browser.new_page()            await page.goto(&#x27;https://www.baidu.com&#x27;)            await page.screenshot(path=f&#x27;screenshot-&#123;browser_type.name&#125;.png&#x27;)            print(await page.title())            await browser.close()asyncio.run(main())\n\n对比这两个代码，我们可以看到，写法和同步模式基本一样，只不过这里导入的是async_playwright方法，不再是sync_playwright方法，以及写法上添加了async/await关键字，最后的运行效果是和同步一样的，另外可以注意到，这个例子中使用了with as语句，with用于管理上下文对象，可以返回一个上下文管理器，即一个PlaywrightContextManger对象，无论代码运行期间是否抛出异常，该对象都能帮助我们自动分配并且释放Playwright的资源\n代码生成Playwright还有一个强大的功能，是可以录制我们在浏览器中的操作，并自动生成代码，有了这个功能，我们甚至可以一行代码不用写，这个功能可以通过playwright调用condegen实现，先来看下condgen命令都有什么参数，输入如下命令:\nplaywright codegen --help\n\n由于我工作的电脑的问题，我的playwright安装有点问题，以上命令无法执行，大家知道知道这个可以查看所有的参数即可\n了解了以上用法之后，我们来尝试启动一个Firefox浏览器，然后将操作结果输出到script.py文件，命令如下:\nplaywright codegen -o script.py -b firefox\n\n运行代码后会弹出一个Firefox浏览器，同时右侧输出一个脚本窗口，实时显示当前操作对应的代码；我们可以在浏览器中随意操作，例如打开百度，点击搜索框并输入nba，再点击搜索按钮，由于无法使用playwright，这里我就用语言描述下:\n浏览器会高亮显示我们正在操作的页面节点，同时显示对应的节点信息，在操作浏览器的过程中，该窗口中的代码会跟着实时变化，所有操作完成后，关闭浏览器后，playwright会生成一个scrit.py文件，这个生成的代码和我们之前写的示例代码几乎差不多，而且也是可以运行的，运行之后会看到它在复现我们刚才所做的操作，所以，有了代码生成功能，只通过简单的可视化点击就能生成代码，可谓非常方便，另外这还有一个值得注意的点，仔细观察一下生成的代码，和前面例子不同的是，这里的new_page方法并不是直接通过browser调用的，而是通过context，这个context又是由browser调用new_context方法生成的，那么这个context究竟是做什么的呢，其实context变量是一个BrowserContext对象，这是一个类似隐身模式的独立上下文环境，其运行资源是单独隔离的，在一些自动化测试过程中，我们可以为每个测试用例单独创建一个BroserContext对象，这样能够保证各个测试用例互不干扰\n支持移动端浏览器示例代码如下:\nfrom playwright.sync_api import sync_playwrightwith sync_playwright() as p:    iphone_12_pro_max = p.devices[&#x27;iPhone 12 Pro Max&#x27;]    browser = p.webkit.launch(headless=False)    context = browser.new_context(        **iphone_12_pro_max,        locale=&#x27;zh-CN&#x27;,        geolocation=&#123;&#x27;longitude&#x27;: 116.39014, &#x27;latitude&#x27;: 39.913904&#125;,        permissions=[&#x27;geolocation&#x27;]    )    page = context.new_page()    page.goto(&#x27;https://amap.com&#x27;)    page.wait_for_load_state(state=&#x27;networkidle&#x27;)    page.screenshot(path=&#x27;location-iphone.png&#x27;)    browser.close()\n\n这里我们先用 PlaywrightContextManager 对象的 devices 属性指定了一台移动设备，这里传入的是手机的型号，比如 iPhone 12 Pro Max，当然也可以传其他名称，比如 iPhone 8，Pixel 2 等。\n前面我们已经了解了 BrowserContext 对象，BrowserContext 对象也可以用来模拟移动端浏览器，初始化一些移动设备信息、语言、权限、位置等信息，这里我们就用它来创建了一个移动端 BrowserContext 对象，通过 geolocation 参数传入了经纬度信息，通过 permissions 参数传入了赋予的权限信息，最后将得到的 BrowserContext 对象赋值为 context 变量。\n接着我们就可以用 BrowserContext 对象来新建一个页面，还是调用 new_page 方法创建一个新的选项卡，然后跳转到高德地图，并调用了 wait_for_load_state 方法等待页面某个状态完成，这里我们传入的 state 是 networkidle，也就是网络空闲状态。因为在页面初始化和加载过程中，肯定是伴随有网络请求的，所以加载过程中肯定不算 networkidle 状态，所以这里我们传入 networkidle 就可以标识当前页面和数据加载完成的状态。加载完成之后，我们再调用 screenshot 方法获取当前页面截图，最后关闭浏览器。\n运行下代码，可以发现这里就弹出了一个移动版浏览器，然后加载了高德地图，并定位到了故宫的位置，如图所示:\n\n选择器前面我们注意到 click 和 fill 等方法都传入了一个字符串，这些字符串有的符合 CSS 选择器的语法，有的又是 text= 开头的，感觉似乎没太有规律的样子，它到底支持怎样的匹配规则呢？下面我们来了解下。\n传入的这个字符串，我们可以称之为 Element Selector，它不仅仅支持 CSS 选择器、XPath，Playwright 还扩展了一些方便好用的规则，比如直接根据文本内容筛选，根据节点层级结构筛选等等\n文本选择文本选择支持直接使用 text= 这样的语法进行筛选，示例如下:\npage.click(&quot;text=Log in&quot;)\n\n这就代表选择文本是 Log in 的节点，并点击\nCSS选择器CSS 选择器之前也介绍过了，比如根据 id 或者 class 筛选:\npage.click(&quot;button&quot;)page.click(&quot;#nav-bar .contact-us-item&quot;)\n\n根据特定的节点属性筛选:\npage.click(&quot;[data-test=login-button]&quot;)page.click(&quot;[aria-label=&#x27;Sign in&#x27;]&quot;)\n\nCSS 选择器 + 文本我们还可以使用 CSS 选择器结合文本值进行海选，比较常用的就是 has-text 和 text，前者代表包含指定的字符串，后者代表字符串完全匹配，示例如下:\npage.click(&quot;article:has-text(&#x27;Playwright&#x27;)&quot;)page.click(&quot;#nav-bar :text(&#x27;Contact us&#x27;)&quot;)\n\n第一个就是选择文本中包含 Playwright 的 article 节点，第二个就是选择 id 为 nav-bar 节点中文本值等于 Contact us 的节点\nCSS 选择器 + 节点关系还可以结合节点关系来筛选节点，比如使用 has 来指定另外一个选择器，示例如下:\npage.click(&quot;.item-description:has(.item-promo-banner)&quot;)\n\n比如这里选择的就是选择 class 为 item-description 的节点，且该节点还要包含 class 为 item-promo-banner 的子节点\n另外还有一些相对位置关系，比如 right-of 可以指定位于某个节点右侧的节点，示例如下:\npage.click(&quot;input:right-of(:text(&#x27;Username&#x27;))&quot;)\n\n这里选择的就是一个 input 节点，并且该 input 节点要位于文本值为 Username 的节点的右侧\nXpath当然 XPath 也是支持的，不过 xpath 这个关键字需要我们自行制定，示例如下:\npage.click(&quot;xpath=//button&quot;)\n\n这里需要在开头指定 xpath= 字符串，代表后面是一个 XPath 表达式\n关于更多选择器的用法和最佳实践，可以参考官方文档：https://playwright.dev/python/docs/selectors\n常用操作方法上面我们了解了浏览器的一些初始化设置和基本的操作实例，下面我们再对一些常用的操作 API 进行说明。\n常见的一些 API 如点击 click，输入 fill 等操作，这些方法都是属于 Page 对象的，所以所有的方法都从 Page 对象的 API 文档查找，文档地址：https://playwright.dev/python/docs/api/class-page\n事件监听Page 对象提供了一个 on 方法，它可以用来监听页面中发生的各个事件，比如 close、console、load、request、response 等等。\n比如这里我们可以监听 response 事件，response 事件可以在每次网络请求得到响应的时候触发，我们可以设置对应的回调方法获取到对应 Response 的全部信息，示例如下:\nfrom playwright.sync_api import sync_playwrightdef on_response(response):    print(f&#x27;Statue &#123;response.status&#125;: &#123;response.url&#125;&#x27;)with sync_playwright() as p:    browser = p.chromium.launch(headless=False)    page = browser.new_page()    page.on(&#x27;response&#x27;, on_response)    page.goto(&#x27;https://spa6.scrape.center/&#x27;)    page.wait_for_load_state(&#x27;networkidle&#x27;)    browser.close()\n\n这里我们在创建 Page 对象之后，就开始监听 response 事件，同时将回调方法设置为 on_response，on_response 对象接收一个参数，然后把 Response 的状态码和链接都输出出来了\n运行之后可以看到控制台输出结果如下:\nStatue 200: https://spa6.scrape.center/Statue 200: https://spa6.scrape.center/css/app.ea9d802a.cssStatue 200: https://spa6.scrape.center/js/app.5ef0d454.jsStatue 200: https://spa6.scrape.center/js/chunk-vendors.77daf991.jsStatue 200: https://spa6.scrape.center/css/chunk-19c920f8.2a6496e0.css...Statue 200: https://spa6.scrape.center/css/chunk-19c920f8.2a6496e0.cssStatue 200: https://spa6.scrape.center/js/chunk-19c920f8.c3a1129d.jsStatue 200: https://spa6.scrape.center/img/logo.a508a8f0.pngStatue 200: https://spa6.scrape.center/fonts/element-icons.535877f5.woffStatue 301: https://spa6.scrape.center/api/movie?limit=10&amp;offset=0&amp;token=NGMwMzFhNGEzMTFiMzJkOGE0ZTQ1YjUzMTc2OWNiYTI1Yzk0ZDM3MSwxNjIyOTE4NTE5Statue 200: https://spa6.scrape.center/api/movie/?limit=10&amp;offset=0&amp;token=NGMwMzFhNGEzMTFiMzJkOGE0ZTQ1YjUzMTc2OWNiYTI1Yzk0ZDM3MSwxNjIyOTE4NTE5Statue 200: https://p0.meituan.net/movie/da64660f82b98cdc1b8a3804e69609e041108.jpg@464w_644h_1e_1cStatue 200: https://p0.meituan.net/movie/283292171619cdfd5b240c8fd093f1eb255670.jpg@464w_644h_1e_1c....Statue 200: https://p1.meituan.net/movie/b607fba7513e7f15eab170aac1e1400d878112.jpg@464w_644h_1e_1c\n\n这个网站我们之前分析过，其真实的数据都是 Ajax 加载的，同时 Ajax 请求中还带有加密参数，不好轻易获取，但有了这个方法之后，这里如果我们想要的Ajax请求，就非常容易了，改写下判定条件，输出对应的JSON结果，改写如下:\nfrom playwright.sync_api import sync_playwrightdef on_response(response):    if &#x27;/api/movie/&#x27; in response.url and response.status == 200:        print(response.json())with sync_playwright() as p:    browser = p.chromium.launch(headless=False)    page = browser.new_page()    page.on(&#x27;response&#x27;, on_response)    page.goto(&#x27;https://spa6.scrape.center/&#x27;)    page.wait_for_load_state(&#x27;networkidle&#x27;)    browser.close()\n\n控制台输出如下:\n&#123;&#x27;count&#x27;: 100, &#x27;results&#x27;: [&#123;&#x27;id&#x27;: 1, &#x27;name&#x27;: &#x27;霸王别姬&#x27;, &#x27;alias&#x27;: &#x27;Farewell My Concubine&#x27;, &#x27;cover&#x27;: &#x27;https://p0.meituan.net/movie/ce4da3e03e655b5b88ed31b5cd7896cf62472.jpg@464w_644h_1e_1c&#x27;, &#x27;categories&#x27;: [&#x27;剧情&#x27;, &#x27;爱情&#x27;], &#x27;published_at&#x27;: &#x27;1993-07-26&#x27;, &#x27;minute&#x27;: 171, &#x27;score&#x27;: 9.5, &#x27;regions&#x27;: [&#x27;中国大陆&#x27;, &#x27;中国香港&#x27;]&#125;, ...&#x27;published_at&#x27;: None, &#x27;minute&#x27;: 103, &#x27;score&#x27;: 9.0, &#x27;regions&#x27;: [&#x27;美国&#x27;]&#125;, &#123;&#x27;id&#x27;: 10, &#x27;name&#x27;: &#x27;狮子王&#x27;, &#x27;alias&#x27;: &#x27;The Lion King&#x27;, &#x27;cover&#x27;: &#x27;https://p0.meituan.net/movie/27b76fe6cf3903f3d74963f70786001e1438406.jpg@464w_644h_1e_1c&#x27;, &#x27;categories&#x27;: [&#x27;动画&#x27;, &#x27;歌舞&#x27;, &#x27;冒险&#x27;], &#x27;published_at&#x27;: &#x27;1995-07-15&#x27;, &#x27;minute&#x27;: 89, &#x27;score&#x27;: 9.0, &#x27;regions&#x27;: [&#x27;美国&#x27;]&#125;]&#125;\n\n获取页面源码要获取页面的 HTML 代码其实很简单，我们直接通过 content 方法获取即可，用法如:\nfrom playwright.sync_api import sync_playwrightwith sync_playwright() as p:    browser = p.chromium.launch(headless=False)    page = browser.new_page()    page.goto(&#x27;https://spa6.scrape.center/&#x27;)    page.wait_for_load_state(&#x27;networkidle&#x27;)    html = page.content()    print(html)    browser.close()\n\n运行结果就是页面的 HTML 代码。获取了 HTML 代码之后，我们通过一些解析工具就可以提取想要的信息了\n页面点击刚才我们通过示例也了解了页面点击的方法，那就是 click，这里详细说一下其使用方法\n页面点击的 API 定义如下:\npage.click(selector, **kwargs)\n\n这里可以看到必传的参数是 selector，其他的参数都是可选的。第一个 selector 就代表选择器，可以用来匹配想要点击的节点，如果传入的选择器匹配了多个节点，那么只会用第一个节点。\n这个方法的内部执行逻辑如下：\n\n根据 selector 找到匹配的节点，如果没有找到，那就一直等待直到超时，超时时间可以由额外的 timeout 参数设置，默认是 30 秒。\n等待对该节点的可操作性检查的结果，比如说如果某个按钮设置了不可点击，那它会等待该按钮变成了可点击的时候才去点击，除非通过 force 参数设置跳过可操作性检查步骤强制点击。\n如果需要的话，就滚动下页面，把需要被点击的节点呈现出来。\n调用 page 对象的 mouse 方法，点击节点中心的位置，如果指定了 position 参数，那就点击指定的位置。\n\nclick 方法的一些比较重要的参数如下：\n\nclick_count：点击次数，默认为 1。\ntimeout：等待要点击的节点的超时时间，默认是 30 秒。\nposition：需要传入一个字典，带有 x 和 y 属性，代表点击位置相对节点左上角的偏移位置。\nforce：即使不可点击，那也强制点击。默认是 False。\n\n具体的 API 设置参数可以参考官方文档：https://playwright.dev/python/docs/api/class-page/#pageclickselector-kwargs\n文本输入文本输入对应的方法是 fill，API 定义如下:\npage.fill(selector, value, **kwargs)\n\n这个方法有两个必传参数，第一个参数也是 selector，第二个参数是 value，代表输入的内容，另外还可以通过 timeout 参数指定对应节点的最长等待时间\n获取节点属性除了对节点进行操作，我们还可以获取节点的属性，方法就是 get_attribute，API 定义如下:\npage.get_attribute(selector, name, **kwargs)\n\n这个方法有两个必传参数，第一个参数也是 selector，第二个参数是 name，代表要获取的属性名称，另外还可以通过 timeout 参数指定对应节点的最长等待时间\n示例如下:\nfrom playwright.sync_api import sync_playwrightwith sync_playwright() as p:    browser = p.chromium.launch(headless=False)    page = browser.new_page()    page.goto(&#x27;https://spa6.scrape.center/&#x27;)    page.wait_for_load_state(&#x27;networkidle&#x27;)    href = page.get_attribute(&#x27;a.name&#x27;, &#x27;href&#x27;)    print(href)    browser.close()\n\n这里我们调用了 get_attribute 方法，传入的 selector 是 a.name，选定了 class 为 name 的 a 节点，然后第二个参数传入了 href，获取超链接的内容，输出结果如下:\n/detail/ZWYzNCN0ZXVxMGJ0dWEjKC01N3cxcTVvNS0takA5OHh5Z2ltbHlmeHMqLSFpLTAtbWIx\n\n可以看到对应 href 属性就获取出来了，但这里只有一条结果，因为这里有个条件，那就是如果传入的选择器匹配了多个节点，那么只会用第一个节点。\n那怎么获取所有的节点呢\n获取多个节点获取所有节点可以使用 query_selector_all 方法，它可以返回节点列表，通过遍历获取到单个节点之后，我们可以接着调用单个节点的方法来进行一些操作和属性获取，示例如下:\nfrom playwright.sync_api import sync_playwrightwith sync_playwright() as p:    browser = p.chromium.launch(headless=False)    page = browser.new_page()    page.goto(&#x27;https://spa6.scrape.center/&#x27;)    page.wait_for_load_state(&#x27;networkidle&#x27;)    elements = page.query_selector_all(&#x27;a.name&#x27;)    for element in elements:        print(element.get_attribute(&#x27;href&#x27;))        print(element.text_content())    browser.close()\n\n这里我们通过 query_selector_all 方法获取了所有匹配到的节点，每个节点对应的是一个 ElementHandle 对象，然后 ElementHandle 对象也有 get_attribute 方法来获取节点属性，另外还可以通过 text_content 方法获取节点文本，运行结果如下:\n/detail/ZWYzNCN0ZXVxMGJ0dWEjKC01N3cxcTVvNS0takA5OHh5Z2ltbHlmeHMqLSFpLTAtbWIx霸王别姬 - Farewell My Concubine/detail/ZWYzNCN0ZXVxMGJ0dWEjKC01N3cxcTVvNS0takA5OHh5Z2ltbHlmeHMqLSFpLTAtbWIy这个杀手不太冷 - Léon/detail/ZWYzNCN0ZXVxMGJ0dWEjKC01N3cxcTVvNS0takA5OHh5Z2ltbHlmeHMqLSFpLTAtbWIz肖申克的救赎 - The Shawshank Redemption/detail/ZWYzNCN0ZXVxMGJ0dWEjKC01N3cxcTVvNS0takA5OHh5Z2ltbHlmeHMqLSFpLTAtbWI0泰坦尼克号 - Titanic/detail/ZWYzNCN0ZXVxMGJ0dWEjKC01N3cxcTVvNS0takA5OHh5Z2ltbHlmeHMqLSFpLTAtbWI1罗马假日 - Roman Holiday/detail/ZWYzNCN0ZXVxMGJ0dWEjKC01N3cxcTVvNS0takA5OHh5Z2ltbHlmeHMqLSFpLTAtbWI2唐伯虎点秋香 - Flirting Scholar/detail/ZWYzNCN0ZXVxMGJ0dWEjKC01N3cxcTVvNS0takA5OHh5Z2ltbHlmeHMqLSFpLTAtbWI3乱世佳人 - Gone with the Wind/detail/ZWYzNCN0ZXVxMGJ0dWEjKC01N3cxcTVvNS0takA5OHh5Z2ltbHlmeHMqLSFpLTAtbWI4喜剧之王 - The King of Comedy/detail/ZWYzNCN0ZXVxMGJ0dWEjKC01N3cxcTVvNS0takA5OHh5Z2ltbHlmeHMqLSFpLTAtbWI5楚门的世界 - The Truman Show/detail/ZWYzNCN0ZXVxMGJ0dWEjKC01N3cxcTVvNS0takA5OHh5Z2ltbHlmeHMqLSFpLTAtbWIxMA==狮子王 - The Lion King\n\n获取单个节点获取单个节点也有特定的方法，就是 query_selector，如果传入的选择器匹配到多个节点，那它只会返回第一个节点，示例如下:\nfrom playwright.sync_api import sync_playwrightwith sync_playwright() as p:    browser = p.chromium.launch(headless=False)    page = browser.new_page()    page.goto(&#x27;https://spa6.scrape.center/&#x27;)    page.wait_for_load_state(&#x27;networkidle&#x27;)    element = page.query_selector(&#x27;a.name&#x27;)    print(element.get_attribute(&#x27;href&#x27;))    print(element.text_content())    browser.close()\n\n运行结果如下:\n/detail/ZWYzNCN0ZXVxMGJ0dWEjKC01N3cxcTVvNS0takA5OHh5Z2ltbHlmeHMqLSFpLTAtbWIx霸王别姬 - Farewell My Concubine\n\n可以看到这里只输出了第一个匹配节点的信息\n网络劫持最后再介绍一个实用的方法 route，利用 route 方法，我们可以实现一些网络劫持和修改操作，比如修改 request 的属性，修改 response 响应结果等\n看一个实例\nfrom playwright.sync_api import sync_playwrightimport rewith sync_playwright() as p:    browser = p.chromium.launch(headless=False)    page = browser.new_page()    def cancel_request(route, request):        route.abort()    page.route(re.compile(r&quot;(\\.png)|(\\.jpg)&quot;), cancel_request)    page.goto(&quot;https://spa6.scrape.center/&quot;)    page.wait_for_load_state(&#x27;networkidle&#x27;)    page.screenshot(path=&#x27;no_picture.png&#x27;)    browser.close()\n\n这里我们调用了 route 方法，第一个参数通过正则表达式传入了匹配的 URL 路径，这里代表的是任何包含 .png 或 .jpg 的链接，遇到这样的请求，会回调 cancel_request 方法处理，cancel_request 方法可以接收两个参数，一个是 route，代表一个 CallableRoute 对象，另外一个是 request，代表 Request 对象。这里我们直接调用了 route 的 abort 方法，取消了这次请求，所以最终导致的结果就是图片的加载全部取消了，运行结果如下所示:\n\n这个设置有什么用呢？其实是有用的，因为图片资源都是二进制文件，而我们在做爬取过程中可能并不想关心其具体的二进制文件的内容，可能只关心图片的 URL 是什么，所以在浏览器中是否把图片加载出来就不重要了。所以如此设置之后，我们可以提高整个页面的加载速度，提高爬取效率。\n另外，利用这个功能，我们还可以将一些响应内容进行修改，比如直接修改 Response 的结果为自定义的文本文件内容。\n首先这里定义一个 HTML 文本文件，命名为 custom_response.html，内容如下:\n&lt;!DOCTYPE html&gt;&lt;html&gt;  &lt;head&gt;    &lt;title&gt;Hack Response&lt;/title&gt;  &lt;/head&gt;  &lt;body&gt;    &lt;h1&gt;Hack Response&lt;/h1&gt;  &lt;/body&gt;&lt;/html&gt;\n\n代码编写如下:\nfrom playwright.sync_api import sync_playwrightwith sync_playwright() as p:    browser = p.chromium.launch(headless=False)    page = browser.new_page()    def modify_response(route, request):        route.fulfill(path=&quot;./custom_response.html&quot;)    page.route(&#x27;/&#x27;, modify_response)    page.goto(&quot;https://spa6.scrape.center/&quot;)    browser.close()\n\n这里我们使用 route 的 fulfill 方法指定了一个本地文件，就是刚才我们定义的 HTML 文件，运行结果如下:\n\n可以看到，Response 的运行结果就被我们修改了，URL 还是不变的，但是结果已经成了我们修改的 HTML 代码。\n所以通过 route 方法，我们可以灵活地控制请求和响应的内容，从而在某些场景下达成某些目的\nSelenium爬取实战目标网站: https://spa2.scrape.center/\n我们要完成以下工作:\n\n通过Selenium遍历列表页，获取每部电影的详情页URL\n通过Selenium根据上一步获取的详情页URL爬取每部电影的详情页\n从详情页中提取每部电影的名称、类别、分数、简介、封面等信息\n\n下面就直接上代码叭:\nfrom selenium import webdriverfrom selenium.common.exceptions import TimeoutExceptionfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.support.wait import WebDriverWaitimport loggingfrom urllib.parse import urljoinfrom os import makedirsfrom os.path import existsimport jsonlogging.basicConfig(level=logging.INFO,                    format=&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;)INDEX_URL = &#x27;https://spa2.scrape.center/page/&#123;page&#125;&#x27;TIMEOUT = 10TOTAL_PAGE = 10# 以上代码都是初始化操作RESULTS_DIR = &#x27;results&#x27;exists(RESULTS_DIR) or makedirs(RESULTS_DIR)options = webdriver.ChromeOptions()options.add_experimental_option(&#x27;excludeSwitches&#x27;, [&#x27;enable-automation&#x27;])options.add_experimental_option(&#x27;useAutomationExtension&#x27;, False)browser = webdriver.Chrome(options=options)  # 创建一个浏览器对象wait = WebDriverWait(browser, TIMEOUT)  # 利用它可以配置页面加载的最长时间def scrape_page(url, condition, locator):  # 通用的爬取方法，可以对任意的URL进行爬取、状态监听以及异常处理    logging.info(&#x27;scraping %s&#x27;, url)    try:        browser.get(url)        wait.until(condition(locator))    except TimeoutException:        logging.error(&#x27;error occurred while scraping %s&#x27;, url, exc_info=True)def scrape_index(page):  # 爬取列表页    url = INDEX_URL.format(page=page)    scrape_page(url, condition=EC.visibility_of_all_elements_located,                locator=(By.CSS_SELECTOR, &#x27;#index .item&#x27;))def parse_index():  # 解析列表页    elements = browser.find_elements_by_css_selector(&#x27;#index .item .name&#x27;)  # 从列表页中提取所有电影节点    for element in elements:        href = element.get_attribute(&#x27;href&#x27;)  # 提取详情页的href        yield urljoin(INDEX_URL, href)  # 合并成完整的URLdef scrape_detail(url):  # 爬取详情页之前，先判断页面是否加载成功，用visibility_of_element_located查看是否将h2加载出来，如果加载出来了，那页面就加载成功    scrape_page(url, condition=EC.visibility_of_element_located,                locator=(By.TAG_NAME, &#x27;h2&#x27;))def parse_detail():  # 爬取详情页    url = browser.current_url    name = browser.find_element_by_tag_name(&#x27;h2&#x27;).text    categories = [element.text for element in browser.find_elements_by_css_selector(&#x27;.categories button span&#x27;)]    cover = browser.find_element_by_css_selector(&#x27;.cover&#x27;).get_attribute(&#x27;src&#x27;)    score = browser.find_element_by_class_name(&#x27;score&#x27;).text    drama = browser.find_element_by_css_selector(&#x27;.drama p&#x27;).text    return &#123;        &#x27;url&#x27;: url,        &#x27;name&#x27;: name,        &#x27;categories&#x27;: categories,        &#x27;cover&#x27;: cover,        &#x27;score&#x27;: score,        &#x27;drama&#x27;: drama    &#125;def save_data(data):    name = data.get(&#x27;name&#x27;)    data_path = f&#x27;&#123;RESULTS_DIR&#125;/&#123;name&#125;.json&#x27;    json.dump(data, open(data_path, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;), ensure_ascii=False, indent=2)def main():    try:        for page in range(1, TOTAL_PAGE + 1):            scrape_index(page)            detail_urls = parse_index()            for detail_url in list(detail_urls):                logging.info(&#x27;get detail url %s&#x27;, detail_url)                scrape_detail(detail_url)                detail_data = parse_detail()                logging.info(&#x27;detail data %s&#x27;, detail_data)                save_data(detail_data)    finally:        browser.close()if __name__ == &#x27;__main__&#x27;:    main()\n\nPyppeteer爬取实战目标网站: https://spa2.scrape.center/\n要完成的工作和上面的一样\n准备工作，安装好Python，最低版本为3.6，安装好Pyppeteer并能成功运行实例\n下面就直接上代码叭:\nimport loggingfrom os.path import existsfrom os import makedirsimport jsonimport asynciofrom pyppeteer import launchfrom pyppeteer.errors import TimeoutErrorlogging.basicConfig(level=logging.INFO,                    format=&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;)INDEX_URL = &#x27;https://spa2.scrape.center/page/&#123;page&#125;&#x27;TIMEOUT = 10TOTAL_PAGE = 10RESULTS_DIR = &#x27;results&#x27;WINDOW_WIDTH, WINDOW_HEIGHT = 1366, 768exists(RESULTS_DIR) or makedirs(RESULTS_DIR)browser, tab = None, NoneHEADLESS = True  # 不会弹出窗口# 以上代码都是准备工作async def init():    global browser, tab  # 设置为全局变量，方便其他方法调用    browser = await launch(headless=HEADLESS,                           args=[&#x27;--disable-infobars&#x27;, f&#x27;--window-size=&#123;WINDOW_WIDTH&#125;,&#123;WINDOW_HEIGHT&#125;&#x27;])  # 隐藏提示条和设置了浏览器宽高    tab = await browser.newPage()    await tab.setViewport(&#123;&#x27;width&#x27;: WINDOW_WIDTH, &#x27;height&#x27;: WINDOW_HEIGHT&#125;)async def scrape_page(url, selector):  # 通用的爬取方法，url为要爬取的页面的URL，使用 goto即可调用此URL访问对应页面，Selector即等待渲染出的节点对应的CSS选择器    logging.info(&#x27;scraping %s&#x27;, url)    try:        await tab.goto(url)        await tab.waitForSelector(selector, options=&#123;            &#x27;timeout&#x27;: TIMEOUT * 1000        &#125;)  # 调用waitForSelector方法，传入selector，并通过options指定了最长等待时间    except TimeoutError:        logging.error(&#x27;error occurred while scraping %s&#x27;, url, exc_info=True)async def scrape_index(page):  # 爬取列表页    url = INDEX_URL.format(page=page)    await scrape_page(url, &#x27;.item .name&#x27;)async def parse_index():  # 解析列表页    return await tab.querySelectorAllEval(&#x27;.item .name&#x27;, &#x27;nodes =&gt; nodes.map(node =&gt; node.href)&#x27;)async def scrape_detail(url):  # 爬取详情页    await scrape_page(url, &#x27;h2&#x27;)async def parse_detail():    url = tab.url    name = await tab.querySelectorEval(&#x27;h2&#x27;, &#x27;node =&gt; node.innerText&#x27;)    categories = await tab.querySelectorAllEval(&#x27;.categories button span&#x27;, &#x27;nodes =&gt; nodes.map(node =&gt; node.innerText)&#x27;)    cover = await tab.querySelectorEval(&#x27;.cover&#x27;, &#x27;node =&gt; node.src&#x27;)    score = await tab.querySelectorEval(&#x27;.score&#x27;, &#x27;node =&gt; node.innerText&#x27;)    drama = await tab.querySelectorEval(&#x27;.drama p&#x27;, &#x27;node =&gt; node.innerText&#x27;)    return &#123;        &#x27;url&#x27;: url,        &#x27;name&#x27;: name,        &#x27;categories&#x27;: categories,        &#x27;cover&#x27;: cover,        &#x27;score&#x27;: score,        &#x27;drama&#x27;: drama    &#125;async def save_data(data):    name = data.get(&#x27;name&#x27;)    data_path = f&#x27;&#123;RESULTS_DIR&#125;/&#123;name&#125;.json&#x27;    json.dump(data, open(data_path, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;), ensure_ascii=False, indent=2)async def main():    await init()    try:        for page in range(1, TOTAL_PAGE + 1):            await scrape_index(page)            detail_urls = await parse_index()            for detail_url in detail_urls:                await scrape_detail(detail_url)                detail_data = await parse_detail()                logging.info(&#x27;data %s&#x27;, detail_data)                await save_data(detail_data)    finally:        await browser.close()if __name__ == &#x27;__main__&#x27;:    asyncio.get_event_loop().run_until_complete(main())\n\nCSS位置偏移反爬案例分析与爬取实战我们学习了Selenium、Pyppeteer等工具，体会了它们的强大，但千万别以为这些工具就是万能的，不容易爬取的数据依然存在，例如网页利用CSS控制文字的偏移位置，或者通过一些特殊的方式隐蔽关键信息，都有可能对数据爬取造成干扰，接下来我们就先了解下CSS位置偏移反爬虫的一些解决方案\n案例导入先介绍下一个案例https://antispider3.scrape.center/，页面如下图所示:\n\n乍一看似乎也没什么特别之处，但如果真用Selenium等工具爬取和提取数据，坑就立马显现出来了，不妨试一试，我们先尝试用Selenium获取首页的页面源代码，并解析每个标题的内容:\nfrom selenium import webdriverfrom pyquery import PyQuery as pqfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.support.wait import WebDriverWaitbrowser = webdriver.Chrome()browser.get(&#x27;https://antispider3.scrape.center/&#x27;)WebDriverWait(browser, 10) \\    .until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, &#x27;.item&#x27;)))html = browser.page_sourcedoc = pq(html)names = doc(&#x27;.item .name&#x27;)for name in names.items():    print(name.text())\n\n然而结果确是这样的：\n\n很多字的顺序都乱了，这是怎么回事呢\n排查我们进浏览器去看下源代码:\n可以看到这源代码本身就是乱的，一个字对应一个span节点，所以用pyqueqy提取出来的标题内容乱序就不足为怪了，那么源代码本身就是乱的，那为什么在网页上看到的标题是正确的?这是因为网页本身利用CSS控制了文字的偏移位置，什么意思呢，我们先观察以下源代码:\n&lt;h3 data-v-7f1a77ef=&quot;&quot; class=&quot;m-b-sm name&quot;&gt;&lt;span data-v-7f1a77ef=&quot;&quot; class=&quot;char&quot; style=&quot;left: 48px;&quot;&gt;                      风                    &lt;/span&gt;&lt;span data-v-7f1a77ef=&quot;&quot; class=&quot;char&quot; style=&quot;left: 16px;&quot;&gt;                      白                    &lt;/span&gt;&lt;span data-v-7f1a77ef=&quot;&quot; class=&quot;char&quot; style=&quot;left: 0px;&quot;&gt;                      清                    &lt;/span&gt;&lt;span data-v-7f1a77ef=&quot;&quot; class=&quot;char&quot; style=&quot;left: 32px;&quot;&gt;                      家                    &lt;/span&gt;&lt;/h3&gt;\n\n可以发现，每个span节点都有一个style属性，表示CSS样式，left的取值各不相同；另外，在浏览器中观察一下每各span节点的完整样式，如下图所示:\n\n可以看到，span还有两个额外的样式，是display: inline-block和position: absolute，后者比较重要，代表绝对定位，设置这个样式后，就可以通过left的值控制span节点在页面中的偏移位置了，例如left:0px代表不偏移，left:16px代表从左边起向右偏移16像素，于是节点就到了右边，那这样就能解释上面字的顺序了\n爬取了解了基本原理后，我们就可以对症下药了，这里只需要获取每个span节点的style属性，提取出偏移值，然后排序就可以得到最终结果了，我们先实现基本的提取方法:\nfrom selenium import webdriverfrom pyquery import PyQuery as pqfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.support.wait import WebDriverWaitimport redef parse_name(name_html):  # name_html:标题的HTML文本    chars = name_html(&#x27;.char&#x27;)    items = []    for char in chars.items():        items.append(&#123;            &#x27;text&#x27;: char.text().strip(),            &#x27;left&#x27;: int(re.search(&#x27;(\\d+)px&#x27;, char.attr(&#x27;style&#x27;)).group(1))  # 提取style属性值        &#125;)    items = sorted(items, key=lambda x: x[&#x27;left&#x27;], reverse=False)  # 字典排序    return &#x27;&#x27;.join([item.get(&#x27;text&#x27;) for item in items])browser = webdriver.Chrome()browser.get(&#x27;https://antispider3.scrape.center/&#x27;)WebDriverWait(browser, 10) \\    .until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, &#x27;.item&#x27;)))html = browser.page_sourcedoc = pq(html)names = doc(&#x27;.item .name&#x27;)for name_html in names.items():    name = parse_name(name_html)    print(name)browser.close()\n\n以上代码不多做解释，最终最终的运行效果就没错了，可是我们发现，少了几个标题，然后内容之间还有空余，我们来看看源代码:\n经过观察，我们发现内部没有span节点的h3标题节点都带有一个额外的取值为name whole的class属性，其余标题节点都分为了一个个span节点，搞清楚了问题所在，接下来稍加判断即可，改写解析方法:\ndef parse_name(name_html):  # name_html:标题的HTML文本    has_whole = name_html(&#x27;.whole&#x27;)    if has_whole:        return name_html.text()    else:        chars = name_html(&#x27;.char&#x27;)        items = []        for char in chars.items():            items.append(&#123;                &#x27;text&#x27;: char.text().strip(),                &#x27;left&#x27;: int(re.search(&#x27;(\\d+)px&#x27;, char.attr(&#x27;style&#x27;)).group(1))  # 提取style属性值            &#125;)        items = sorted(items, key=lambda x: x[&#x27;left&#x27;], reverse=False)  # 字典排序        return &#x27;&#x27;.join([item.get(&#x27;text&#x27;) for item in items])\n\n这样我们就成功爬取了书籍网站上的每本书的名称，刚刚用火狐使了下，下面看看效果:\n\n字体反爬案例分析与爬取实战接下来我们再分析一个反爬案例，该案例将真实的数据隐藏到字体文件里，使我们即使获取到了页面源代码，也没法直接提取数据的真实值\n案例导入案例网站: https://antispider4.scrape.center/\n我们先按正常的逻辑来爬取一些信息，例如电影标题、类别、评分等，代码实现如下:\nfrom selenium import webdriverfrom pyquery import PyQuery as pqfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.support.wait import WebDriverWaitbrowser = webdriver.Firefox()browser.get(&#x27;https://antispider4.scrape.center/&#x27;)WebDriverWait(browser, 10) \\    .until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, &#x27;.item&#x27;)))html = browser.page_sourcedoc = pq(html)items = doc(&#x27;.item&#x27;)for item in items.items():    name = item(&#x27;.name&#x27;).text()    categories = [o.text() for o in item(&#x27;.categories button&#x27;).items()]    score = item(&#x27;.score&#x27;).text()    print(f&#x27;name: &#123;name&#125; categories: &#123;categories&#125; score: &#123;score&#125;&#x27;)browser.close()\n\n运行结果如下，我们发现score看不到任何东西，但是在页面上是能看到的啊:\n\n经过观察，我们发现评分对应的源代码并不包含数字信息，如下图所示:\n\nspan节点中啥也没有，那自然提取不出来了，那页面上的评分是怎么显示出来的呢，其实也是CSS在搞鬼\n案例分析我们观察源码得到，各个span节点的不同之处在于内部i节点的class取值不太一样；可以看到下图中一共有3个span节点，对应的class取值分别是icon-789、icon-981和icon-504，这和显示出来的9.5有什么关系呢？\n\n会发现i节点内部有一个::before字段，在CSS中，该字段用于创建一个伪节点，即这个节点和i节点或者span节点不一样；::before可以往特定的节点中插入内容，同时在CSS中使用content字段定义这个内容；我们在第一个i节点里看到了9这个数字，再观察另外两个i节点，可以看到，这三个组合起来就是9.5\n实战那class的取值和content字段值的映射关系是怎么定义的呢，我们可以在浏览器中追踪CSS源代码，代码文件如下图标注所示:\n\n进入文件之后，我们可以看到整个CSS源代码都放在一行，点击”{}”按钮格式化代码，如下图所示:\n\n我们可以在其中找出如下内容:\n\n原来class对应的值就是一个个评分结果，这样我们就有底了，只需要解析对应的结果再做转换即可；这里需要读取CSS文件并提取映射关系，这个CSS文件是: https://spa2.scrape.center/css/app.ea9d802a.css，其部分内容如下所示:\n\n我们可以试着用requsest库读取结果，并通过正则表达式将映射关系提取出来，代码实现如下:\nimport reimport requestsurl = &#x27;https://antispider4.scrape.center/css/app.654ba59e.css&#x27;response = requests.get(url)pattern = re.compile(&#x27;.icon-(.*?):before\\&#123;content:&quot;(.*?)&quot;\\&#125;&#x27;)results = re.findall(pattern, response.text)icon_map = &#123;item[0]: item[1] for item in results&#125;\n\n这里我们首先使用request库提取了CSS文件的内容，然后使用了正则表达式进行了文本匹配，表达式写作:.icon-(.*?):before\\&#123;content:&quot;(.*?)&quot;\\&#125;，这个表达式并没有考虑空格，因为CSS源代码本身就没有空格\n以上结果就类似:\n&#123;    ...    &quot;at&quot;: &quot;@&quot;,    &quot;A&quot;: &quot;A&quot;,    ...&#125;\n\n例如使用789索引，得到的结果就是9:\nprint(icon_map[&#x27;789&#x27;])  # 9\n\n所以我们只需要修改下逻辑，代码如下:\nfrom selenium import webdriverfrom pyquery import PyQuery as pqfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.support.wait import WebDriverWaitimport reimport requestsurl = &#x27;https://antispider4.scrape.center/css/app.654ba59e.css&#x27;response = requests.get(url)pattern = re.compile(&#x27;.icon-(.*?):before\\&#123;content:&quot;(.*?)&quot;\\&#125;&#x27;)results = re.findall(pattern, response.text)icon_map = &#123;item[0]: item[1] for item in results&#125;def parse_score(item):    elements = item(&#x27;.icon&#x27;)    icon_values = []    for element in elements.items():        class_name = (element.attr(&#x27;class&#x27;))        icon_key = re.search(&#x27;icon-(\\d+)&#x27;, class_name).group(1)        icon_value = icon_map.get(icon_key)        icon_values.append(icon_value)    return &#x27;&#x27;.join(icon_values)browser = webdriver.Chrome()browser.get(&#x27;https://antispider4.scrape.center/&#x27;)WebDriverWait(browser, 10) \\    .until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, &#x27;.item&#x27;)))html = browser.page_sourcedoc = pq(html)items = doc(&#x27;.item&#x27;)for item in items.items():    name = item(&#x27;.name&#x27;).text()    categories = [o.text() for o in item(&#x27;.categories button&#x27;).items()]    score = parse_score(item)    print(f&#x27;name: &#123;name&#125; categories: &#123;categories&#125; score: &#123;score&#125;&#x27;)browser.close()\n\n这里我们定义了一个parse_score方法，它接收一个Pyquery对象item，对应着一个电影条目；首先提取item中所有带icon这个class的节点，然后遍历这些节点，从class属性里提取对应的icon代号，例如icon-789，提取的结果就是789，和我们刚刚构造的icon_map是相对应的，将其赋值给icon_key，然后使用icon_key从icon_map中查找对应的真实值，赋值为icon_value，最后将icon_value拼合成一个字符串返回\n"},{"title":"腾讯云服务器添加虚拟内存","url":"/2022/02/25/%E8%85%BE%E8%AE%AF%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%B7%BB%E5%8A%A0%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/","content":"我的小服务器是1核2G然后加50G的，这样有时候在上面运行服务就有点卡顿，特别是运行了Gitlab之后，下面我们来看看如何添加虚拟内存\n查看内存使用情况用free命令查看内存使用情况，我们会发现swap分区大小为0，这说明原来腾讯云服务器默认是没有划分swap分区的，所以由于我的服务器物理内存本身就很少，而且又没设置swap分区，运行效果可想而知，稍有点并发量、或者恶意用户探测访问等，网站就很容易卡壳了\nswap的作用swap是用来做虚拟内存的。虽然swap无法代替物理内存，但不可缺少\nswap分区作用:当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间被临时保存到Swap空间中，等到那些程序要运行时，再从Swap中恢复保存的数据到内存中。这样，系统总是在物理内存不够时，才进行Swap交换\n创建swap的两种方式\n建立一个swap分区\n创建一个swap交换文件\n\n运行速度: &gt; swap分区 &gt; swap文件\n这里我不用建立分区这个方法，如果你是以下情况我也不建议:\n当你的数据盘已经装了很多内容，不方便重新规划的话，也只好使用swap文件了。像我由于只有一块磁盘，而且磁盘已经装了不少内容，所以就没有选择磁盘格式化，而是选择创建swap文件。\n\n下面介绍创建swap文件的方法:\n创建swap文件定义swap的大小及位置首先，选择你swap文件要放置的位置，比如直接在根目录/ 下创建或者选择一个目录，如/opt。比如我直接在根目录下创建，然后设置swap分区的名称为swapfile\ncd /\n\nsudo dd if=/dev/zero of=/swapfile bs=1k count=4096000\n\n上面swapfile为你创建swap文件的名称，你可以根据需要改成你自己的名称，如bs 即blocksizes，每个块大小为1k;count=4096000,总大小为4G的文件。因为建立swap分区大小的标准一般为物理内存的两倍，而我的内存是2G，所以我选择swap文件大小为4G，当然，也要考虑你硬盘剩余容量的大小。我的硬盘还剩30G，所以再划分4G给swap文件绰绰有余。如果你的内存是0.5G，那么count大小可以选择1024000(1G)\n建立swapmkswap /swapfile\n\n启动swapswapon /swapfile\n\n检查是否正确free -m\n\n或者:\nswapon -s\n\n以上命令能看到到swap总量大小然后使用了多少\n设置开机自启swap文件原理:\n修改 /etc/fstab 使其启动时自动mount添加方法如下:\n\n先赋予**/etc/fstab**修改权限\nsudo chmod 777 /etc/fstab\n然后添加语句:\necho &quot;/swapfile swap swap defaults 0 0&quot; &gt;&gt;/etc/fstab\n\n这里注意: /swapfile 路径可以修改,可以根据创建的swap文件具体路径来配置\n\n\n删除swap交换文件如果不再需要swap，可以清理该文件: swapoff /swapfile\n以上内容参考自: https://blog.csdn.net/qq_29856169/article/details/115430525\n"},{"title":"浅谈一下我在我的小服务器上安装GitLab的坎坷历程","url":"/2022/02/25/%E6%B5%85%E8%B0%88%E4%B8%80%E4%B8%8B%E6%88%91%E5%9C%A8%E6%88%91%E7%9A%84%E5%B0%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%AE%89%E8%A3%85GitLab%E7%9A%84%E5%9D%8E%E5%9D%B7%E5%8E%86%E7%A8%8B/","content":"云服务器系统: ubuntu18.04\n云服务器配置:1核2G+50G(建议这个配置的配置下虚拟内存，详情点击这里查看)\n首先我的服务器之前是安装过Docker的，所以我才决定用Docker来安装GitLab，如果还没安装Docker，请点击这里跳转，先安装Docker\n关于GitLab版本的介绍GitLab有两个版本:\n\nCommunity Edition 社区版\nEnterprise Edition 企业版，企业版比社区版功能更丰富，但需要授权码，如果没有授权码的情况下使用企业版相当于使用社区版\n\nGitLab安装(以企业版为例)我们执行以下代码:\ndocker run --detach --hostname gitlab-server --publish 9090:9090 --publish 8022:22 --name gitlab --restart always --volume /srv/gitlab/config:/etc/gitlab --volume /srv/gitlab/logs:/var/log/gitlab --volume /srv/gitlab/data:/var/opt/gitlab gitlab/gitlab-ee:latest\n\n如果你的终端显示没有权限，那就在命令的最开头加一个sudo，或者直接使用su命令然后输入root用户密码直接切换成root用户，如果你想以普通用户运行docker命令，那就需要将此普通用户加入到docker组中，使用以下命令将普通用户加入到docker组:(这里以test用户为例)\ngpasswd -a test docker\n\n然后我们来看看上面这一长串命令的各参数以及对应的值是啥意思:\n\n这里有两个--publish参数，第一个是配置http的访问端口，这里我两个都配置的是9090端口，前一个9090代表云服务器的端口，后一个9090代表docker容器的端口，这两个端口是对接的，也就是说我们访问云服务的9090端口，就会跳进docker容器中的9090端口进行访问http服务，如果这个端口被占用了，那也可以设定其他的，总之就是设置你想以哪个端口访问docker容器中的GitLab，这两个端口都可随意设置，只要端口不被其他服务占用即可第二个--publish参数那就是设置ssh的\n然后我们还要配置下gitlab.rb这个配置文件，用以下命令进入:\nsudo vi /srv/gitlab/config/gitlab.rb\n\n\n设置external_url\n## GitLab URL##! URL on which GitLab will be reachable.##! For more details on configuring external_url see:##! https://docs.gitlab.com/omnibus/settings/configuration.html#configuring-the-external-url-for-gitlabexternal_url &#x27;http://192.168.199.175:9090&#x27;\n设置ssh_port\n### GitLab Shell settings for GitLabgitlab_rails[&#x27;gitlab_shell_ssh_port&#x27;] = 8022\n\n以上external_url和ssh_port可能不好定位，如果一个个找那就是考验我们的眼睛，我们可以用vi或者vim的查看功能，输入:，然后跟上一个/再跟上你要搜索的字符串，如果有很多个的话使用n键定位到下一个，只有一个的话vim会提示已经到底了并且再继续按n键还是定位的同一个\n插一句: 我之前在docker上尝试了好多次然后到后面使用docker ps命令后面都提示unhealthy，这令我很苦恼，要不我为啥说坎坷呢，我查阅资料说在gitlab.rb这个配置文件中要把worker_process = 2这个配置项解除注释，或者改为worker_process = 1，后面我发现容器状态变为healthy了，可能是因为我改了这个叭\n然后我们就可以重启GitLab容器使得设置生效了，使用以下命令:\nsudo docker restart gitlab\n\n这个重启的过程稍微有点漫长，我们可以使用docker ps命令来查看容器的状态，如果显示starting那就是还在启动中，显示healthy那就是启动成功，若启动成功，我们就可以在浏览器中以http://云服务器地址:9090来访问GitLab了，这个时候就会要我们输入用户名和密码，在一个空的GitLab中，有一个初始用户叫root，但是我不知道密码啊，下面我们来看看如何设置密码\n设置默认密码\n查看容器名称，其实容器名称我们在刚开始的一大段命令中就以--name指定了，如果记不住的话那就用以下命令查看下也行:\ndocker ps\n进入GitLab容器(这里以gitlab容器为例)，这个命令其实就是进入到了对应的主机，这里就是进入了gitlab-server这个主机，因为上面指定了主机名，输入exit便可返回宿主机\ndocker exec -it gitlab bash\n启动Ruby on Rails控制台(这个过程要稍微等一下)\ngitlab-rails console -e production\n搜索用户\nuser = User.where(id: 1).first\n\n这个id:1是从哪儿来的呢，这里有有个小技巧，我们访问这个形式的链接就会返回以下结果:\n链接示例:\nhttp://175.24.172.64:9090/api/v4/users?username=root\n\n返回结果示例:\n\n从上图中我们就得到了root用户的id\n\n更换密码\nuser.password = &#x27;xxxxxx&#x27;\n确认更换密码\nuser.password_confirmation = &#x27;xxxxxx&#x27;\n保存\nuser.save!\n\n"}]