[{"title":"Python中常用的国内pip源","url":"/2021/12/29/Python%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84pip%E6%BA%90/","content":"在我们下载包的时候，很可能由于网络原因会很卡，这个时候可能需要科学上网，但是我们又没有买节点，或者没有搭建海外服务器，这个时候我们就可以访问一些国内的pip源，这里面和国外上传的pip源几乎是一样的，也是一段时间就会更新:\n\n阿里云: http://mirrors.aliyun.com/pypi/simple/\n中国科学技术大学: https://pypi.mirrors.ustc.edu.cn/simple/\n豆瓣: http://pypi.douban.com/simple/\n清华大学: https://pypi.tuna.tsinghua.edu.cn/simple/\n华中科技大学: http://pypi.hustunique.com/\n\n注意: 新版ubuntu要求使用https源\n","categories":["Database"]},{"title":"Python中pip和pip3的区别","url":"/2021/12/29/Python%E4%B8%ADpip%E5%92%8Cpip3%E7%9A%84%E5%8C%BA%E5%88%AB/","content":"pip是Python的一款很好用的包管理工具，类似于node中的npm，Python有Python2和Python3的区别，那么pip也有pip和pip3的区别,大概是这样的: \n相同点(虽然主要是区别，但还是有相同点的撒):\n\npip和pip3版本不同，但二者都位于Script\\目录下\n\n不同点：\n\n如果系统中只安装了Python2，那么就只能用pip\n如果系统中只安装了Python3，那么既可以使用pip也可以使用pip3，二者是等价的\n如果系统中同时安装了Python2和Python3，则pip默认给Python2使用，pip3默认给Python3使用\n重要: 在虚拟环境中，若只存在一个Python版本，可以认为在用系统中的pip和pip3命令都是相同作用的\n\n"},{"title":"Python中with...as...语句的深度解刨","url":"/2021/12/28/Python%E4%B8%ADwith...as...%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%B7%B1%E5%BA%A6%E8%A7%A3%E5%88%A8/","content":"任何一门编程语言中，文件的输入输出、数据库的连接断开等，都是很常见的资源管理操作。但资源都是有限的，在写程序时，必须保证这些资源在使用过后得到释放，不然就容易造成资源泄露，轻者使得系统处理缓慢，严重时会使系统崩溃。\n例如，前面在介绍文件操作时，一直强调打开的文件最后一定要关闭，否则会程序的运行造成意想不到的隐患。但是，即便使用 close() 做好了关闭文件的操作，如果在打开文件或文件操作过程中抛出了异常，还是无法及时关闭文件。\n为了更好地避免此类问题，不同的编程语言都引入了不同的机制。在 Python 中，对应的解决方式是使用 with as 语句操作上下文管理器（context manager），它能够帮助我们自动分配并且释放资源，代码示例如下:\nwith open(&quot;test.txt&quot;) as file:    data = file.read()    print(data)# 等价于try:    file = open(&quot;test.txt&quot;)    data = file.read()    print(data)finally:    file.close()\n\nwith…as…语句只会捕获异常而不会处理异常，代码示例如下:\nwith open(&quot;test.txt&quot;) as file:    data = file.read()    print(data)# 若没有test.txt，会出现以下错误,程序会就此停下，说明并不会处理异常FileNotFoundError Traceback (most recent call last)&lt;ipython-input-4-bf5e860f28d5&gt; in &lt;module&gt;      1 try:----&gt; 2     file = open(&quot;test.txt&quot;)      3     data = file.read()      4     print(data)      5 # except Exception as err:FileNotFoundError: [Errno 2] No such file or directory: &#x27;test.txt&#x27;\n\n"},{"title":"Python如何升级pip,以及如何查看pip版本","url":"/2021/12/29/Python%E5%A6%82%E4%BD%95%E5%8D%87%E7%BA%A7pip,%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8Bpip%E7%89%88%E6%9C%AC/","content":"有些时候我们用pip安装包的时候会报红提示说安装失败，也有时候会出现一串黄色的警告说pip版本太低，这个时候我们可能就该考虑升级下pip，升级pip会获得更好的体验然后很多新的包也会收录在新版本的pip下，我们来看下如何升级: \n\n打开命令行键入以下命令:\npip3 install --upgrade pip -i &quot;https://pypi.mirrors.ustc.edu.cn/simple&quot;\n\n对以上命令做下解释:\n\npip3: 如果在系统中既有Python2又有Python3那么且两个都有pip工具,pip3就是为Python3服务\n-i: 指定包的源\n\n\n\n"},{"title":"Python每个版本都自带pip嘛,以及如何安装pip","url":"/2021/12/29/Python%E6%AF%8F%E4%B8%AA%E7%89%88%E6%9C%AC%E9%83%BD%E8%87%AA%E5%B8%A6pip%E5%98%9B,%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85pip/","content":"pip是Python的包管理工具，该工具提供了对Python包的查找、下载、安装、以及卸载的功能，目前如果你在Python.org下载最新版本的安装包，则是已经自带了该工具，Python2.7.9+或者Python3.4+以上版本都自带pip工具(通常跟wheel.exe在同一个目录下)\n下面讲讲如果安装的时候没有自带pip工具那么如何安装pip工具：\n\n访问https://bootstrap.pypa.io/get-pip.py这个网址，然后Ctrl+S将get-pip.py文件保存到你所安装的Python的Script目录下\n然后进入Script目录，并且在该目录下进入下命令行界面\n在命令行界面输入python get-pip.py，pip3工具就会自动安装\n安装成功之后输入python -m pip –version，确保成功安装了pip\n\n"},{"title":"Python如何修改pip源","url":"/2021/12/29/Python%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9pip%E6%BA%90/","content":"如果每次都pip用-i指定源会比较麻烦，我们可以把某个国内源设置为默认，这样下次就会从默认源里面寻找包并且下载，来看看如何设为默认:\n在命令行中键入以下命令:\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n\n以上以清华源的为例\n"},{"title":"Python类中call函数的作用","url":"/2021/12/25/Python%E7%B1%BB%E4%B8%ADcall%E5%87%BD%E6%95%B0%E7%9A%84%E4%BD%9C%E7%94%A8/","content":"本节再介绍 Python类中一个非常特殊的实例方法，即 call()。该方法的功能类似于在类中重载 () 运算符，使得类实例对象可以像调用普通函数那样，以“对象名()”的形式使用，一句话总结: call函数可以把类变成函数来调用\nclass Demo():    def __init__(self, name):        self.name = name    def __call__(self):        print(self.name)Demo(&#x27;孙悟空&#x27;)() # 输出 孙悟空\n\n在Python中，凡是可以将()直接应用到自身并执行，都称为可调用对象，可调用对象包括自定义的函数，Python内置函数以及这里讲的类实例对象，对于可调用对象，实际上“名称()”可以理解为是“名称.call()”的简写。仍以上面程序中定义的 clangs 实例对象为例，其最后一行代码还可以改写为如下形式：\nclangs.__call__(&quot;C语言中文网&quot;,&quot;http://c.biancheng.net&quot;)\n"},{"title":"Python魔法方法总览","url":"/2021/12/28/Python%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95%E6%80%BB%E8%A7%88/","content":"关于魔法方法: 使用魔法方法可以使Python的自由度变得更高，当不需要重写魔法方法也可以在规定的默认情况下生效，在需要重写时也可以让使用者根据自己的需求来重写部分方法来达到自己的预期。而且众所周知Python是支持面向对象的语言，其基本魔法方法就使得Python在面向对象方面做得更好。\n今天在CSDN上看到了有一篇文章整理得还不错，讲述了很多魔法方法以及其作用，详情见:https://blog.csdn.net/qq_38520096/article/details/79237593?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164067535716780261982154%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=164067535716780261982154&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-8-79237593.first_rank_v2_pc_rank_v29&amp;utm_term=python%E7%9A%84%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95&amp;spm=1018.2226.3001.4187\n"},{"title":"对Docker的认识","url":"/2021/12/29/%E5%AF%B9Docker%E7%9A%84%E8%AE%A4%E8%AF%86/","content":"首先，Docker是个容器，使用的是宿主机的资源，因为都是Linux，所以内核资源是可以共用的，无论什么发行版，他们的内核都是Linux kernel，所以Docker才能实现，Docker其实只共用了宿主机的内核，然后我们可以在里面安装镜像，运行一个隔离于系统的独立系统，但是默认是不和宿主机发生交互的，如果要使用到宿主机的文件，就要用volumn将宿主机的文件挂载到容器中，让容器可以访问\n现在windows上也可以安装Docker，其实windows上的Docker只是一个客户端，实际上还是开了一个虚拟机跑Linux，然后Linux里再跑Docker\n"},{"title":"Linux(ubuntu)提示command not fonund的解决","url":"/2021/12/29/Linux(ubuntu)%E6%8F%90%E7%A4%BAcommand%20not%20fonund%E7%9A%84%E8%A7%A3%E5%86%B3/","content":"Linux系统中，-bash: wget: comment not found是找不到命令的意思，也就是无法执行下载命令，这是因为系统太干净了，没有安装下载命令的控制器，我们给系统安装个下载命令即可:\nCentOS系统:\nyum install wget -y\n\nDebian/Ubuntu系统:\napt -get install -y wget\n\n"},{"title":"关于入门Go需要知道的几个特性","url":"/2021/12/29/%E5%85%B3%E4%BA%8E%E5%85%A5%E9%97%A8Go%E7%9A%84%E5%87%A0%E4%B8%AA%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","content":"\ngo的关键字比较少，只有25个，这样可以简化编码过程中的混乱和复杂度\n\ngo没有类和继承的概念，但它通过接口的概念来实现多态\n\ngo支持交叉编译，比如说可以在运行Linux系统的计算机开发能在windows上运行的应用，这是第一门完全支持UTF-8的编程语言，就连他的源码文件格式都是使用UTF-8编码\n\ngo被设计成一门应用与搭载web服务器，存储集群或类似用途的巨型中央服务器的系统编程语言，对于高性能分布式系统领域而言，go有着更高的开发效率，提供了海量并行的支持，这对于游戏服务端的开发最好不过了\n\n尽管go编译器产生的是本地可执行代码，这些代码仍旧运行在go的runtime中，这个runtime类似java和.net所用到的虚拟机，它负责管理包括内存分配，垃圾回收，栈处理、goroutine、channel、切片，map和反射等\n\ngo fmt，这是个工具用来将你的源代码格式化成符合官方统一标准的风格\n\ngo doc，这是个工具从go程序和包文件中提取顶级声明的首行注释以及每个对象的相关注释，并生成相关文档\n\ngo install, 这是go的包的安装工具，类似Ruby中的rubygems\n\ngo test是一个轻量级的单元测试框架\n\ngo fix用于将你的go代码从旧的发行版迁移到最新的发行版\n\ncgo提供了对FFI(外部函数接口)的支持，能够使用go代码安全地调用c语言库，cgo会代替go编译器来产生可以组合在同一个包中的go和c代码\n\n在go代码中使用c语言需要用import&quot;C&quot;来导入，一般还需要import&quot;unsafe&quot;,然后你可以在import&quot;C&quot;之前使用注释(但行或多行注释均可)的形势导入C语言库(甚至有效的C语言代码)，注意他们之间没有空格\n\n左大括号需要放在函数定义这一行\n\nfmt.Println和fmt.Print只差了一个空格\n2021-12-29 18:08:20\n\n\n"},{"title":"在Docker中安装Python3.7","url":"/2021/12/29/%E5%9C%A8Docker%E4%B8%AD%E5%AE%89%E8%A3%85Python3.7/","content":"详情见: \nhttps://www.icode9.com/content-1-120863.html\n"},{"title":"如何在ubuntu16中安装Python","url":"/2021/12/29/%E5%A6%82%E4%BD%95%E5%9C%A8ubuntu16%E4%B8%AD%E5%AE%89%E8%A3%85Python/","content":"详情见:(我这采用的是第二种方法)https://www.runoob.com/docker/ubuntu-docker-install.html\n"},{"title":"查看Docker是否安装成功以及使用Docker安装nginx","url":"/2021/12/29/%E6%9F%A5%E7%9C%8BDocker%E6%98%AF%E5%90%A6%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8Docker%E5%AE%89%E8%A3%85nginx/","content":"\n检查是否安装成功\n使用命令:\ndocker ps\n\n使用docker搜索nginx:\n使用命令:\ndocker search nginx\n使用 docker安装nginx:\n使用命令:\ndocker pull nginx\n\n运行nignx:\n使用命令:\ndocker run nginx\n检查Docker是否安装成功可以使用命令:\ndocker version\n\n有client和service两部分表示docker安装启动都成功了\n\n\n"},{"title":"LeetCode最大回文子串","url":"/2021/12/30/Leetcode%E6%9C%80%E5%A4%A7%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/","content":"动态规划:\n对于一个字串而言，如果它是回文串，并且长度大于2，那么将它首位的两个字母去掉之后，它仍然是个回文串，根据这个思路，我们就可以用动态规划的方法解决本题，我们用s[i, j]表示字符串s的第i个到第j个字母组成的串是否为回文串:\n我们可以得到只有s[i+1, j-1]是回文串，并且s的第i个和第j个字母相同时，s[i, j]才会是回文串\n上文所有讨论都是建立在字串长度大于2的前提上的，我们还需要考虑动态规划中的边界条件，就是字串的长度为1或2。对于长度为1的字串，他显然是个回文串，对于长度为2的字串，只要它的两个字母相同，他就是一个回文串，因此我们就可以得到动态规划的边界条件\nclass Solution:    def longestPalindrome(self, s: str) -&gt; str:        n = len(s)        if n &lt; 2:            return s                max_len = 1        begin = 0        # dp[i][j] 表示 s[i..j] 是否是回文串        dp = [[False] * n for _ in range(n)]        for i in range(n):            dp[i][i] = True                # 递推开始        # 先枚举子串长度        for L in range(2, n + 1):            # 枚举左边界，左边界的上限设置可以宽松一些            for i in range(n):                # 由 L 和 i 可以确定右边界，即 j - i + 1 = L 得                j = L + i - 1                # 如果右边界越界，就可以退出当前循环                if j &gt;= n:                    break                                    if s[i] != s[j]:                    dp[i][j] = False                 else:                    if j - i &lt; 3:                        dp[i][j] = True                    else:                        dp[i][j] = dp[i + 1][j - 1]                                # 只要 dp[i][L] == true 成立，就表示子串 s[i..L] 是回文，此时记录回文长度和起始位置                if dp[i][j] and j - i + 1 &gt; max_len:                    max_len = j - i + 1                    begin = i        return s[begin:begin + max_len]\n\n\n\n"},{"title":"Scrapy添加User-agent的方法","url":"/2021/12/30/Scrapy%E6%B7%BB%E5%8A%A0User-agent%E7%9A%84%E6%96%B9%E6%B3%95/","content":"\n直接在spider中指定，比如在Scrapy项目中有一个项目grasp_baidu:\nimport scrapyclass graspbaidu(scrapy.Spider):    name = &#x27;graspbaidu&#x27;    allowed_domians = [&#x27;www.baidu.com&#x27;]    start_urls = [&quot;http//:www.baidu.com&quot;]    def parse(self, response):        self.logger.debug(response.text)\n\n这里的start_urls会默认由scrapy自带的start_request处理，然后再交给parse函数，我们就可以重写个start_request，然后里面带个UA即可，比如：\ndef start_request(self):    for i in range(1, 2):    url = ff&#x27;https://api2.fx361.com/JunJiProject/JUNJI_012_001/getSearchList?bkpagesize=14&amp;pagesize=30&amp;keyword=%E7%9B%91%E7%90%86%E5%88%9B%E6%96%B0&amp;pageIndex=&#123;i&#125;&amp;fragmentSize=150&#x27;    req = scrapy.Request(url, callback=self.parse, dont_filter=True, headers=self.headers)\n在配置文件settings.py中设置(一劳永逸):\n将settings.py中的USER_AGENT修改一下即可\n\n如果想修改的更加灵活，比如设置随机的Ua，那就需要如下用到一个库:\nfrom fake_useragent import UserAgent\n\n然后需要在middlewares.py文件中添加一个RandomUserAgentMiddleware的类，如下:\nclass RandomUserAgentMiddleware(object):    # 随机更换 user_agent    def __init__(self,srawler):        super(RandomUserAgentMiddleware,self).__init__()        self.ua = UserAgent()    @classmethod    def from_crawler(cls,crawler):        return cls(crawler)     def process_request(self,request,spider):        def get_ua():        request.headers.setdefault(&#x27;User-Agent&#x27;,self.ua.random)        \n\n然后后我们在settings.py中调用这个中间件:\nDOWNLOADER_MIDDLEWARES = &#123;    &#x27;scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware&#x27;: None,    &#x27;scrapydownloadertest.middlewares.RandomUserAgentMiddleware&#x27;: 543,&#125;\n\n"},{"title":"关于协程记录一下","url":"/2021/01/01/%E5%85%B3%E4%BA%8E%E5%8D%8F%E7%A8%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%8B/","content":"\n\n什么是可迭代对象:\n可迭代对象(iterable): Python中的任意对象，只要它定义了可以返回一个迭代器的__iter__方法，或者定义了可以支持下标索引的__gititem__方法这两个魔法方法，那么他就是一个可迭代对象，简单说，可迭代对象就是能提供迭代器的任意对象,常见的可迭代对象有:字符串，列表，字典，元组等。\nfrom collections.abc import Iterable, Iterator, Generatorstr_1 = &#x27;sixkery&#x27;print(&#x27;字符串是否是可迭代对象：&#x27;,isinstance(str_1,Iterable))print(&#x27;字符串是否是迭代器：&#x27;,isinstance(str_1,Iterator))print(&#x27;字符串是否是生成器：&#x27;,isinstance(str_1,Generator))list_1 = [1,2,3,4]print(&#x27;列表是否是可迭代对象：&#x27;,isinstance(list_1,Iterable))print(&#x27;列表是否是迭代器：&#x27;,isinstance(list_1,Iterator))print(&#x27;列表是否是生成器：&#x27;,isinstance(list_1,Generator))dict_1 = &#123;&#x27;name&#x27;:&#x27;小沐&#x27;,&#x27;age&#x27;:23&#125;print(&#x27;字典是否是可迭代对象：&#x27;,isinstance(dict_1,Iterable))print(&#x27;字典是否是迭代器：&#x27;,isinstance(dict_1,Iterator))print(&#x27;字典是否是生成器：&#x27;,isinstance(dict_1,Generator))\n\n以上都是可迭代对象，可以使用方法dir()查看是否有__iter__来判断一个变量是否是可迭代对象，可迭代对象都可以使用for循环\nif &#x27;__iter__&#x27; in dir(list()):\tprint(&#x27;list是可迭代对象&#x27;)\n什么是迭代器\n迭代器，是在可迭代对象的基础上实现的，创建一个迭代器，首先要用一个可迭代对象:\n用iter()方法即可把可迭代对象转化为迭代器：\nstr_1 = &#x27;asdfg&#x27; # 字符串，是可迭代对象alterator = iter(str_1) # 通过方法 iter() 把字符串变成迭代器print(&#x27;是否成功转换成迭代器:&#x27;,isinstance(alterator,Iterator))\n\n迭代器比可迭代对象多了一个函数next(),我们可以用它来获取元素，for循环也是支持的,这是因为在迭代器内部实现了__next__方法：\nnext(alterator)# &#x27;a&#x27;\n\nfor i in alterator:    print(i)# ...\n生成器:\n之所以引入生成器，是为了实现一个在计算下一个值时不需要浪费空间的结构，通常我们使用列表，即使很大一个列表在一开始也得生成，如果能需要使用的时候自动生成下一个那就节省了很大空间\n之前说的迭代器，是在可迭代对象的基础上加了一个next方法，而生成器是在迭代器的基础上，再实现了yield,所以生成器也可以使用for和next()\nyield是啥呢?它相当于我们函数中的return，在每次next(),或者for循环便利的时候，都会在yield的地方将新的值返回回去，并在这里阻塞，等待下一次的调用，正是有了这个机制，才使得生成器在Python中大放异彩，实现节省内存，实现异步编程。\n\n将列表生成式的中括号改成小括号就是一个生成器啦：\na = (x*x for x in range(1,5))next(a)# 1a = (x*x for x in range(1,5))print(&#x27;是否是生成器：&#x27;,isinstance(a,Generator))# 是否是生成器： True\n实现生成器函数(yield)：\ndef my_gen(n):    a = 0    while a &lt; n:        yield a        a += 1if __name__ == &#x27;__main__&#x27;:    gen = my_gen(5)    print(&#x27;是否是生成器：&#x27;,isinstance(gen,Generator))    for i in gen:        print(i)    # 是否是生成器： True01234\n生成器的执行状态，生成器在其生命周期中，会有以下四个状态:\n\nGEN_CREATED: 等待开始执行\nGEN_RUNNING: 解释器正在执行(只有在多线程应用中才能看到这个状态)\nGEN_SUSPENDED: 在yield表达式处暂停\nGEN_CLOSED: 执行结束\n\nfrom inspect import getgeneratorstatedef my_gen(n):    a = 0    while a &lt; n:        yield a        a += 1if __name__ == &#x27;__main__&#x27;:    gen = my_gen(5)    print(getgeneratorstate(gen)) # 等待开始执行        print(next(gen))    print(getgeneratorstate(gen)) # 在 yield 表达式出暂停        print(next(gen))    gen.close() # 手动关闭结束生成器    print(getgeneratorstate(gen)) # 执行结束GEN_CREATED0GEN_SUSPENDED1GEN_CLOSED\n生成器的异常处理\n在生成器工作中，若生成器不满足生成元素的条件，获取没有元素生产了，就会抛出异常(Stopiteration)\na = (x*x for x in range(1,3))next(a)next(a)next(a)\n\n---------------------------------------------------------------------------StopIteration                             Traceback (most recent call last)&lt;ipython-input-50-0f82892640d1&gt; in &lt;module&gt;()      2 next(a)      3 next(a)----&gt; 4 next(a)StopIteration: \n\n所以在定义生成器时，要考虑这个问题，在不满足生产元素条件的时候，抛出异常:\ndef my_gen(n):    a = 0    while a &lt; n:        yield a        a += 1    raise StopIterationif __name__ == &#x27;__main__&#x27;:    gen = my_gen(2)    next(gen)    next(gen)    next(gen)\n\n不过如果用for循环遍历生成器就不会抛出异常\n\n\n\n从生成器过渡到协程: yield\n通过上面的介绍，我们知道了生成器为我们引入了暂停函数执行(yield)的功能，当我们有了暂停函数的功能之后，就想能不能在生成器暂停的时候向生成器发送一点东西(gen.send(None)),这种机制催生了携程的诞生\n协程: 协程是为非抢占式多任务产生子程序组件的，协程允许不同入口点在不同位置暂停或开始执行任务\n从本质上来看，协程并不属于某种语言的概念，而是编程模型上的概念\n协程和线程一样都能交叉串行执行任务，但是线程频繁加锁解锁，线程切换。协程只要在yield暂停处把任务交到别处执行，协程还是很有发展潜力的\ndef fn(n):    a = 0    while a &lt; n:        jump = yield a        if jump is None:            jump = 1        a += jump        if __name__ == &#x27;__main__&#x27;:    itr = fn(5)    print(next(itr))    print(itr.send(2))\n\n02\n\nyield a 是将a返回出去\njump = yield 是接收传递进来的值\n\n\n"},{"title":"Python对象引用,可变性和垃圾回收机制","url":"/2021/12/30/Python%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8,%E5%8F%AF%E5%8F%98%E6%80%A7%E5%92%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/","content":"\n\nPython中的变量到底是什么\nPython的变量实质上是一个指针:\n\n事先没有预定大小，可以是任意类型，比如int,str\n\n可以理解成一个便利贴，可以贴在任何类型上\na = 1a = &#x27;tyu&#x27;\n\n可以理解成一个便利贴，a贴在1上\n注意:\n\n是先生成对象，然后再贴\n不需要声明类型\n\n看一个例子:\na = [1, 2, 3]\nb = a\nb.append(4)\nprint(a)\n输出：[1, 2, 3, 4]\n结论: a和b贴在了同一个地方\n判断一下a和b是不是同一个对象\na = [1,2,3]b = [1,2,3]print(a is b)# 输出：True\n\n再判断一下a和b是不是同一个内存地址:\na = [1,2,3]b = [1,2,3]print(id(a),id(b))# 输出：8533576 8533576\n\n\n==和is的区别\nis是判断两个变量引用对象id是否相等\n==用于判断引用变量的值是否相等\n整数:\na = 123456789b = 123456789print(a is b)print(a == b)# 结果：True True\n\n字符串:\na = &#x27;123456789&#x27;b = &#x27;123456789&#x27;print(a is b)print(a == b)# 结果：True True\n\n列表:\na = [1,2,3]b = [1,2,3]print(a is b)print(a == b)# 结果：False True\n\n字典:\na = &#123;&#x27;name&#x27;:&#x27;sixkery&#x27;&#125;b = &#123;&#x27;name&#x27;:&#x27;sixkery&#x27;&#125;print(a is b)print(a == b)# 结果：False True\n\n集合:\na = (1,2)b = (1,2)print(a is b)print(a == b)# 结果：False True\n\n总结:只要对象的值一样，那么a == b的值一定为True\n如果对象的类型为整数或者字符串且值一样，则a == b和a is b的值都为True(负浮点数不符合)\na = -1.0b = -1.0print(a is b)print(a == b)# 结果：False True\ndel语句和垃圾回收\nPython中垃圾回收算法是: 引用计数\na = 1 # 1 的计数器上加一b = a # 1 的计数器上再加一del a # 计数器减一print(b)print(a)# 结果：1Traceback (most recent call last):   File &quot;e:/python/test.py&quot;, line 8, in &lt;module&gt;    print(a) NameError: name &#x27;a&#x27; is not defined\n\n当计数器加为0的时候，Python就会把1回收，不占用内存\n\n\n"},{"title":"Python之多线程","url":"/2021/12/30/Python%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/","content":"多个任务可以由多进程完成，也可以由一个进程内的多线程完成。\n一个进程由多个线程组成，一个进程至少有一个线程。\n由于线程是操作系统直接支持的单元，因此，高级语言都内置多线程的支持，Python也不例外，并且Python的线程是真正Posix Thread，不是模拟出来的线程。\nPython的标准库提供了两个模块:_thread和threading，_thread是低级模块，threading是高级模块。绝大多数的情况下，我们只用threading就够了。\n启动一个线程就是把函数传入并创建Thread实例,然后调用start(),函数开始执行就可以了:\nimport timeimport threading #线程执行的代码def loop():    print(&#x27;thread %s is running&#x27; % threading.current_thread().name)    n = 0    while n &lt; 5:        n += 1        print(&#x27;thread %s &gt;&gt;&gt; %s&#x27; % (threading.current_thread().name,n))        time.sleep(1)    print(&#x27;thread %s end&#x27; % threading.current_thread().name) print(&#x27;thread %s is running...&#x27; % threading.current_thread().name)t = threading.Thread(target=loop,name=&#x27;LoopTread&#x27;)t.start()t.join()print(&#x27;thread %s end&#x27; % threading.current_thread().name)\n\n运行结果:\nthread MainThread is running...thread LoopTread is runningthread LoopTread &gt;&gt;&gt; 1thread LoopTread &gt;&gt;&gt; 2thread LoopTread &gt;&gt;&gt; 3thread LoopTread &gt;&gt;&gt; 4thread LoopTread &gt;&gt;&gt; 5thread LoopTread endthread MainThread end\n\n由于任何进程都会默认开启一个线程，我们把该线程称为主线程，主线程又可以开启新的线程，Python的threading模块有个current_thread()函数，它永远返回当前线程的实例；主线程实例的名字叫Main Thread，子线程的名字在创建的时候指定，我们用LoopThread命名子线程,名字仅仅在打印的时候用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为Thread-1,Thread-2\nLock\n多进程和多线程最大的不同在于，多进程中，同一个变量，各自有一份拷贝到每个进程，互不影响，而线程中，所有变量都是所有线程共享所有，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险就在与多线程同时修改一个变量，把内容给改乱了，举个栗子:\n#假定这是你的银行存款balance = 0 def change_it(n):    #先存后取    global balance    balance += n    balance -= n def run_thread(n):    for i in range(100000):        change_it(n) t1 = threading.Thread(target=run_thread,args=(5,))t2 = threading.Thread(target=run_thread,args=(8,)) t1.start()t2.start()t1.join()t2.join()print(balance)\n\n我们定义了一个共享变量balance，初始化为0，并且启动两个线程，先存后去，理论上结果应该为0，但是由于线程的调度是由操作系统决定的，当t1，t2交替执行时，只要循环次数足够多，balence的结果就不一定是0了，原因是因为高级语言的一条语句在cpu执行的时候是若干条语句，即使一个简单的计算:\nbalance += n\n\n也要分成两步:\n\n计算balance + n结果存到临时变量中\n将临时变量的值赋给balance\n\n究其原因，是因为修改balance需要多条语句，而执行这几条语句时，线程可能中断，从而导致多个线程把一个对象的内容改乱了。\n两个线程同时一存一取，就可能导致余额不对，你肯定不希望你的银行存款莫名其妙地变成了负数，所以我们要确保balance计算正确，就要给change_it()上一把锁，当某个线程开始执行change_it()时，我们说，该线程因为获得了锁，因此其他线程不能同时执行change_it(),只能等待，直到锁被释放后，获得该锁以后才能改。由于锁只有一个，无论多少线程，同一时间最多只有一个线程持有该锁，所以，不会造成修改的冲突。创建一个锁就是通过threading.Lock()来实现：\nlock = threading.Lock()def run_thread(n):    for i in range(100000):        #先要获取锁        lock.acquire()        try:            #放心改吧            change_it(n)        finally:            #改完记得释放锁哦            lock.release()\n\n当多个线程同时执行lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。\n获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用try…finally…来确保锁一定会被释放。\n\n锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行\n坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。\n其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。\n\n多核CPU\n如果你拥有一个多核CPU，你肯定在想，多核应该可以同时执行多个线程。\n如果写一个死循环的话，会出现什么情况呢？\n打开Mac OS X的Activity Monitor，或者Windows的TaskManager，都可以监控某个进程的CPU使用率，我们可以监控到一个死循环线程会100%占用一个CPU。如果有两个死循环线程，再多核CPU中，可以监控到会占用200%的CPU，就是占用两个CPU核心。如果想把N核CPU的核心全部跑满，就必须启动N个死循环线程，在Python中真的如此嘛?\n试试用Python写个死循环:\nimport threading, multiprocessing def loop():    x = 0    while True:        x = x ^ 1 for i in range(multiprocessing.cpu_count()):    t = threading.Thread(target=loop)    t.start()\n\n启动与CPU核心数量相同的N个线程，在4核CPU上可以监控到CPU占用率仅有102%，也就是仅使用了一核，但是用C、C++或Java来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%，为什么Python不行呢？\n因为Python的线程虽然是真正的 线程，但解释器在执行代码时，有一个GIL锁: Global Interpreter Lock,任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。\nGIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。\n所以，在Python中，可以使用多线程，但不要指望能有效利用多核，如果一定要通过多线程利用多核，那就只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。\n不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自的独立的GIL锁，互不影响。\n"},{"title":"Python图片灰度处理","url":"/2021/12/30/Python%E5%9B%BE%E7%89%87%E7%81%B0%E5%BA%A6%E5%A4%84%E7%90%86/","content":"Python的PIL库为我们提供了一些操作图片的方法，我们可以用这些把图片处理成我们想要的样子，比如把图片变模糊，或者改变大小，还有就是今天我们要讲的把图片变成漫画或者说素描的风格:\nfrom PIL import Imageimport numpy as npa = np.asarray(Image.open(&#x27;1.jpg&#x27;).convert(&#x27;L&#x27;)).astype(&#x27;float&#x27;)depath = 10 # (0-100)grad = np.gradient(a)# 取图像灰度的梯度值grad_x,grad_y = grad # 分别取横纵图像梯度值grad_x = grad_x * depath / 100.grad_y = grad_y * depath / 100.A = np.sqrt(grad_x ** 2 + grad_y ** 2 + 1.)uni_x = grad_x / Auni_y = grad_y / Auni_z = 1. / Avec_el = np.pi / 2.2 # 光源的俯视角度，弧度值vec_az = np.pi / 4 # 光源的方位角度，弧度值dx = np.cos(vec_el) * np.cos(vec_az) # 光源对 x 轴的影响dy = np.cos(vec_el) * np.sin(vec_az) # 光源对 y 轴的影响dz = np.sin(vec_el) # 光源对 z 轴的影响b = 255 * (dx * uni_x + dy * uni_y + dz * uni_z) # 光源归一化b = b.clip(0,255)im = Image.fromarray(b.astype(&#x27;uint8&#x27;)) # 重构图像im.save(&#x27;2.jpg&#x27;)\n\n"},{"title":"Python之多进程","url":"/2021/12/30/Python%E4%B9%8B%E5%A4%9A%E8%BF%9B%E7%A8%8B/","content":"要让Python实现多进程(multiprocessing),我们先来了解下操作系统相关知识, Unix和Linux操作系统提供了一个fork()函数系统调用，它非常特殊，普通的函数，调用一次它执行一次，但是fork()函数调用一次执行两次，因为操作系统自动把当前进程(称为父进程)复制了一份(称为子进程)，然后，分别在子进程和父进程中执行，子进程永远返回0，而父进程返回子进程的ID，而子进程只要调用getpid()就可以拿到父进程的ID。Python中os模块封装了常见的系统调用，其中就包括fork(),可以在Python程序中轻松创建子程序：\nimport os print(&#x27;Process (%s) start ...&#x27; % os.getpid())#Only work on Unix/linux/Mac#不能在Windows平台上运行pid = os.fork()if pid == 0:    print(&#x27;I am child process (%) and my parent is %s.&#x27; % (os.getpid(),os.getppid()))else:    print(&#x27;I (%) just created a child process (%).&#x27; % (os.getpid(),pid))\n\n运行结果:\nProcess (876) start...I (876) just created a child process (877).I am child process (877) and my parent is 876.\n\n由于windows平台下没有fork()函数调用，多以代码没有办法在windows平台下运行，有了fork调用，一个进程在接到任务的时候就可以复制出来一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出新的子进程来处理新的http请求。\nmultiprocessing(多进程)\n如果你想写多进程的服务程序，Unix/LInix平台最好了，当然也可以在Windows平台下来编写，因为Python跨平台，multiprocessing模块就是跨平台版本的多进程模块。multiprocessing模块提供了一个Process类来代表一个进程对象，下面一个例子来演示启动一个进程并等待结束的例子：\nimport osfrom multiprocessing import Process #子进程要执行的代码def run_proc(name):    print(&#x27;Run child process %s (%s)&#x27; % (name,os.getpid())) if __name__ == &#x27;__main__&#x27;:    print(&#x27;parent process %s&#x27; % os.getpid())    p = Process(target=run_proc,args=(&#x27;test&#x27;,))#创建子程序    print(&#x27;Child process will start&#x27;)    p.start()#子程序开始执行    p.join()    print(&#x27;Child process end.&#x27;)\n\n\n创建子程序时，只需要传入衣蛾执行的函数和函数的参数\n\n创建一个Process实例，用start()方式开启，这样创建的进程比fork还简单\n\njoin()方法可以等join子进程执行完后再继续往下运行，通常用于进程之间的同步\n\n如果想要启动大量的子进程，可以用进程池的方式批量创建子进程，如下所示：\nimport os,time,randomfrom multiprocessing import Pool def long_time_task(name):    print(&#x27;Run task %s (%s)...&#x27; % (name,os.getpid()))    start = time.time()    time.sleep(random.random() * 3)    end = time.time()    print(&#x27;Task %s run %0.2f seconds.&#x27; % (name,(end-start))) if __name__ == &#x27;__main__&#x27;:    print(&#x27;Parent process %s.&#x27; % os.getpid())    p = Pool(4)    for i in range(5):        p.apply_async(long_time_task,args=(i,))    print(&#x27;Waiting for all subprocess done...&#x27;)    p.close()    p.join()    print(&#x27;All subprocess done&#x27;)\n\n"},{"title":"Python思维导图","url":"/2021/12/31/Python%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/","content":"\n\n原文链接:https://blog.csdn.net/qq_44647926/article/details/90669352?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164090955916780269896755%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=164090955916780269896755&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-13-90669352.first_rank_v2_pc_rank_v29&amp;utm_term=Python&amp;spm=1018.2226.3001.4187\n"},{"title":"什么是宝塔面板","url":"/2021/12/31/%E4%BB%80%E4%B9%88%E6%98%AF%E5%AE%9D%E5%A1%94%E9%9D%A2%E6%9D%BF/","content":"简单来说: 就是装在服务器上的管理面板！\n宝塔面板是一款简单好用的服务器运维面板，简单说来就是一个可视化的面板管理工具，支持一键LAMP/LNMP/集群/监控/网站/FTP/数据库/JAVA等100多项服务器管理功能。出错少而且安全，由于宝塔面板既有windows版本也有linux版本，尤其是Linux服务器很多用户不会操作，宝塔是为了让那些不会linux的人使用的，使用宝塔，操作linux更简单，更方便，这里要提醒一下虽然宝塔面板可以安装在物理服务器或者云服务器，虚拟主机无法安装的，但是云服务器基本都是可以安装的。\n大型网站程序都安装在服务器上，服务器用的是Linux系统，进行服务器维护需要记住很多的linux命令，这就比较麻烦；\n面板的好处就是通过一个交互界面就能完成服务器的维护工作，比如更新系统，添加网站，修改设置等等，以前需要记住各种命令，下你在通过面板点点按钮就可以了，省时省力.\n"},{"title":"Docker最详细入门教程","url":"/2022/01/05/Docker%E6%9C%80%E8%AF%A6%E7%BB%86%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","content":"请参考: http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html\n"},{"title":"科学上网教程","url":"/2021/12/31/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E6%95%99%E7%A8%8B/","content":"最近在搭hexo博客的时候在一篇theme配置教程中看到了一个开源的图床项目，里面有关于科学上网的介绍，这里我把它搬出来，详情请点击:https://github.com/Alvin9999/new-pac/wiki\n"},{"title":"推荐一款基于GitHub好用的在线图床工具","url":"/2021/12/31/%E6%8E%A8%E8%8D%90%E4%B8%80%E6%AC%BE%E5%9F%BA%E4%BA%8Egitgub%E5%A5%BD%E7%94%A8%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%9B%BE%E5%BA%8A%E5%B7%A5%E5%85%B7/","content":"这是一款基于GItHubAPI开发的图床神器，图片外链使用jsDriver进行CDN加速，免下载，免安装，打开网站简单配置后即可直接使用，免费，稳定，高效\nPicX官网: https://picx.xpoet.cn/#/upload\nPicXGitHub地址: https://github.com/XPoet/picx\n"},{"title":"Bash脚本教程","url":"/2022/01/05/Bash%E8%84%9A%E6%9C%AC%E6%95%99%E7%A8%8B/","content":"请参考: https://www.ruanyifeng.com/blog/2020/04/bash-tutorial.html\n"},{"title":"SSH最详细入门教程","url":"/2022/01/05/SSH%E6%9C%80%E8%AF%A6%E7%BB%86%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","content":"请参考: https://www.ruanyifeng.com/blog/2020/12/ssh-tutorial.html\n"},{"title":"Docker10分钟快速入门","url":"/2022/01/05/Docker10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","content":"\ndocker是用来解决什么样的问题而出现的呢？\n比如你写了个web应用，并且本地调试没有任何问题，这时候你想发给你的朋友试试看，或者部署到远程的云服务器上，那么首先，你需要配置相同的软件，比如数据库，web服务器，必要的插件，库等等:\n\n而且你还不能保证软件一定能正常地运行起来，因为别人用的可能是完全不同的操作系统，即便同样是使用Linux，每一种发行版也会有微小的区别，为了模拟完全相同的本地环境，我们自然会想到使用虚拟机:\n\n但是虚拟机需要模拟硬件，运行整个操作系统，不但体积臃肿，内存占用高，程序的性能也会收到影响，这时候我们的docker就派上了用场，Docker在概念上与虚拟机非常类似，但却轻量很多，它不会去模拟底层的硬件，只会为每一个应用提供完全隔离的运行环境:\n你可以在环境中配置不同的工具软件，并且不同环境之间相互不影响，这个“环境”在Docker中也被称作container/容器，降到这里，我么就不得不提到Docker中的三个重要概念，Dockerfile，Image和Container:\n\n\nDocker中三个重要的概念\n\nImage:\n\n你可以把它理解为一个虚拟机的快照(Snapshot)，里面包含了你要部署的应用程序以及它所关联的所有库，通过镜像，我们可以创建许多个不同的Container容器:\n这里的容器就像是一台台运行起来的虚拟机，里面运行了你的应用程序，每个容器是独立运行的，他们相互之间不影响，最后Dockerfile就像是一个自动化脚本，它主要被用来创建我们之前讲到的镜像(Image)，这个过程就好比是我们在虚拟机中安装操作系统和软件一样，只不过是通过Dockerfile这个自动化脚本完成了\n\nImage\nDocker把应用程序及其依赖，打包在Image文件里面，只有通过这个文件,才能生成Docker容器，Image文件可以看成是容器的模板，Docker根据Image文件生成容器的实例，同一个Image文件，可以生成多个同时运行的容器实例\n# 列出本机的所有 image 文件。$ docker image ls# 删除 image 文件$ docker image rm imageName\nContainer\nContainer就类似于我们所创建的虚拟机，内存没有虚拟机那么大，也更容易创建\n\n\n\n快速上手Docker的最好方法就是亲自安装并去使用它:\n如果你是用的是windows和mac，你可以在官网下载一个Docker Desktop的应用，而且在win10上你可以使用WSL2(也就是windows下的Linux子系统)来运行Docker，如果你不是使用的windows最新的预览版本，WSL2的安装可能稍微复杂一点，不过也是按照官网的给定步骤进行安装，在linux中，我们可以直接使用包管理工具，按照官网给定的指示一步步执行即可，如果使用的是vscode，也特别推荐安装docker的扩展:\n\n他会提供Dockerfile的语法检测，代码高亮，自动补全等等，你也可以通过菜单运行各种Docker命令并且在左侧面板中看到你创建的所有镜像:\n\n接下来我们就尝试使用Docker来部署一个应用，以之前写的一个python程序举例，这是一个非常简单的用Flask搭建的记账工具:\n\n首先我们在应用的根目录下创建一个Dockerfile文件:\n\n第一行我们需要用FROM命令指定一个基础镜像(base image)这样可以帮我们节省许多软件安装和配置的时间:\n\n可以看到在DockerHub上提供了许多高质量的操作系统镜像，比如ubuntu:\n不同的操作系统提供不同的包管理工具，比如ubuntu上的apt，Fedora上的dnf，当然在Docker Hub上还有许多方便某一种语言，某种框架开发的镜像，比如你nginx,Python,node等：\n\n由于我这里做的是python的开发，自然我会使用Python的镜像，这样免去了它的安装步骤，这里的Python是官方镜像的名字:\n\n冒号后面这一串是版本号，同时也是一个标签，我们可以在docker hub中搜索Python然后点击Python转到docker hub的镜像页面，里面可以找到所有支持的标签:\n比如我们这里用的是Python 3.8版本：\n\n运行在debian buster的发行版本上，后面的workdir指定了之后所有Docker命令的工作路径(working directory),注意是这个命令之后的所有Docker命令，比如我们马上要讲到的run，copy等：\n\n当然如果这个路径不存在，Docker会自动帮你创建，这样可以避免使用绝对路径或者手动cd切换路径，增加程序的可读性，之后，我们可以调用copy命令将所有的程序拷贝到Docker镜像中(copy./app表示将当前目录下所有文件(除了.dockerignore排除的路径),都拷贝进入image文件的/app目录)：\n第一个参数代表本地文件，“.”代表程序根目录下的所有文件，第二个参数代表Docker镜像中的路径，这里的.代表当前的工作路径，也就是之前指定的app目录，随后的run允许我们在创建镜像时运行任意的shell命令，因为我们用的是Linux镜像，所以像echo，pwd，cp，rm这些都是合法的，比如我这里用到pip install 来安装Python程序的所有关联:\n通过以上的所有命令，我们就可以完成一个Docker镜像的创建，在Dockerfile的最后，我们会用到CMD来指定当Docker容器运行起来以后要执行的命令：\n\n大家需要注意这里容器和镜像的区别(容器不等于镜像),并且它和之前讲到的run不一样，run是创建镜像时使用的，而cmd是运行容器时使用的，到这里我们的自动化脚本dockerfile就完成了，接下来我们可以使用docker build来创建一个镜像，这里的-t指定了镜像的名字，最后面的.告诉docker应该在当前目录下寻找这个dockerfile，这个不能省略:\n\n第一次调用docker build会比较慢，因为docker会下载必要的镜像文件:\n然后一行行运行我们的指令，不过再次调用就会快很多，\n因为docker会缓存之前的每一个操作，这个在Docker中也被称为分层:\n\n这里我们就不展开谈论了\n有了镜像之后，我们就可以通过docker run来启动一个容器\n这里需要注意的是这个-p参数：\n\n他会将容器上的某一个端口，映射到你的本地主机上，这样你才能从主机上访问容器中的web应用，前面的80是我们本地主机上的端口，后面是容器上的端口，这个不要搞反了，第二个参数-d(–detached)让容器在后台运行，这样容器的输出就不会直接显示在控制台，如果不出意外的话，你已经可以在浏览器中访问这个web应用了，我们通过Docker Desktop这个图形界面可以查看应用在后台的所有输出:\n这个对于调试非常方便，同时我们可以看到当前容器的各种信息：\n\n这里的congainer显示了我们创建的所有容器,我们可以选择停止，重启或者删除他们，还可以通过shell远程调试这个容器：\n\n\n这里是它们所对应的的命令行指令：\n\n需要注意的是，当我们删除一个容器的时候，之前所做的修改，新添加的数据会全部丢失，这就好比是我们删除一个虚拟机，里面的数据会一通销毁一样，如果我们希望保留容器中的数据，我们可以使用Docker提供的volume数据卷:\n你可以把它当做是一个在本地主机和不同容器中共享的文件夹:\n\n比如你在某个容器中修改了某一个volume的数据，他会同时反映在其他的容器上:\n\n我们可以通过docker volume create来创建一个数据卷：\n\n随后在启动容器的时候我们可以通过-v参数指定将这个数据卷挂载(mount)到容器中的哪一个路径上:\n\n这里可以看到我们将my-finance-data挂载到了/etc/finance这个路径下，向这个路径写入的任何数据都会被永久保存在这个数据卷中\n\n多容器共同协作\n之前我们讲到的例子都只涉及单个容器，但在实际使用中，我们的应用程序可能会用到多个容器共同协作，比如我们可以使用一个容器来运行web应用，另一个容器来运行数据库系统:\n\n这样可以做到数据和应用逻辑的有效分离，比如当web程序宕机了，数据库依然在有效运转，这个时候我们只需要修复web容器即可，而Docker compose刚好可以帮我们做到这一点：\n我们可以创建一个docker-compose.yml文件，在这个文件下，我们通过services来定义多个container，比如这里我们定义一个web容器，它里面运行了我们的web应用，然后再定义一个db容器，里面运行了mysql数据库系统,这里我们可以通过这两个环境变量指定数据库的名称和连接密码：\n\n同时在db容器中，我们还可以通过volumes指定一个数据卷用来永久存放数据：\n\n定义完毕之后，我们保存文件，使用docker compose up来运行所有容器，这里的-d(detach)同样代表在后台运行所有的容器，不直接输出在控制台:\n\n与这个命令对应的，我们可以使用docker compose down来停止并删除所有的容器:\n不过新创建的数据卷需要我们手动删除(除非在上面的命令中加上–volumes参数)：\n\n另外刚刚讲到的所有操作都可以做图形界面上完成\n\n简单聊下Docker和kubernetes的区别和联系\n虽然大家都说kubernetes在逐渐取代Dokcer，但其实指的是kubernetes中的容器引擎(container engines)而已：\n实际上kubernetes和Docker并不是同一个层面上的东西，在之前的例子中，我们的应用，数据库容器都运行在同一个计算机中，随着应用规模的增大，一台计算机没有办法满足我们的需求:\n\n当我们想使用一个集群的电脑来提供服务，并做到负载均衡，故障转移等等，这个时候kubernetes就可以大显身手了，一句话将，kubernetes所做的就是将你的各个容器分发到一个集群(cluster)上运行，并进行全自动化的管理，包括应用的部署和升级\n\n最后附上docker中文教程\nhttps://www.coonote.com/docker/docker-tutorial.html\n\n\n"},{"title":"Kubernetes(k8s)10分钟快速入门","url":"/2022/01/06/Kubernetes(k8s)10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","content":"\n首先来看看Kubernetes用来解决一个什么样的问题\n我们知道Docker就像是一个轻量型的虚拟机，它将应用程序的代码，工具库和运行环境全部都封装到了一个容器中:\n因此大大降低了测试和部署的难度，我们要做的不过是在服务器上运行一条指令而已:\n\n但如果你要部署的是像购物系统这类架构复杂，规模庞大的应用，他们需要根据访问量自动分配服务器，网络资源，并且在某个容器宕机之后自动进行灾难恢复，故障转移：\n这个时候Kubernetes就可以大显身手了\n\n我们先从整体上来认识下Kubernetes的工作原理\n我们知道，Kubernetes是一个用于大规模部署分布式应用的平台，他管理着一系列的主机或者服务器：\n他们被称作Node(节点)，每个节点运行了相对独立的pod：\npod是Kubernetes中可以部署的最小执行单元，说白了他就是一个或者多个容器的集合，其中运行了我们应用的某一部分核心组件，比如数据库，web服务器等等，当然这么多的pod，他们需要相互协调才能做到负载均衡或者故障转移，这就需要一台中心计算机来集中管理，这个中心计算机被称作Control Plane(控制面板):\n控制平面通过专有的API与各个节点进行通信，他会实时监测节点的网络状态来平衡服务器的负载，或者临时下发指令来应对突发的状况，比如Kubernetes发现某个容器或者pod挂掉了，他会立即启用在后台预先准别好的，随时待命的备用容器来替换它，这些容器被称作Replica Set(副本集合),正是由于他们的存在，才让我们的应用能够长时间，不间断地可靠运行，而以上讲到的所有节点连同控制面板，一起被称作一个cluster(集群)集群代表了Kubernetes所管理的全部主机节点，要配置一个Kubernetes集群，我们当然可以亲自租用服务器去搭建环境，不过步骤会稍微繁琐一点，另一种做法是使用现成的、预先配置好的云服务提供商:\n\n一种完全免费的方法是使用minikube在本地模拟一个Kubernetes集群，这也是我接下来要用到的方法：\n\n使用Kubernetes\n上面我们提到，使用minikube在本地模拟一个Kubernetes集群，在这里面，我们照样可以使用Kubernetes的全部功能，只不过他不是一个真实的生产环境而已\n我们按照这里的步骤下载并安装对应的版本:\n随后只需要一行指令minikube start启动本地模拟的集群即可:\n\n我们来讲下如何在上面部署一个应用\n首先我们需要创建一个yaml文件，里面定义了我们应用的基本信息，比如它由哪些pod组成，里面运行了哪些容器，以及网络配置等等，它和docker中的dockerfile很类似，你可以把它当做一个自动化脚本，里面描述了应用部署的整个过程，另外在vscode中，强烈建议去安装一个Kubernetes插件，他除了提供基本的语法检测、代码提示，在左侧面板中该显示了我们急缺的各种信息、运行状态：\n整个部署的过程也都可以通过图形界面完成\n这里我们先创建一个deployment.yaml文件，然后输入deployment:\n\n让vscode帮我们生成一个最最基本的配置：\n可以看到这里列出了相当多的属性，我们可以将鼠标悬停在上面找到每个属性的详细用法:\n\n接下来我们去修改其中我们关系的部分即可，首先第一步我们先将所有的myapp改成我们应用的名字，这里的replicas指定了连同备用pod在内的所有pod数量:\n然后最重要的是这里的这个templates，它里面定义了与pod相关的所有信息：\n比如下面的container指定了pod中运行的所有容器\n这里我还是用上个视频同样的项目，一个简单的记账工具(一个非常简单的web应用)作为演示，不过我事先将他的镜像(image)上传到了Docker Hub上：\n这样Kubernetes可以自动拉取到它，于是我们这里直接填写镜像的名称即可：\n另外我们可以通过这里的limits为每一个pod设置合理的cpu和内存配额：\n\n最下面的containerPort指定了容器需要对外暴露的端口：\n比如我们web容器使用的是5000端口\n在默认情况下，我们的pod只能与同一个集群内的其他pod进行通信，虽然每一个pod都拥有一个独立的ip\n\n但这个ip地址对于外网是不可见的，如果要从外网访问我们的应用，我们还需要用到Kubernetes中另一个重要的组件–服务(Services)\n现在我们讲一种最最基础的服务，NodePort，它是一种最原始的将应用端口暴露给外网的方式：\n\n建立在它之上，Kubernetes还提供LoadBalancer或者更加复杂的ingress来实现负载的均衡，不过这里就不展开讨论了，我们先在下方用三个横线隔开(yaml中列表的语法)，然后输入Service来添加一个服务：接下来我们在selectors中指定应当将数据转发到哪一个pod上,这里直接填写之前的应用名称即可：\n\n随后的type指定了服务的类型，也就是NodePort:\n后面的port和targetport我们设置成5000和容器端口保持一致，最后的nodeport指定了暴露给外网的端口，这里我设置成了30080，当然我们也可以省略这一行让Kubernetes自动进行分配：\n到这里我们的配置文件就完成了，接下来到了真正应用部署的环节：\n\n应用部署\n这里我们会用到一个命令行工具kubectl来与kubernetes集群进行交互：\n这是一个所有平台通用的工具，就好比我们之前用到的docker命令一样，他可以操纵任何的集群，包括我们本地模拟的ninikube，通常Docker的桌面版本都自带了cubectl命令，但如果你计算机中没有安装Docker，则需要去这里额外下载:\n安装完毕后，我么可以使用kubectl apply来部署我们的应用，并且传入之前创建的这个yaml文件：\n可以看到这个命令被成功执行，此时kubernetes会在后台开始应用的部署：\n我们可以通过kubectl get pods查看所有pod的运行状态，这里显示了我们之前指定的其中包括pod在内的三个pod,他们目前都是正常运行的状态:\n\n另外使用kubectl get services可以查看所有创建的服务\n\n看到这里，既然应用已经被成功部署，我们自然可以去浏览器中访问它。由于这里我们用到的是minikube模拟的集群，所以需要用到一个专门的指令minikube service 后面跟上我们服务的名字：\n这样minikube会自动在浏览器中打开我们的应用，另外顺便提一下，之前所有的操作也都可以通过vscode中的插件完成，里面可以查看各个节点，pod，服务的运行状态，停止或者删除它们：\n\n更新应用\n这个时候如果我们想要更新应用，比如切换容器镜像的版本，或者重新分配cpu和内存资源，我们只需要去修改之前的deployment.yaml文件：\n然后再次调用kubectl apply即可\n\nkubernetes会在后台无缝地更新我们的应用，确保新版本运行起来以后再去销毁旧的版本，因此用户不会遇到服务停机的问题，类似的，如果我们不再需要这个应用，那么可以通过kubectl delete命令从集群上完全移除它：\n后面我们传入相同的配置文件即可\n讲到这里，我们也不是是介绍了kubernetes中一个非常简单的应用部署，通常生产环境下的应用比这个要复杂得多，如果大家想继续深入的话，还是建议去阅读下官方的文档，里面可以找到各种实用的案例，包括安全配置，网络管理，故障排除甚至是GPU调度等等\n\n\n"},{"title":"Puppeteer10分钟快速上手","url":"/2022/01/06/Puppeteer10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/","content":"爬虫，它就像是一只在互联网删爬行的蜘蛛，会根据我们实现定义好的规制为我们抓取需要的信息，以Python为例，你可以使用urllib或者requests发起一个http请求，并使用beautifulsoup或者lxml来分析返回的html文档，从中提取你需要的信息:\n当然你也可以使用Scrapy这种专门为爬虫设计的框架，帮你完成从数据抓取，解析，存储以及调试的所有流程，Scrapy这类框架的优点自然是功能全，速度快，灵活性高，扩展性强，但是由于现在大多数网站都是动态加载的，前端呈现的内容可能由极其复杂的JavaScript程序控制，遇到加密混淆的程序，可能自己还得去逆向分析很久，今天我为大家介绍另一种，基于puppeteer的爬虫思路， 虽然他的效率不是最高的，但一定能让你在最短的时间内快速实现一个爬虫，并帮你抓取到需要的信息\n\n首先来介绍下puppeteer\npuppeteer是一款强大web自动化工具，相比较selenium，phantomjs这些老牌的框架，puppeteer绝对是后起之秀，如果你写了一个web应用，你需要对页面的功能进行测试，譬如检测某个按钮是否会唤醒对话框界面，puppeter就完全可以胜任这个任务，由于它可以对浏览器进行操控，获取页面数据，自然也可以用它来做爬虫，爬虫不过是它众多应用中的其中一种，其实对于任何自动化的操作，我们都可以用它来完成，谷歌官方的puppeteer是通过JavaScript调用的，但是它在Python，Ruby，Go上都有对应的移植版本，如果你使用Python，你可以下载一个叫做pyppeteer的包，其中所有的API都是一致的，除了少数语法的不同，这里以JavaScript作为演示：\n\nJavaScript演示puppeteer\n首先确保你计算机中安装了Node.js：\n然后创建一个目录来保存我们这个项目(也就是这里的web-scraping-node)：\n\n然后使用npm init 初始化工程:\n最后使用命令npm i puppeteer:\n这过程会持续一段时间，取决于你的网速\n接着我们在文档的入门指南中找到这样一段样例程序，我们直接将代码复制到编辑器中，在它的基础上做修改:\n\n这是修改前的代码:\n这10行代码非常简单:\n这是创建一个浏览器对象:\nconst browser = await puppeteer.launch();\n\n打开一个新页面:\nconst page = await browser.newPage();\n\n然后转到example.com\nawait page.goto(&#x27;https://example.com&#x27;);\n\n保存一张截图后退出:\nawait page.screenshot(&#123;path: &#x27;example.png&#x27;&#125;);\n\n如果你运行代码，在短暂的等待之后，程序会当前目录下保存一张截图文件:\n这里我们稍做修改，首先在创建浏览器对象的时候传入一个新参数headless: false,因为puppeteer默认运行在无头(headless)模式下，也就是说浏览器窗口并不会显示出来，这里我们通过这个参数关闭无头模式，接着我们将网址改为百度，并且删除后面的screenshot()和borwser.close(),保存程序，运行程序，可以看到puppeteer成功打开了百度并显示在新创建的浏览器窗口中，需要注意的是，这里窗口边缘的空白是一个feature，并不是一个bug:\n\n\n用puppeteer写爬虫\n将bilibili上的音乐的热门信息给提取出来\n以下是实施的步骤:我们打开浏览器的控制台，然后我们可以在这里输入任何JavaScript表达式来做测试，比如:\n\n\n如果我们想要在页面中提取相似的元素，我们可以用到selector(选择器)或者xpath，选择器的语法更为简单些，这里我们以选择器为例，比如你想要的匹配页面中的所有链接，可以在控制台中输入$$(‘a’),如果你想要匹配所有li元素下的a标签则可以输入$$(‘li &gt; a’),这里我们想找出能匹配这个视频标题的选择器，其实chrome给我们提供了一个便利，我们可以在标题上点右键，选择下方的检查，选中的元素就会以高亮的形式显示在右边:\n我们点击右键，选择这里的复制选择器：\n\n接下来我们只需要稍作修改，比如删掉这里多余的部分，做一些简化:\n就可以提取出所有的标题元素了：\n然后我们可以遍历返回的每个元素，将标题文字给提取出来:\n\n我们可以先记下这段选择器，待会儿我们就会用到，我们先将浏览器中的网址直接拷贝过来,接下来使用page对象的$$eval函数来获取所有的视频标题：\n这里的第一个参数是选择器，就是我之前测试时用于提取标题的选择器，第二个参数要求你传入一个函数，这个函数会直接在网页的上下文中运行，筛选出你需要的数据并返回给puppeteer，这里我做的是遍历所有的a标签,并将其中的文本给提取出来，我们可以调用log函数将结果打印出来：\n\n运行程序，我们可以看到这样的结果：\n这里为了让程序更健壮，我们可以在获取标题之前，先等待标题元素的出现，这样可以避免页面加载期，无法找到元素而报错的现象:\n后面的代码直接上，我们限定了数据的时间，然后以json的数据格式保存下来：\nconst puppeteer = require(&quot;puppeteer&quot;);const fs = require(&quot;fs&quot;);(async () =&gt; &#123;  let data = [];  const browser = await puppeteer.launch(&#123;    headless: false,    userDataDir: &quot;./data&quot;,  &#125;);  const page = await browser.newPage();  for (let mo = 1; mo &lt; 12; mo++) &#123;    for (let pg = 1; pg &lt;= 10; pg++) &#123;      mo = mo.toString().padStart(2, &quot;0&quot;);      await page.goto(        &quot;https://www.bilibili.com/v/music/cover/?spm_id_from=333.5.b_7375626e6176.3#&quot; +          `/all/click/0/$&#123;pg&#125;/2020-$&#123;mo&#125;-01,2020-$&#123;mo&#125;-29`      );      await page.waitForSelector(&quot;.vd-list-cnt &gt; ul &gt; li &gt; div &gt; div.r &gt; a&quot;);      let titles = await page.$$eval(        &quot;.vd-list-cnt &gt; ul &gt; li &gt; div &gt; div.r &gt; a&quot;,        (links) =&gt; links.map((x) =&gt; x.innerText)      );      console.log(titles);      data = data.concat(titles);    &#125;  &#125;  fs.writeFile(&quot;data.json&quot;, JSON.stringify(data, null, &quot;\\t&quot;), function (err) &#123;    if (err) &#123;      console.log(err);    &#125;  &#125;);&#125;)();\n最后我想提一个大家可能经常会遇到的问题\n我们每次运行脚本的时候，puppteteer磨人都会为我们创建一个崭新的实例，也就是像网页的缓存、cookie都会在脚本退出之后自动销毁：\n像网站的登录信息也不会被保存下来，而通常我们并不希望每次运行脚本都去登录一次，这里我们可以给launch指定另外一个参数，他会将浏览器的数据保存在这个指定的路径下，因此所有的浏览器实例都会共享这些数据：\n登录信息也会被保存下来\n其实用puppteteer来做爬虫确实是一种不错的选择，要知道现在大多数网站都是使用了前端的JavaScript程序来做渲染的，相比于http层的爬虫工具，puppteteer更像是一个模拟网页操作的机器人，他用起来直观很多，也帮我们省去了不少分析前端代码的时间，不过想scrapy还是很强大的，尤其是他的速度和性能\n源码：https://github.com/rossning92/web-scraping\nPuppeteer 中文文档：https://zhaoqize.github.io/puppeteer-api-zh_CN/\n\n\n"},{"title":"mac终端美化教程","url":"/2022/01/07/mac%E7%BB%88%E7%AB%AF%E7%BE%8E%E5%8C%96%E6%95%99%E7%A8%8B/","content":"mac终端美化请参考:https://www.wolai.com/fishc/exwe9Srj8St6THjGE6YVyz\n"},{"title":"Linux系统启动过程","url":"/2022/01/07/Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/","content":"按下系统的电源开关，过一会儿就可以看到Linux的登录界面，你是否想过，从按下电源开关到登录界面的出现，这后面到底发生了什么?\n我们先来看看一个整体的流程图:\n\nLinux系统在启动过程中，首先是固件(PC上大多是CMOS/BIOS)的物理检测，诸如检测系统的显卡，CPU和硬盘等，可从系统按下电源键后看到此检测信息；检测没有问题后，将读取硬盘的MBR(主引导记录)中的自举程序，Linux中常用的自举程序如LILO和GRUB。自举程序GRUB在系统启动期间只有一个作用，就是启动内核，内核在引导期间有两个主要的作用，一个是驱动系统硬件，另一个是启动系统init，init进程将读取其配置文件/etc/initab完成后继续所有的引导。\n整个过程基本可以分为六个步骤:BIOS–&gt;MBR(GRUB)–&gt;Kernel–&gt;Init–&gt;Runlevel:\n\n\n\n\n\n\n"},{"title":"10分钟彻底搞懂“动态规划”算法","url":"/2022/01/06/10%E5%88%86%E9%92%9F%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82%E2%80%9C%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E2%80%9D%E7%AE%97%E6%B3%95/","content":"动态规划是计算机中解决最优化问题的一种方法，它通常给我们的印象是效率高，速度快，但对于初学者来说，可能并不是那么容易理解，今天，我们抛开所有的数学公式，用实例给大家彻底讲懂动态规划算法。\n首先我们来看一个经典的动态规划问题:\n给你一个无序的数组，要求我们找出其中最长的递增的子序列:\n\n比如这里的1，2，4就是其中一个:\n\n1，2，3是另外一个答案:\n\n这里我们再对这个问题做一些简化，我们要求这个算法只返回最长序列的”长度”就好了:\n\n也就是3:\n\n如果是你，你会怎么去求解这个问题呢？\n其实最容易想到的办法是暴力枚举，或者叫暴力搜索；比如从1出发，下一个数字可以取5，2，4或者3，因为他们都是递增的:\n\n假如我们第二个数字选5的话，再下一个数字就取不了了，因为剩下的2，4，3都比5小，不能构成一个递增序列:\n那如果第二个数字选2的话，下一个数字可以是4，也可以是3，此时构成的递增序列长度为3:\n\n以此类推，如果第三个数字取4，下一个数字依然不能选，因为3比4小：\n\n算法就这样一直循环往复地执行下去，直到我们把每个子序列都找了个遍：\n并且在遍历过程中，我们实时记录最长的子序列长度，最后可以知道，最长的子序列长度为3:\n\n最后，我们按照同样的方法计算”从5出发”，”从2出发”，”从4出发”，”从3出发”的序列长度，选出最长的那个，算法结束：\n\n那么我们应该如何去实现这个算法呢？\n我们可以定义一个函数L，这个函数会返回从数组第i个数字开始的最长子序列长度：\n\n然后我们检查i后面的所有数字，我们将索引记为j，只要这个数比当前数大(也就是说可以构成递增序列),我们就递归地调用函数自身，去计算从j开始的最长子序列长度:\n\n然后加1得到目前这个序列的总长度:\n\n接着我们只需要遍历所有的j，然后选出最长的子序列长度返回即可:\n\n当然这个递归函数不能永无止境地调用下去，当i取到最后一个数字的时候，由于它后面已经没有其他数字与它构成子序列了\n\n所以我们直接返回长度1:\n接下来我们只需要对数组中的每一个数i依次调用L函数，然后选出长度最长的那个返回即可：\n我们可以带入之前的数据进行测试:\n\n可以看到这个算法成功返回了3:\n\n这个算法虽然能够帮我们算出答案，不过它最大的问题在于时间复杂度，假设数组的长度为n，那就一共存在2^n个子序列，而每一个子序列我们都需要去遍历一次(判断是否是递增序列)\n\n很显然这是一个指数级别的算法，最慢的算法之一，如果我们用长度为100的数组做测试，可以看到程序运行了整整5秒才算出答案：\n\n我这自己重写了一遍半分钟还没出结果：\n\n那有没有可能对算法进行一些优化呢，如果我们观察这个遍历树，会发现里面存在大量的重复计算：\n比如我们在遍历子序列1，2， 4的时候就已经计算过“从4开始的最大子序列的长度”\n\n后面遍历1,4的时候又重复计算了一次\n\n为了避免重复的计算，我们可以在第一次计算的时候将结果保存下来，之后遍历到相同的节点我们就不用再重复计算了\n\n直接将之前的结果返回\n这里我们可以用一个字典(哈希表)memo记录下“从i开始最长的子序列长度”也就是代码中的max_len，然后我们在函数的开头检查之前是否保存过这个答案，如果是，直接返回结果，否则再去计算答案：\n可以看到经过修改的代码，只用了1毫秒就计算出了结果\n\n相比较之前的5秒是巨大的速度提升，动态规划正是通过避免重复节点的计算，来加速整个计算的过程，由于用到了字典(哈希表)来保存了计算的中间结果，因此我们也称之为“记忆化”搜索，这也是大家经常会说动态规划是“空间”换“时间”,当然也有人叫它“带备忘录”的递归或者叫递归树的“剪枝”，它们都是同一个意思，因为我们不需要对这些树子节点进行重复计算了：\n有了递归的算法，我们还可以尝试将它改写成非递归，或者也叫迭代的形式，这样我们可以更加直观地去分析算法的时间复杂度，并且避免了递归时候的函数调用开销：\n从之前的算法我们知道，要计算出从“1”开始的最长子序列长度，我们需要依次检查它后面的所有数\n\n由于1可以和5，2，4，3构成递增序列，所以我们需要递归地计算从5,2,4,3开始的最长子序列长度，然后选出最长的那个，然后加1得到与第一个数构成的最长子序列长度：\n同样的，要计算从“5”出发的最长子序列，我们也需要先检查它后面的数：\n然后进行同样的计算\n这里很显然，因为后面没有数可以与它构成递增序列，所以结果直接是1：\n\n我们这样以此类推下去，直到最后一个数，由于从3出发的子序列之能是它自己，所以长度直接是1:\n\n从这里的公式中可以发现，我们只要从后往前依次计算，就能把所有的答案给推算出来，大家是不是觉得很像数学归纳法：\n\n最后我们根据列出的式子来实现这个迭代算法：这里我们可以通过两个循环，外面的循环代表从下往上的依次计算：\n里面的循环用于遍历括号中的这些数值:\n\n运算的结果我们可以存放在一个数组中，我们直接叫它L：\n接下来只要后面的数比当前数大(能构成递增序列)，我们就按同样的方法来计算这个L(i):\n最后我们返回L数组中最大的那个即可\n\n这个该写的迭代算法同样可以帮我们计算出最终答案，并且由于这里只用了两个循环，每个循环最多执行n次，因此算法的时间复杂度是o(n^2)和之前的指数级别的算法是天壤之别\n最后我们来总结下动态规划的一般思路：\n\n穷举法/暴力搜索\n记忆化搜索/剪枝\n改写成迭代形式\n\n首先，我们可以先简单粗暴地将所有答案穷举出来\n\n并画出递归树\n\n尝试写一个递归函数来求解，如果发现遍历中存在大量的重复计算\n\n我们可以尝试用哈希表将数据缓存下来\n\n之后遍历到相同的节点就直接查表，避免重复的计算\n最后，我们可以将计算的过程表示出来，然后观察公式求解的顺序\n\n并尝试将递归形式改写成更简洁高效的迭代形式:\n如果大家搞懂了之前的内容，不如我们来试试另一个经典的动态规划问题，给你一个数组，要求我们要找出其中连续子序列的最大和:\n\n比如这里的[2, -1, 2, 6]和最大:\n这个问题又如何求解呢\n"},{"title":"0.1+02等于0.3嘛，无可避免的浮点误差","url":"/2022/01/07/0.1+02%E7%AD%89%E4%BA%8E0.3%E5%98%9B%EF%BC%8C%E6%97%A0%E5%8F%AF%E9%81%BF%E5%85%8D%E7%9A%84%E6%B5%AE%E7%82%B9%E8%AF%AF%E5%B7%AE/","content":"在我们印象中，计算机总是能高效准确地进行运算:直到有一天你满怀欣喜地打开最喜欢的编程环境，输入0.1+0.2，但计算机却返回这个:\n你下意识觉得这可能是一个bug，然后在不同语言中反复求证，却一致地得到相同的答案：\n\n究竟是道德的沦丧还是人性的扭曲\n这一切都要从一个盛行了三十多年的标准IEEE-754讲起，IEEE-754定义了浮点数的格式、存储和运算：\n它对浮点数的表示和我们熟知的科学计数法如出一辙\n\n\n\n\n一个浮点数会被分成两部分存储,第一部分尾数(mantissa)也叫做有效数字(signigicand)，也就是下图用红色高亮的部分，第二部分指数(exponent)也就是这里黄色高亮的部分：\n由于尾数和指数分开存储，使得浮点数天生可以表示很大范围的数字，你可以用它表示整个星系的大小，也可以表示微观粒子的半径，并且现代计算机对浮点数做了大量优化，能够在很短时间内进行相当复杂的运算，一个典型的例子就图形渲染，每秒60帧的画面，每帧几百万的像素点同时参与光照计算，大家可以想想这个计算量\n为了了解计算机中的浮点数，我们先来看看十进制世界的我们是如何表示小数的\n首先在整数部分，我们有个位，十位，百位，千位，同样在小数部分我们有1/10,1/100,1/1000等等：\n比如我们写上在个位写0，在小数部分的1/10上写1就可以精确表示0.1，但是计算机使用的是二进制，每一位只能是0或者1，并且逢二进一，因此整数位分别表示有多少个一，多少个二，多少个四多少个八，其实这对应着2的一次方，2的二次方，2的三次方等等，小数部分则表示1/2,1/4,1/8,1/16等等：\n在二进制中，我们可以轻易地表示1/2,1/4或者3/4没有任何问题，但是二进制中没有1/10,求出的答案与1十分接近但却不等于1:\n虽然计算机不总是能精确地表示小数，但在大多数情况下这并不是问题，比如在物理引擎中，我们会用到浮点数来计算物体的坐标，假设误差导致每一帧中物体的位置偏离0.00001，由于这个量实在太小，即便累加一秒，可能还不及一个像素点的长度，用户根本无法察觉，但是另一方面如果银行使用浮点数来表示货币，每存入0.1块钱，由于浮点误差的存在，导致账号中会多累加这么多钱:\n在频繁的交易下，这种误差积少成多对银行来说就是巨大的损失\n\n要解决这个问题，最容易想到的就是用整型来替代浮点数\n\n比如1块钱当作整型数100来存储，这样1分钱就可以准确无误地用数值1来表示，最后我们只需要在显示货币的时候除以一百即可：\n另外现代的编程语言或者数据库中都提供一个特殊的数据类型decimal(十进制定点数),专门用来表示任意精度的十进制数：\n\n用它来进行运算不会产生任何的精度问题\n\n当然在大多数时候，我们依然会用到浮点数，因为浮点数能高效地进行运算，并且节省内存空间，只要我们心里有数，知道程序出现误差可能会导致出现逻辑错误，并且加以防范就好了，比如直接用等号去判断两个浮点数是否相等，这种用操作是很不可靠的，正确的做法应当是去计算这两个数的差别是否小于某个误差范围：\n\n在现代的编程语言中大多都内置了判断浮点数是否相等的工具函数，比如python中的isclose：\n使用他们可以规避很多由浮点误差而导致的程序逻辑错误：\n浮点数的这些奇怪特性可能一开始让很多人摸不着头脑，但在了解之后发现他不过是一个基本的数学概念，科学计数法的二进制版本，仅此而已：\n由于0.1在二进制中是无限循环小数，计算机没有办法精确表示，从而丢失了精度，也就造就了为什么我们输入0.1+0.2但计算机返回的却不是0.3的情况：\n"},{"title":"记一次sourcetree推送代码进度条一直在动可就是推不上去的错误解决方法","url":"/2022/01/07/%E8%AE%B0%E4%B8%80%E6%AC%A1sourcetree%E6%8E%A8%E9%80%81%E4%BB%A3%E7%A0%81%E8%BF%9B%E5%BA%A6%E6%9D%A1%E4%B8%80%E7%9B%B4%E5%9C%A8%E5%8A%A8%E5%8F%AF%E5%B0%B1%E6%98%AF%E6%8E%A8%E4%B8%8D%E4%B8%8A%E5%8E%BB%E7%9A%84%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","content":"今天在某个本地仓库新增了一些数据，然后想着把数据提交一下，然后在使用sourcetree的时候提交进度条在移动然后始终推送不上去，后面在网上查阅资料说可能是安装了git但是没有给surcetree权限:\nhttps://blog.csdn.net/Baron0071/article/details/84062638?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-84062638.pc_agg_new_rank&amp;utm_term=sourcetree%E6%8E%A8%E9%80%81%E4%B8%80%E7%9B%B4%E8%BD%AC&amp;spm=1000.2123.3001.4430\n我照着他的步骤执行了一遍发现我确实是这么配置的但是在我点击确定后就能推送上去了，这可能是soucetree的一个小bug叭\n"}]