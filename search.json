[{"title":"Python中常用的国内pip源","url":"/2021/12/29/Python%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84pip%E6%BA%90/","content":"在我们下载包的时候，很可能由于网络原因会很卡，这个时候可能需要科学上网，但是我们又没有买节点，或者没有搭建海外服务器，这个时候我们就可以访问一些国内的pip源，这里面和国外上传的pip源几乎是一样的，也是一段时间就会更新:\n\n阿里云: http://mirrors.aliyun.com/pypi/simple/\n中国科学技术大学: https://pypi.mirrors.ustc.edu.cn/simple/\n豆瓣: http://pypi.douban.com/simple/\n清华大学: https://pypi.tuna.tsinghua.edu.cn/simple/\n华中科技大学: http://pypi.hustunique.com/\n\n注意: 新版ubuntu要求使用https源\n","categories":["Database"]},{"title":"Python中pip和pip3的区别","url":"/2021/12/29/Python%E4%B8%ADpip%E5%92%8Cpip3%E7%9A%84%E5%8C%BA%E5%88%AB/","content":"pip是Python的一款很好用的包管理工具，类似于node中的npm，Python有Python2和Python3的区别，那么pip也有pip和pip3的区别,大概是这样的: \n相同点(虽然主要是区别，但还是有相同点的撒):\n\npip和pip3版本不同，但二者都位于Script\\目录下\n\n不同点：\n\n如果系统中只安装了Python2，那么就只能用pip\n如果系统中只安装了Python3，那么既可以使用pip也可以使用pip3，二者是等价的\n如果系统中同时安装了Python2和Python3，则pip默认给Python2使用，pip3默认给Python3使用\n重要: 在虚拟环境中，若只存在一个Python版本，可以认为在用系统中的pip和pip3命令都是相同作用的\n\n"},{"title":"Python中with...as...语句的深度解刨","url":"/2021/12/28/Python%E4%B8%ADwith...as...%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%B7%B1%E5%BA%A6%E8%A7%A3%E5%88%A8/","content":"任何一门编程语言中，文件的输入输出、数据库的连接断开等，都是很常见的资源管理操作。但资源都是有限的，在写程序时，必须保证这些资源在使用过后得到释放，不然就容易造成资源泄露，轻者使得系统处理缓慢，严重时会使系统崩溃。\n例如，前面在介绍文件操作时，一直强调打开的文件最后一定要关闭，否则会程序的运行造成意想不到的隐患。但是，即便使用 close() 做好了关闭文件的操作，如果在打开文件或文件操作过程中抛出了异常，还是无法及时关闭文件。\n为了更好地避免此类问题，不同的编程语言都引入了不同的机制。在 Python 中，对应的解决方式是使用 with as 语句操作上下文管理器（context manager），它能够帮助我们自动分配并且释放资源，代码示例如下:\nwith open(&quot;test.txt&quot;) as file:    data = file.read()    print(data)# 等价于try:    file = open(&quot;test.txt&quot;)    data = file.read()    print(data)finally:    file.close()\n\nwith…as…语句只会捕获异常而不会处理异常，代码示例如下:\nwith open(&quot;test.txt&quot;) as file:    data = file.read()    print(data)# 若没有test.txt，会出现以下错误,程序会就此停下，说明并不会处理异常FileNotFoundError Traceback (most recent call last)&lt;ipython-input-4-bf5e860f28d5&gt; in &lt;module&gt;      1 try:----&gt; 2     file = open(&quot;test.txt&quot;)      3     data = file.read()      4     print(data)      5 # except Exception as err:FileNotFoundError: [Errno 2] No such file or directory: &#x27;test.txt&#x27;\n\n"},{"title":"Python如何升级pip,以及如何查看pip版本","url":"/2021/12/29/Python%E5%A6%82%E4%BD%95%E5%8D%87%E7%BA%A7pip,%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8Bpip%E7%89%88%E6%9C%AC/","content":"有些时候我们用pip安装包的时候会报红提示说安装失败，也有时候会出现一串黄色的警告说pip版本太低，这个时候我们可能就该考虑升级下pip，升级pip会获得更好的体验然后很多新的包也会收录在新版本的pip下，我们来看下如何升级: \n\n打开命令行键入以下命令:\npip3 install --upgrade pip -i &quot;https://pypi.mirrors.ustc.edu.cn/simple&quot;\n\n对以上命令做下解释:\n\npip3: 如果在系统中既有Python2又有Python3那么且两个都有pip工具,pip3就是为Python3服务\n-i: 指定包的源\n\n\n\n"},{"title":"Python每个版本都自带pip嘛,以及如何安装pip","url":"/2021/12/29/Python%E6%AF%8F%E4%B8%AA%E7%89%88%E6%9C%AC%E9%83%BD%E8%87%AA%E5%B8%A6pip%E5%98%9B,%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85pip/","content":"pip是Python的包管理工具，该工具提供了对Python包的查找、下载、安装、以及卸载的功能，目前如果你在Python.org下载最新版本的安装包，则是已经自带了该工具，Python2.7.9+或者Python3.4+以上版本都自带pip工具(通常跟wheel.exe在同一个目录下)\n下面讲讲如果安装的时候没有自带pip工具那么如何安装pip工具：\n\n访问https://bootstrap.pypa.io/get-pip.py这个网址，然后Ctrl+S将get-pip.py文件保存到你所安装的Python的Script目录下\n然后进入Script目录，并且在该目录下进入下命令行界面\n在命令行界面输入python get-pip.py，pip3工具就会自动安装\n安装成功之后输入python -m pip –version，确保成功安装了pip\n\n"},{"title":"Python如何修改pip源","url":"/2021/12/29/Python%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9pip%E6%BA%90/","content":"如果每次都pip用-i指定源会比较麻烦，我们可以把某个国内源设置为默认，这样下次就会从默认源里面寻找包并且下载，来看看如何设为默认:\n在命令行中键入以下命令:\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n\n以上以清华源的为例\n"},{"title":"Python类中call函数的作用","url":"/2021/12/25/Python%E7%B1%BB%E4%B8%ADcall%E5%87%BD%E6%95%B0%E7%9A%84%E4%BD%9C%E7%94%A8/","content":"本节再介绍 Python类中一个非常特殊的实例方法，即 call()。该方法的功能类似于在类中重载 () 运算符，使得类实例对象可以像调用普通函数那样，以“对象名()”的形式使用，一句话总结: call函数可以把类变成函数来调用\nclass Demo():    def __init__(self, name):        self.name = name    def __call__(self):        print(self.name)Demo(&#x27;孙悟空&#x27;)() # 输出 孙悟空\n\n在Python中，凡是可以将()直接应用到自身并执行，都称为可调用对象，可调用对象包括自定义的函数，Python内置函数以及这里讲的类实例对象，对于可调用对象，实际上“名称()”可以理解为是“名称.call()”的简写。仍以上面程序中定义的 clangs 实例对象为例，其最后一行代码还可以改写为如下形式：\nclangs.__call__(&quot;C语言中文网&quot;,&quot;http://c.biancheng.net&quot;)\n"},{"title":"Python魔法方法总览","url":"/2021/12/28/Python%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95%E6%80%BB%E8%A7%88/","content":"关于魔法方法: 使用魔法方法可以使Python的自由度变得更高，当不需要重写魔法方法也可以在规定的默认情况下生效，在需要重写时也可以让使用者根据自己的需求来重写部分方法来达到自己的预期。而且众所周知Python是支持面向对象的语言，其基本魔法方法就使得Python在面向对象方面做得更好。\n今天在CSDN上看到了有一篇文章整理得还不错，讲述了很多魔法方法以及其作用，详情见:https://blog.csdn.net/qq_38520096/article/details/79237593?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164067535716780261982154%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=164067535716780261982154&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-8-79237593.first_rank_v2_pc_rank_v29&amp;utm_term=python%E7%9A%84%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95&amp;spm=1018.2226.3001.4187\n"},{"title":"对Docker的认识","url":"/2021/12/29/%E5%AF%B9Docker%E7%9A%84%E8%AE%A4%E8%AF%86/","content":"首先，Docker是个容器，使用的是宿主机的资源，因为都是Linux，所以内核资源是可以共用的，无论什么发行版，他们的内核都是Linux kernel，所以Docker才能实现，Docker其实只共用了宿主机的内核，然后我们可以在里面安装镜像，运行一个隔离于系统的独立系统，但是默认是不和宿主机发生交互的，如果要使用到宿主机的文件，就要用volumn将宿主机的文件挂载到容器中，让容器可以访问\n现在windows上也可以安装Docker，其实windows上的Docker只是一个客户端，实际上还是开了一个虚拟机跑Linux，然后Linux里再跑Docker\n"},{"title":"Linux(ubuntu)提示command not fonund的解决","url":"/2021/12/29/Linux(ubuntu)%E6%8F%90%E7%A4%BAcommand%20not%20fonund%E7%9A%84%E8%A7%A3%E5%86%B3/","content":"Linux系统中，-bash: wget: comment not found是找不到命令的意思，也就是无法执行下载命令，这是因为系统太干净了，没有安装下载命令的控制器，我们给系统安装个下载命令即可:\nCentOS系统:\nyum install wget -y\n\nDebian/Ubuntu系统:\napt -get install -y wget\n\n"},{"title":"关于入门Go需要知道的几个特性","url":"/2021/12/29/%E5%85%B3%E4%BA%8E%E5%85%A5%E9%97%A8Go%E7%9A%84%E5%87%A0%E4%B8%AA%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","content":"\ngo的关键字比较少，只有25个，这样可以简化编码过程中的混乱和复杂度\n\ngo没有类和继承的概念，但它通过接口的概念来实现多态\n\ngo支持交叉编译，比如说可以在运行Linux系统的计算机开发能在windows上运行的应用，这是第一门完全支持UTF-8的编程语言，就连他的源码文件格式都是使用UTF-8编码\n\ngo被设计成一门应用与搭载web服务器，存储集群或类似用途的巨型中央服务器的系统编程语言，对于高性能分布式系统领域而言，go有着更高的开发效率，提供了海量并行的支持，这对于游戏服务端的开发最好不过了\n\n尽管go编译器产生的是本地可执行代码，这些代码仍旧运行在go的runtime中，这个runtime类似java和.net所用到的虚拟机，它负责管理包括内存分配，垃圾回收，栈处理、goroutine、channel、切片，map和反射等\n\ngo fmt，这是个工具用来将你的源代码格式化成符合官方统一标准的风格\n\ngo doc，这是个工具从go程序和包文件中提取顶级声明的首行注释以及每个对象的相关注释，并生成相关文档\n\ngo install, 这是go的包的安装工具，类似Ruby中的rubygems\n\ngo test是一个轻量级的单元测试框架\n\ngo fix用于将你的go代码从旧的发行版迁移到最新的发行版\n\ncgo提供了对FFI(外部函数接口)的支持，能够使用go代码安全地调用c语言库，cgo会代替go编译器来产生可以组合在同一个包中的go和c代码\n\n在go代码中使用c语言需要用import&quot;C&quot;来导入，一般还需要import&quot;unsafe&quot;,然后你可以在import&quot;C&quot;之前使用注释(但行或多行注释均可)的形势导入C语言库(甚至有效的C语言代码)，注意他们之间没有空格\n\n左大括号需要放在函数定义这一行\n\nfmt.Println和fmt.Print只差了一个空格\n2021-12-29 18:08:20\n\n\n"},{"title":"在Docker中安装Python3.7","url":"/2021/12/29/%E5%9C%A8Docker%E4%B8%AD%E5%AE%89%E8%A3%85Python3.7/","content":"详情见: \nhttps://www.icode9.com/content-1-120863.html\n"},{"title":"如何在ubuntu16中安装Python","url":"/2021/12/29/%E5%A6%82%E4%BD%95%E5%9C%A8ubuntu16%E4%B8%AD%E5%AE%89%E8%A3%85Python/","content":"详情见:(我这采用的是第二种方法)https://www.runoob.com/docker/ubuntu-docker-install.html\n"},{"title":"查看Docker是否安装成功以及使用Docker安装nginx","url":"/2021/12/29/%E6%9F%A5%E7%9C%8BDocker%E6%98%AF%E5%90%A6%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8Docker%E5%AE%89%E8%A3%85nginx/","content":"\n检查是否安装成功\n使用命令:\ndocker ps\n\n使用docker搜索nginx:\n使用命令:\ndocker search nginx\n使用 docker安装nginx:\n使用命令:\ndocker pull nginx\n\n运行nignx:\n使用命令:\ndocker run nginx\n检查Docker是否安装成功可以使用命令:\ndocker version\n\n有client和service两部分表示docker安装启动都成功了\n\n\n"},{"title":"LeetCode最大回文子串","url":"/2021/12/30/Leetcode%E6%9C%80%E5%A4%A7%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/","content":"动态规划:\n对于一个字串而言，如果它是回文串，并且长度大于2，那么将它首位的两个字母去掉之后，它仍然是个回文串，根据这个思路，我们就可以用动态规划的方法解决本题，我们用s[i, j]表示字符串s的第i个到第j个字母组成的串是否为回文串:\n我们可以得到只有s[i+1, j-1]是回文串，并且s的第i个和第j个字母相同时，s[i, j]才会是回文串\n上文所有讨论都是建立在字串长度大于2的前提上的，我们还需要考虑动态规划中的边界条件，就是字串的长度为1或2。对于长度为1的字串，他显然是个回文串，对于长度为2的字串，只要它的两个字母相同，他就是一个回文串，因此我们就可以得到动态规划的边界条件\nclass Solution:    def longestPalindrome(self, s: str) -&gt; str:        n = len(s)        if n &lt; 2:            return s                max_len = 1        begin = 0        # dp[i][j] 表示 s[i..j] 是否是回文串        dp = [[False] * n for _ in range(n)]        for i in range(n):            dp[i][i] = True                # 递推开始        # 先枚举子串长度        for L in range(2, n + 1):            # 枚举左边界，左边界的上限设置可以宽松一些            for i in range(n):                # 由 L 和 i 可以确定右边界，即 j - i + 1 = L 得                j = L + i - 1                # 如果右边界越界，就可以退出当前循环                if j &gt;= n:                    break                                    if s[i] != s[j]:                    dp[i][j] = False                 else:                    if j - i &lt; 3:                        dp[i][j] = True                    else:                        dp[i][j] = dp[i + 1][j - 1]                                # 只要 dp[i][L] == true 成立，就表示子串 s[i..L] 是回文，此时记录回文长度和起始位置                if dp[i][j] and j - i + 1 &gt; max_len:                    max_len = j - i + 1                    begin = i        return s[begin:begin + max_len]\n\n\n\n"},{"title":"Scrapy添加User-agent的方法","url":"/2021/12/30/Scrapy%E6%B7%BB%E5%8A%A0User-agent%E7%9A%84%E6%96%B9%E6%B3%95/","content":"\n直接在spider中指定，比如在Scrapy项目中有一个项目grasp_baidu:\nimport scrapyclass graspbaidu(scrapy.Spider):    name = &#x27;graspbaidu&#x27;    allowed_domians = [&#x27;www.baidu.com&#x27;]    start_urls = [&quot;http//:www.baidu.com&quot;]    def parse(self, response):        self.logger.debug(response.text)\n\n这里的start_urls会默认由scrapy自带的start_request处理，然后再交给parse函数，我们就可以重写个start_request，然后里面带个UA即可，比如：\ndef start_request(self):    for i in range(1, 2):    url = ff&#x27;https://api2.fx361.com/JunJiProject/JUNJI_012_001/getSearchList?bkpagesize=14&amp;pagesize=30&amp;keyword=%E7%9B%91%E7%90%86%E5%88%9B%E6%96%B0&amp;pageIndex=&#123;i&#125;&amp;fragmentSize=150&#x27;    req = scrapy.Request(url, callback=self.parse, dont_filter=True, headers=self.headers)\n在配置文件settings.py中设置(一劳永逸):\n将settings.py中的USER_AGENT修改一下即可\n\n如果想修改的更加灵活，比如设置随机的Ua，那就需要如下用到一个库:\nfrom fake_useragent import UserAgent\n\n然后需要在middlewares.py文件中添加一个RandomUserAgentMiddleware的类，如下:\nclass RandomUserAgentMiddleware(object):    # 随机更换 user_agent    def __init__(self,srawler):        super(RandomUserAgentMiddleware,self).__init__()        self.ua = UserAgent()    @classmethod    def from_crawler(cls,crawler):        return cls(crawler)     def process_request(self,request,spider):        def get_ua():        request.headers.setdefault(&#x27;User-Agent&#x27;,self.ua.random)        \n\n然后后我们在settings.py中调用这个中间件:\nDOWNLOADER_MIDDLEWARES = &#123;    &#x27;scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware&#x27;: None,    &#x27;scrapydownloadertest.middlewares.RandomUserAgentMiddleware&#x27;: 543,&#125;\n\n"},{"title":"关于协程记录一下","url":"/2021/01/01/%E5%85%B3%E4%BA%8E%E5%8D%8F%E7%A8%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%8B/","content":"\n\n什么是可迭代对象:\n可迭代对象(iterable): Python中的任意对象，只要它定义了可以返回一个迭代器的__iter__方法，或者定义了可以支持下标索引的__gititem__方法这两个魔法方法，那么他就是一个可迭代对象，简单说，可迭代对象就是能提供迭代器的任意对象,常见的可迭代对象有:字符串，列表，字典，元组等。\nfrom collections.abc import Iterable, Iterator, Generatorstr_1 = &#x27;sixkery&#x27;print(&#x27;字符串是否是可迭代对象：&#x27;,isinstance(str_1,Iterable))print(&#x27;字符串是否是迭代器：&#x27;,isinstance(str_1,Iterator))print(&#x27;字符串是否是生成器：&#x27;,isinstance(str_1,Generator))list_1 = [1,2,3,4]print(&#x27;列表是否是可迭代对象：&#x27;,isinstance(list_1,Iterable))print(&#x27;列表是否是迭代器：&#x27;,isinstance(list_1,Iterator))print(&#x27;列表是否是生成器：&#x27;,isinstance(list_1,Generator))dict_1 = &#123;&#x27;name&#x27;:&#x27;小沐&#x27;,&#x27;age&#x27;:23&#125;print(&#x27;字典是否是可迭代对象：&#x27;,isinstance(dict_1,Iterable))print(&#x27;字典是否是迭代器：&#x27;,isinstance(dict_1,Iterator))print(&#x27;字典是否是生成器：&#x27;,isinstance(dict_1,Generator))\n\n以上都是可迭代对象，可以使用方法dir()查看是否有__iter__来判断一个变量是否是可迭代对象，可迭代对象都可以使用for循环\nif &#x27;__iter__&#x27; in dir(list()):\tprint(&#x27;list是可迭代对象&#x27;)\n什么是迭代器\n迭代器，是在可迭代对象的基础上实现的，创建一个迭代器，首先要用一个可迭代对象:\n用iter()方法即可把可迭代对象转化为迭代器：\nstr_1 = &#x27;asdfg&#x27; # 字符串，是可迭代对象alterator = iter(str_1) # 通过方法 iter() 把字符串变成迭代器print(&#x27;是否成功转换成迭代器:&#x27;,isinstance(alterator,Iterator))\n\n迭代器比可迭代对象多了一个函数next(),我们可以用它来获取元素，for循环也是支持的,这是因为在迭代器内部实现了__next__方法：\nnext(alterator)# &#x27;a&#x27;\n\nfor i in alterator:    print(i)# ...\n生成器:\n之所以引入生成器，是为了实现一个在计算下一个值时不需要浪费空间的结构，通常我们使用列表，即使很大一个列表在一开始也得生成，如果能需要使用的时候自动生成下一个那就节省了很大空间\n之前说的迭代器，是在可迭代对象的基础上加了一个next方法，而生成器是在迭代器的基础上，再实现了yield,所以生成器也可以使用for和next()\nyield是啥呢?它相当于我们函数中的return，在每次next(),或者for循环便利的时候，都会在yield的地方将新的值返回回去，并在这里阻塞，等待下一次的调用，正是有了这个机制，才使得生成器在Python中大放异彩，实现节省内存，实现异步编程。\n\n将列表生成式的中括号改成小括号就是一个生成器啦：\na = (x*x for x in range(1,5))next(a)# 1a = (x*x for x in range(1,5))print(&#x27;是否是生成器：&#x27;,isinstance(a,Generator))# 是否是生成器： True\n实现生成器函数(yield)：\ndef my_gen(n):    a = 0    while a &lt; n:        yield a        a += 1if __name__ == &#x27;__main__&#x27;:    gen = my_gen(5)    print(&#x27;是否是生成器：&#x27;,isinstance(gen,Generator))    for i in gen:        print(i)    # 是否是生成器： True01234\n生成器的执行状态，生成器在其生命周期中，会有以下四个状态:\n\nGEN_CREATED: 等待开始执行\nGEN_RUNNING: 解释器正在执行(只有在多线程应用中才能看到这个状态)\nGEN_SUSPENDED: 在yield表达式处暂停\nGEN_CLOSED: 执行结束\n\nfrom inspect import getgeneratorstatedef my_gen(n):    a = 0    while a &lt; n:        yield a        a += 1if __name__ == &#x27;__main__&#x27;:    gen = my_gen(5)    print(getgeneratorstate(gen)) # 等待开始执行        print(next(gen))    print(getgeneratorstate(gen)) # 在 yield 表达式出暂停        print(next(gen))    gen.close() # 手动关闭结束生成器    print(getgeneratorstate(gen)) # 执行结束GEN_CREATED0GEN_SUSPENDED1GEN_CLOSED\n生成器的异常处理\n在生成器工作中，若生成器不满足生成元素的条件，获取没有元素生产了，就会抛出异常(Stopiteration)\na = (x*x for x in range(1,3))next(a)next(a)next(a)\n\n---------------------------------------------------------------------------StopIteration                             Traceback (most recent call last)&lt;ipython-input-50-0f82892640d1&gt; in &lt;module&gt;()      2 next(a)      3 next(a)----&gt; 4 next(a)StopIteration: \n\n所以在定义生成器时，要考虑这个问题，在不满足生产元素条件的时候，抛出异常:\ndef my_gen(n):    a = 0    while a &lt; n:        yield a        a += 1    raise StopIterationif __name__ == &#x27;__main__&#x27;:    gen = my_gen(2)    next(gen)    next(gen)    next(gen)\n\n不过如果用for循环遍历生成器就不会抛出异常\n\n\n\n从生成器过渡到协程: yield\n通过上面的介绍，我们知道了生成器为我们引入了暂停函数执行(yield)的功能，当我们有了暂停函数的功能之后，就想能不能在生成器暂停的时候向生成器发送一点东西(gen.send(None)),这种机制催生了携程的诞生\n协程: 协程是为非抢占式多任务产生子程序组件的，协程允许不同入口点在不同位置暂停或开始执行任务\n从本质上来看，协程并不属于某种语言的概念，而是编程模型上的概念\n协程和线程一样都能交叉串行执行任务，但是线程频繁加锁解锁，线程切换。协程只要在yield暂停处把任务交到别处执行，协程还是很有发展潜力的\ndef fn(n):    a = 0    while a &lt; n:        jump = yield a        if jump is None:            jump = 1        a += jump        if __name__ == &#x27;__main__&#x27;:    itr = fn(5)    print(next(itr))    print(itr.send(2))\n\n02\n\nyield a 是将a返回出去\njump = yield 是接收传递进来的值\n\n\n"},{"title":"Python对象引用,可变性和垃圾回收机制","url":"/2021/12/30/Python%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8,%E5%8F%AF%E5%8F%98%E6%80%A7%E5%92%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/","content":"\n\nPython中的变量到底是什么\nPython的变量实质上是一个指针:\n\n事先没有预定大小，可以是任意类型，比如int,str\n\n可以理解成一个便利贴，可以贴在任何类型上\na = 1a = &#x27;tyu&#x27;\n\n可以理解成一个便利贴，a贴在1上\n注意:\n\n是先生成对象，然后再贴\n不需要声明类型\n\n看一个例子:\na = [1, 2, 3]\nb = a\nb.append(4)\nprint(a)\n输出：[1, 2, 3, 4]\n结论: a和b贴在了同一个地方\n判断一下a和b是不是同一个对象\na = [1,2,3]b = [1,2,3]print(a is b)# 输出：True\n\n再判断一下a和b是不是同一个内存地址:\na = [1,2,3]b = [1,2,3]print(id(a),id(b))# 输出：8533576 8533576\n\n\n==和is的区别\nis是判断两个变量引用对象id是否相等\n==用于判断引用变量的值是否相等\n整数:\na = 123456789b = 123456789print(a is b)print(a == b)# 结果：True True\n\n字符串:\na = &#x27;123456789&#x27;b = &#x27;123456789&#x27;print(a is b)print(a == b)# 结果：True True\n\n列表:\na = [1,2,3]b = [1,2,3]print(a is b)print(a == b)# 结果：False True\n\n字典:\na = &#123;&#x27;name&#x27;:&#x27;sixkery&#x27;&#125;b = &#123;&#x27;name&#x27;:&#x27;sixkery&#x27;&#125;print(a is b)print(a == b)# 结果：False True\n\n集合:\na = (1,2)b = (1,2)print(a is b)print(a == b)# 结果：False True\n\n总结:只要对象的值一样，那么a == b的值一定为True\n如果对象的类型为整数或者字符串且值一样，则a == b和a is b的值都为True(负浮点数不符合)\na = -1.0b = -1.0print(a is b)print(a == b)# 结果：False True\ndel语句和垃圾回收\nPython中垃圾回收算法是: 引用计数\na = 1 # 1 的计数器上加一b = a # 1 的计数器上再加一del a # 计数器减一print(b)print(a)# 结果：1Traceback (most recent call last):   File &quot;e:/python/test.py&quot;, line 8, in &lt;module&gt;    print(a) NameError: name &#x27;a&#x27; is not defined\n\n当计数器加为0的时候，Python就会把1回收，不占用内存\n\n\n"},{"title":"Python之多线程","url":"/2021/12/30/Python%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/","content":"多个任务可以由多进程完成，也可以由一个进程内的多线程完成。\n一个进程由多个线程组成，一个进程至少有一个线程。\n由于线程是操作系统直接支持的单元，因此，高级语言都内置多线程的支持，Python也不例外，并且Python的线程是真正Posix Thread，不是模拟出来的线程。\nPython的标准库提供了两个模块:_thread和threading，_thread是低级模块，threading是高级模块。绝大多数的情况下，我们只用threading就够了。\n启动一个线程就是把函数传入并创建Thread实例,然后调用start(),函数开始执行就可以了:\nimport timeimport threading #线程执行的代码def loop():    print(&#x27;thread %s is running&#x27; % threading.current_thread().name)    n = 0    while n &lt; 5:        n += 1        print(&#x27;thread %s &gt;&gt;&gt; %s&#x27; % (threading.current_thread().name,n))        time.sleep(1)    print(&#x27;thread %s end&#x27; % threading.current_thread().name) print(&#x27;thread %s is running...&#x27; % threading.current_thread().name)t = threading.Thread(target=loop,name=&#x27;LoopTread&#x27;)t.start()t.join()print(&#x27;thread %s end&#x27; % threading.current_thread().name)\n\n运行结果:\nthread MainThread is running...thread LoopTread is runningthread LoopTread &gt;&gt;&gt; 1thread LoopTread &gt;&gt;&gt; 2thread LoopTread &gt;&gt;&gt; 3thread LoopTread &gt;&gt;&gt; 4thread LoopTread &gt;&gt;&gt; 5thread LoopTread endthread MainThread end\n\n由于任何进程都会默认开启一个线程，我们把该线程称为主线程，主线程又可以开启新的线程，Python的threading模块有个current_thread()函数，它永远返回当前线程的实例；主线程实例的名字叫Main Thread，子线程的名字在创建的时候指定，我们用LoopThread命名子线程,名字仅仅在打印的时候用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为Thread-1,Thread-2\nLock\n多进程和多线程最大的不同在于，多进程中，同一个变量，各自有一份拷贝到每个进程，互不影响，而线程中，所有变量都是所有线程共享所有，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险就在与多线程同时修改一个变量，把内容给改乱了，举个栗子:\n#假定这是你的银行存款balance = 0 def change_it(n):    #先存后取    global balance    balance += n    balance -= n def run_thread(n):    for i in range(100000):        change_it(n) t1 = threading.Thread(target=run_thread,args=(5,))t2 = threading.Thread(target=run_thread,args=(8,)) t1.start()t2.start()t1.join()t2.join()print(balance)\n\n我们定义了一个共享变量balance，初始化为0，并且启动两个线程，先存后去，理论上结果应该为0，但是由于线程的调度是由操作系统决定的，当t1，t2交替执行时，只要循环次数足够多，balence的结果就不一定是0了，原因是因为高级语言的一条语句在cpu执行的时候是若干条语句，即使一个简单的计算:\nbalance += n\n\n也要分成两步:\n\n计算balance + n结果存到临时变量中\n将临时变量的值赋给balance\n\n究其原因，是因为修改balance需要多条语句，而执行这几条语句时，线程可能中断，从而导致多个线程把一个对象的内容改乱了。\n两个线程同时一存一取，就可能导致余额不对，你肯定不希望你的银行存款莫名其妙地变成了负数，所以我们要确保balance计算正确，就要给change_it()上一把锁，当某个线程开始执行change_it()时，我们说，该线程因为获得了锁，因此其他线程不能同时执行change_it(),只能等待，直到锁被释放后，获得该锁以后才能改。由于锁只有一个，无论多少线程，同一时间最多只有一个线程持有该锁，所以，不会造成修改的冲突。创建一个锁就是通过threading.Lock()来实现：\nlock = threading.Lock()def run_thread(n):    for i in range(100000):        #先要获取锁        lock.acquire()        try:            #放心改吧            change_it(n)        finally:            #改完记得释放锁哦            lock.release()\n\n当多个线程同时执行lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。\n获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用try…finally…来确保锁一定会被释放。\n\n锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行\n坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。\n其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。\n\n多核CPU\n如果你拥有一个多核CPU，你肯定在想，多核应该可以同时执行多个线程。\n如果写一个死循环的话，会出现什么情况呢？\n打开Mac OS X的Activity Monitor，或者Windows的TaskManager，都可以监控某个进程的CPU使用率，我们可以监控到一个死循环线程会100%占用一个CPU。如果有两个死循环线程，再多核CPU中，可以监控到会占用200%的CPU，就是占用两个CPU核心。如果想把N核CPU的核心全部跑满，就必须启动N个死循环线程，在Python中真的如此嘛?\n试试用Python写个死循环:\nimport threading, multiprocessing def loop():    x = 0    while True:        x = x ^ 1 for i in range(multiprocessing.cpu_count()):    t = threading.Thread(target=loop)    t.start()\n\n启动与CPU核心数量相同的N个线程，在4核CPU上可以监控到CPU占用率仅有102%，也就是仅使用了一核，但是用C、C++或Java来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%，为什么Python不行呢？\n因为Python的线程虽然是真正的 线程，但解释器在执行代码时，有一个GIL锁: Global Interpreter Lock,任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。\nGIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。\n所以，在Python中，可以使用多线程，但不要指望能有效利用多核，如果一定要通过多线程利用多核，那就只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。\n不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自的独立的GIL锁，互不影响。\n"},{"title":"Python图片灰度处理","url":"/2021/12/30/Python%E5%9B%BE%E7%89%87%E7%81%B0%E5%BA%A6%E5%A4%84%E7%90%86/","content":"Python的PIL库为我们提供了一些操作图片的方法，我们可以用这些把图片处理成我们想要的样子，比如把图片变模糊，或者改变大小，还有就是今天我们要讲的把图片变成漫画或者说素描的风格:\nfrom PIL import Imageimport numpy as npa = np.asarray(Image.open(&#x27;1.jpg&#x27;).convert(&#x27;L&#x27;)).astype(&#x27;float&#x27;)depath = 10 # (0-100)grad = np.gradient(a)# 取图像灰度的梯度值grad_x,grad_y = grad # 分别取横纵图像梯度值grad_x = grad_x * depath / 100.grad_y = grad_y * depath / 100.A = np.sqrt(grad_x ** 2 + grad_y ** 2 + 1.)uni_x = grad_x / Auni_y = grad_y / Auni_z = 1. / Avec_el = np.pi / 2.2 # 光源的俯视角度，弧度值vec_az = np.pi / 4 # 光源的方位角度，弧度值dx = np.cos(vec_el) * np.cos(vec_az) # 光源对 x 轴的影响dy = np.cos(vec_el) * np.sin(vec_az) # 光源对 y 轴的影响dz = np.sin(vec_el) # 光源对 z 轴的影响b = 255 * (dx * uni_x + dy * uni_y + dz * uni_z) # 光源归一化b = b.clip(0,255)im = Image.fromarray(b.astype(&#x27;uint8&#x27;)) # 重构图像im.save(&#x27;2.jpg&#x27;)\n\n"},{"title":"Python之多进程","url":"/2021/12/30/Python%E4%B9%8B%E5%A4%9A%E8%BF%9B%E7%A8%8B/","content":"要让Python实现多进程(multiprocessing),我们先来了解下操作系统相关知识, Unix和Linux操作系统提供了一个fork()函数系统调用，它非常特殊，普通的函数，调用一次它执行一次，但是fork()函数调用一次执行两次，因为操作系统自动把当前进程(称为父进程)复制了一份(称为子进程)，然后，分别在子进程和父进程中执行，子进程永远返回0，而父进程返回子进程的ID，而子进程只要调用getpid()就可以拿到父进程的ID。Python中os模块封装了常见的系统调用，其中就包括fork(),可以在Python程序中轻松创建子程序：\nimport os print(&#x27;Process (%s) start ...&#x27; % os.getpid())#Only work on Unix/linux/Mac#不能在Windows平台上运行pid = os.fork()if pid == 0:    print(&#x27;I am child process (%) and my parent is %s.&#x27; % (os.getpid(),os.getppid()))else:    print(&#x27;I (%) just created a child process (%).&#x27; % (os.getpid(),pid))\n\n运行结果:\nProcess (876) start...I (876) just created a child process (877).I am child process (877) and my parent is 876.\n\n由于windows平台下没有fork()函数调用，多以代码没有办法在windows平台下运行，有了fork调用，一个进程在接到任务的时候就可以复制出来一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出新的子进程来处理新的http请求。\nmultiprocessing(多进程)\n如果你想写多进程的服务程序，Unix/LInix平台最好了，当然也可以在Windows平台下来编写，因为Python跨平台，multiprocessing模块就是跨平台版本的多进程模块。multiprocessing模块提供了一个Process类来代表一个进程对象，下面一个例子来演示启动一个进程并等待结束的例子：\nimport osfrom multiprocessing import Process #子进程要执行的代码def run_proc(name):    print(&#x27;Run child process %s (%s)&#x27; % (name,os.getpid())) if __name__ == &#x27;__main__&#x27;:    print(&#x27;parent process %s&#x27; % os.getpid())    p = Process(target=run_proc,args=(&#x27;test&#x27;,))#创建子程序    print(&#x27;Child process will start&#x27;)    p.start()#子程序开始执行    p.join()    print(&#x27;Child process end.&#x27;)\n\n\n创建子程序时，只需要传入衣蛾执行的函数和函数的参数\n\n创建一个Process实例，用start()方式开启，这样创建的进程比fork还简单\n\njoin()方法可以等join子进程执行完后再继续往下运行，通常用于进程之间的同步\n\n如果想要启动大量的子进程，可以用进程池的方式批量创建子进程，如下所示：\nimport os,time,randomfrom multiprocessing import Pool def long_time_task(name):    print(&#x27;Run task %s (%s)...&#x27; % (name,os.getpid()))    start = time.time()    time.sleep(random.random() * 3)    end = time.time()    print(&#x27;Task %s run %0.2f seconds.&#x27; % (name,(end-start))) if __name__ == &#x27;__main__&#x27;:    print(&#x27;Parent process %s.&#x27; % os.getpid())    p = Pool(4)    for i in range(5):        p.apply_async(long_time_task,args=(i,))    print(&#x27;Waiting for all subprocess done...&#x27;)    p.close()    p.join()    print(&#x27;All subprocess done&#x27;)\n\n"},{"title":"Python思维导图","url":"/2021/12/31/Python%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/","content":"\n\n原文链接:https://blog.csdn.net/qq_44647926/article/details/90669352?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164090955916780269896755%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=164090955916780269896755&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-13-90669352.first_rank_v2_pc_rank_v29&amp;utm_term=Python&amp;spm=1018.2226.3001.4187\n"},{"title":"什么是宝塔面板","url":"/2021/12/31/%E4%BB%80%E4%B9%88%E6%98%AF%E5%AE%9D%E5%A1%94%E9%9D%A2%E6%9D%BF/","content":"简单来说: 就是装在服务器上的管理面板！\n宝塔面板是一款简单好用的服务器运维面板，简单说来就是一个可视化的面板管理工具，支持一键LAMP/LNMP/集群/监控/网站/FTP/数据库/JAVA等100多项服务器管理功能。出错少而且安全，由于宝塔面板既有windows版本也有linux版本，尤其是Linux服务器很多用户不会操作，宝塔是为了让那些不会linux的人使用的，使用宝塔，操作linux更简单，更方便，这里要提醒一下虽然宝塔面板可以安装在物理服务器或者云服务器，虚拟主机无法安装的，但是云服务器基本都是可以安装的。\n大型网站程序都安装在服务器上，服务器用的是Linux系统，进行服务器维护需要记住很多的linux命令，这就比较麻烦；\n面板的好处就是通过一个交互界面就能完成服务器的维护工作，比如更新系统，添加网站，修改设置等等，以前需要记住各种命令，下你在通过面板点点按钮就可以了，省时省力.\n"},{"title":"Docker最详细入门教程","url":"/2022/01/05/Docker%E6%9C%80%E8%AF%A6%E7%BB%86%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","content":"请参考: http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html\n"},{"title":"科学上网教程","url":"/2021/12/31/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E6%95%99%E7%A8%8B/","content":"最近在搭hexo博客的时候在一篇theme配置教程中看到了一个开源的图床项目，里面有关于科学上网的介绍，这里我把它搬出来，详情请点击:https://github.com/Alvin9999/new-pac/wiki\n"},{"title":"推荐一款基于GitHub好用的在线图床工具","url":"/2021/12/31/%E6%8E%A8%E8%8D%90%E4%B8%80%E6%AC%BE%E5%9F%BA%E4%BA%8Egitgub%E5%A5%BD%E7%94%A8%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%9B%BE%E5%BA%8A%E5%B7%A5%E5%85%B7/","content":"这是一款基于GItHubAPI开发的图床神器，图片外链使用jsDriver进行CDN加速，免下载，免安装，打开网站简单配置后即可直接使用，免费，稳定，高效\nPicX官网: https://picx.xpoet.cn/#/upload\nPicXGitHub地址: https://github.com/XPoet/picx\n"},{"title":"Bash脚本教程","url":"/2022/01/05/Bash%E8%84%9A%E6%9C%AC%E6%95%99%E7%A8%8B/","content":"请参考: https://www.ruanyifeng.com/blog/2020/04/bash-tutorial.html\n"},{"title":"SSH最详细入门教程","url":"/2022/01/05/SSH%E6%9C%80%E8%AF%A6%E7%BB%86%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","content":"请参考: https://www.ruanyifeng.com/blog/2020/12/ssh-tutorial.html\n"},{"title":"Docker10分钟快速入门","url":"/2022/01/05/Docker10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","content":"\ndocker是用来解决什么样的问题而出现的呢？\n比如你写了个web应用，并且本地调试没有任何问题，这时候你想发给你的朋友试试看，或者部署到远程的云服务器上，那么首先，你需要配置相同的软件，比如数据库，web服务器，必要的插件，库等等:\n\n而且你还不能保证软件一定能正常地运行起来，因为别人用的可能是完全不同的操作系统，即便同样是使用Linux，每一种发行版也会有微小的区别，为了模拟完全相同的本地环境，我们自然会想到使用虚拟机:\n\n但是虚拟机需要模拟硬件，运行整个操作系统，不但体积臃肿，内存占用高，程序的性能也会收到影响，这时候我们的docker就派上了用场，Docker在概念上与虚拟机非常类似，但却轻量很多，它不会去模拟底层的硬件，只会为每一个应用提供完全隔离的运行环境:\n你可以在环境中配置不同的工具软件，并且不同环境之间相互不影响，这个“环境”在Docker中也被称作container/容器，降到这里，我么就不得不提到Docker中的三个重要概念，Dockerfile，Image和Container:\n\n\nDocker中三个重要的概念\n\nImage:\n\n你可以把它理解为一个虚拟机的快照(Snapshot)，里面包含了你要部署的应用程序以及它所关联的所有库，通过镜像，我们可以创建许多个不同的Container容器:\n这里的容器就像是一台台运行起来的虚拟机，里面运行了你的应用程序，每个容器是独立运行的，他们相互之间不影响，最后Dockerfile就像是一个自动化脚本，它主要被用来创建我们之前讲到的镜像(Image)，这个过程就好比是我们在虚拟机中安装操作系统和软件一样，只不过是通过Dockerfile这个自动化脚本完成了\n\nImage\nDocker把应用程序及其依赖，打包在Image文件里面，只有通过这个文件,才能生成Docker容器，Image文件可以看成是容器的模板，Docker根据Image文件生成容器的实例，同一个Image文件，可以生成多个同时运行的容器实例\n# 列出本机的所有 image 文件。$ docker image ls# 删除 image 文件$ docker image rm imageName\nContainer\nContainer就类似于我们所创建的虚拟机，内存没有虚拟机那么大，也更容易创建\n\n\n\n快速上手Docker的最好方法就是亲自安装并去使用它:\n如果你是用的是windows和mac，你可以在官网下载一个Docker Desktop的应用，而且在win10上你可以使用WSL2(也就是windows下的Linux子系统)来运行Docker，如果你不是使用的windows最新的预览版本，WSL2的安装可能稍微复杂一点，不过也是按照官网的给定步骤进行安装，在linux中，我们可以直接使用包管理工具，按照官网给定的指示一步步执行即可，如果使用的是vscode，也特别推荐安装docker的扩展:\n\n他会提供Dockerfile的语法检测，代码高亮，自动补全等等，你也可以通过菜单运行各种Docker命令并且在左侧面板中看到你创建的所有镜像:\n\n接下来我们就尝试使用Docker来部署一个应用，以之前写的一个python程序举例，这是一个非常简单的用Flask搭建的记账工具:\n\n首先我们在应用的根目录下创建一个Dockerfile文件:\n\n第一行我们需要用FROM命令指定一个基础镜像(base image)这样可以帮我们节省许多软件安装和配置的时间:\n\n可以看到在DockerHub上提供了许多高质量的操作系统镜像，比如ubuntu:\n不同的操作系统提供不同的包管理工具，比如ubuntu上的apt，Fedora上的dnf，当然在Docker Hub上还有许多方便某一种语言，某种框架开发的镜像，比如你nginx,Python,node等：\n\n由于我这里做的是python的开发，自然我会使用Python的镜像，这样免去了它的安装步骤，这里的Python是官方镜像的名字:\n\n冒号后面这一串是版本号，同时也是一个标签，我们可以在docker hub中搜索Python然后点击Python转到docker hub的镜像页面，里面可以找到所有支持的标签:\n比如我们这里用的是Python 3.8版本：\n\n运行在debian buster的发行版本上，后面的workdir指定了之后所有Docker命令的工作路径(working directory),注意是这个命令之后的所有Docker命令，比如我们马上要讲到的run，copy等：\n\n当然如果这个路径不存在，Docker会自动帮你创建，这样可以避免使用绝对路径或者手动cd切换路径，增加程序的可读性，之后，我们可以调用copy命令将所有的程序拷贝到Docker镜像中(copy./app表示将当前目录下所有文件(除了.dockerignore排除的路径),都拷贝进入image文件的/app目录)：\n第一个参数代表本地文件，“.”代表程序根目录下的所有文件，第二个参数代表Docker镜像中的路径，这里的.代表当前的工作路径，也就是之前指定的app目录，随后的run允许我们在创建镜像时运行任意的shell命令，因为我们用的是Linux镜像，所以像echo，pwd，cp，rm这些都是合法的，比如我这里用到pip install 来安装Python程序的所有关联:\n通过以上的所有命令，我们就可以完成一个Docker镜像的创建，在Dockerfile的最后，我们会用到CMD来指定当Docker容器运行起来以后要执行的命令：\n\n大家需要注意这里容器和镜像的区别(容器不等于镜像),并且它和之前讲到的run不一样，run是创建镜像时使用的，而cmd是运行容器时使用的，到这里我们的自动化脚本dockerfile就完成了，接下来我们可以使用docker build来创建一个镜像，这里的-t指定了镜像的名字，最后面的.告诉docker应该在当前目录下寻找这个dockerfile，这个不能省略:\n\n第一次调用docker build会比较慢，因为docker会下载必要的镜像文件:\n然后一行行运行我们的指令，不过再次调用就会快很多，\n因为docker会缓存之前的每一个操作，这个在Docker中也被称为分层:\n\n这里我们就不展开谈论了\n有了镜像之后，我们就可以通过docker run来启动一个容器\n这里需要注意的是这个-p参数：\n\n他会将容器上的某一个端口，映射到你的本地主机上，这样你才能从主机上访问容器中的web应用，前面的80是我们本地主机上的端口，后面是容器上的端口，这个不要搞反了，第二个参数-d(–detached)让容器在后台运行，这样容器的输出就不会直接显示在控制台，如果不出意外的话，你已经可以在浏览器中访问这个web应用了，我们通过Docker Desktop这个图形界面可以查看应用在后台的所有输出:\n这个对于调试非常方便，同时我们可以看到当前容器的各种信息：\n\n这里的congainer显示了我们创建的所有容器,我们可以选择停止，重启或者删除他们，还可以通过shell远程调试这个容器：\n\n\n这里是它们所对应的的命令行指令：\n\n需要注意的是，当我们删除一个容器的时候，之前所做的修改，新添加的数据会全部丢失，这就好比是我们删除一个虚拟机，里面的数据会一通销毁一样，如果我们希望保留容器中的数据，我们可以使用Docker提供的volume数据卷:\n你可以把它当做是一个在本地主机和不同容器中共享的文件夹:\n\n比如你在某个容器中修改了某一个volume的数据，他会同时反映在其他的容器上:\n\n我们可以通过docker volume create来创建一个数据卷：\n\n随后在启动容器的时候我们可以通过-v参数指定将这个数据卷挂载(mount)到容器中的哪一个路径上:\n\n这里可以看到我们将my-finance-data挂载到了/etc/finance这个路径下，向这个路径写入的任何数据都会被永久保存在这个数据卷中\n\n多容器共同协作\n之前我们讲到的例子都只涉及单个容器，但在实际使用中，我们的应用程序可能会用到多个容器共同协作，比如我们可以使用一个容器来运行web应用，另一个容器来运行数据库系统:\n\n这样可以做到数据和应用逻辑的有效分离，比如当web程序宕机了，数据库依然在有效运转，这个时候我们只需要修复web容器即可，而Docker compose刚好可以帮我们做到这一点：\n我们可以创建一个docker-compose.yml文件，在这个文件下，我们通过services来定义多个container，比如这里我们定义一个web容器，它里面运行了我们的web应用，然后再定义一个db容器，里面运行了mysql数据库系统,这里我们可以通过这两个环境变量指定数据库的名称和连接密码：\n\n同时在db容器中，我们还可以通过volumes指定一个数据卷用来永久存放数据：\n\n定义完毕之后，我们保存文件，使用docker compose up来运行所有容器，这里的-d(detach)同样代表在后台运行所有的容器，不直接输出在控制台:\n\n与这个命令对应的，我们可以使用docker compose down来停止并删除所有的容器:\n不过新创建的数据卷需要我们手动删除(除非在上面的命令中加上–volumes参数)：\n\n另外刚刚讲到的所有操作都可以做图形界面上完成\n\n简单聊下Docker和kubernetes的区别和联系\n虽然大家都说kubernetes在逐渐取代Dokcer，但其实指的是kubernetes中的容器引擎(container engines)而已：\n实际上kubernetes和Docker并不是同一个层面上的东西，在之前的例子中，我们的应用，数据库容器都运行在同一个计算机中，随着应用规模的增大，一台计算机没有办法满足我们的需求:\n\n当我们想使用一个集群的电脑来提供服务，并做到负载均衡，故障转移等等，这个时候kubernetes就可以大显身手了，一句话将，kubernetes所做的就是将你的各个容器分发到一个集群(cluster)上运行，并进行全自动化的管理，包括应用的部署和升级\n\n最后附上docker中文教程\nhttps://www.coonote.com/docker/docker-tutorial.html\n\n\n"},{"title":"Kubernetes(k8s)10分钟快速入门","url":"/2022/01/06/Kubernetes(k8s)10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","content":"\n首先来看看Kubernetes用来解决一个什么样的问题\n我们知道Docker就像是一个轻量型的虚拟机，它将应用程序的代码，工具库和运行环境全部都封装到了一个容器中:\n因此大大降低了测试和部署的难度，我们要做的不过是在服务器上运行一条指令而已:\n\n但如果你要部署的是像购物系统这类架构复杂，规模庞大的应用，他们需要根据访问量自动分配服务器，网络资源，并且在某个容器宕机之后自动进行灾难恢复，故障转移：\n这个时候Kubernetes就可以大显身手了\n\n我们先从整体上来认识下Kubernetes的工作原理\n我们知道，Kubernetes是一个用于大规模部署分布式应用的平台，他管理着一系列的主机或者服务器：\n他们被称作Node(节点)，每个节点运行了相对独立的pod：\npod是Kubernetes中可以部署的最小执行单元，说白了他就是一个或者多个容器的集合，其中运行了我们应用的某一部分核心组件，比如数据库，web服务器等等，当然这么多的pod，他们需要相互协调才能做到负载均衡或者故障转移，这就需要一台中心计算机来集中管理，这个中心计算机被称作Control Plane(控制面板):\n控制平面通过专有的API与各个节点进行通信，他会实时监测节点的网络状态来平衡服务器的负载，或者临时下发指令来应对突发的状况，比如Kubernetes发现某个容器或者pod挂掉了，他会立即启用在后台预先准别好的，随时待命的备用容器来替换它，这些容器被称作Replica Set(副本集合),正是由于他们的存在，才让我们的应用能够长时间，不间断地可靠运行，而以上讲到的所有节点连同控制面板，一起被称作一个cluster(集群)集群代表了Kubernetes所管理的全部主机节点，要配置一个Kubernetes集群，我们当然可以亲自租用服务器去搭建环境，不过步骤会稍微繁琐一点，另一种做法是使用现成的、预先配置好的云服务提供商:\n\n一种完全免费的方法是使用minikube在本地模拟一个Kubernetes集群，这也是我接下来要用到的方法：\n\n使用Kubernetes\n上面我们提到，使用minikube在本地模拟一个Kubernetes集群，在这里面，我们照样可以使用Kubernetes的全部功能，只不过他不是一个真实的生产环境而已\n我们按照这里的步骤下载并安装对应的版本:\n随后只需要一行指令minikube start启动本地模拟的集群即可:\n\n我们来讲下如何在上面部署一个应用\n首先我们需要创建一个yaml文件，里面定义了我们应用的基本信息，比如它由哪些pod组成，里面运行了哪些容器，以及网络配置等等，它和docker中的dockerfile很类似，你可以把它当做一个自动化脚本，里面描述了应用部署的整个过程，另外在vscode中，强烈建议去安装一个Kubernetes插件，他除了提供基本的语法检测、代码提示，在左侧面板中该显示了我们急缺的各种信息、运行状态：\n整个部署的过程也都可以通过图形界面完成\n这里我们先创建一个deployment.yaml文件，然后输入deployment:\n\n让vscode帮我们生成一个最最基本的配置：\n可以看到这里列出了相当多的属性，我们可以将鼠标悬停在上面找到每个属性的详细用法:\n\n接下来我们去修改其中我们关系的部分即可，首先第一步我们先将所有的myapp改成我们应用的名字，这里的replicas指定了连同备用pod在内的所有pod数量:\n然后最重要的是这里的这个templates，它里面定义了与pod相关的所有信息：\n比如下面的container指定了pod中运行的所有容器\n这里我还是用上个视频同样的项目，一个简单的记账工具(一个非常简单的web应用)作为演示，不过我事先将他的镜像(image)上传到了Docker Hub上：\n这样Kubernetes可以自动拉取到它，于是我们这里直接填写镜像的名称即可：\n另外我们可以通过这里的limits为每一个pod设置合理的cpu和内存配额：\n\n最下面的containerPort指定了容器需要对外暴露的端口：\n比如我们web容器使用的是5000端口\n在默认情况下，我们的pod只能与同一个集群内的其他pod进行通信，虽然每一个pod都拥有一个独立的ip\n\n但这个ip地址对于外网是不可见的，如果要从外网访问我们的应用，我们还需要用到Kubernetes中另一个重要的组件–服务(Services)\n现在我们讲一种最最基础的服务，NodePort，它是一种最原始的将应用端口暴露给外网的方式：\n\n建立在它之上，Kubernetes还提供LoadBalancer或者更加复杂的ingress来实现负载的均衡，不过这里就不展开讨论了，我们先在下方用三个横线隔开(yaml中列表的语法)，然后输入Service来添加一个服务：接下来我们在selectors中指定应当将数据转发到哪一个pod上,这里直接填写之前的应用名称即可：\n\n随后的type指定了服务的类型，也就是NodePort:\n后面的port和targetport我们设置成5000和容器端口保持一致，最后的nodeport指定了暴露给外网的端口，这里我设置成了30080，当然我们也可以省略这一行让Kubernetes自动进行分配：\n到这里我们的配置文件就完成了，接下来到了真正应用部署的环节：\n\n应用部署\n这里我们会用到一个命令行工具kubectl来与kubernetes集群进行交互：\n这是一个所有平台通用的工具，就好比我们之前用到的docker命令一样，他可以操纵任何的集群，包括我们本地模拟的ninikube，通常Docker的桌面版本都自带了cubectl命令，但如果你计算机中没有安装Docker，则需要去这里额外下载:\n安装完毕后，我么可以使用kubectl apply来部署我们的应用，并且传入之前创建的这个yaml文件：\n可以看到这个命令被成功执行，此时kubernetes会在后台开始应用的部署：\n我们可以通过kubectl get pods查看所有pod的运行状态，这里显示了我们之前指定的其中包括pod在内的三个pod,他们目前都是正常运行的状态:\n\n另外使用kubectl get services可以查看所有创建的服务\n\n看到这里，既然应用已经被成功部署，我们自然可以去浏览器中访问它。由于这里我们用到的是minikube模拟的集群，所以需要用到一个专门的指令minikube service 后面跟上我们服务的名字：\n这样minikube会自动在浏览器中打开我们的应用，另外顺便提一下，之前所有的操作也都可以通过vscode中的插件完成，里面可以查看各个节点，pod，服务的运行状态，停止或者删除它们：\n\n更新应用\n这个时候如果我们想要更新应用，比如切换容器镜像的版本，或者重新分配cpu和内存资源，我们只需要去修改之前的deployment.yaml文件：\n然后再次调用kubectl apply即可\n\nkubernetes会在后台无缝地更新我们的应用，确保新版本运行起来以后再去销毁旧的版本，因此用户不会遇到服务停机的问题，类似的，如果我们不再需要这个应用，那么可以通过kubectl delete命令从集群上完全移除它：\n后面我们传入相同的配置文件即可\n讲到这里，我们也不是是介绍了kubernetes中一个非常简单的应用部署，通常生产环境下的应用比这个要复杂得多，如果大家想继续深入的话，还是建议去阅读下官方的文档，里面可以找到各种实用的案例，包括安全配置，网络管理，故障排除甚至是GPU调度等等\n\n\n"},{"title":"Puppeteer10分钟快速上手","url":"/2022/01/06/Puppeteer10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/","content":"爬虫，它就像是一只在互联网删爬行的蜘蛛，会根据我们实现定义好的规制为我们抓取需要的信息，以Python为例，你可以使用urllib或者requests发起一个http请求，并使用beautifulsoup或者lxml来分析返回的html文档，从中提取你需要的信息:\n当然你也可以使用Scrapy这种专门为爬虫设计的框架，帮你完成从数据抓取，解析，存储以及调试的所有流程，Scrapy这类框架的优点自然是功能全，速度快，灵活性高，扩展性强，但是由于现在大多数网站都是动态加载的，前端呈现的内容可能由极其复杂的JavaScript程序控制，遇到加密混淆的程序，可能自己还得去逆向分析很久，今天我为大家介绍另一种，基于puppeteer的爬虫思路， 虽然他的效率不是最高的，但一定能让你在最短的时间内快速实现一个爬虫，并帮你抓取到需要的信息\n\n首先来介绍下puppeteer\npuppeteer是一款强大web自动化工具，相比较selenium，phantomjs这些老牌的框架，puppeteer绝对是后起之秀，如果你写了一个web应用，你需要对页面的功能进行测试，譬如检测某个按钮是否会唤醒对话框界面，puppeter就完全可以胜任这个任务，由于它可以对浏览器进行操控，获取页面数据，自然也可以用它来做爬虫，爬虫不过是它众多应用中的其中一种，其实对于任何自动化的操作，我们都可以用它来完成，谷歌官方的puppeteer是通过JavaScript调用的，但是它在Python，Ruby，Go上都有对应的移植版本，如果你使用Python，你可以下载一个叫做pyppeteer的包，其中所有的API都是一致的，除了少数语法的不同，这里以JavaScript作为演示：\n\nJavaScript演示puppeteer\n首先确保你计算机中安装了Node.js：\n然后创建一个目录来保存我们这个项目(也就是这里的web-scraping-node)：\n\n然后使用npm init 初始化工程:\n最后使用命令npm i puppeteer:\n这过程会持续一段时间，取决于你的网速\n接着我们在文档的入门指南中找到这样一段样例程序，我们直接将代码复制到编辑器中，在它的基础上做修改:\n\n这是修改前的代码:\n这10行代码非常简单:\n这是创建一个浏览器对象:\nconst browser = await puppeteer.launch();\n\n打开一个新页面:\nconst page = await browser.newPage();\n\n然后转到example.com\nawait page.goto(&#x27;https://example.com&#x27;);\n\n保存一张截图后退出:\nawait page.screenshot(&#123;path: &#x27;example.png&#x27;&#125;);\n\n如果你运行代码，在短暂的等待之后，程序会当前目录下保存一张截图文件:\n这里我们稍做修改，首先在创建浏览器对象的时候传入一个新参数headless: false,因为puppeteer默认运行在无头(headless)模式下，也就是说浏览器窗口并不会显示出来，这里我们通过这个参数关闭无头模式，接着我们将网址改为百度，并且删除后面的screenshot()和borwser.close(),保存程序，运行程序，可以看到puppeteer成功打开了百度并显示在新创建的浏览器窗口中，需要注意的是，这里窗口边缘的空白是一个feature，并不是一个bug:\n\n\n用puppeteer写爬虫\n将bilibili上的音乐的热门信息给提取出来\n以下是实施的步骤:我们打开浏览器的控制台，然后我们可以在这里输入任何JavaScript表达式来做测试，比如:\n\n\n如果我们想要在页面中提取相似的元素，我们可以用到selector(选择器)或者xpath，选择器的语法更为简单些，这里我们以选择器为例，比如你想要的匹配页面中的所有链接，可以在控制台中输入$$(‘a’),如果你想要匹配所有li元素下的a标签则可以输入$$(‘li &gt; a’),这里我们想找出能匹配这个视频标题的选择器，其实chrome给我们提供了一个便利，我们可以在标题上点右键，选择下方的检查，选中的元素就会以高亮的形式显示在右边:\n我们点击右键，选择这里的复制选择器：\n\n接下来我们只需要稍作修改，比如删掉这里多余的部分，做一些简化:\n就可以提取出所有的标题元素了：\n然后我们可以遍历返回的每个元素，将标题文字给提取出来:\n\n我们可以先记下这段选择器，待会儿我们就会用到，我们先将浏览器中的网址直接拷贝过来,接下来使用page对象的$$eval函数来获取所有的视频标题：\n这里的第一个参数是选择器，就是我之前测试时用于提取标题的选择器，第二个参数要求你传入一个函数，这个函数会直接在网页的上下文中运行，筛选出你需要的数据并返回给puppeteer，这里我做的是遍历所有的a标签,并将其中的文本给提取出来，我们可以调用log函数将结果打印出来：\n\n运行程序，我们可以看到这样的结果：\n这里为了让程序更健壮，我们可以在获取标题之前，先等待标题元素的出现，这样可以避免页面加载期，无法找到元素而报错的现象:\n后面的代码直接上，我们限定了数据的时间，然后以json的数据格式保存下来：\nconst puppeteer = require(&quot;puppeteer&quot;);const fs = require(&quot;fs&quot;);(async () =&gt; &#123;  let data = [];  const browser = await puppeteer.launch(&#123;    headless: false,    userDataDir: &quot;./data&quot;,  &#125;);  const page = await browser.newPage();  for (let mo = 1; mo &lt; 12; mo++) &#123;    for (let pg = 1; pg &lt;= 10; pg++) &#123;      mo = mo.toString().padStart(2, &quot;0&quot;);      await page.goto(        &quot;https://www.bilibili.com/v/music/cover/?spm_id_from=333.5.b_7375626e6176.3#&quot; +          `/all/click/0/$&#123;pg&#125;/2020-$&#123;mo&#125;-01,2020-$&#123;mo&#125;-29`      );      await page.waitForSelector(&quot;.vd-list-cnt &gt; ul &gt; li &gt; div &gt; div.r &gt; a&quot;);      let titles = await page.$$eval(        &quot;.vd-list-cnt &gt; ul &gt; li &gt; div &gt; div.r &gt; a&quot;,        (links) =&gt; links.map((x) =&gt; x.innerText)      );      console.log(titles);      data = data.concat(titles);    &#125;  &#125;  fs.writeFile(&quot;data.json&quot;, JSON.stringify(data, null, &quot;\\t&quot;), function (err) &#123;    if (err) &#123;      console.log(err);    &#125;  &#125;);&#125;)();\n最后我想提一个大家可能经常会遇到的问题\n我们每次运行脚本的时候，puppteteer磨人都会为我们创建一个崭新的实例，也就是像网页的缓存、cookie都会在脚本退出之后自动销毁：\n像网站的登录信息也不会被保存下来，而通常我们并不希望每次运行脚本都去登录一次，这里我们可以给launch指定另外一个参数，他会将浏览器的数据保存在这个指定的路径下，因此所有的浏览器实例都会共享这些数据：\n登录信息也会被保存下来\n其实用puppteteer来做爬虫确实是一种不错的选择，要知道现在大多数网站都是使用了前端的JavaScript程序来做渲染的，相比于http层的爬虫工具，puppteteer更像是一个模拟网页操作的机器人，他用起来直观很多，也帮我们省去了不少分析前端代码的时间，不过想scrapy还是很强大的，尤其是他的速度和性能\n源码：https://github.com/rossning92/web-scraping\nPuppeteer 中文文档：https://zhaoqize.github.io/puppeteer-api-zh_CN/\n\n\n"},{"title":"mac终端美化教程","url":"/2022/01/07/mac%E7%BB%88%E7%AB%AF%E7%BE%8E%E5%8C%96%E6%95%99%E7%A8%8B/","content":"mac终端美化请参考:https://www.wolai.com/fishc/exwe9Srj8St6THjGE6YVyz\n"},{"title":"Linux系统启动过程","url":"/2022/01/07/Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/","content":"按下系统的电源开关，过一会儿就可以看到Linux的登录界面，你是否想过，从按下电源开关到登录界面的出现，这后面到底发生了什么?\n我们先来看看一个整体的流程图:\n\nLinux系统在启动过程中，首先是固件(PC上大多是CMOS/BIOS)的物理检测，诸如检测系统的显卡，CPU和硬盘等，可从系统按下电源键后看到此检测信息；检测没有问题后，将读取硬盘的MBR(主引导记录)中的自举程序，Linux中常用的自举程序如LILO和GRUB。自举程序GRUB在系统启动期间只有一个作用，就是启动内核，内核在引导期间有两个主要的作用，一个是驱动系统硬件，另一个是启动系统init，init进程将读取其配置文件/etc/initab完成后继续所有的引导。\n整个过程基本可以分为六个步骤:BIOS–&gt;MBR(GRUB)–&gt;Kernel–&gt;Init–&gt;Runlevel:\n\n\n\n\n\n\n"},{"title":"10分钟彻底搞懂“动态规划”算法","url":"/2022/01/06/10%E5%88%86%E9%92%9F%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82%E2%80%9C%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E2%80%9D%E7%AE%97%E6%B3%95/","content":"动态规划是计算机中解决最优化问题的一种方法，它通常给我们的印象是效率高，速度快，但对于初学者来说，可能并不是那么容易理解，今天，我们抛开所有的数学公式，用实例给大家彻底讲懂动态规划算法。\n首先我们来看一个经典的动态规划问题:\n给你一个无序的数组，要求我们找出其中最长的递增的子序列:\n\n比如这里的1，2，4就是其中一个:\n\n1，2，3是另外一个答案:\n\n这里我们再对这个问题做一些简化，我们要求这个算法只返回最长序列的”长度”就好了:\n\n也就是3:\n\n如果是你，你会怎么去求解这个问题呢？\n其实最容易想到的办法是暴力枚举，或者叫暴力搜索；比如从1出发，下一个数字可以取5，2，4或者3，因为他们都是递增的:\n\n假如我们第二个数字选5的话，再下一个数字就取不了了，因为剩下的2，4，3都比5小，不能构成一个递增序列:\n那如果第二个数字选2的话，下一个数字可以是4，也可以是3，此时构成的递增序列长度为3:\n\n以此类推，如果第三个数字取4，下一个数字依然不能选，因为3比4小：\n\n算法就这样一直循环往复地执行下去，直到我们把每个子序列都找了个遍：\n并且在遍历过程中，我们实时记录最长的子序列长度，最后可以知道，最长的子序列长度为3:\n\n最后，我们按照同样的方法计算”从5出发”，”从2出发”，”从4出发”，”从3出发”的序列长度，选出最长的那个，算法结束：\n\n那么我们应该如何去实现这个算法呢？\n我们可以定义一个函数L，这个函数会返回从数组第i个数字开始的最长子序列长度：\n\n然后我们检查i后面的所有数字，我们将索引记为j，只要这个数比当前数大(也就是说可以构成递增序列),我们就递归地调用函数自身，去计算从j开始的最长子序列长度:\n\n然后加1得到目前这个序列的总长度:\n\n接着我们只需要遍历所有的j，然后选出最长的子序列长度返回即可:\n\n当然这个递归函数不能永无止境地调用下去，当i取到最后一个数字的时候，由于它后面已经没有其他数字与它构成子序列了\n\n所以我们直接返回长度1:\n接下来我们只需要对数组中的每一个数i依次调用L函数，然后选出长度最长的那个返回即可：\n我们可以带入之前的数据进行测试:\n\n可以看到这个算法成功返回了3:\n\n这个算法虽然能够帮我们算出答案，不过它最大的问题在于时间复杂度，假设数组的长度为n，那就一共存在2^n个子序列，而每一个子序列我们都需要去遍历一次(判断是否是递增序列)\n\n很显然这是一个指数级别的算法，最慢的算法之一，如果我们用长度为100的数组做测试，可以看到程序运行了整整5秒才算出答案：\n\n我这自己重写了一遍半分钟还没出结果：\n\n那有没有可能对算法进行一些优化呢，如果我们观察这个遍历树，会发现里面存在大量的重复计算：\n比如我们在遍历子序列1，2， 4的时候就已经计算过“从4开始的最大子序列的长度”\n\n后面遍历1,4的时候又重复计算了一次\n\n为了避免重复的计算，我们可以在第一次计算的时候将结果保存下来，之后遍历到相同的节点我们就不用再重复计算了\n\n直接将之前的结果返回\n这里我们可以用一个字典(哈希表)memo记录下“从i开始最长的子序列长度”也就是代码中的max_len，然后我们在函数的开头检查之前是否保存过这个答案，如果是，直接返回结果，否则再去计算答案：\n可以看到经过修改的代码，只用了1毫秒就计算出了结果\n\n相比较之前的5秒是巨大的速度提升，动态规划正是通过避免重复节点的计算，来加速整个计算的过程，由于用到了字典(哈希表)来保存了计算的中间结果，因此我们也称之为“记忆化”搜索，这也是大家经常会说动态规划是“空间”换“时间”,当然也有人叫它“带备忘录”的递归或者叫递归树的“剪枝”，它们都是同一个意思，因为我们不需要对这些树子节点进行重复计算了：\n有了递归的算法，我们还可以尝试将它改写成非递归，或者也叫迭代的形式，这样我们可以更加直观地去分析算法的时间复杂度，并且避免了递归时候的函数调用开销：\n从之前的算法我们知道，要计算出从“1”开始的最长子序列长度，我们需要依次检查它后面的所有数\n\n由于1可以和5，2，4，3构成递增序列，所以我们需要递归地计算从5,2,4,3开始的最长子序列长度，然后选出最长的那个，然后加1得到与第一个数构成的最长子序列长度：\n同样的，要计算从“5”出发的最长子序列，我们也需要先检查它后面的数：\n然后进行同样的计算\n这里很显然，因为后面没有数可以与它构成递增序列，所以结果直接是1：\n\n我们这样以此类推下去，直到最后一个数，由于从3出发的子序列之能是它自己，所以长度直接是1:\n\n从这里的公式中可以发现，我们只要从后往前依次计算，就能把所有的答案给推算出来，大家是不是觉得很像数学归纳法：\n\n最后我们根据列出的式子来实现这个迭代算法：这里我们可以通过两个循环，外面的循环代表从下往上的依次计算：\n里面的循环用于遍历括号中的这些数值:\n\n运算的结果我们可以存放在一个数组中，我们直接叫它L：\n接下来只要后面的数比当前数大(能构成递增序列)，我们就按同样的方法来计算这个L(i):\n最后我们返回L数组中最大的那个即可\n\n这个该写的迭代算法同样可以帮我们计算出最终答案，并且由于这里只用了两个循环，每个循环最多执行n次，因此算法的时间复杂度是o(n^2)和之前的指数级别的算法是天壤之别\n最后我们来总结下动态规划的一般思路：\n\n穷举法/暴力搜索\n记忆化搜索/剪枝\n改写成迭代形式\n\n首先，我们可以先简单粗暴地将所有答案穷举出来\n\n并画出递归树\n\n尝试写一个递归函数来求解，如果发现遍历中存在大量的重复计算\n\n我们可以尝试用哈希表将数据缓存下来\n\n之后遍历到相同的节点就直接查表，避免重复的计算\n最后，我们可以将计算的过程表示出来，然后观察公式求解的顺序\n\n并尝试将递归形式改写成更简洁高效的迭代形式:\n如果大家搞懂了之前的内容，不如我们来试试另一个经典的动态规划问题，给你一个数组，要求我们要找出其中连续子序列的最大和:\n\n比如这里的[2, -1, 2, 6]和最大:\n这个问题又如何求解呢\n"},{"title":"0.1+02等于0.3嘛，无可避免的浮点误差","url":"/2022/01/07/0.1+02%E7%AD%89%E4%BA%8E0.3%E5%98%9B%EF%BC%8C%E6%97%A0%E5%8F%AF%E9%81%BF%E5%85%8D%E7%9A%84%E6%B5%AE%E7%82%B9%E8%AF%AF%E5%B7%AE/","content":"在我们印象中，计算机总是能高效准确地进行运算:直到有一天你满怀欣喜地打开最喜欢的编程环境，输入0.1+0.2，但计算机却返回这个:\n你下意识觉得这可能是一个bug，然后在不同语言中反复求证，却一致地得到相同的答案：\n\n究竟是道德的沦丧还是人性的扭曲\n这一切都要从一个盛行了三十多年的标准IEEE-754讲起，IEEE-754定义了浮点数的格式、存储和运算：\n它对浮点数的表示和我们熟知的科学计数法如出一辙\n\n\n\n\n一个浮点数会被分成两部分存储,第一部分尾数(mantissa)也叫做有效数字(signigicand)，也就是下图用红色高亮的部分，第二部分指数(exponent)也就是这里黄色高亮的部分：\n由于尾数和指数分开存储，使得浮点数天生可以表示很大范围的数字，你可以用它表示整个星系的大小，也可以表示微观粒子的半径，并且现代计算机对浮点数做了大量优化，能够在很短时间内进行相当复杂的运算，一个典型的例子就图形渲染，每秒60帧的画面，每帧几百万的像素点同时参与光照计算，大家可以想想这个计算量\n为了了解计算机中的浮点数，我们先来看看十进制世界的我们是如何表示小数的\n首先在整数部分，我们有个位，十位，百位，千位，同样在小数部分我们有1/10,1/100,1/1000等等：\n比如我们写上在个位写0，在小数部分的1/10上写1就可以精确表示0.1，但是计算机使用的是二进制，每一位只能是0或者1，并且逢二进一，因此整数位分别表示有多少个一，多少个二，多少个四多少个八，其实这对应着2的一次方，2的二次方，2的三次方等等，小数部分则表示1/2,1/4,1/8,1/16等等：\n在二进制中，我们可以轻易地表示1/2,1/4或者3/4没有任何问题，但是二进制中没有1/10,求出的答案与1十分接近但却不等于1:\n虽然计算机不总是能精确地表示小数，但在大多数情况下这并不是问题，比如在物理引擎中，我们会用到浮点数来计算物体的坐标，假设误差导致每一帧中物体的位置偏离0.00001，由于这个量实在太小，即便累加一秒，可能还不及一个像素点的长度，用户根本无法察觉，但是另一方面如果银行使用浮点数来表示货币，每存入0.1块钱，由于浮点误差的存在，导致账号中会多累加这么多钱:\n在频繁的交易下，这种误差积少成多对银行来说就是巨大的损失\n\n要解决这个问题，最容易想到的就是用整型来替代浮点数\n\n比如1块钱当作整型数100来存储，这样1分钱就可以准确无误地用数值1来表示，最后我们只需要在显示货币的时候除以一百即可：\n另外现代的编程语言或者数据库中都提供一个特殊的数据类型decimal(十进制定点数),专门用来表示任意精度的十进制数：\n\n用它来进行运算不会产生任何的精度问题\n\n当然在大多数时候，我们依然会用到浮点数，因为浮点数能高效地进行运算，并且节省内存空间，只要我们心里有数，知道程序出现误差可能会导致出现逻辑错误，并且加以防范就好了，比如直接用等号去判断两个浮点数是否相等，这种用操作是很不可靠的，正确的做法应当是去计算这两个数的差别是否小于某个误差范围：\n\n在现代的编程语言中大多都内置了判断浮点数是否相等的工具函数，比如python中的isclose：\n使用他们可以规避很多由浮点误差而导致的程序逻辑错误：\n浮点数的这些奇怪特性可能一开始让很多人摸不着头脑，但在了解之后发现他不过是一个基本的数学概念，科学计数法的二进制版本，仅此而已：\n由于0.1在二进制中是无限循环小数，计算机没有办法精确表示，从而丢失了精度，也就造就了为什么我们输入0.1+0.2但计算机返回的却不是0.3的情况：\n"},{"title":"记一次sourcetree推送代码进度条一直在动可就是推不上去的错误解决方法","url":"/2022/01/07/%E8%AE%B0%E4%B8%80%E6%AC%A1sourcetree%E6%8E%A8%E9%80%81%E4%BB%A3%E7%A0%81%E8%BF%9B%E5%BA%A6%E6%9D%A1%E4%B8%80%E7%9B%B4%E5%9C%A8%E5%8A%A8%E5%8F%AF%E5%B0%B1%E6%98%AF%E6%8E%A8%E4%B8%8D%E4%B8%8A%E5%8E%BB%E7%9A%84%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","content":"今天在某个本地仓库新增了一些数据，然后想着把数据提交一下，然后在使用sourcetree的时候提交进度条在移动然后始终推送不上去，后面在网上查阅资料说可能是安装了git但是没有给surcetree权限:\nhttps://blog.csdn.net/Baron0071/article/details/84062638?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-84062638.pc_agg_new_rank&amp;utm_term=sourcetree%E6%8E%A8%E9%80%81%E4%B8%80%E7%9B%B4%E8%BD%AC&amp;spm=1000.2123.3001.4430\n我照着他的步骤执行了一遍发现我确实是这么配置的但是在我点击确定后就能推送上去了，这可能是soucetree的一个小bug叭\n"},{"title":"Git+Github10分钟完全入门以及Git图形界面GitKraken的基础使用","url":"/2022/01/07/Git+Github10%E5%88%86%E9%92%9F%E5%AE%8C%E5%85%A8%E5%85%A5%E9%97%A8%E4%BB%A5%E5%8F%8AGit%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2GitKraken%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/","content":"大家也许听说过git是一款使用人数众多的分布式版本控制系统，可是到底什么是版本控制系统，git和github又有什么区别和联系呢\n今天，我们来用一个全新的视角来了解这款必备工具，并解密这些被复杂化的概念和生僻术语\n在我们码代码的时候，我们可能经常会有这样的需求，我们可能希望保存源代码的不同版本，当软件出现bug时我们可以回溯到之前的状态，比较版本之间的差别从而找出bug的源头，并且，再多人分工协作的时候，我们也会经常修改到相同的文件，这时候，如果有一个工具能够帮助我们完成修改的合并，也许就可以帮我们节省不少的时间，那么版本控制系统也应运而生:\n如果你只是经常写一些脚本或者简单程序的话，版本控制软件可能用得比较少，但是项目规模一旦大起来，或者涉及到团队协作的时候，版本控制系统可以说是必不可少的，git其实也只是众多版本控制系统中的一种，其它的你可能听过的还包括CVS、Subversion、Mecurial、Perforce、Bazaar等等:\n其实它们都有各自的优缺点，并且应用的领域也稍有不同，git可以说是应用最为广泛，并且最适合于中小项目开发的工具之一，而且版本控制的许多概念其实是互通的，如果你还没接触过相关软件的话，我也非常推荐从git这一款入门，另外git本身其实是一款命令行工具，可能很多人更加推崇使用命令行工具而不是图形化工具，这个我觉得是仁者见仁智者见智，这两个我自己平时也都会用到，命令行更方便于写脚本、自动化，图形化工具的操作通常更直观，入门也更加轻松；当然在这里最重要的还是掌握git以及版本控制系统的核心概念,因此作为入门我推荐的是一个叫做GitKraKen的图形化客户端它支持主流的操作系统，界面很漂亮，功能也很全面，并且对个人的开发是完全免费的，大家可以通过下面的链接在官网上下载对应的版本安装：\n\n第一次使用GitKraKen它会提示你进行登录\n\n这里我推荐大家用自己的GitHbu账号登录，如果还没有GitHub账号的小伙伴现在可以去注册一个，因为早晚都会用到的，登录完成之后呢，他会提示你输入一些个人信息，比如你的用户名称和邮件地址，这个信息和签名档很像，他会附带在你每一次的代码提交上\n\n信息填写完毕之后呢，我们就来到了GitKraKen的主界面，接下来的第一步是创建一个代码仓库(Repository)\n\n仓库这个术语指的是与项目相关的所有文件，包括源代码、工程文件、资源文件和一些配置信息，它可以是本地的仓库，可以是保存在远程服务器上的仓库，仓库之间可以相互同步，比如你可以把本地计算机上的代码同步到远程的服务器上\n\ngithub上就保存了很多远程代码仓库，他也是当今最大的代码托管网站和开源社区\n这里创建代码仓库的时候呢，我们直接一步到位，点击这个按钮创建一个托管在GitHub上的代码仓库\n\n待会儿我们就不用再特别设置用于同步的远程服务器了\n\n这里，我们选择之前登录的GitHub账号，给仓库起一个名字\n\n并附上一个简短的介绍，最后点击下面绿色的按钮完成创建\n\n中间这个很大的区域显示了代码的所有提交历史，其中的每一项代表一个提交(commit)\n\n提交这个术语很像是游戏里面的检查点或者是一个快照，在每一次你对代码做出修改之后，你可以提交这一次的所有修改，此时git会保存当前的代码快照，在之后的若干次修改之后，我们也可以轻松地回溯到这一次修改的状态，可以看到，这里唯一的一个提交是在新建代码仓库时候自动创建的\n\n我们选中这个提交后，可以看到这个提交中修改的所有文件，比如这里可以看到有一个新文件README被创建(这里加号所代表的)\n\n那么接下来，我们新建一个代码文件，并完成一次新的提交，我们可以先点击文件菜单中的“在文件浏览器中打开”\n\n然后找到当前代码仓库在本地计算机上存放的位置，这里我们新创建一个文件并命名为hello.c,然后我们在里面随便写一个helloworld程序，保存文件之后，我们回到GitKraKen中，可以看到中间的“提交历史”中多出了一项WIP，代表这个提交”正在施工中”(working in progress)\n在右边我们可以看到多出来了一个我们刚刚创建的源代码文件，点击它也可以看到文件中被修改的具体内容\n\n接下来，我们来提交这个文件，我们首先点击这里的Stage\n\ngit要求再对修改的文件提交之前必须将它们Stage，你可以把它想象成提交之前的一个必经阶段，防止你误操作，然后你可以在下面输入你对这次代码提交的一个小总结，这个信息是必填的(在sourcetree不是必须的),你想想如果你面对的是大堆”无名的”历史提交，想从中找出你需要的如同是大海捞针\n\n最后点击下面的提交按钮完成这一次提交\n\n到目前为止，我们所有操作都是针对你本地计算机上的代码仓库的，如果我们去浏览GitHub上的远程仓库，可以看到还是处于最原始的状态\n\n如果我们希望将所有的提交都同步到远程的GitHub服务器上，让所有人都能看到你的修改的话，我们需要使用到Git中的Push功能\n\n在GitKraken中我们点工具栏中的Push按钮即可\n\n这里的origin通常指的是默认的远程的服务器，推送之后呢，如果我们再次刷新GitHub上的页面，可以看到所有的代码已经成功上传上去了\n\n如果我们点这里的commits也可以看到和本地一样的所有代码的提交历史\n\n我们既然可以把本地代码提交推送到远程服务器，就一定可以从远程服务器下载新的提交\n接下来我们来讲一下Git中与Push相对应的Pull(拉取)操作\n比如这里我的一个朋友小罗也往远程服务器上推送了一个提交\n\n我们点开后发现他对README.md文件进行了一点小修改\n\n如果我们切换到GitKraken中也可以看到提交历史的最上面多出来了这一条\n\n左边有两个小标签我们需要注意下，这个写有master并画有电脑图标的标签代表本地仓库中的提交，上面这个则是表示GitHub上远程仓库的提交，这里的master是一个分支branch，我们待会儿会讲到，那这个时候如果我们想把这位同学的修改同步到本地仓库的话我们可以点击GitKraken中的pull按钮\n\n之后呢这两个图标会重叠在一起，代表本地仓库和远程仓库的提交历史已经完全一样了\n\n这时候我们也打开本地仓库中的README.txt文件，也可以看到其中修改的内容，那可能有人问，比如当不同的人去修改相同的文件的时候git会怎么做呢，接下来，我们来看一下git中的合并操作(Merge),也是版本控制工具中非常重要的一环，这里在最新的提交中我们看到小罗同学修改了一下hello.c文件，往里面添加了一个函数multiply()\n\n\n接下来我们在本地也去修改同一个文件，将主函数中输出的字符串修改一下\n\n然后按照之前的步骤，在本地提交这一次修改，这里，我们看到提交的历史出现了一个分叉，下面这个显示了远程仓库中小罗同学的提交，上面这个是我刚才创建的本地提交，如果我们希望这两个对hello.c的修改同时应用在你本地的代码仓库中，我们则需要将这两个提交合并起来，合并其实在Git中有很多种方式，我们先讲一种最简单的，就是使用之前提到的Pull功能，git会在获取远程提交的同时将远程的提交合并到本地的提交中，这里我们可以点上面的Pull按钮，可以看到在窗口的最上面，git为我们自动生成了一个新提交，这个提交做的事情就是将之前的两个提交合并起来\n\n这时候如果我们打开hello.c也可以看到这两处的修改已经被git自动合并了\n这时候可能有人问了，如果两个人修改代码的同一处位置，git又会怎么做呢，我们一起来研究一下\n这里小罗同学修改了一下这里的字符串，在前面加了一个“Little”,我们也去修改同一行代码，把这里的“Yoyo”改成“Hey”，然后本地提交这一次修改，可以看到这里的提交又开始出现了分叉\n\n接下来我们来合并他们，按照之前的做法，我们可以之间点击Pull，不过这次git的自动合并失败了\n\n取而代之的是一个错误信息，告诉我们这里有冲突(conflict)需要我们手动解决，原因很简单，git也不知道应该如何合并了，毕竟我们修改的是同一行代码，我们可以点右边的冲突文件下的这个hello.c文件，左边窗口显示的是我们刚刚的修改，右边显示的是远程仓库上小罗的修改(还记得我们之前说的origin通常代表远程仓库嘛)，下面的这个窗口代表合并之后的结果，是我们手动解决冲突用的\n\n那我们看了代码当然明白，应该该将Yoyo改成Hey，并在后面加一个Little\n修改完成之后我们保存文件回到之前的窗口和之前一样描述一下这次合并的内容并完成这一次提交\n\n软件中对应的命令行指令:\n\n"},{"title":"10个Python编程技巧 让你的代码更上一层楼","url":"/2022/01/08/10%E4%B8%AAPython%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7%20%E8%AE%A9%E4%BD%A0%E7%9A%84%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%B8%8A%E4%B8%80%E5%B1%82%E6%A5%BC/","content":"Python可以说是近十年来增长速度最快、应用最广泛，并且是世界范围内最受欢迎的编程语言之一，今天，我来给大家讲10个我个人觉得非常实用，但可能并不是所有人都知道的Python编程技巧，保持这些良好的编程习惯，可以让我们写出更清晰、更优雅、更易读、更赏心悦目的代码\nPython语言其实在设计之初就有在考虑它语法的简洁性和可读性，可能有人听说过Python之禅(Zen of Python)这其实是Tim Peters在Python中留下的一个彩蛋，如果你进入Python，然后输入import this，你会看到作者留下的一条条编程建议:\n\n其中列出的这20条规制，就是在告诉你Python程序编写的指导方针，另外，大家如果听说过Pythonic这个词，它其实是用Python加上后缀ic创造出来的一个英语单词，它指的也是具有Python独特风格、简介而优雅的代码，最后甚至在Python语言的提案PEP8中也定义了一条条让代码更清晰、更简洁的代码规范，这里我筛选出了10个重要的技巧，接下来我们就用实例来一一讲解下叭:\n\n变量交换\n在很多编程语言中，如果我们需要交换变量a和b中的内容，通常我们可以定义一个临时变量，先将a的内容存放在其中，然后将a设置为b，再将b设置成这个临时变量:\n不过，上面这段代码在Python中其实可以被改成这样:\n\n这样的话，程序的可读性是不是提高了很多呢\n\n字符串格式化(String Formatting)\n通常在程序中我们需要组合或者拼接字符串的话，我们可以用加号来做字符串的连接:\n如果只是做两个字符串的拼接，这样写其实没有什么问题，不过如果字符串比较多的话，类似于这种情况:\n\n这样的程序会显得非常杂乱并且不易阅读，而且，当我们在连接整形数据的时候还需要进行类型的转换，不然程序也会报错:\n其实我们可以把程序写成这个样子:\n\n利用Python中的百分号语法来格式化字符串，其中%s代表这里的内容会被替换成一个字符串，这里的s是string的首字母，这里的%d会被替换成一个十进制数，d是decimal的缩写，最后面这个%()中定义了需要被替换的内容，虽然程序写成这样已经好看很多了，我们在这里还可以做的更好一些，我们可以利用Python中的format()函数和花括号语法，把程序写成这样:\n\nformat()在这里是字符串对象的一个方法，调用它会返回被格式化后的新字符串，而花括号中的内容会被最终替换成format()函数中传入的各个参数\n使用这种方式的另一个好处是，如果你有重复的需要被替换的内容，你可以在花括号中写入被替换参数的索引，就像这样:\n因此这里的两个花括号都会被替换成同一个内容，也就是这里索引为0的第一个参数name，最后如果你使用的是Python3.6以上的版本，这里有一个最简单的写法:\n也是我最喜欢的，叫做f-string，我们只需要在字符串开头写一个f，花括号中的内容就会被自动替换成指定表达式的值，注意，这里我说的是表达式，比如我们可以把这里的age改成age+1,Python将会把表达式运行的结果也就是29替换在字符串中，由于这里可以填写任意的表达式，所以你甚至可以调用一个函数返回一个数值，并替换在字符串中，这也是没有问题的\n\nPython中的yield语法\n比如在这里，我们定义了一个函数fibonacci()，来列举斐波那契数列中的前n个数\n\n斐波那契数列大家应该都听说过，简而言之，就是除了最前面两个数之外，其中每个数字都是前两个数字之和，比如这里的5是前面2跟3的和:\n这个程序里面有两个变量:a和b，他们分别代表前一个数和当前的数，这里的循环会执行n次，而每次循环，程序都会把之前的数存放在一个叫做nums的列表中，然后之前的数会被替换成当前这个数，当前这个数会被替换成前两个数之和，然后程序就会循环往复地执行下去，直到计算出第n个数为止，此时，如果我们使用print()在屏幕上显示这10个数，我们会得到这样的结果:\n\n\n在这里，我们可以修改这个fibonacci()函数来使用Python的yield语法\n我们首先把“list末尾添加元素”的操作替换成yield a\n\n然后删掉这里的nums列表，这样修改后的程序会完成和之前一样的操作:\n这里的yield表示每当我们计算出一个元素，就立马把这个元素给送出去，也就是说外面的for loop中就会立即输出这个数，因此使用yield的好处是，我们并不需要等待整个列表都生成完毕后再来一个一个地输出，yield在英文中的意思是产出，单从字面上来看还是比较抽象的，不过它和return的区别是，当你的函数yield一个数值以后，函数并不会立即停止，而会继续执行下去，yield的优势在于一些非常耗时的操作，比如我们可以写一个函数来从网络上下载一系列文档，并输入每个文档的内容，如果我们使用yield，则可以保证在一个文被下载成功后，就立马输出它的内容，而无需等待所有文档都下载完毕\n\n列表解析式(List Comprehension)\n比如在这里我们有一系列水果的名字\n\n存放在一个叫fruit的列表中，如果我们希望把这些名字都改为大写，这里有很多种办法，比如写一个for loop遍历所有名字，并把他们改写成大写\n\n其实这里有一个更为简单的语法，之前的代码可以直接被改写成这样\n\n后面这个方括号语法实际上是在构造一个新的列表，并把它赋值给之前的这个fruit变量，我们可以这样来理解这个语法，方括号的后半部分实际上是在告诉Python我需要枚举fruit变量中的所有元素，而其中的每一个元素的名字叫做x，而方括号里的前半部分x.upper()则是将这里的每个字符串x转换成大写，列表解析式其实还有另外一种应用，筛选或者过滤列表中的元素，比如，如果我们希望挑选出列表里以a开头的水果，那么一种常见的方法是写一个循环，然后挑选出需要的元素存放在一个新列表中，其实利用我们之前讲到的列表解析式，我们可以将程序改写成这样\n\n\nPython中关于循环的技巧:Enumerate()函数\n还是使用之前的例子，如果我们需要按顺序输出某一个列表中的所有元素，我们可以使用for…in的语法，如果我们希望同时得到每一个水果在列表中对应的索引值，比如apple的索引是0，pear是1，我们可以使用一个叫做enumerate()的函数，把程序改成这样\n\n这里的enumerate()函数会在每一次循环的过程中提供两个参数。第一个i代表列表元素的索引值，第二个x代表元素中的内容\n\n反向遍历\n这个其实是对上一个技巧的延伸，如果我们希望将fruit中的元素后往前依次输出，那么我们应该怎么做呢，其实我们只需要在遍历元素的时候加入reversed()函数就搞定了\n\n\n按顺序遍历\n这里我们再延伸一下，如果我们希望输出的元素是按照水果名字的字典顺序，也就是说名字以a开头的排在最前面，以z开头的排在最后面，应该怎么办呢，这里我们可以使用到Python中的一个内建函数sorted()，将fruit用这个函数括起来就好了，sorted()函数会返回一个新的并经过排序后的列表，因此我们在使用循环输出时，内容就已经被事先排序好了\n\n\n字典的合并操作\n比如在这里我们有两个字典，其中存放不同用户的用户名和密码\n\n这时候，我们可以写这么一个程序将这两个字典合并成一个字典，也就是这里的c\n\n不过我们可以将这里的5行代码，改成更加简洁的形式\n他们都会执行完全一样的操作，这里的这两个*在Python中叫做解包(unpacking)，也就是说这里的**a和**b相当于是将字典a和b中的内容直接填写到了这里\n\nPython中的三元运算符\n在Python程序中，我们经常会完成这么一项操作:\n\n将一个变量设置成不同的值，比如在这个例子中，我们会根据score里面存储的数值是否大于60，来决定s里面的内容是pass还是fail，其实这里的代码可以直接被改成这样\n\n这里的if…else称为Python中的三元运算符，当if后面的条件满足时，表达式会输出前面的这个值，当条件不满足时，表达式会输出后面这个值，它的功能等价于c或者java中的三元运算符，尽管它们的写法完全不一样\n\n\nPython中序列的解包\n比如我们在这里，我们定义了一个变量name，里面存储了张三同学的姓和名\n\n如果我们想单独提取出它的姓和名，并把它们存放在不同的变量里，我们可以利用字符串对象中的split()方法，把这个字符串按空格分割成多个字符串，然后我们再利用列表的索引提取出对应的姓和名\n\n不过这段程序可以被我们改成这个样子:\n\n这里，我们直接将split()函数返回的列表中的元素赋值给first_name和last_name,中间以逗号的形式隔开，这个操作在Python中被称作序列解包，需要注意的是，这里的”序列”其实并不一定需要是列表，它也可以是元组，甚至是range，因为它们都代表一系列元素，也就是序列\n\nPython中的with语句\n在Python中，如果我们想读取某一个文件的内容，我们可以使用open()函数打开一个文件，并利用返回的这个文件对象f来对文件进行操作\n\n不过，当我们完成对文件的读取，不在需要这个对象之后，一定不要忘记调用close()方法来关闭这个文件，如果你忘记关闭这个文件，Python将一直占用这个文件的系统资源，直到你的程序完全退出为止，对于一个小脚本来说，这不是什么大事，但是对于一个需要长时间在服务器里运行的程序，你的系统资源可能很快就被吃光，然后你的程序就会崩溃，所以一个好的习惯是使用Python的with语句，将程序改写成这种形式\n\n这样写的话，就不需要手动的调用close()函数了，当with语句之后的代码执行完毕之后，这个文件就会自动被Python关闭\n\n\n"},{"title":"2021 Web开发完全指南","url":"/2022/01/10/2021%20Web%E5%BC%80%E5%8F%91%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/","content":"过去的10年可以说是web技术变革最大，更新迭代最快的10年，如今的web已经不单单是信息展示的渠道，更是各种功能复杂应用的集合，这是一张2021年的web开发路线图\n\n可以看到其中囊括的知识点非常细碎和繁杂，可能也让许多刚接触web开发的小伙伴一头雾水，这里呢，我会从整体的角度出发，用实例向大家解释现代web开发中的各种概念以及它们的最佳学习路线\n那么首先web是如何运作的呢，简单来说，当我们在浏览器中输入网址的时候，浏览器会通过一系列网络操作找到我们要访问的服务器\n\n并向这个服务器发起一个http请求\n\n服务器在收到请求后，会根据请求的类型，将对应的文档返回给浏览器，浏览器会渲染该页面并最终显示在屏幕上，这个页面其实是一个HTML格式的文档\n\n大家可以通过”!”在vscode中快速创建一个HTML文档\n\nHTML文档通常由许多潜逃的标签组成，这些标签决定了我们页面的基本结构，通常一个页面会由头部标签&lt;head&gt;内容标签&lt;body&gt;构成，在````body```下面又可以放置标题、段落、列表、图片、表格、表单等等，你浏览器所做的事情就是去渲染这份HTML文档，并显示在你的电脑屏幕上，现如今，大家看到的绝大多数页面都使用的是HTML5的格式，它除了更加清晰的语法，以及良好的浏览器兼容性之外，还提供原生的音视频格式支持\n\n这也是flash能够逐渐淡出我们视线的原因，当然还有Canvas，WebGL这些图形API的支持，通过它们我们甚至可以在浏览器实现一款画质精良的三维游戏\n\n如果说HTML定义了文档的结构和内容，那css则是用来为页面添加不同的样式风格，也正是它名字“样式表的由来”，为页面添加样式有许多种方法，最简单的我们可以通过在HTML头部加入&lt;style&gt;标签，随后我们可以使用css的选择器(selector)来指定需要修改样式的元素，也就是这里我指定的button对象，后面花括号的每一行允许我们指定边距、边框、字体，背景颜色等等，通过组合css提供的各项属性，我们可以制作出非常漂亮的界面\n\n当然在实际使用中，我们也可以选择现成的css框架帮我们制作专业的跨平台用户界面，除了最广为人知的bootstrap，它可以用来快速实现对移动端友好的响应式布局，你也可以使用Materialize来实现统一的Material界面风格，如果你喜欢轻量级的框架，你还可以尝试只有4KB不到的Pure.css等等，除此之外，css还提供原生的补间动画支持，我们可以利用css的animation属性来定义动画的种类和时长，并利用@keyframes[动画名]{}定义动画中用到的所有关键帧\n\n\n另外值得一提的是css3中加入的新布局方式–FlexBox\n\n使用它可以轻易的实现传统css中很难实现的这些布局效果\n\n比如像导航栏，表单，大小不一的卡片等等\n\n如果说HTML和CSS决定了页面的外观，那JavaScript则允许我们给网页加入动态的行为，比如我们可以通过JavaScript来修改页面的内容，也就是我们平时所得DOM树操作\n或者使用JavaScript对鼠标键盘时间做出相应，JavaScript也可以用于请求远程服务器的数据，也就是我们经常听到的XHR/AJAX技术，它可以根据需要想服务器请求数据，并用来更新页面的部分内容\n\n通过JavaScript，我们甚至可以通过websocket或者webRTC来替代HTTP请求，他们可以用于实现更低延迟的网络通信，比如用作即时聊天，在线游戏等等，由于WdbGL的存在，我们还可以用JavaScript做三维的实时图像渲染，甚至用于在浏览器中训练深度神经网络，现在被主流浏览器支持的JavaScript版本是ES6，里面包含了类\n\n箭头表达式\n\nPromise\n\n模板字符串\n\n变量的解构赋值\n\n新的遍历语法\n\n新的导入导出语法等等，这些都是应当掌握的并且在实际开发中被广泛用到的新特性，另一个与JavaScript相关，虽然不一定马上用到，但是非常值得去了解的是TypeScript，简单来说它为JavaScript中的每一个对象加入了可选的类型标注，是JavaScript语言的一个超集\n\n这样做的好处是能够在编译时做到类型的检查，提前捕捉程序错误\n\n当然这些类型标记也同样给你的IDE提供了额外的类型信息，帮助它完成更好的代码提示和自动补全功能\n\n既然说到JavaScript，我们就不得不提到Node，Node是一个脱离浏览器运行的JavaScript运行时，它使用与Chrome完全一样的v8引擎，性能是相当地不错，你可以使用Node编写控制台程序，原生的桌面应用，服务器程序等等\n\n另外node自带一个包管理器–npm，类似于Python的pip，你可以用它来安装数不胜数的第三方库，这也是Node大获成功的重要原因之一，待会儿我们讲到的React就需要npm来安装，\n按照如今web发展的大趋势，与用户交互的逻辑都逐渐从后端向前端迁移，前端的逻辑通常都非常复杂，为了减轻前端开发的负担，我们往往会选择使用现成的前端界面框架，现在流行的前端界面框架基本是这三种:React、Angular和Vue，这三个框架都会将界面元素组件化，从而提高代码复用，我这里用React来做一个简单的示范\nReact允许我们通过函数式编程的方式来渲染用户界面，这里函数的输入是我们要显示的数据，他们被称为“属性”，或者“状态”\n\n函数的输出则是渲染之后的HTML标签，这样做的好处是渲染的结果会由输入的这些数据唯一决定\n\n也就是大家常说的“单向数据流”模式\n\n这种模式从源头上避免了组件之间数据的复杂传递，因此也更易于调试\n说完了前端，我们来看看后端开发\n也就是服务器的部分，后端其实有相当多的语言和框架可供我们选择，我这里以JavaScript以及Express.js为例来介绍一下后端服务器的部分，因为最近这几年在Web开发中有一个逐渐流行的技术栈–MERN，它代表数据库使用的MongoDB服务端的运行环境Node.js\n前端使用的React，以及后端的服务器框架Express.js\n\n这个技术栈的特点在于它所有的组件全都是使用JavaScript编写的，因此大大降低了开发和维护的成本，后端服务器做的主要事情是响应前端的请求，并向前端提供数据，现代的web应用通常都会通过API的方式与后端进行通信\n\nAPI简单来说就是预先商定好的通信协议或者数据格式，比如这里的这个/aip/zodiac用于返回当前的年份和生肖\n\n如果你在浏览器中手动访问这个地址，服务器会将数据以json格式返回\n\n通过API我们可以实现前后端逻辑的分离\n\n并且如果你的应用同时有安卓，ios客户端的话，也可以复用相同的API\n说到API，我们就不得不提到经典的REST风格的API，简单来说，他会根据不同的HTTP请求类型，来对数据做对应的增删改查操作，这里的jsonplaceholder是一个用于演示的REST API，接下来我们以它为例来快速了解下REST API的基本用法\n\n比如这里我们以GET方法去访问/todos这个地址\n\n服务器会将所有的“待办事项”以json格式返回\n并且我们可以通过在地址后面加上/10指明只需要返回第十条数据\n\n或者像这样传入额外的参数\n\n筛选出userid=5的所有数据，如果我们想添加一条新数据，我们可以使用POST方法去请求同一个地址，并将要添加的数据以json格式发送给服务器\n\n服务器在成功添加数据之后，会将新添加的数据直接返回给浏览器\n\n如果我们要更新某条数据，我们可以使用PATCH方法\n\n同样的如果要删除数据，我们可以使用DELETE方法\n\n顺便值得一提的是这几年逐渐流行的另一种API架构–GraphQL\n\nGraphQL允许使用一种相当灵活的查询语言，来精确获取你需要的数据\n\n它的灵活性和可扩展性会比REST API高出很多，正因为如此，GraphQL非常适合大型项目的API设计，当然如果你的项目只需要简单固定的API，GraphQL就显得有些大材小用了\n接下来我们来了解下数据库管理系统\n如果你的web应用需要对大规模数据进行并发的读取和修改，同时还要兼顾到数据的完整性和安全性，数据库将会是必不可少的一部分，现在的数据库系统大致可以分为两类，SQL和NoSQL类型的数据库\n\nSQL指的是传统的关系型数据库\n\n它使用结构化查询语言(SQL)对数据进行查询和修改\n\n关系型数据库对数据有相当严格的一致性和完整性检查，至今快50年的历史也足以证明它是相当可靠的\n相反，NoSQL的数据库减少了许多的强制检查，通常具有更优的读写性能，并且对数据的格式要求也更加松散，更能够适应日益变化的需求\n\n作为SQL和NoSQL的入门，我非常推荐使用PostgreSQL或者MongoDB，这两个数据库都是开源免费的，并且有相当数量的用户群，这里我以MongoDB为例来介绍下JavaScript中数据库的基本使用，我们可以使用一个叫做mongoose的包对mongoDB进行访问，在使用数据库之前，我们需要先定义数据的结构(Schema)\n\n比如这里的联系人Contact由姓名电话和一些其他信息组成，可以看到name是字符串，并且是必须填写的字段，cteateDate是一个日期对象，它会被自动设置成数据创建时的时间，在定义了数据的结构之后，我们可以利用之前讲到的REST API在POST请求时，我们可以使用new Contact创建一个新的联系人\n\n并使用save方法将数据保存至数据库，最后将新添加的Contact对象以json格式返回\n此时如果我们访问这个REST API，当数据被成功保存之后，可以看到这里返回的新联系人id以及它的创建时间\n\n最后在web开发中还有非常重要的一环，通常我们会听到这么一个词DevOps，它是“开发”和“运维”这两个词的组合\n\n它所解决的问题是如何将你写的web应用部署运行到最终的服务器上并让所有人访问，不过DevOps会通过各种自动化手段让整个部署流程更省事和可靠\n在最后，我想向大家推荐几个web的学习资源，它们都是GitHub上超高星标的仓库\n\nWeb开发路线图：https://github.com/ccloli/developer-roadmap-zh-CN\n现代Web开发魔法全书：https://github.com/dexteryy/spellbook-of-modern-webdev\n成为Web全栈工程师：https://github.com/bmorelli25/Become-A-Full-Stack-Web-Developer\nAwesome列表系列：https://github.com/sindresorhus/awesome\n\n"},{"title":"从0制作树莓派机器人","url":"/2022/01/11/%E4%BB%8E0%E5%88%B6%E4%BD%9C%E6%A0%91%E8%8E%93%E6%B4%BE%E6%9C%BA%E5%99%A8%E4%BA%BA/","content":"大家一定都听说过树莓派，Arduino，单片机，卡片电脑，嵌入式之类的术语\n\n这些到底有什么区别呢，并且我们可以用它们能做出哪些有趣的东西呢，今天我来带大家从零制作一个可以远程控制的树莓派机器人\n\n你可以通过手机远程访问，并实时监测家里的安全，当然除此之外，我们也可以用它来做一些有意识的应用，比如你可以把它当做一个可以人脸追踪的摄像头\n\n在你和亲朋好友的视频聊天中让机器人自动跟随你的视角，让你成为通话的焦点\n树莓派其实是一款单板电脑\n\n它使用的是博通ARM架构的64位处理器，和大家平时使用的智能手机芯片同属于一种架构，上面集成了可以用作图像渲染的GPU，1-4不等的LPDDR(Low Power DDR)内存，以及USB、HDMI、以太网接口等等，它可以运行包括Linux，甚至WIndows在内的多个操作系统，其实完全可以当做一台低配置电脑来使用，这里顺便提一下，经常拿来和树莓派作比较的Arduino其实是一款单板的微处理器，它的用途和功能相比树莓派来说要简单和纯粹许多，Arduino板搭载的基本是Atmel的8位微处理器，主频在16MHZ，速度还远不及树莓派的百分之一，不过这恰恰是Arduino的优点，造价便宜，耗电量低，由于没有操作系统的束缚，也非常适合拿来做一些实性很高的应用，大家如果玩过无人机，应该听说过这款著名的开源飞控(飞行控制器)APM，它就是基于Arduino开发的\n另外我们经常听到的一个术语是单片机，单片机又被称作微控制器，或者MCU(Microcontaoller Unit)它是将处理器，存储器，内存还有各种io端口都集成在芯片内部的电路上，严格意义上Arduino不能被称作是单片机，不过上面搭载的Ateml微控制器是单片机，树莓派上的博通芯片也不能称作单片机，因为他的复杂程度已经远远超过单片机的范畴，相反它被称作“”芯片上系统“，又叫做SOC(System on Chip),这里我使用树莓派作为主控板的主要原因是因为它开发效率高，工具库全，对新手也非常友好\n\n你想想几乎整个Linux生态的软件、工具库都可以拿来使用，它可以做的事情实在是太多了\n接下来我们来看一看机器人上其他硬件的组成\n电机驱动模块\n大家都知道，微处理器上的IO端口通常只能提供非常有限的电流，以树莓派为例，单个GPIO端口只能提供16mA的最大电流，这个电流用来驱动一个发光二极管(LED)绰绰有余，但直流电机的额定电流通常都比它高出一到两个数量级，直接用IO端口驱动电机是根本不可能实现的，且不谈电机换向的问题，这也为什么我们需要使用外部电路来驱动电机的原因，电机的驱动模块有很多种，比如大家经常听到的价格也很便宜的H桥电机驱动芯片L293D\n\n我这里使用的是类似的另一种，导通电阻很低，效率远超L293D的驱动芯片TB6612FNG，\n\n\n主要还是考虑到省电的原因，大家在选择驱动电路时，一定要结合自己的需要，比如你需要同时驱动多少个电机，最大电压和电流是多少，以及芯片待机时的功耗是多少等等，价格最贵的不一定是最合适的\n机器人的电池\n我使用的电池是从旧的移动电源里拆解下来的锂电池，这里的锂电池又叫做聚合物锂离子电池，锂电池的优点有很多: 循环寿命长、重量轻、容量大、并且能量密度高，这也是数码设备无一例外使用锂电池的原因，这里需要注意的是，我们并不能直接将锂电池连接到树莓派和电机驱动电路上\n\n因为锂电池的标称电压是3.7V，而电机驱动电路和树莓派都工作在5V上下，直接连接是不能够驱动设备的，当然这里还有一个原因是，锂电池都非常脆弱，过充和过放都会导致电池的永久损伤甚至是爆炸，因此，锂电池的使用必须搭配额外的保护电路，这里我使用的是一款带开关，支持microUSB充电的锂电池保护电路，它同时支持向两个USB接口输出2.5A的最大电流，刚好符合我们的要求，通常这类保护电路是为移动电源提供的，它们的功能比较单一，价格也很便宜，所以可以很轻松地在网上购买到\n机器人的运动系统\n机器人的运动系统可以分为很多种，有轮式的，履带式的，关节式的，还有仿生机器人式的，我这里使用的是双轮差速的驱动方式，也是在消费领域应用最广泛的，例如，家里的扫地机器人就是这种方式驱动的，它有两个显著的有点:机械构造简单，并且支持原地的旋转\n电机\n电机的部分，我使用的是型号为N20的直流减速电机，减速电机其实就是在普通电机的基础上，加上了齿轮减速箱，在功率恒定的情况下，虽然降低了电机的转速，但是可以提供了较大的力矩，由于我们的机器人使用的都是小功率的配件，并且安装上电池后会有一定的重量，在这种情况下，使用减速电机是非常适合的\n摄像头\n摄像头我使用的是带红外的USB摄像头\n\n这样在弱光或是夜间也可以正常使用，我们在使用USB摄像头的时候只需要看摄像头是否支持UVC(USB Video Class)协议即可，现在市面上已经很少见到不使用UVC协议的摄像头了，所以家里面闲置的摄像头，通常也可以直接拿来在树莓派上使用，当然在树莓派上也可以使用MIPI/CSI接口的摄像头模块\n\n这个接口在移动设备上会被广泛用到\n主要因为它支持更高带宽，更高分辨率图像的传输\n\n操作系统的安装\n首先，必须要准备一张空白的SD卡，当然读写速度越快越好\n\n然后去树莓派官网下载叫做Respbery Pi OS(Lite)的操作系统\n\n这个操作系统是基于Debian的，Debian是使用人数最多的Linux发行版之一，比如大家经常听到的Ubuntu就是基于Debian的，然后我们可以根据官网上提供的步骤，另外再下载一个Raspberry Pi Imager的工具，然后将下载的操作系统映像写入SD卡\n\n写入完毕之后呢，我们只需要将SD卡放回树莓派，接上USB电源启动即可\n\n你可以通过使用外接USB键盘和显示器的方式来使用树莓派，不过这样比较麻烦，因为你还得专门准备一个显示器和键盘，这里我是使用远程操作的方式来使用树莓派的，先让树莓派连接上家里的WiFi，然后用ssh来访问树莓派，ssh(secure shell)在Linux上是一个经常被用到的工具，它是用来和远程服务器通行的一种加密传输协议，在这里呢，我们会利用它从你的PC，Mac或者Linux系统里远程操作你的树莓派\n\n启用ssh的方式其实很简单，在操作系统被写入SD卡之后，先不要着急取下SD卡，我们可以在计算机上找到这个叫做boot的分区\n\n然后新建一个空文件\n\n并命名为ssh就好了，配置WiFi信息的方法也很类似，我们同样在这个分区里面创建一个wpa_supplicant.conf文件，然后把下面这段文字粘贴进去\n\n未完待续，参考自:https://www.bilibili.com/video/BV14g4y1q7yf?spm_id_from=333.999.0.0\n"},{"title":"一个10分钟的numpy入门教程","url":"/2022/01/11/%E4%B8%80%E4%B8%AA10%E5%88%86%E9%92%9F%E7%9A%84numpy%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","content":"如果你打算在Python中做数据分析、科学运算、数据处理，那你多少会用到numpy这个库，当然你肯定还听过pandas、scipy、PIL、amtplolib等等\n\n这些都是科学运算中非常常用的库，不过这些不是我们现在讲的重点，下面我们来看看numpy\nnumpy为我们提供了一个特殊的数组对象\n我们可以用它表示普通的一维数组\n\n或者二维的矩阵，或者任意维的数据\n并且它可以对数组中的数据进行非常高效的运算\n\n比如用作数据统计，图像处理，线性代数，傅里叶变换等等，我们都知道，Python是一个很慢很慢的语言，而numpy之所以能运行这么快的原因，是因为它底层是用C语言实现的目标代码，当然对于任何想要运算的数据，我们也需要预先将它们表示成numpy数组的形式，也就是所谓的向量化，当然如果你希望将运算速度再提升一个数量级，你甚至可以使用你的GPU来对这些数据做并行运算，那么接下来我们就用实例来讲解下numpy的基本使用叭\nnumpy中所有的计算都是围绕着数组进行的，因此在运算之前，我们需要将计算的数据表示成数组的形式，我们首先需要导入numpy这个库\n\n并起一个别名np，然后我们可以用np.array()来创建一个数组\n\n括号中是数组的初始化数据，当然我们也可以使用np.zeros()创建一个全零的数组\n\n这里传入的参数是数组的尺寸，(3, 2)代表一个三行二列的数组，在numpy中，数组可以是一维、二维、甚至是更高维度的\n\n二维数组可以用于存放矩阵或者表格数据，多维数组通常用来表示更加复杂的数据\n在numpy中，我们会用到shage来获取数组的尺寸，比如这里的3，是数组第一维的尺寸，我们可以理解为行数，2是数组的第二维的尺寸，我们可以理解为列的个数\n\n类似的，我们可以使用np.ones()创建一个全部是1的数组\n\n另外我们可以使用np.arange()创建一个递增或递减的数列\n\n类似于Python的range\nnp.linspace()会返回介于某个区间等间距分布的数\n\n前面两个是区间范围，第三个参数是输出样本的总数\n另外我们还可以通过np.random.rand(2, 4)生成一个随机的数组，\n\n在numpy中，数组默认的数据类型是64位的浮点数，不过我们可以在创建数组时，通过dtype指定其他的数据类型\n\n对于现有的数组，我们也可以通过satype()来转换数据类型\n\n在numpy中我们可以轻松地对数组进行常见的数学运算\n两个相同尺寸的数组可以直接进行四则运算\n\n他会将数组同位置的元素进行加减乘除\n在乘法运算中还有一个np.dot()，他会对两个向量进行点乘运算\n另一个 与乘法相关的是@符号，它会进行矩阵的乘法运算，等同于np.matmul()函数，而不是将相对应的元素直接相乘\n\n我们还可以使用np.sqrt对所有数依次求平方根\n\n使用np.sin()，np.cos()进行三角函数运算\n\n或者np.log()，log.power()进行对数和指数运算等等\n\n当然你也可以将一个numpy数组与单独的一个数做运算\n\nnumpy会分别计算各个元素与这个数的乘积，产生一个同尺寸的新数组，这个操作在numpy里面被称作广播\n比较有意思的是，不同尺寸的数组也可以直接做运算\n\n在运算之前，numpy会将这两个数组扩展至相同的尺寸，然后再将相同位置的元素相加\n\n另外，我们还可以通过min()或者max(),返回数组中最小或者最大的元素\n\nargmin()和argmax()会返回最小或者最大元素所在的索引\n\nsum会返回所有数据的总和\n\nmean()，median()会返回数据的平均值，中位数\n\nvar()和std()会返回数据的方差和标准方差\n\n对于以上提到的函数，如果你的数组是多维数组，你还可以指定一个额外的参数axis，当axis等于0时，它会将每一行中对应的数据相加，axis=0代表第一个维度，也就是行\n\n以此类推axis=1则代表第二个维度，也就是列\n\n如果你想要获取数组中的元素，你可以使用与Python list非常相似的语法，比如你要获取第1行第2列的元素，你可以使用下表0和1，中间以逗号分隔\n\n另外，我们还可以通过条件筛选出指定的元素，比如在方括号中输入a&lt;3则会返回所有小于3的元素\n\n我们还可以通过逻辑运算符组合不同的条件，比如下面这个例子将筛选出大于3并且是偶数的数\n\n这里需要注意的是，“与”运算需要用&amp;符号来表示，“或”运算则需要用竖线表示\n如果你要获取的第一行，但是1-2列的数据，你可以使用0:2这种切片的语法，这个和Python的列表是一样的\n\n如果你要获取第一行，但是所有列的元素，你可以单写一个冒号，然后将冒号前后的范围省略掉，当然你也可以直接把整个冒号给省略掉\n\n另外我们可以在冒号的后面再加一个冒号，第二个冒号后面可以跟一个跨度，也就是步长\n\n\n比较有意思的是，这个跨度还可以取负值，我们可以通过复苏的跨度，从右往左逆向返回这个数组，比如在numpy中会经常看到::-1的写法，其实它做的事情就是将数组翻转一下而已\n\n当然说了这么多，光看一堆数字确实也不够直观，不如我们来看一下numpy的一个典型应用图片处理，通常我们可以把一张灰度图看作是一个二维的数组， 数组中的每个元素用来表示像素点的亮度值\n\n\n对于彩色的图片，我们可以用三维数组来表示\n\n数组中的第三维分别存储了像素点的红绿蓝分量\n我们可以使用pillow这个库来读取图片文件\n\n随后我们可以通过np.array(im)将图片转换成一个numpy数组\n可以看到这个图片一共960行，1280列，并且有红绿蓝3个颜色分量，我们可以通过下表来访问某个像素点的颜色\n\n也可以通过这种方式单独提取出所有像素点的红色分量\n\n然后图片就成了这样\n\n我们也可以通过这样的方式将两张图按比例混合在一起，这里需要注意的是，运算的结果是浮点数，为了显示图片，我们需要将图片转换成整型数\n另外我们可以利用之前讲到的跨度来对图片进行降采样，如果我们想要翻转图片，我们可以选跨度-1\n\n这由于我们指定的是第一个维度，因此图片会上下翻转\n\n如果我们想要裁剪图片的某一部分，我们可以利用之前讲到的切片\n\n\n\n"},{"title":"计算机操作系统基础笔记","url":"/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0/","content":"此内容参考自今日头条:https://www.toutiao.com/a7051472133389713933/?log_from=f0ef8adb57f57_1641951133601\n"},{"title":"免费的内网穿透工具推荐(win)","url":"/2022/01/12/%E5%85%8D%E8%B4%B9%E7%9A%84%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90(win)/","content":"此内容参考自今日头条:https://www.toutiao.com/a7028937143393206815/?log_from=27e046c60a8e6_1641951433723\n"},{"title":"TCP/IP网络通信之Socket编程入门","url":"/2022/01/11/TCPIP%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E4%B9%8BSocket%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/","content":"大家好，在这里我会为大家讲解socket的基本工作原理，并用它来实现一个简单的服务器，客户端通信\nsocket是一套用于不同主机间通信的API，它工作在我们的TCP/IP协议栈上，它的应用无处不在，比如你的手机应用、用于服务器管理的ssh客户端\n\n全都是基于socket实现的，要通过socket与不同主机建立通信，我们只需要指定主机的IP地址和一个端口号\n\n显而易见，IP地址用于唯一标识你的网络设备，那我们为甚需要额外指定一个端口号呢\n如果没有端口号，操作系统则没有办法区分数据到底应该发送到哪一个应用上\n\n因此端口主要用于区分主机上的不同应用\n通过socket我们可以建立一条用于不同主机，不同应用之间的虚拟数据通道\n\n并且它是点对点(应用对应用)的\n一个形象的比喻是将一条数据线连接在不同应用的插槽上，这也是socket这个名字的由来\n\n这里不得不吐槽下socket的中文翻译”套接字”到底是什么鬼\n我们经常用到的socket有两种类型，名字你们一定听过，TCP和UDP，TCP是我们今天要讲的重点，它主要有两个特点，首先TCP协议是可靠的，它的底层会自动检测并回传丢失的数据包，因此对调用者来说，你发送的数据，对方一定会接收到\n\n其次，发送和接受到的数据顺序是完全一样的\n\n比如你发送了一串字符，对方就一定会原封不动地收到同一份字符串，这也是为什么大家说TCP是基于“数据流”的协议\n\n另外需要注意的是，TCP要求收发数据的双方扮演不同的角色:服务器和客户端，服务器会被动等待客户端的连接，它自己不会主动发起请求\n\n与TCP相反UDP正如它的名字，以报文(Datagram)为单位来收发数据，并且UDP不会自动回传丢失的数据包，因此不保证数据一定能被对方接收到\n\n正是因为缺少了这些检查，UDP通常具有更低的延迟并占用更少的系统资源，它也更适合像视频通话，这种实时性要求较高的应用\n下面我以Python为例来讲解socket编程的部分，但其实你可以完全使用自己喜欢的编程语言，几乎所有的编程语言都支持socket，除了语法不同，它们的用法都是完全一致的，首先我们来创建一个简单的服务器，这个服务器只做一件事，就是将接受到的消息原封不动地发送回去，\n第一行我们导入socket这个库\n\n然后我们调用socket中的socket()来创建一个socket s\nwith是Python中的一个语法糖，它单纯代表当代码离开with块的时候自动调用s.close()来销毁这个socket\n\n这里我们需要指定两个参数，第一个参数大家直接填写AF_INEF即可\n\n这个代表我们使用的是IPV4的地址家族(address family)\n第二个参数，SOCK_STREAM代表我们使用的是TCP协议，这里的STREAM也正是代表TCP是个“流式”协议，接下里爱的bind()将我们创建的这个socket关联到我们主机的某一个网卡(又:网络接口/network interface)和端口上，网卡我们可以通过IP地址指定，这里我使用的是0.0.0.0这个特殊的地址，它单纯代表你主机上的任意网卡都可以使用socket进行通信\n\n接下来的listen()将socket置为监听状态，并等待客户端的连接，在下面的accept()会接受来自任意客户端的连接，并返回一个新的socket c，以及客户端的IP地址，需要注意的是这个c是一个与之前s不同的socket，socket s主要用于监听，而socket c则用于与连接的客户端进行通信\n\n接下来的这几行代码，我们首先打印客户端的IP地址，然后是一个循环，这个循环会一直调用recv()接收客户端传来的信息，这里的1024代表一次性接收数据的最大长度1024个字节，然后只要数据不为空，我们就原封不动地将代码回传给客户端\n\n接下来，我们来简单测试一下这个服务器程序\n我们先运行代码\n\n然后新开一个窗口，这里我们会用到一个命令行工具netcat，它是Linux下非常常用的网络测试工具，可以用来读写TCP/UDP的数据，当然在windows下你也可以找到它的替代版nmap\n\n我们可以输入nc，后面直接跟上服务器的IP地址，127.0.0.1是一个回送地址(loopback address)\n\n代表本地计算机，再后面的1234是端口号，我们按下回车，可以看到服务器接收到了一个新连接\n\n这里我们随便输入字符串，服务器也会原封不动地返回回来\n\n这一步也验证了服务器代码是没有问题的\n接下来我们继续看看客户端的程序\n客户端的代码非常简单，这里我们用同样的方法创建一个socket s\n\n与服务器不同的是，这里我们直接调用connect()函数，并传入服务器的IP地址和端口号\n\n随后我们调用sendall()函数发送一条消息给服务器，需要注意的是，这里的参数是一个字节序列，并不是字符串，所以千万不要忘记这个b，然后我们调用recv()接受服务器的消息，并将结果打印出来\n\n这里我们新开一个窗口，测试一下客户端的代码，可以看到客户端也成功输出了发送的字符串，然后程序退出，以上我们就讲完了基本服务器和客户端的代码实现，不过这里的服务器有个很大的问题，它只能同时处理一个客户端的请求\n\n要并发地与多个客户端进行通信，这里有几种方法\n我们先来看看最简单的，多线程的服务器\n通过创建线程来响应不同客户端的请求\n首先前面bind和listen的部分和之前的代码完全一样，随后我们写一个循环，然后在循环中不停调用accept()接受来自客户端的连接，为了避免程序的阻塞(block)， 我们直接创建一个新的线程，也就是这里的handle_client()函数，并将客户端的socket c和地址传递给这个线程\n\n然后线程中的代码和之前的完全一样\n\n会不停地回传客户点端发送的信息\n最后我们运行服务器代码，然后新开两个窗口，使用之前讲到的nc命令同时与服务器建立连接，可以看到修改后的服务器可以同时完成这两个客户端的请求\n\n多线程显然能帮我们解决多连接并发的问题，不过它也有自身的局限性，由于GIL的存在，Python中的线程其实做不到真正的并发，并且线程自身也会占用额外的系统资源，除了线程之外，我们还可以使用基于事件驱动的seletors来实现多个连接的并发，或者通过asyncio来实现异步的socket代码\n总结一下:实现一个简单的HTTP服务器，HTTP是TCP协议的一个典型应用，也是浏览器与服务器交互的主要方式，通常服务器会监听80端口，然后等待客户端的连接，客户端在连上服务器以后，首先需要指定要访问的资源，然后客户端会提供一系列额外的信息，每一条都是以冒号分隔的键值对\n\n比如里面包括我们的浏览器的版本等待，这一部分也被称作消息的头部(header)，随后是一个空行，再之后是消息的主体(body)(如果有的话)\n\n服务器在收到消息后，会以同样的格式来响应客户端的请求，首先第一行是一个状态行(status line)，里面包含一个状态码，比如200代表请求成功，404代表请求的资源不存在等等，接着同样是一系列键值对，里面包含了请求资源的类型，服务器信息等等\n\n再后面是一个空行，最后紧跟消息的主体(body)(如果有的话)\n\n在了解了HTTP的基本原理之后，我们可以修改之前的代码来实现这个服务器，首先在handle_client中，我们读取客户端发来的消息，然后我们将消息拆分成一行一行的字符串，存放在header这个列表中，需要注意的是，HTTP标准中定义的换行符是“回车+换行”(CRLF)，这也是我这里用”\\r\\n”来进行字符串分割的原因，接着我们提取出请求的文件名，和一般的web服务器一样，如果客户请求的是根路径，我们则直接返回index.html\n\n随后我们读取文件内容，并返回一个状态号为200的消息\n\n如果请求的文件不存在则直接返回404\n\n最后我们运行代码，并在浏览器中输入本机的IP，可以看到这里成功显示了我本地创建的html测试文件\n\n如果我们去访问其他不存在的文件，则会收到一个错误信息\n这里说一句题外话，其实Python的标准库里已经实现了一个简易的HTTP服务器，它主要用在开发和测试中，调用起来也很方便，大家可以直接输入这个命令使用\npython -m http.server 8000\n\n最后这里附上代码\nsocket_test_server.py\nimport socketwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\ts.bind((&quot;0.0.0.0&quot;, 1235))\ts.listen()\tc, addr = s.accept()\twith c:\t\tprint(addr, &quot;connected.&quot;)\t\twhile True:\t\t\tdata = c.recv(1024)\t\t\tif not data:\t\t\t\tbreak\t\t\tc.sendall(data)\n\nsocket_test_client.py\nimport socketwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\ts.connect((&quot;127.0.0.1&quot;, 1235))\ts.sendall(b&quot;hello lhj&quot;)\tdata = s.recv(1024)\tprint(&quot;Received&quot;, repr(data))\n\n"},{"title":"一次性搞懂线程同步机制","url":"/2022/01/12/%E4%B8%80%E6%AC%A1%E6%80%A7%E6%90%9E%E6%87%82%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/","content":"使用线程，我们可以并发地在各个CPU核心上执行任务，最大化CPU的利用率，但线程也可能导致各种奇怪的资源竞争问题\n\n相信大家一定都看过这个经典案例\n\n用不同的线程去更新同一段内存数据，比如我们这里总共创建10个线程\n\n每个线程累加这个数字1000000次，运行程序你会发现得到的结果并不是预期的10000000，实际显示的数字可能会比它小很多，并且每次输出的结果还都不一样\n\n这里我会向大家解释为什么会出现这种情况，以及各种常见的线程同步机制\n\n我们先来回顾一下刚才的这段程序，其实问题就出在数字累加的这行代码上，虽然在程序中我们简单地写作n++，但是当程序被编译成机器代码时，n++其实被翻译成三条不同的机器指令(machine code)\n\n它们分别是，将内存中的数据加载到CPU的寄存器eax中，然后将eax中的数据+1，最后再将计算结果写回内存，换句话说，这里的n++并不是原子操作(atomic operation)，原子操作指的是不能被继续拆分、或者被其他操作打断的指令，这里顺带解释一下，寄存器(Registers)是CPU内部的小型存储器\n\n用来临时存放计算数据，CPU中的运算都离不开寄存器，它们的容量非常有限，但读写速度会比内存快很多，回到刚才的代码，如果不同的线程按照顺序依次执行\n比如线程A先将数据5读入寄存器，然后+1得到6并写回内存，然后线程B再将数据6读入寄存器，+1得到7并写回内存，这样没有任何问题，但问题在于线程是并发执行的\n\n可能线程A还未将累加后的数据写会内存，线程B就已经开始读取数据到寄存器，这样线程B就会读到修改之前的旧数据，最后的结果是数据只被累加了一次，这个就是我们平时说的线程资源竞争而导致的数据不一致问题，要解决这个问题，我们需要对线程进行同步，也就是让原先异步的操作依次有序地执行，而锁(lock)是我们接下来要讲的第一种，也是最最基本的线程同步机制，它的概念非常简单，在同一时间，只有一个线程可以获得(acquire)锁的拥有权(ownership)，此时其他的线程只能干等着，直到这个锁被持有者释放掉(release)\n\n锁的获取和释放有时候也被叫做上锁(lock)和解锁(unlock)，在不同的语言或者操作系统中，通常会用到不同的锁的实现，比如C++或者Go中的mutex互斥锁\n\n\njava则允许使用synchronized关键字来对某个函数、对象或者代码上锁\n\n当然更底层一些，我们甚至可以调用操作系统的API来实现锁的功能，其他的你可能听过的还包括自旋锁、读写锁等等\n\n总而言之，锁的核心概念是非常简单的\n我们只需要记住在访问共享资源之前上锁，并在结束之后解锁即可\n\n修改运行程序，我们可以看到，这里输出了我们的预期结果10000000，虽然这是一个样例程序，但是频繁加锁和解锁的操作是非常低效的\n\n这样会完全打破线程的并发执行\n其实我们完全可以在线程中创建一个临时变量做计算，然后再将最终的结果累加到全局的共享变量中，这样只有最后一个操作需要同步，而线程的主体仍能并发地执行，另外在使用锁的时候需要格外小心，多个锁的嵌套使用很可能导致线程的死锁(deadlock)现象\n比如这里有两个线程和两把锁\n\n线程1先获取锁1再获取锁2，线程2刚好相反，先获取锁2在获取锁1，如果这俩个线程同时运行，恰好线程q先获取了锁1，然后线程2获取了锁2，然后线程1继续执行，由于锁2被线程2占用，所以线程1会被阻塞，同时由于锁1被线程1占用，所以线程2也会被阻塞\n\n于是线程1和线程2同时被阻塞，也就造成了线程的死锁，这里关键的问题在于上锁的顺序，如果我们让所有线程都按照同样的顺序上锁，其实是可以避免这种情况的，不过实际情况肯恩远比这个复杂，每个线程会用到不同的锁，并且加锁和解锁的操作分散在代码的各个角落，所以另一种做法是，干脆就用单个锁来保护所有的共享资源\n\n并且仅仅在访问资源的时候再去上锁，虽然这么做会损失掉一部分线程的并发性(concurrency)，但好处在于程序的逻辑会更容易维护\n讲到这里，我们顺便提一下部分语言支持的atomic语法修饰，这是一种不使用锁(如果硬件支持)但依然能够解决资源竞争的方法，比如像之前简单的加减操作，在机器内部会直接翻译成硬件支持的原子操作\n\n\n也就说指令已经是不可拆分的最小步骤，因此不需要同步，它的效率通常比使用锁更高\n另外建立在锁之上，线程中还有其它更复杂、更高级的同步机制，比如信号量、条件变量等等，虽然它们也可以用来保护共享资源，但更主要的用途是在线程中传递信号(signaling)，比如使用条件变量，你可以让线程进入等待，直到某个条件成立后再继续执行，这个条件可能是网络资源被成功加载，或者某项数据准备完毕等等\n\n而信号量则更加灵活一点，你可以先让所有的线程进行等待，但在同一时间内，只让特定数量的线程被唤醒\n\n在后面我将再向大家详细解释信号量和条件变量的工作原理，因为它们很容易和锁混淆，但实际用途却完全不一样\n"},{"title":"“并发、并行、异步、同步”的区别","url":"/2022/01/12/%E2%80%9C%E5%B9%B6%E5%8F%91%E3%80%81%E5%B9%B6%E8%A1%8C%E3%80%81%E5%BC%82%E6%AD%A5%E3%80%81%E5%90%8C%E6%AD%A5%E2%80%9D%E7%9A%84%E5%8C%BA%E5%88%AB/","content":"并发、并行、异步、同步，这些术语之间到底有什么区别和联系呢\n\n首先并发是一个比较宽泛的概念，它单纯地代表计算机能够同时执行多项任务\n\n至于计算机怎么做到“并发”则有许多不同的形式，比如对于一个单核处理器，计算机可以通过分配时间片的方式，让一个任务运行一段时间，然后切换另一个任务，再运行一段时间，不同的任务会这样交替往复地一直执行下去，这个过程也被称作是进程或者线程的上下文切换(context switching)\n\n当然对于多核处理器，情况就有所不同了，我们可以在不同的核心上真正并行地执行任务，而不用通过分配时间片的方式运行，这种情况也就是我们所说的并行(parallelism)\n\n至于同步和异步则是两种不同的编程模型，“同步”代表需要等到必须前一个任务执行完毕之后才能进行下一个任务，因此在同步中并没有并发或者并行的概念，而“异步“”则代表不同的任务之间并不会相互等待，也就是说，你在执行任务A的时候，也可以同时运行任务B，一个典型实现异步的方式则是通过多线程编程，你可以创建多个线程，并且启动它们\n\n在多核的情况下，每个线程就会被分配到独立的核心上运行，实现真正的“并行”，当然如果你使用的是单核处理器，或者通过设置亲和力(Affinity)强制将线程绑定到某个核心上，操作系统则会通过分配时间片的方式来执行这些线程，这些线程依然是在“并发”地执行，当然像某些编程语言，比如JavaScript本身是没有多线程的概念的，不过通过它的函数回调(function callback)机制，我们依然能做到单线程的“并发”，比如你可以通过fetch()同时访问多个网络资源\n\n我们在调用fetch()函数的时候，程序并不会等待，而会直接继续执行下去，当获取到网路资源以后\n\n回调函数才会被掉起，需要注意的是，虽然主函数和回调函数看起来是同时进行的\n\n但它们依然是运行在同一个线程中\n\n因此通过这种异步编程方式，我们完全可以做到单线程的“并发”，而且这并不是JavaScript的专利，很多语言也都提供了原生的异步编程方式，比如C#，Rusut，C++2.0中的co_await，Python中的asyncio等等等等\n\n\n\n\n那到这里你肯定会问，对于多线程编程和这种单线程的异步编程，我们应当如何选择呢，简而言之，对于I/O密集型的应用程序，比如Web应用，就会经常执行网络操作，数据库访问，这类应用就非常适合使用异步编程的方式，反之如果我们使用多线程的方式，则会浪费不少的系统资源，因为每个线程的绝大多数时间都是在等待这些I/O操作，而线程自身会占用额外的内存，线程的切换也会有额外的开销，更不用说线程之间的资源竞争问题\n\n而多线程编程则非常适合于计算量密集的应用\n\n比如视频图像处理，科学计算等等，它能让每一个CPU核心发挥最大的功效，而不是消耗在空闲的等待上\n纠错:\n关于Python的例子我举得不太恰当，CPython中的GIL会导致Python代码的线程并不能做到真正并发，使用htop查看CPU使用率尽管在多核处理器也不会超过100%\n"},{"title":"Python实例方法、类方法、静态方法的区别与作用","url":"/2022/01/13/Python%E5%AE%9E%E4%BE%8B%E6%96%B9%E6%B3%95%E3%80%81%E7%B1%BB%E6%96%B9%E6%B3%95%E3%80%81%E9%9D%99%E6%80%81%E6%96%B9%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E4%BD%9C%E7%94%A8/","content":"\n实例方法\n定义: 第一个参数必须是实例对象，该参数名一般约定为“self”，通过它来传递实例的属性和方法(也可以传类的属性和方法)，简而言之，实例方法就是类的实例能够使用的方法\n调用: 只能由实例对象调用\n\n类方法\n定义: 使用装饰器@classmethod。第一个参数必须是当前类对象，该参数名一般约定为“cls”，通过它来传递类的属性和方法(不能传实例的属性和方法)，原则上，类方法是将类本身作为对象进行操作的方法。假设有个方法，且这个方法在逻辑上采用类本身作为对象来调用更合理，那么这个方法就可以定义为类方法。另外，如果需要继承，也可以定义为类方法\n调用: 实例对象和类对象都可以调用\n\n静态方法\n定义: 使用装饰器@staticmethod。参数随意，没有“self”和“cls”参数，但是方法体中不能使用类或实例的任何属性和方法\n调用: 实例对象和类对象都可以调用\n\n\n"},{"title":"软件构建CMake 快速入门","url":"/2022/01/13/%E8%BD%AF%E4%BB%B6%E6%9E%84%E5%BB%BACMake%20%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","content":"今天我们来讲一下软件构建工具，无论你用的是什么平台、什么编程语言，构建(Build)都是软件开发中必不可少的一个步骤\n\n如果你的项目只有一个源文件，我们当然可以用一行命令完成编译、链接的整个过程\n\n但如果你面对的是一个复杂的项目，其中包含不同的模块、组件，每个组件由若干个源文件组成，里面还用到了不少的第三方库\n\n\n这时候如果我们再去手动编译链接，将会非常的低效，而软件构建所做的就是全自动完成代码编译、链接、打包的整个过程，并且还能管理不同组件、甚至包括第三方库的关联，我们平时使用的IDE大多都内置了构建系统，只是我们没有留意罢了\n\n每一个构建工具通常有各自擅长的领域，如果你在VS中做C++开发，那么多半用到的是微软自己的MSBuild\n\n如果你使用Android Stuiod写移动端的程序，那么多半用到的是Gradle等等\n\n当然还有一些更复杂、更万能的构建系统，比如Bazel、BUCK\n\n\n它们试图使用单个工具来完成各种语言在不同环境下的构建，今天我会以CMake为例专门介绍一下C和C++程序的构建\n\n它是一个被广泛使用的、开源免费使用并且完全跨平台的构建工具，如果你希望在不同平台上编译运行你的软件，以后就不再需要手动配置Makefile，vs或者Xcode工程了，我们今天讲到的CMake会自动帮你做到这一切\n 首先我们看看CMake的安装，我们可以直接在官网下载最新的安装包\n\n也可以使用操作系统自带的包管理工具\n\n随后可以试着在命令行中输入CMake命令\n\n这里如果找不到命令的话可能还需要手动配置安装路径到PATH环境变量下\n\n另外我们要确保计算机上安装有C++的编译工具，比如windows下的MSBuild工具链或者直接安装Visual Studio，在Linux下则需要安装gcc或者clang等等，这是因为CMake自身是不带编译工具的，他会根据你编写的构建规则，也就是我们马上要讲道德CMakeLists文件，来自动生成目标平台下的原生工程文件\n\n比如windows下的VS工程或者Linux下的Makefile等等，因此要顺利完成编译，C++工具链是必不可少的，接下来我会从最简单的，只有单个源文件的例子来介绍CMake的基本用法，最后我会用之前视频中创建的一个黑洞渲染的工程，来讲解相对复杂一点的情况，刚好这个工程包含多个源文件、图片资源还会有一些第三方库，因此更加贴近与实际项目一些\n首先我们要做的第一件事是在项目的根目录下创建一个CMakeLists.txt文件，对于一个最简单的、只有一个源文件的工程，这三行代码是必不可少的\n\n首先第一行指定了构建项目所需的最低CMake版本，第二行指定了工程的名字，我们随后输出的可执行文件也会和它同一个名称\n\n第三行表示我们的项目需要构建一个可执行文件，并且它由main.cpp编译而成\n随后我们需要根据这个CMakeList文件生成目标平台下的原生工程，这个过程在CMake中叫做”配置”\n\n我们可以在菜单中找到CMake Configure命令\n\n或者VScode在打开项目时会自动提示你进行项目“配置”\n\n我们只需要选择平台原生的C++构建工具然后等待配置完成即可\n\n\n接下来到了真正构建环节\n这里我们可以使用快捷键F7，或者在菜单中运行CMake: Build命令\n\n如果一切顺利的话，面板中会输出成功编译的可执行文件\n\n\n另外我们所做的“配置”和“构建”操作都有对应的命令行指令，我们也可以在输出面板中找到它们\n\n在通常情况下，使用菜单或者图形界面自然更方便一些，但入股哦我们想在服务器上做持续继承(CI)，进行自动化的编译和测试，这里的命令行就格外有用了\n接下来，我们来看第二个相对复杂一点的工程配置，之前我们讲到这个工程包含了多个源文件、图片资源还有一些第三方库，因此这里的CmakeLists也会相对复杂一些\n\n首先前两行和我们之前讲到的完全一样，它们定义了CMake最低版本和工程文件名，随后映入眼帘的是一系列的find_package()命令，它会在你的计算机中寻找符合要求的第三方库\n\n首先你需要确保计算机中事先安装好了它们\n\n关于库的安装我后面再说\n其次这些库也需要支持用CMake进行构建，这个一般没有问题，因为大多数常见的C++库都提供了CMake的支持，这个命令的第一个参数是各个库的名字，后面的REQUIRED代表这个库是必须的，如果计算机中没有安装则会直接报错\n我们继续来看后面这个命令，由于这个项目由多个源文件组成，所以我们先调用file GLOB命令通过通配符匹配所有的C++源文件，并将它存放在变量SRC_FILE中，随后我们调用相同的add_executable()命令来构建一个可执行文件，第一个参数是工程文件的名字，这里的CMAKE_PROJECT_NAME是一个宏，会被自动替换成这里的工程名Blackhole，第二个禅师则是我们之前匹配的所有源文件\n由于我们项目用到了一些第三方库，所以自然少不了链接(Link)库的操作\n\n如果忘记了这个步骤，那么你应该会遇到经典的符号无法解析的错误\n\n并且由于我们项目用到了C++17以上的语法，所以这里需要通过target_compile_fetures()打开对C++17的支持，最后我们用到这个命令add_custom_command\n\n这里的POST_BUILD也就是字面意思代表编译之后要执行的操作，我们会调用CMake命令将根目录下的assets文件夹拷贝到输出路径下\n\n这一步只是一个简单的自动化，避免了文件的手动复制，这样在构建完成之后我们可以在输出路径下找到应用所需所有文件\n\n在最后我们来讲下C++第三方库的安装\n由于CMake只是一个构建工具，它并不包含库的安装和管理，如果我们的项目用到了第三方库，则需要确保计算机中事先安装好了它们，常见的安装方式有直接下载库的源文件，然后手动构建并指定CMake库的路径，当然对于Linux和mac我们也可以直接通过包管理工具安装，不过缺点是，每安装一个库都需要执行许多繁琐的步骤，并且不同平台下的配置过程也不太一样，因此这里推荐一个微软的开源工具vcpkg\n\n虽然名字叫vcpkg，不过它是一个跨平台的C++库管理工具，类似Python的pip，你要做的是先调用vcpkg install 安装第三方库\n\n然后在CMake构建的时候指定vcpkg工具链即可，如果你用过的是命令行，只需要额外传递一个参数CMAKE_TOOLCHAIN_FILE\n\n如果你用的是vscode插件，那么在设置中添加这个路径即可\n\n关于vcpkg的安装步骤大家可以参考官方详细的文档\nCMake其实是一个非常灵活但也非常复杂的工具，这个最好还是边学边用\n"},{"title":"js混淆-源码乱码题目详解","url":"/2022/01/13/js%E6%B7%B7%E6%B7%86-%E6%BA%90%E7%A0%81%E4%B9%B1%E7%A0%81%E9%A2%98%E7%9B%AE%E8%AF%A6%E8%A7%A3/","content":"我们打开猿人学的刷题网站:https://match.yuanrenxue.com/list\n我们先来看第一题，第一题是关于js混淆的，这题目看着就比较有意思，我们来看看\n首先我们打开一题，然后按F12打开调试，发现这边一打开就有个断点\n\n然后我们可以在设置间隔的函数中把debugger给跳过(右键点击Never pause here)\n\n我们过掉这个debug之后，重新抓下包，可以看到1到3页都是有的\n\n点击第四页就会弹出一个弹窗\n\n可以看到这边有个payload，我们主要要解这m参数\n\n这个参数的话竖线后面是一个时间戳\n"}]